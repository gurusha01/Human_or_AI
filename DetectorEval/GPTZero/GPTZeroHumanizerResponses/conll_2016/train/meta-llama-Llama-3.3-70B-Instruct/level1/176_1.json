{
    "version": "2025-03-13-base",
    "scanId": "211261e2-0781-4d06-9979-571da1ec321c",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9998695850372314,
                    "sentence": "This article provides an overview of Sentence Pair Scoring.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998717308044434,
                    "sentence": "The process of categorizing two sentences according to their semantic likeness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998708963394165,
                    "sentence": "The authors merge assignments like Answer Sentence Selection and Recognizing Textual Entailment into one cohesive framework, alongside introducing yodaqa/large2470 and wqmprop datasets to address current dataset challenges.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999866783618927,
                    "sentence": "The key findings of this study include;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998546838760376,
                    "sentence": "Bringing together tasks, within one framework enables a deeper grasp of the issue of scoring pairs of sentences comprehensively.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998631477355957,
                    "sentence": "Introducing datasets like yodaqa/large2470 and wqmprop that offer a tougher and more authentic assessment environment, for sentence pair scoring models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999898374080658,
                    "sentence": "Demonstrating the possibility of developing models that can score sentence pairs across different tasks through cross task learning transfer.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998288154602051,
                    "sentence": "The key points of this paper are;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998700618743896,
                    "sentence": "The authors offer an examination of the current body of research on evaluating sentence pairs with a focus on the scattered nature of studies in this field and the necessity, for a cohesive framework.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998961687088013,
                    "sentence": "The presentation of datasets and showcasing their impact on assessing the performance of models, for scoring sentence pairs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998568892478943,
                    "sentence": "The writers employ cross task transfer learning to show how universal models that are independent of tasks can be used for scoring sentence pairs effectively.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998679161071777,
                    "sentence": "The paper has shortcomings, namely;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999244213104248,
                    "sentence": "The models created by the authors exhibit results but are not yet at the cutting edge for tasks, like Recognizing Textual Entailment and Semantic Textual Similarity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998918175697327,
                    "sentence": "The paper would improve with a thorough examination of the findings and a consideration of the constraints associated with the models and datasets employed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998645186424255,
                    "sentence": "Some of the ways experiments are conducted could be enhanced by using datasets for adjusting hyperparameters instead of just relying on a single dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998526573181152,
                    "sentence": "Queries, for writers;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997754693031311,
                    "sentence": "How do the writers aim to overcome the constraints of their models, in areas where they fall short compared to the most advanced technologies available?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998514652252197,
                    "sentence": "Could the writers offer information about the datasets they utilized such as their sizes and qualities along with insights, into how they were gathered and prepared?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998380541801453,
                    "sentence": "How do the writers intend to expand their research to include assignments and datasets and what are the possible uses of their study?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999787980622046,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 2.120193779539596e-05,
                        "ai_paraphrased": 0.9999787980622046
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 2.120183779539599e-05,
                            "ai_paraphrased": 0.9999787980622046
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This article provides an overview of Sentence Pair Scoring. The process of categorizing two sentences according to their semantic likeness. The authors merge assignments like Answer Sentence Selection and Recognizing Textual Entailment into one cohesive framework, alongside introducing yodaqa/large2470 and wqmprop datasets to address current dataset challenges. \nThe key findings of this study include; \nBringing together tasks, within one framework enables a deeper grasp of the issue of scoring pairs of sentences comprehensively. \nIntroducing datasets like yodaqa/large2470 and wqmprop that offer a tougher and more authentic assessment environment, for sentence pair scoring models. \nDemonstrating the possibility of developing models that can score sentence pairs across different tasks through cross task learning transfer. \nThe key points of this paper are; \nThe authors offer an examination of the current body of research on evaluating sentence pairs with a focus on the scattered nature of studies in this field and the necessity, for a cohesive framework. \nThe presentation of datasets and showcasing their impact on assessing the performance of models, for scoring sentence pairs. \nThe writers employ cross task transfer learning to show how universal models that are independent of tasks can be used for scoring sentence pairs effectively. \nThe paper has shortcomings, namely; \nThe models created by the authors exhibit results but are not yet at the cutting edge for tasks, like Recognizing Textual Entailment and Semantic Textual Similarity. \nThe paper would improve with a thorough examination of the findings and a consideration of the constraints associated with the models and datasets employed. \nSome of the ways experiments are conducted could be enhanced by using datasets for adjusting hyperparameters instead of just relying on a single dataset. \nQueries, for writers; \nHow do the writers aim to overcome the constraints of their models, in areas where they fall short compared to the most advanced technologies available? \nCould the writers offer information about the datasets they utilized  such as their sizes and qualities  along with insights, into how they were gathered and prepared? \nHow do the writers intend to expand their research to include assignments and datasets and what are the possible uses of their study? "
        }
    ],
    "editorDocumentId": null
}