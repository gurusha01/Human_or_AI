{
    "version": "2025-03-13-base",
    "scanId": "4d17827b-3b3d-4038-9b18-223f104c110f",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999948143959045,
                    "sentence": "This research introduces a method for resolving event coreference without depending on external semantic tools like WordNet or FrameNet that may not work well across different domains of knowledge or contexts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999947547912598,
                    "sentence": "Of relying on those resources the authors use convolutional neural networks (CNNs) to create feature representations for event mentions and their surrounding sentences.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999939203262329,
                    "sentence": "These representations are enhanced with pairwise features to calculate a coreference score.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999945163726807,
                    "sentence": "The model shows performance in comparison, to other models when tested with the ACE 2005 dataset and its extended version (ACE++) proving its effectiveness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999938607215881,
                    "sentence": "The writers also offer an examination of errors in the text and point out difficulties, like figuring out pronouns and inconsistencies in annotations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999916553497314,
                    "sentence": "The key highlights of the paper include;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999925494194031,
                    "sentence": "The suggested two part structure efficiently integrates sentence characteristics, with paired features without relying on semantic references yet still upholds cutting edge effectiveness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999922513961792,
                    "sentence": "Error Review; The writers conduct an examination of errors in the system and highlight major obstacles as well as avenues for future exploration, like resolving pronouns and addressing inconsistencies in annotations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999988853931427,
                    "sentence": "Advantages",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999921917915344,
                    "sentence": "Independence from semantic sources such as WordNet and FrameNet is a key advantage of the model because it allows for easy adaptation to different fields and decreases the need, for expensive domain specific databases.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999920129776001,
                    "sentence": "The model excels in performance according to the standards by delivering strong outcomes, on the ACE 2005 dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999915361404419,
                    "sentence": "Surpassing or equaling previous systems that heavily depend on external features.These findings underscore the effectiveness of the suggested framework.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999924302101135,
                    "sentence": "The paper delves into an examination of errors and provides valuable insights into the difficulties faced in event coreference resolution tasks like pronoun resolution and annotation inconsistencies find depth, in evaluation and point out areas that can be enhanced.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999922513961792,
                    "sentence": "The authors thoroughly assess their models performance, across datasets (ACE and ACE++) and metrics to provide a comprehensive evaluation of its capabilities.They also examine clustering strategies and feature ablations to reinforce the empirical results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999838471412659,
                    "sentence": "Areas of improvement",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999904632568359,
                    "sentence": "There is not much new in the architecture field when it comes to using CNN for extracting features from sentences.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999905228614807,
                    "sentence": "It's a well known approach but lacks novelty.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999904036521912,
                    "sentence": "It would be helpful to delve into why CNN was picked over architectures, like recurrent or transformer based models typically used for sequence modeling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999987781047821,
                    "sentence": "The model faces difficulties, in connecting pronouns to events as mentioned in the error analysis section of the paper without providing clear solutions to tackle this issue effectively.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999856948852539,
                    "sentence": "The paper sometimes mixes its contributions with previous research findings which makes it challenging to identify the unique aspects of the suggested approach clearly outlining what is innovative, versus what is drawn from established methods would enhance the clarity of the presentation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999880790710449,
                    "sentence": "Authors are often posed with inquiries.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999877214431763,
                    "sentence": "Why did they opt for CNN models of other architectures like recurrent or transformer based models, for extracting sentence features and have they looked into these other options?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999695420265198,
                    "sentence": "How well does the model handle cross document event coreference resolution tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999786019325256,
                    "sentence": "Would the suggested architecture work effectively, in similar scenarios?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999737739562988,
                    "sentence": "Have we thought about whether including features at the level of conversation or using trained language models, like BERT could enhance the clarity of pronoun references?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999719262123108,
                    "sentence": "Additional thoughts",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999752640724182,
                    "sentence": "In terms; The paper significantly advances the area of event coreference resolution by showing that you don't always need external semantic tools to achieve excellent results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999766945838928,
                    "sentence": "Howeverᅳimproving pronoun resolution and testing the model with a range of datasets would enhance the study even more.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.9997932945046398,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997932945046398,
                "mixed": 0.00020670549536025372
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997932945046398,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997932945046398,
                    "human": 0,
                    "mixed": 0.00020670549536025372
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999961265411997,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 3.8734588001429155e-06,
                        "ai_paraphrased": 0.9999961265411997
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 3.873358800142946e-06,
                            "ai_paraphrased": 0.9999961265411997
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "\n\nThis research introduces a method for resolving event coreference without depending on external semantic tools like WordNet or FrameNet that may not work well across different domains of knowledge or contexts. Of relying on those resources the authors use convolutional neural networks (CNNs) to create feature representations for event mentions and their surrounding sentences. These representations are enhanced with pairwise features to calculate a coreference score. The model shows performance in comparison, to other models when tested with the ACE 2005 dataset and its extended version (ACE++) proving its effectiveness. The writers also offer an examination of errors in the text and point out difficulties, like figuring out pronouns and inconsistencies in annotations. \nThe key highlights of the paper include; \nThe suggested two part structure efficiently integrates sentence characteristics, with paired features without relying on semantic references yet still upholds cutting edge effectiveness. \n\nError Review; The writers conduct an examination of errors in the system and highlight major obstacles as well as avenues for future exploration, like resolving pronouns and addressing inconsistencies in annotations. \nAdvantages\nIndependence from semantic sources such as WordNet and FrameNet is a key advantage of the model because it allows for easy adaptation to different fields and decreases the need, for expensive domain specific databases. \nThe model excels in performance according to the standards by delivering strong outcomes, on the ACE 2005 dataset. Surpassing or equaling previous systems that heavily depend on external features.These findings underscore the effectiveness of the suggested framework. \nThe paper delves into an examination of errors and provides valuable insights into the difficulties faced in event coreference resolution tasks like pronoun resolution and annotation inconsistencies find depth, in evaluation and point out areas that can be enhanced. \nThe authors thoroughly assess their models performance, across datasets (ACE and ACE++) and metrics to provide a comprehensive evaluation of its capabilities.They also examine clustering strategies and feature ablations to reinforce the empirical results. \nAreas of improvement\nThere is not much new in the architecture field when it comes to using CNN for extracting features from sentences. It's a well known approach but lacks novelty. It would be helpful to delve into why CNN was picked over architectures, like recurrent or transformer based models typically used for sequence modeling. \nThe model faces difficulties, in connecting pronouns to events as mentioned in the error analysis section of the paper without providing clear solutions to tackle this issue effectively. \n\nThe paper sometimes mixes its contributions with previous research findings which makes it challenging to identify the unique aspects of the suggested approach clearly outlining what is innovative, versus what is drawn from established methods would enhance the clarity of the presentation. \nAuthors are often posed with inquiries.\nWhy did they opt for CNN models of other architectures like recurrent or transformer based models, for extracting sentence features and have they looked into these other options? \nHow well does the model handle cross document event coreference resolution tasks. Would the suggested architecture work effectively, in similar scenarios? \nHave we thought about whether including features at the level of conversation or using trained language models, like BERT could enhance the clarity of pronoun references? \nAdditional thoughts\nIn terms; The paper significantly advances the area of event coreference resolution by showing that you don't always need external semantic tools to achieve excellent results. However—improving pronoun resolution and testing the model with a range of datasets would enhance the study even more. "
        }
    ],
    "editorDocumentId": null
}