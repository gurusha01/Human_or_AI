{
    "version": "2025-03-13-base",
    "scanId": "449869b0-49e2-41ff-99d4-9d09b8f99cd3",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999987483024597,
                    "sentence": "Advantages;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982118606567,
                    "sentence": "This document introduces an approach to enhancing existing techniques for creating text representations through vectors by incorporating methods like skipgram with negative sampling and Glove along with other PMI based strategies into the mix.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999978542327881,
                    "sentence": "The shift, from analyzing word co occurrences to focusing on n gram statistics is recognized as adding complexity as it expands both the range of words included in the embeddings and the contextual space they represent.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980330467224,
                    "sentence": "The study effectively tackles this issue by presenting a technique, for calculating ngram embeddings with ngram context in a manner that delivers impressive outcomes on tasks related to similarity and analogy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999983906745911,
                    "sentence": "Areas, for improvement;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999976754188538,
                    "sentence": "One key drawback of the paper is its failure to include experiments showcasing the use of these embeddings in real life scenarios, outside the simulated examples provided which could greatly boost the strength and practical value of the manuscript.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "Lets talk about some topics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999974966049194,
                    "sentence": "Although there are some constraints in place; the paper makes a contribution to the field of study.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999974370002747,
                    "sentence": "The authors have made an addition, to the ACL conference through their exploration of n gram based embedding methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999973773956299,
                    "sentence": "After going through the authors response; it is evident that the research holds promise and could have an impact.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.999993899938166,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 6.100061833876683e-06,
                        "ai_paraphrased": 0.999993899938166
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 6.099961833876713e-06,
                            "ai_paraphrased": 0.999993899938166
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "Advantages; \nThis document introduces an approach to enhancing existing techniques for creating text representations through vectors by incorporating methods like skipgram with negative sampling and Glove along with other PMI based strategies into the mix. The shift, from analyzing word co occurrences to focusing on n gram statistics is recognized as adding complexity as it expands both the range of words included in the embeddings and the contextual space they represent. The study effectively tackles this issue by presenting a technique, for calculating ngram embeddings with ngram context in a manner that delivers impressive outcomes on tasks related to similarity and analogy. \nAreas, for improvement; \nOne key drawback of the paper is its failure to include experiments showcasing the use of these embeddings in real life scenarios, outside the simulated examples provided which could greatly boost the strength and practical value of the manuscript. \nLets talk about some topics.\nAlthough there are some constraints in place; the paper makes a contribution to the field of study. The authors have made an addition, to the ACL conference through their exploration of n gram based embedding methods. After going through the authors response; it is evident that the research holds promise and could have an impact. "
        }
    ],
    "editorDocumentId": null
}