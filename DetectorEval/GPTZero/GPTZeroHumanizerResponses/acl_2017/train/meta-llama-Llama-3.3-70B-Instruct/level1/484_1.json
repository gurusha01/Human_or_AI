{
    "version": "2025-03-13-base",
    "scanId": "36d052ce-0ad3-4d6f-84ed-fe8358856c85",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9821550250053406,
                    "sentence": "In this paper the authors suggest an approach, for automatic speech recognition (ASr).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.988210916519165,
                    "sentence": "They introduce a system that integrates both CTC and attention based methods to improve ASr performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9893104434013367,
                    "sentence": "The researchers suggest a combined learning approach using both CTC and attention based objectives to train an encoder network efficiently harnessing the benefits of both methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9935654997825623,
                    "sentence": "CTC for monotonic alignment and attention, for adaptable alignment.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9939912557601929,
                    "sentence": "The authors have come up with a decoding method that combines CTC and attention probabilities to enhance hypotheses accuracy without relying on traditional search methods, like length penalties and coverage terms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.994198203086853,
                    "sentence": "Cutting edge outcomes in Japanese and Mandarin automatic speech recognition tasks; The new system delivers results that match or exceed the performance of hybrid automatic speech recognition systems on the Corpus of Spontaneous Japanese (CSJ) and HKUST Mandarin Chinese conversational telephone speech recognition (MTS).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9937160611152649,
                    "sentence": "This is achieved without relying on aids, like pronunciation dictionaries and language models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9917949438095093,
                    "sentence": "The paper shines in aspects, such as;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9872994422912598,
                    "sentence": "The combined approach of CTC and attention proves to be highly effective as it successfully tackles the problem of misalignment present, in attention based ASRs while also harnessing the benefits of CTC by ensuring an alignment throughout the process.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.9906752109527588,
                    "sentence": "The new decoding approach removes the requirement, for search methods and enhances the systems overall efficiency.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.1132139265537262,
                    "sentence": "Cutting edge outcomes are obtained by the system showcasing performance on par with or better, than hybrid ASRs in tackling two difficult ASRand tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.09576793760061264,
                    "sentence": "The shortcomings of this document are as follows;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.10869894921779633,
                    "sentence": "The authors could delve deeper into analyzing the combined CTC and attention model by providing a thorough examination of the effects of the hyperparameter λ on the systems performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.12048384547233582,
                    "sentence": "The authors could offer a comparison to various end to end ASRs to improve their analysis further by including systems, with different attention mechanisms or decoding strategies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.11198387295007706,
                    "sentence": "The authors could delve deeper into the intricacies of the system they propose by offering a more thorough analysis of training and decoding times.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.06833988428115845,
                    "sentence": "Authors are often asked the questions;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.08208493143320084,
                    "sentence": "How does the parameter λ impact the effectiveness of the combined CTC and attention model in speech recognition tasks and what value of λ is considered ideal, for ASRs?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.054396167397499084,
                    "sentence": "How well does the suggested system work with speech recognition tasks, like English speech recognition and what difficulties are involved in implementing the system for these tasks?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.05724132061004639,
                    "sentence": "What uses does the suggested system have and how can it be combined with other speech processing systems, like speech synthesis or dialogue systems?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.4691181347565028,
            "class_probabilities": {
                "human": 0.5303295994140208,
                "ai": 0.4691181347565028,
                "mixed": 0.0005522658294763523
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.5303295994140208,
            "confidence_category": "low",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.4691181347565028,
                    "human": 0.5303295994140208,
                    "mixed": 0.0005522658294763523
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly uncertain about this document. The writing style and content are not particularly AI-like.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "In this paper the authors suggest an approach, for automatic speech recognition (ASr). They introduce a system that integrates both CTC and attention based methods to improve ASr performance. \nThe researchers suggest a combined learning approach using both CTC and attention based objectives to train an encoder network efficiently harnessing the benefits of both methods. CTC for monotonic alignment and attention, for adaptable alignment. \nThe authors have come up with a decoding method that combines CTC and attention probabilities to enhance hypotheses accuracy without relying on traditional search methods, like length penalties and coverage terms. \nCutting edge outcomes in Japanese and Mandarin automatic speech recognition tasks; The new system delivers results that match or exceed the performance of hybrid automatic speech recognition systems on the Corpus of Spontaneous Japanese (CSJ) and HKUST Mandarin Chinese conversational telephone speech recognition (MTS). This is achieved without relying on aids, like pronunciation dictionaries and language models. \nThe paper shines in aspects, such as; \nThe combined approach of CTC and attention proves to be highly effective as it successfully tackles the problem of misalignment present, in attention based ASRs while also harnessi​ng the benefits of CTC by ensuring an alignment throughout the process. \nThe new decoding approach removes the requirement, for search methods and enhances the systems overall efficiency. \nCutting edge outcomes are obtained by the system showcasing performance on par with or better, than hybrid ASRs in tackling two difficult ASRand tasks. \nThe shortcomings of this document are as follows; \nThe authors could delve deeper into analyzing the combined CTC and attention model by providing a thorough examination of the effects of the hyperparameter λ on the systems performance. \nThe authors could offer a comparison to various end to end ASRs to improve their analysis further by including systems, with different attention mechanisms or decoding strategies. \nThe authors could delve deeper into the intricacies of the system they propose by offering a more thorough analysis of training and decoding times. \nAuthors are often asked the questions; \nHow does the parameter λ impact the effectiveness of the combined CTC and attention model in speech recognition tasks and what value of λ is considered ideal, for ASRs? \nHow well does the suggested system work with speech recognition tasks, like English speech recognition and what difficulties are involved in implementing the system for these tasks? \nWhat uses does the suggested system have and how can it be combined with other speech processing systems, like speech synthesis or dialogue systems? "
        }
    ],
    "editorDocumentId": null
}