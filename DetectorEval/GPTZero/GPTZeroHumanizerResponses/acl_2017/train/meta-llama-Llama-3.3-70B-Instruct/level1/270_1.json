{
    "version": "2025-03-13-base",
    "scanId": "a41ebd2b-47aa-4d4e-bbda-f9e3cf0e5529",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9916515350341797,
                    "sentence": "The research paper introduces a cutting edge achievement in understanding natural language inferences (NLIs) on the SNLI dataset from Stanford University with an impressive accuracy of 88%.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.990142285823822,
                    "sentence": "The writers suggest an approach, by blending neural models focused on sequences and syntactic trees to grasp both specific and overall inference details effectively in their hybrid model with three key elements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9866120219230652,
                    "sentence": "Input encoding process, local inference modeling phase and inference composition component.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9941694736480713,
                    "sentence": "The writers prove that their upgraded sequential reasoning model (ESIM) performs better than all models even those with more intricate network designs.They also indicate that blending parsing information, with tree LSTMs enhances ESIM and leads to further enhancements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9656236171722412,
                    "sentence": "Primary Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9937726259231567,
                    "sentence": "The authors introduce a sequential inference model called Enhanced Sequential Inference Model (ESIM) that surpasses all existing models in performance even when compared to those, with more intricate network structures.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9912631511688232,
                    "sentence": "The authors show that adding parsing details, with tree LSTMs boosts ESIM and brings about further enhancements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9846064448356628,
                    "sentence": "The authors suggest a neural inference model that merges sequential and syntactic tree based models to grasp local inference details and how they come together.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.958977460861206,
                    "sentence": "Areas of expertise",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9782059788703918,
                    "sentence": "The paper has achieved the results possible on the SNLI dataset by showcasing the effectiveness of the model that was suggested.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9811761379241943,
                    "sentence": "The writers suggest a design that merges sequential and syntactic tree based models in a unique way compared to past methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9833516478538513,
                    "sentence": "The paper thoroughly examines how well the model performs by conducting in depth analysis such, as ablation studies and illustrating attention weights visually.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9898850321769714,
                    "sentence": "Areas, for improvement",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9906386137008667,
                    "sentence": "The model, under consideration is intricate.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9793863892555237,
                    "sentence": "Demands meticulous adjustment of hyperparameters.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9849184155464172,
                    "sentence": "The models effectiveness relies on how the syntax is parsed which can sometimes be inaccurate.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9894342422485352,
                    "sentence": "Limited Interpretability Issue; Understanding the decisions made by the model might prove challenging as they are not easily explained or understood that may lead to confusion regarding why a specific prediction was generated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9896901845932007,
                    "sentence": "Queries, for Writers",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9926846027374268,
                    "sentence": "How do the writers intend to tackle the intricacies of the suggested model and enhance its effectiveness for use, in real world scenarios?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9882567524909973,
                    "sentence": "Could the writers offer information on how the models effectiveness is influenced by the accuracy of syntactic analysis and suggestions, for enhancing parsing precision?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9805161952972412,
                    "sentence": "How do the writers aim to enhance the transparency of the models decisions and offer explanations of the predictions that are easier for humans to understand?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997932945046397,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997932945046397,
                "mixed": 0.00020670549536025372
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997932945046397,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997932945046397,
                    "human": 0,
                    "mixed": 0.00020670549536025372
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999443379991321,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 5.5662000867848724e-05,
                        "ai_paraphrased": 0.9999443379991321
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 5.566190086784875e-05,
                            "ai_paraphrased": 0.9999443379991321
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "\nThe research paper introduces a cutting edge achievement in understanding natural language inferences (NLIs) on the SNLI dataset from Stanford University with an impressive accuracy of 88%. The writers suggest an approach, by blending neural models focused on sequences and syntactic trees to grasp both specific and overall inference details effectively in their hybrid model with three key elements. Input encoding process, local inference modeling phase and inference composition component. The writers prove that their upgraded sequential reasoning model (ESIM) performs better than all models even those with more intricate network designs.They also indicate that blending parsing information, with tree LSTMs enhances ESIM and leads to further enhancements. \nPrimary Contributions\nThe authors introduce a sequential inference model called Enhanced Sequential Inference Model (ESIM) that surpasses all existing models in performance even when compared to those, with more intricate network structures. \nThe authors show that adding parsing details, with tree LSTMs boosts ESIM and brings about further enhancements. \nThe authors suggest a neural inference model that merges sequential and syntactic tree based models to grasp local inference details and how they come together. \nAreas of expertise\nThe paper has achieved the results possible on the SNLI dataset by showcasing the effectiveness of the model that was suggested. \nThe writers suggest a design that merges sequential and syntactic tree based models in a unique way compared to past methods. \nThe paper thoroughly examines how well the model performs by conducting in depth analysis such, as ablation studies and illustrating attention weights visually. \nAreas, for improvement\nThe model, under consideration is intricate. Demands meticulous adjustment of hyperparameters. \nThe models effectiveness relies on how the syntax is parsed which can sometimes be inaccurate. \nLimited Interpretability Issue; Understanding the decisions made by the model might prove challenging as they are not easily explained or understood that may lead to confusion regarding why a specific prediction was generated. \nQueries, for Writers\nHow do the writers intend to tackle the intricacies of the suggested model and enhance its effectiveness for use, in real world scenarios? \nCould the writers offer information on how the models effectiveness is influenced by the accuracy of syntactic analysis and suggestions, for enhancing parsing precision? \nHow do the writers aim to enhance the transparency of the models decisions and offer explanations of the predictions that are easier for humans to understand? "
        }
    ],
    "editorDocumentId": null
}