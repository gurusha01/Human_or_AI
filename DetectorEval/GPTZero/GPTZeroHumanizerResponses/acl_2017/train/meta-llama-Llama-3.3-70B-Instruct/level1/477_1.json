{
    "version": "2025-03-13-base",
    "scanId": "0188656d-1348-4011-8ac9-9701fb23b95a",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9995211362838745,
                    "sentence": "This study provides an analysis of different word representation models that take into account varying degrees of understanding morphological structures in languages, with diverse morphological characteristics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994173645973206,
                    "sentence": "The researchers examined ten models by changing the subword units (characters like trigrams and morphemes) as well as the composition functions (addition and bi LSTMs with CNN) to find out the most efficient combination, for language modeling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999270498752594,
                    "sentence": "The authors conduct tests on ten languages that represent a variety of structures (fusion based agglutinative, root and pattern based and reduplication) to evaluate the performance of various models, across different languages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987873435020447,
                    "sentence": "The authors examine how character based models understand patterns and how they work in various types of languages with different structures.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986915588378906,
                    "sentence": "The paper excels, in the following aspects;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.998850405216217,
                    "sentence": "The writers employ a variety of languages and datasets to gain an insight into how different models perform in various linguistic contexts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.998859703540802,
                    "sentence": "The authors conduct an assessment of the findings by exploring the closest words to those that are repeated in reduplication form to understand how the models grasp morphological patterns.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990800619125366,
                    "sentence": "The drawbacks of this document include;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999004602432251,
                    "sentence": "The authors analysis of the results was thorough.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990246891975403,
                    "sentence": "Could have gone further in exploring the implications of the findings and understanding why there were performance variations, among the models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992669820785522,
                    "sentence": "The authors missed out on talking about the drawbacks of the models and the possible biases, in the datasets that might have influenced the outcomes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999098539352417,
                    "sentence": "The authors fail to offer a conclusion regarding the optimal model or the ideal mix of subword units and composition functionsᅳa point that could have been beneficial, for practitioners.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984906911849976,
                    "sentence": "Questions, for writers;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988596439361572,
                    "sentence": "How do the writers intend to tackle the constraints of the models and the possible biases, in the datasets in their work?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988966584205627,
                    "sentence": "Could the writers offer explanations, on the qualitative evaluation of the findings related to the closest matches of repeated words?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999082088470459,
                    "sentence": "What do the authors believe would be the impact on the outcomes if they decided to employ an alternate assessment measure, like accuracy or F measure of perplexity?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9999999999999999,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9999999999999999,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9999999999999999,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9999999999999999,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999810407289141,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 1.8959271085863368e-05,
                        "ai_paraphrased": 0.9999810407289141
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 1.8959171085863398e-05,
                            "ai_paraphrased": 0.9999810407289141
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This study provides an analysis of different word representation models that take into account varying degrees of understanding morphological structures in languages, with diverse morphological characteristics. \nThe researchers examined ten models by changing the subword units (characters like trigrams and morphemes) as well as the composition functions (addition and bi LSTMs with CNN) to find out the most efficient combination, for language modeling. \nThe authors conduct tests on ten languages that represent a variety of structures (fusion based agglutinative, root and pattern based and reduplication) to evaluate the performance of various models, across different languages. \nThe authors examine how character based models understand patterns and how they work in various types of languages with different structures. \nThe paper excels, in the following aspects; \n\nThe writers employ a variety of languages and datasets to gain an insight into how different models perform in various linguistic contexts. \nThe authors conduct an assessment of the findings by exploring the closest words to those that are repeated in reduplication form to understand how the models grasp morphological patterns. \nThe drawbacks of this document include; \n The authors analysis of the results was thorough. Could have gone further in exploring the implications of the findings and understanding why there were performance variations, among the models. \nThe authors missed out on talking about the drawbacks of the models and the possible biases, in the datasets that might have influenced the outcomes. \nThe authors fail to offer a conclusion regarding the optimal model or the ideal mix of subword units and composition functions—a point that could have been beneficial, for practitioners. \nQuestions, for writers; \nHow do the writers intend to tackle the constraints of the models and the possible biases, in the datasets in their work? \nCould the writers offer explanations, on the qualitative evaluation of the findings related to the closest matches of repeated words? \nWhat do the authors believe would be the impact on the outcomes if they decided to employ an alternate assessment measure, like accuracy or F measure of perplexity? "
        }
    ],
    "editorDocumentId": null
}