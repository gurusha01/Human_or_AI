{
    "version": "2025-03-13-base",
    "scanId": "c7f053c8-d285-496c-8254-3547ecf1d0c9",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9993048906326294,
                    "sentence": "This study introduces a LDA based approach called segLDACop that creates cohesive document segments by simultaneously segmenting documents and assigning topics to their content words using specific topic distributions for each segment and a copula to link the topics with the words, within a segment.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993073344230652,
                    "sentence": "The primary achievements of this study include;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992972612380981,
                    "sentence": "The model segments documents and assigns topics to words in a manner to enable more flexible and natural topic assignments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994363188743591,
                    "sentence": "The model utilizes Franks copula to connect the topics linked with the words, in a segment to maintain topic coherence.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995237588882446,
                    "sentence": "The system depends on topic distributions that're specific to both the document and its segments to accommodate nuanced variations, in topic assignments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994993209838867,
                    "sentence": "The highlights of this paper include;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993155598640442,
                    "sentence": "The model shows results, than other advanced LDA based models in terms of perplexity across six publicly accessible datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994287490844727,
                    "sentence": "1. Improved topic consistency is evident, in the models output based on the Normalized Pointwise Mutual Information (PMWNI).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993632435798645,
                    "sentence": "Achieving performance in text classification tasks is evident, in the models enhanced results based on the Micro F score.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995567202568054,
                    "sentence": "The shortcomings of this document include;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993239045143127,
                    "sentence": "The computational intricacy lies in the fact that the models deduction phase could require an amount of computational resources mainly because of employing Gibbs sampling and determining probabilities based on copulas.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995056390762329,
                    "sentence": "Hyperparameter adjustment is a step, in optimizing the models performance as it involves fine tuning various parameters that can be quite time consuming and demand substantial computational resources.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992830753326416,
                    "sentence": "The limited interpretability arises from the complexity introduced by copulas, segmentation and topic assignment making it difficult to grasp the outcomes and comprehend the connections, between topics and segments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9989233613014221,
                    "sentence": "Queries, for writers;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988874197006226,
                    "sentence": "How do the writers intend to tackle the intricacies involved in the models inference procedure?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992680549621582,
                    "sentence": "Could the writers offer details, on how they fine tuned the hyperparameters and how the models performance was affected by varying hyperparameter configurations?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9992485642433167,
                    "sentence": "How do the authors intend to enhance the clarity of the models outcomes by focusing on comprehension of the connections, between subjects and sections?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997932945046397,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997932945046397,
                "mixed": 0.00020670549536025372
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997932945046397,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997932945046397,
                    "human": 0,
                    "mixed": 0.00020670549536025372
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999652305265169,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 3.476947348315386e-05,
                        "ai_paraphrased": 0.9999652305265169
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 3.476937348315389e-05,
                            "ai_paraphrased": 0.9999652305265169
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This study introduces a LDA based approach called segLDACop that creates cohesive document segments by simultaneously segmenting documents and assigning topics to their content words using specific topic distributions for each segment and a copula to link the topics with the words, within a segment. \nThe primary achievements of this study include; \nThe model segments documents and assigns topics to words in a manner to enable more flexible and natural topic assignments. \nThe model utilizes Franks copula to connect the topics linked with the words, in a segment to maintain topic coherence. \nThe system depends on topic distributions that're specific to both the document and its segments to accommodate nuanced variations, in topic assignments. \nThe highlights of this paper include; \nThe model shows results, than other advanced LDA based models in terms of perplexity across six publicly accessible datasets. \n1. Improved topic consistency is evident, in the models output based on the Normalized Pointwise Mutual Information (PMWNI).\nAchieving performance in text classification tasks is evident, in the models enhanced results based on the Micro F score. \nThe shortcomings of this document include; \nThe computational intricacy lies in the fact that the models deduction phase could require an amount of computational resources mainly because of employing Gibbs sampling and determining probabilities based on copulas. \nHyperparameter adjustment is a step, in optimizing the models performance as it involves fine tuning various parameters that can be quite time consuming and demand substantial computational resources. \nThe limited interpretability arises from the complexity introduced by copulas, segmentation and topic assignment making it difficult to grasp the outcomes and comprehend the connections, between topics and segments. \nQueries, for writers; \nHow do the writers intend to tackle the intricacies involved in the models inference procedure? \nCould the writers offer details, on how they fine tuned the hyperparameters and how the models performance was affected by varying hyperparameter configurations? \nHow do the authors intend to enhance the clarity of the models outcomes by focusing on comprehension of the connections, between subjects and sections? "
        }
    ],
    "editorDocumentId": null
}