{
    "version": "2025-03-13-base",
    "scanId": "d49fdb14-4664-4be6-82bf-bb2bd6f6396b",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "Reflection, on the Document",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "In brief here's the overview.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999993443489075,
                    "sentence": "This study delves into the aspects of how word embeddings are structured when trained with the Skip Gram model (SG).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999991655349731,
                    "sentence": "The authors introduce a framework for additive compositionality and prove that the SG model showcases this property more rigorously than previously believed under certain conditions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999990463256836,
                    "sentence": "They also draw a correlation, between the SG model and the Sufficient Dimensionality Reduction (SDR) indicating that SG embeddings are optimally designed from an information standpoint given particular circumstances.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999991059303284,
                    "sentence": "The study also pinpoints the combination operator, for situations where additive compositionality is not applicable and clarifies how linear compositionality aids in resolving word analogies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999985098838806,
                    "sentence": "Key Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998927116394,
                    "sentence": "The paper convincingly demonstrates that when certain conditions are met additive compositionality in word embeddings holds true and introduces a stringent concept (short distance instead of narrow angle).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998927116394,
                    "sentence": "This represents a step forward, in comprehending the mathematical characteristics of word embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999990463256836,
                    "sentence": "The authors suggest that Skip Gram embeddings can be converted into Sparse Distributed Representations (SDR) embeddings by integrating information about word patterns.This finding is innovative.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "Shows that Skip Gram embeddings excel at retaining shared information despite potential inaccuracies, in the Skip Gram model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999989867210388,
                    "sentence": "The paper discusses the composition operator for situations where simple vector addition does not apply, offering insights, on how compositionality can be expanded beyond basic additive methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982118606567,
                    "sentence": "Areas of expertise",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998927116394,
                    "sentence": "The paper presents mathematical evidence to support its arguments and establishes a firm theoretical groundwork for the identified compositional aspects, in SG embeddings.Its findings are well founded and shed light upon a primarily empirical phenomenon.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "Fresh perspectives on Skip Gram model have been revealed in a light by establishing a link, with SDR models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999987483024597,
                    "sentence": "A noteworthy advancement that links two crucial frameworks in the realms of machine learning and information theory.This finding holds significance in enhancing embedding models and their real world applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999995768070221,
                    "sentence": "The practical implications of word analogies are clear when considering how linear compositionality allows for solving them in an theoretically sound manner shedding light on why SG embeddings excel at analogy tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999954700469971,
                    "sentence": "The paper is nicely written with defined terms and clear explanations of theorems and proofs.The authors also thoughtfully discuss issues, like the constraints of assuming uniformity throughout.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999936819076538,
                    "sentence": "Areas of improvement.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999995768070221,
                    "sentence": "The paper has theoretical contributions but could benefit from empirical experiments demonstrating the practical implications of the nonlinear composition operator and its connection with SDR models in real world datasets, for added strength.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999969601631165,
                    "sentence": "Assumptions about word frequency being consistent are helpful, for understanding linear compositionality.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999969601631165,
                    "sentence": "Often do not hold true in real world language data sets.The authors recognize this limitation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967217445374,
                    "sentence": "Do not delve into other methods to tackle the issue.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967217445374,
                    "sentence": "The mention of SDR models is interesting, in this context; however the paper lacks instances or tests showcasing how this connection can be utilized in real world scenarios which hinders the direct use of the findings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999954104423523,
                    "sentence": "Queries, for Writers",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967217445374,
                    "sentence": "Have you tested out the nonlinear composition operator, in real world experiments to see how it stacks up against the traditional additive compositionality approach?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999968409538269,
                    "sentence": "Is there a way we can use the relationship between SG and SDR models for enhancing the training process or boosting the performance of SG embeddings, in fields where this connection proves especially advantageous?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999971985816956,
                    "sentence": "How much do your results change when you don't follow the assumption of uniformity enough Have you considered other assumptions, like Zipfed distributions and how they might give you similar insights?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999966025352478,
                    "sentence": "Additional thoughts",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999968409538269,
                    "sentence": "This paper provides theoretical insights into how word embeddings exhibit compositionality and the connection, between SG and SDR models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960064888,
                    "sentence": "However its significance could be bolstered through verification and real world applications of the suggested insights.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999966700608244,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 3.329939175578726e-06,
                        "ai_paraphrased": 0.9999966700608244
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 3.329839175578756e-06,
                            "ai_paraphrased": 0.9999966700608244
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "Reflection, on the Document\nIn brief here's the overview.\nThis study delves into the aspects of how word embeddings are structured when trained with the Skip Gram model (SG). The authors introduce a framework for additive compositionality and prove that the SG model showcases this property more rigorously than previously believed under certain conditions. They also draw a correlation, between the SG model and the Sufficient Dimensionality Reduction (SDR) indicating that SG embeddings are optimally designed from an information standpoint given particular circumstances. The study also pinpoints the combination operator, for situations where additive compositionality is not applicable and clarifies how linear compositionality aids in resolving word analogies. \nKey Contributions\nThe paper convincingly demonstrates that when certain conditions are met additive compositionality in word embeddings holds true and introduces a stringent concept (short distance instead of narrow angle). This represents a step forward, in comprehending the mathematical characteristics of word embeddings. \nThe authors suggest that Skip Gram embeddings can be converted into Sparse Distributed Representations (SDR) embeddings by integrating information about word patterns.This finding is innovative. Shows that Skip Gram embeddings excel at retaining shared information despite potential inaccuracies, in the Skip Gram model. \nThe paper discusses the composition operator for situations where simple vector addition does not apply, offering insights, on how compositionality can be expanded beyond basic additive methods. \nAreas of expertise\nThe paper presents mathematical evidence to support its arguments and establishes a firm theoretical groundwork for the identified compositional aspects, in SG embeddings.Its findings are well founded and shed light upon a primarily empirical phenomenon. \nFresh perspectives on Skip Gram model have been revealed in a light by establishing a link, with SDR models. A noteworthy advancement that links two crucial frameworks in the realms of machine learning and information theory.This finding holds significance in enhancing embedding models and their real world applications. \nThe practical implications of word analogies are clear when considering how linear compositionality allows for solving them in an theoretically sound manner shedding light on why SG embeddings excel at analogy tasks. \nThe paper is nicely written with defined terms and clear explanations of theorems and proofs.The authors also thoughtfully discuss issues, like the constraints of assuming uniformity throughout. \nAreas of improvement.\nThe paper has theoretical contributions but could benefit from empirical experiments demonstrating the practical implications of the nonlinear composition operator and its connection with SDR models in real world datasets, for added strength. \nAssumptions about word frequency being consistent are helpful, for understanding linear compositionality. Often do not hold true in real world language data sets.The authors recognize this limitation. Do not delve into other methods to tackle the issue. \nThe mention of SDR models is interesting, in this context; however the paper lacks instances or tests showcasing how this connection can be utilized in real world scenarios which hinders the direct use of the findings. \nQueries, for Writers \nHave you tested out the nonlinear composition operator, in real world experiments to see how it stacks up against the traditional additive compositionality approach? \nIs there a way we can use the relationship between SG and SDR models for enhancing the training process or boosting the performance of SG embeddings, in fields where this connection proves especially advantageous? \nHow much do your results change when you don't follow the assumption of uniformity enough Have you considered other assumptions, like Zipfed distributions and how they might give you similar insights? \nAdditional thoughts \nThis paper provides theoretical insights into how word embeddings exhibit compositionality and the connection, between SG and SDR models. However its significance could be bolstered through verification and real world applications of the suggested insights. "
        }
    ],
    "editorDocumentId": null
}