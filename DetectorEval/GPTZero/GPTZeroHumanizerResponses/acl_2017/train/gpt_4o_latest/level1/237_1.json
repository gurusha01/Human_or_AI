{
    "version": "2025-03-13-base",
    "scanId": "78abcfd8-cf60-44d7-92c0-cc6f9519e0cc",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999979734420776,
                    "sentence": "Lets take a look, at it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958872795105,
                    "sentence": "Contributions",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980926513672,
                    "sentence": "This research suggests a way to gauge the emotional tone of words using vector space models (VSMs) both in unsupervised and semi supervised scenarios.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980330467224,
                    "sentence": "The authors create dimensions within complex vector spaces and deduce word polarities based on cosine distances, from reference vectors.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998152256012,
                    "sentence": "The proposed techniques are tested against the PMI.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999975562095642,
                    "sentence": "IR algorithm (Turney 2002) showing results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999975562095642,
                    "sentence": "Additionally the study compares the efficiency of two embedding modelsᅳ Word2Vec and GloVeᅳ for sentiment analysis tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999968409538269,
                    "sentence": "The main achievements of this study include;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999973177909851,
                    "sentence": "The paper introduces an approach by using dimensionality reduction (PCA) to discover a sentiment axis within complex word embeddings and determine the sentiment orientation of individual words accurately.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999954104423523,
                    "sentence": "Comparative analysis of semi supervised methods in action!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999971389770508,
                    "sentence": "The research delves into how unsupervised and semi supervised techniques work and finds that the semi supervised Word Embedding model tops the charts with a 66% accuracy rate, in sentiment analysis tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999966025352478,
                    "sentence": "The suggested techniques excel in addressing the issue of available information compared to PMl lR and GloVe when it comes to collocation based sentiment analysis by utilizing dense vector modeling like WordZVec.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967217445374,
                    "sentence": "Advantages",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999969005584717,
                    "sentence": "Approach; Introducing a sentiment aspect, into vector space models is an original and well founded strategy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999972581863403,
                    "sentence": "The authors utilize PCA to extract sentiment details from word embeddings in a manner.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999971985816956,
                    "sentence": "The study thoroughly assesses its approaches by comparing them to a recognized benchmark (PMl lR) and, across two different embedding models (WordZVec and GloVe).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999964833259583,
                    "sentence": "The findings are comprehensively detailed with understandable visual aids and statistical relationships.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999968409538269,
                    "sentence": "The suggested approaches have been proven to require data and handle sparsity better than PMIR methods do.This makes them appropriate, for practical use cases where there may be a lack of labeled data or extensive collections of text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960660934448,
                    "sentence": "Reproducibility is strengthened by the authors thorough explanations of their configuration such, as datasets used and evaluation measures employed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963045120239,
                    "sentence": "Areas of improvement",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999968409538269,
                    "sentence": "The suggested techniques show results than PMT.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999968409538269,
                    "sentence": "IR but their classification accuracy is lower (, up to 66%) compared to top notch supervised models that usually reach above 80%.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999969005584717,
                    "sentence": "This hinders the effectiveness of the approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999978542327881,
                    "sentence": "Building reference vectors using vector averaging may not capture the sentiment domain effectively according to the authors, who acknowledge this limitation without delving into alternative strategies extensively.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979138374329,
                    "sentence": "The research only focuses its testing within movie review datasets, like IMDB and Stanford Sentiment Treebank without exploring how well the techniques could be applied to domains or languages outside of this scope which might impact their overall usefulness in a wider context.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999974966049194,
                    "sentence": "The paper mentions that GloVe performs effectively than Word to Vec but fails to delve deeply into the reasons, behind this besides hinting at potential limitations based on collocations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933242797852,
                    "sentence": "Queries, for Writers",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999970197677612,
                    "sentence": "Have you thought about trying approaches to create reference points that better capture the emotional tone of a text by using methods, like supervised learning adjustments or categorization techniques?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "How do you think your techniques would work on types of data sets such as product reviews or social media posts, from different languages besides English?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999974370002747,
                    "sentence": "Can you share details, on why GloVe consistently falls short in performance when compared to Word@vec?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999968409538269,
                    "sentence": "Are there attributes of the embedding models that can clarify this difference?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958872795105,
                    "sentence": "Further Thoughts",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980926513672,
                    "sentence": "In terms this document outlines a hopeful path for sentiment analysis without supervision or with partial supervision using vector space models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999973177909851,
                    "sentence": "Although the outcomes are not as good as those of supervised methods the techniques introduced are creative and tackle important issues such, as sparse data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999973177909851,
                    "sentence": "Delving deeper into constructing reference vectors and generalizing across domains could greatly boost the effectiveness of this research.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.9000234362273952
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 27,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 31,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 32,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 0.9997938739332978,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997938739332978,
                "mixed": 0.00020612606670239523
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997938739332978,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997938739332978,
                    "human": 0,
                    "mixed": 0.00020612606670239523
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999792629550405,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 2.0737044959484095e-05,
                        "ai_paraphrased": 0.9999792629550405
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 2.0736944959484125e-05,
                            "ai_paraphrased": 0.9999792629550405
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "Lets take a look, at it.\nContributions\nThis research suggests a way to gauge the emotional tone of words using vector space models (VSMs) both in unsupervised and semi supervised scenarios. The authors create dimensions within complex vector spaces and deduce word polarities based on cosine distances, from reference vectors. The proposed techniques are tested against the PMI. IR algorithm (Turney 2002) showing results. Additionally the study compares the efficiency of two embedding models— Word2Vec and GloVe— for sentiment analysis tasks. The main achievements of this study include; \nThe paper introduces an approach by using dimensionality reduction (PCA) to discover a sentiment axis within complex word embeddings and determine the sentiment orientation of individual words accurately. \nComparative analysis of semi supervised methods in action! The research delves into how unsupervised and semi supervised techniques work and finds that the semi supervised Word Embedding model tops the charts with a 66% accuracy rate, in sentiment analysis tasks. \nThe suggested techniques excel in addressing the issue of available information compared to PMl lR and GloVe when it comes to collocation based sentiment analysis by utilizing dense vector modeling like WordZVec. \nAdvantages\nApproach; Introducing a sentiment aspect, into vector space models is an original and well founded strategy. The authors utilize PCA to extract sentiment details from word embeddings in a manner. \nThe study thoroughly assesses its approaches by comparing them to a recognized benchmark (PMl lR) and, across two different embedding models (WordZVec and GloVe). The findings are comprehensively detailed with understandable visual aids and statistical relationships. \nThe suggested approaches have been proven to require data and handle sparsity better than PMIR methods do.This makes them appropriate, for practical use cases where there may be a lack of labeled data or extensive collections of text. \nReproducibility is strengthened by the authors thorough explanations of their configuration such, as datasets used and evaluation measures employed. \nAreas of improvement\nThe suggested techniques show results than PMT. IR but their classification accuracy is lower (, up to 66%) compared to top notch supervised models that usually reach above 80%. This hinders the effectiveness of the approach. \nBuilding reference vectors using vector averaging may not capture the sentiment domain effectively according to the authors, who acknowledge this limitation without delving into alternative strategies extensively. \nThe research only focuses its testing within movie review datasets, like IMDB and Stanford Sentiment Treebank without exploring how well the techniques could be applied to domains or languages outside of this scope which might impact their overall usefulness in a wider context. \nThe paper mentions that GloVe performs effectively than Word to Vec but fails to delve deeply into the reasons, behind this besides hinting at potential limitations based on collocations. \nQueries, for Writers \nHave you thought about trying approaches to create reference points that better capture the emotional tone of a text by using methods, like supervised learning adjustments or categorization techniques? \nHow do you think your techniques would work on types of data sets such as product reviews or social media posts, from different languages besides English? \nCan you share details, on why GloVe consistently falls short in performance when compared to Word@vec ? Are there attributes of the embedding models that can clarify this difference? \nFurther Thoughts \nIn terms this document outlines a hopeful path for sentiment analysis without supervision or with partial supervision using vector space models. Although the outcomes are not as good as those of supervised methods the techniques introduced are creative and tackle important issues such, as sparse data. Delving deeper into constructing reference vectors and generalizing across domains could greatly boost the effectiveness of this research. "
        }
    ],
    "editorDocumentId": null
}