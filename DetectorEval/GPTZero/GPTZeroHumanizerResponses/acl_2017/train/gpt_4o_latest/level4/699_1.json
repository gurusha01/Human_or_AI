{
    "version": "2025-03-13-base",
    "scanId": "9c997b94-37ce-4995-9554-a1844c2ad032",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999915361404419,
                    "sentence": "This study presents a framework for generating keyphrases using an encoder decoder approach with results showing that the model outperforms methods in cases where there is labeled data, for training purposes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999926090240479,
                    "sentence": "\"Advantages;\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999898672103882,
                    "sentence": "The document is nicely.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999918341636658,
                    "sentence": "Clear in its explanations of the methods underlying principles.It gives information to make it easy to replicate the experiments.The use of an encoder decoder framework with a copy function may seem simple.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999901056289673,
                    "sentence": "The results, from the experiments are persuasive and support the papers assertion about generating missing key phrases.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999903440475464,
                    "sentence": "Shortcomings;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99998939037323,
                    "sentence": "The suggested method mentioned previously isn't particularly innovative and falls short in providing generalization to new areas as highlighted in Section 5 point 3 of the discussion section; it performs below par compared to unsupervised models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999985933303833,
                    "sentence": "Even though one of the aspects highlighted in this paper is the importance of having a substantial amount and high quality training data sets available, for use; this specific point is not explicitly given much emphasis.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999455809593201,
                    "sentence": "Lets talk about this topic in general.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999876856803894,
                    "sentence": "The paper was a read.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999104142189026,
                    "sentence": "I hope it gets accepted!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999470114707947,
                    "sentence": "I'm interested in how the training datas size and variety affect the methods performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999450445175171,
                    "sentence": "It would also be great to have the values of pg and pc (with examples from Figure 1) included in the CopyRNN model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999476671218872,
                    "sentence": "In my past work, with CopyNet, sometimes the copying mechanism acts strangely and its not clear why that happens.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                }
            ],
            "completely_generated_prob": 0.9997938739332978,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997938739332978,
                "mixed": 0.00020612606670239523
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997938739332978,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997938739332978,
                    "human": 0,
                    "mixed": 0.00020612606670239523
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999965892401012,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 3.4107598987374587e-06,
                        "ai_paraphrased": 0.9999965892401012
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 3.4106598987374885e-06,
                            "ai_paraphrased": 0.9999965892401012
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This study presents a framework for generating keyphrases using an encoder decoder approach with results showing that the model outperforms methods in cases where there is labeled data, for training purposes. \n\"Advantages;\"  \nThe document is nicely. Clear in its explanations of the methods underlying principles.It gives information to make it easy to replicate the experiments.The use of an encoder decoder framework with a copy function may seem simple. The results, from the experiments are persuasive and support the papers assertion about generating missing key phrases. \nShortcomings;   \nThe suggested method mentioned previously isn't particularly innovative and falls short in providing generalization to new areas as highlighted in Section 5 point 3 of the discussion section; it performs below par compared to unsupervised models. Even though one of the aspects highlighted in this paper is the importance of having a substantial amount and high quality training data sets available, for use; this specific point is not explicitly given much emphasis. \nLets talk about this topic in general.  \nThe paper was a read. I hope it gets accepted! I'm interested in how the training datas size and variety affect the methods performance. It would also be great to have the values of pg and pc (with examples from Figure 1) included in the CopyRNN model. In my past work, with CopyNet, sometimes the copying mechanism acts strangely and its not clear why that happens. "
        }
    ],
    "editorDocumentId": null
}