{
    "version": "2025-03-13-base",
    "scanId": "a4f3052c-1c17-4ab2-8767-4c4a87474b4c",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999982118606567,
                    "sentence": "This research paper delves into approaches to converting sequences of digits into words using the major system technique.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999971985816956,
                    "sentence": "In this systems framework;.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998152256012,
                    "sentence": "Each digit is linked to one or multiple consonant sounds through pre established mappings..",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982714653015,
                    "sentence": "The resulting output usually comprises a series of words where the initial digits are transformed into characters or combinations of characters in the eventual word sequence.. Vowels are inserted amidst the sounds to shape coherent words; however their positioning, within the word remains flexible and can vary.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982118606567,
                    "sentence": "The paper suggests methods for transforming number sequences to make the result more memorable, by using rules of grammar and practical approaches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998152256012,
                    "sentence": "The use of natural language processing (NLP) principles in this piece caught my attention because I have not seen an ACL paper discussing this subject previously.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980926513672,
                    "sentence": "However the paper and its main concepts seem outdated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999997079372406,
                    "sentence": "Relying heavily on ngram models, for creation frequent sequences of POS tags and heuristic methods provide the work with a touch that reminds me of research conducted 15 to 20 years ago.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979734420776,
                    "sentence": "I'm not sure if the ideas presented here are innovative enough to warrant being published in ACL in 2017.The paper doesn't bring new to NLP in terms of modeling or search techniques and doesn't convincingly demonstrate its relevance, to the application domain as it mainly involves constrained generation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980926513672,
                    "sentence": "When working on converting a sequence into another by using a direct connection method like a character level sequence to sequence encoder decoder model (for example the work done by Sutskever et al., 2014 in Sequence to sequence learning with neural networks) it appears that this type of model is suitable for the task at hand.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979138374329,
                    "sentence": "This approach is likely to generate results with a streamlined process (without the need for complicated trigram models or additional steps, like POS tagging and scoring heuristics).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999997615814209,
                    "sentence": "Furthermore it could utilize training data from various types of content resulting in the elimination of a pre tagged corpus or a reliance on a parser.This method would be more in line, with the standards set forth in a research paper from 2017.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999981551955921,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 1.8448044078924558e-06,
                        "ai_paraphrased": 0.9999981551955921
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 1.8447044078924859e-06,
                            "ai_paraphrased": 0.9999981551955921
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This research paper delves into approaches to converting sequences of digits into words using the major system technique. In this systems framework;. Each digit is linked to one or multiple consonant sounds through pre established mappings.. The resulting output usually comprises a series of words where the initial digits are transformed into characters or combinations of characters in the eventual word sequence.. Vowels are inserted amidst the sounds to shape coherent words; however their positioning, within the word remains flexible and can vary. The paper suggests methods for transforming number sequences to make the result more memorable, by using rules of grammar and practical approaches. \nThe use of natural language processing (NLP) principles in this piece caught my attention because I have not seen an ACL paper discussing this subject previously. However the paper and its main concepts seem outdated. Relying heavily on ngram models, for creation frequent sequences of POS tags and heuristic methods provide the work with a touch that reminds me of research conducted 15 to 20 years ago.  I'm not sure if the ideas presented here are innovative enough to warrant being published in ACL in 2017.The paper doesn't bring new to NLP in terms of modeling or search techniques and doesn't convincingly demonstrate its relevance, to the application domain as it mainly involves constrained generation. \nWhen working on converting a sequence into another by using a direct connection method like a character level sequence to sequence encoder decoder model (for example the work done by Sutskever et al., 2014 in Sequence to sequence learning with neural networks) it appears that this type of model is suitable for the task at hand. This approach is likely to generate results with a streamlined process (without the need for complicated trigram models or additional steps, like POS tagging and scoring heuristics). Furthermore it could utilize training data from various types of content resulting in the elimination of a pre tagged corpus or a reliance on a parser.This method would be more in line, with the standards set forth in a research paper from 2017. "
        }
    ],
    "editorDocumentId": null
}