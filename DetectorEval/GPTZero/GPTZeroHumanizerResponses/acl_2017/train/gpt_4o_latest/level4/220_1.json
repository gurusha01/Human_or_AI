{
    "version": "2025-03-13-base",
    "scanId": "f9592d68-e5b4-4888-8880-18acb71c7abe",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999967217445374,
                    "sentence": "This paper is really well done!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "Its written well and has some interesting findings and a creative approach compared to previous research methods used in the field of study.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999975562095642,
                    "sentence": "The detailed corpus annotations will definitely be helpful for researchers in this area too.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982714653015,
                    "sentence": "Section 5s qualitative discussion was particularly insightful and engaging.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999985694885254,
                    "sentence": "Unlike machine learning papers that just list results without much explanation or depth this paper offers valuable insights, for readers.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "Weak points can be found in Section 4A where the phrase \"The remaining parts of the models input are adjusted to zero...\" may not be completely clear until you refer to Figure 2 for details about it.A short explanation here could make things easier to understand.Furthermore in Figure 2,the input layers, for the LSTMs are marked as \"5 times Embeddings (50 dimensions) \" for the networks handling dependency labels.This appears to be incorrectᅳor if accurate it requires explanation to clarify its meaning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999985694885254,
                    "sentence": "In Section 4.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "Discussion Point; I find the comment about LSTMs being great for modeling language sequences and being the preferred model choice a bit strange here.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986290931702,
                    "sentence": "The issue we're dealing with isn't exactly sequential in the sense.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986290931702,
                    "sentence": "In this scenario each example feeds all five words to the network at once for every data point.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986290931702,
                    "sentence": "Theres no connection, between consecutive examples.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "Even though using an LSTM architecture could be the decision the rationale mentioned doesn't quite match up.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "Hey there!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "Could it be that I've gotten something here?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998152256012,
                    "sentence": "I'd love to hear the authors elaborate, on this point.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 9,
                    "completely_generated_prob": 0.9257822263275673
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999854978521874,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 1.450214781258312e-05,
                        "ai_paraphrased": 0.9999854978521874
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 1.450204781258315e-05,
                            "ai_paraphrased": 0.9999854978521874
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This paper is really well done! Its written well and has some interesting findings and a creative approach compared to previous research methods used in the field of study. The detailed corpus annotations will definitely be helpful for researchers in this area too. Section 5s qualitative discussion was particularly insightful and engaging. Unlike machine learning papers that just list results without much explanation or depth this paper offers valuable insights, for readers. \nWeak points can be found in Section 4A where the phrase \"The remaining parts of the models input are adjusted to zero...\" may not be completely clear until you refer to Figure 2 for details about it.A short explanation here could make things easier to understand.Furthermore in Figure 2,the input layers, for the LSTMs are marked as \"5 times Embeddings (50 dimensions) \" for the networks handling dependency labels.This appears to be incorrect—or if accurate it requires explanation to clarify its meaning. \nIn Section 4. Discussion Point; I find the comment about LSTMs being great for modeling language sequences and being the preferred model choice a bit strange here. The issue we're dealing with isn't exactly sequential in the sense. In this scenario each example feeds all five words to the network at once for every data point. Theres no connection, between consecutive examples. Even though using an LSTM architecture could be the decision the rationale mentioned doesn't quite match up. Hey there! Could it be that I've gotten something here? I'd love to hear the authors elaborate, on this point. "
        }
    ],
    "editorDocumentId": null
}