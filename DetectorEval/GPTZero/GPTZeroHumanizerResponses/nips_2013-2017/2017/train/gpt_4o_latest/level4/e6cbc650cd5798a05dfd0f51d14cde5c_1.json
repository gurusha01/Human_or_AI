{
    "version": "2025-03-13-base",
    "scanId": "0201ff35-6f7f-44e5-ab2b-684a5b7df7a7",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999198913574219,
                    "sentence": "This study presents a recurrent network model for sparse estimation that is inspired by sparse Bayesian learning (SBL).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999331831932068,
                    "sentence": "The researchers show that this recurrent architecture can implement a version of SBL and through simulations highlight the temporal dynamics of various parameters involved in the process.This discovery encourages the integration of concepts from recurrent network design into enhancing the architecture.The developed recurrent network seems to demonstrate performance compared to traditional optimization methods, in simulations and two distinct real world applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999420046806335,
                    "sentence": "The idea of using a network for sparse estimation shows great promise in terms of its impact potential.The paper is well articulated; the authors offer thorough explanations for their design decisions.The numerical experiments are thorough.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999953031539917,
                    "sentence": "Indicate that the suggested method is successful, in addressing complex sparse decomposition issues.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99992835521698,
                    "sentence": "Weaknesses in the paper include the method and experiment details being placed in the supplementary material rather than, in the main text itself which makes it less specific; however; this can be attributed to paper length restrictions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999929959455489,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 7.00405445116956e-06,
                        "ai_paraphrased": 0.9999929959455489
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 7.003954451169591e-06,
                            "ai_paraphrased": 0.9999929959455489
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This study presents a recurrent network model for sparse estimation that is inspired by sparse Bayesian learning (SBL). The researchers show that this recurrent architecture can implement a version of SBL and through simulations highlight the temporal dynamics of various parameters involved in the process.This discovery encourages the integration of concepts from recurrent network design into enhancing the architecture.The developed recurrent network seems to demonstrate performance compared to traditional optimization methods, in simulations and two distinct real world applications. \nThe idea of using a network for sparse estimation shows great promise in terms of its impact potential.The paper is well articulated; the authors offer thorough explanations for their design decisions.The numerical experiments are thorough. Indicate that the suggested method is successful, in addressing complex sparse decomposition issues. \nWeaknesses in the paper include the method and experiment details being placed in the supplementary material rather than, in the main text itself which makes it less specific; however; this can be attributed to paper length restrictions. "
        }
    ]
}