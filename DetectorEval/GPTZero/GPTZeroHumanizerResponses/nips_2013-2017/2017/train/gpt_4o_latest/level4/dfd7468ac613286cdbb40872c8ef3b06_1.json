{
    "version": "2025-03-13-base",
    "scanId": "004db62c-e470-4f08-b51a-a54cb06cff5d",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999964833259583,
                    "sentence": "This research paper introduces a generative model called MMD GAN that combines the strengths of generative adversarial networks (GANs and generative moment matching networks (GMMNs).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961853027344,
                    "sentence": "It uses mean discrepancy (MMD) with a kernel function that is adaptively learned through an adversarial process to maximize MMD.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999927878379822,
                    "sentence": "The paper includes analysis to show non degeneracy and practical results that indicate the model can generate samples comparable, to those produced by Wasserstein GANs (W GANs).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999893307685852,
                    "sentence": "Overall I believe that this paper is well done as it presents a yet impactful idea in a clear manner The approach put forward is appealing in concept and the choices made for modeling are clearly explained The writing is clear and easy to understand The theoretical contributions are strong and the links, to existing methods are well explained In the experimental evaluation the method has been benchmarked against tough datasets using solid baselines and has produced impressive resultsMatching the performance levels of GMMNs and WGANS is quite remarkable since previous studies have pointed out a difference, in their effectiveness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999931454658508,
                    "sentence": "The paper could use a thorough examination to explain the reasons behind the noted enhancements in performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999902844429016,
                    "sentence": "In particular; How does MMD GAN tackle the requirement for mini batches effectively covering the sample space to achieve a low MMD level, within each batch set still necessary here?)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999915957450867,
                    "sentence": "Also important is understanding what factors contribute to its performance compared to WGANs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999790191650391,
                    "sentence": "I have some remarks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999741911888123,
                    "sentence": "In Section 3 of the text discusses how the method relates to GAN models; however wouldn't it be more appropriate to compare it directly to WGAN models instead?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999712109565735,
                    "sentence": "If I'm not mistaken, in my interpretation MMD GAN could be seen as a version of WGAN that incorporates kernelization.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999839067459106,
                    "sentence": "It looks like the idea of limiting the gradient of a function to ensure stability is similar to the Lipschitz constraint used in Wasserstein GAN models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999852776527405,
                    "sentence": "Have you considered using the penalty technique proposed in the \"enhanced Wasserstein GAN\" research instead of simply clipping the gradient?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999869465827942,
                    "sentence": "Studies have demonstrated that this method is more successful, than gradient clipping methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999898076057434,
                    "sentence": "If someone says that the suggested approach helps prevent mode collapse, in AI models better tracking log probabilities could offer a reliable way to assess it quantitatively as shown in Wu et al., 2017.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999992847442627,
                    "sentence": "In Section 5 the test seems to focus broadly and not specifically measure stability concerns (such as avoiding the problematic outcomes common, in standard GAN models).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999928386874448,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 7.161312555202192e-06,
                        "ai_paraphrased": 0.9999928386874448
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 7.161212555202222e-06,
                            "ai_paraphrased": 0.9999928386874448
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This research paper introduces a generative model called MMD GAN that combines the strengths of generative adversarial networks (GANs and generative moment matching networks (GMMNs). It uses mean discrepancy (MMD) with a kernel function that is adaptively learned through an adversarial process to maximize MMD. The paper includes analysis to show non degeneracy and practical results that indicate the model can generate samples comparable, to those produced by Wasserstein GANs (W GANs).\nOverall I believe that this paper is well done as it presents a yet impactful idea in a clear manner The approach put forward is appealing in concept and the choices made for modeling are clearly explained The writing is clear and easy to understand The theoretical contributions are strong and the links, to existing methods are well explained In the experimental evaluation the method has been benchmarked against tough datasets using solid baselines and has produced impressive resultsMatching the performance levels of GMMNs and WGANS is quite remarkable since previous studies have pointed out a difference, in their effectiveness. \nThe paper could use a thorough examination to explain the reasons behind the noted enhancements in performance. In particular; How does MMD GAN tackle the requirement for mini batches effectively covering the sample space to achieve a low MMD level, within each batch set still necessary here?) Also important is understanding what factors contribute to its performance compared to WGANs. \nI have some remarks.\nIn Section 3 of the text discusses how the method relates to GAN models; however wouldn't it be more appropriate to compare it directly to WGAN models instead? If I'm not mistaken, in my interpretation MMD GAN could be seen as a version of WGAN that incorporates kernelization. \nIt looks like the idea of limiting the gradient of a function to ensure stability is similar to the Lipschitz constraint used in Wasserstein GAN models. Have you considered using the penalty technique proposed in the \"enhanced Wasserstein GAN\" research instead of simply clipping the gradient? Studies have demonstrated that this method is more successful, than gradient clipping methods. \nIf someone says that the suggested approach helps prevent mode collapse, in AI models better tracking log probabilities could offer a reliable way to assess it quantitatively as shown in Wu et al., 2017. \nIn Section 5 the test seems to focus broadly and not specifically measure stability concerns (such as avoiding the problematic outcomes common, in standard GAN models)."
        }
    ]
}