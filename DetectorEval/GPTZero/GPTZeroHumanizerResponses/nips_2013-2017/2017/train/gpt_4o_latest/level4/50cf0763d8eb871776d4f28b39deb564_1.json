{
    "version": "2025-03-13-base",
    "scanId": "a717dbf8-c2ee-407a-b6fe-b66989f5681c",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999958276748657,
                    "sentence": "This study explores how quickly M estimators converge when estimating parameters in various models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999964833259583,
                    "sentence": "Generative and discriminative ones are compared here.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999966025352478,
                    "sentence": "Generative models estimate the parameters of two sample sets and determine their difference; whereas discriminative models directly estimate this gap using Bayes' rule and logistic regression techniques.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999962449073792,
                    "sentence": "The authors establish convergence rates by introducing the idea of local separability to measure how effectively a loss function behaves as separable, across different criteria.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960660934448,
                    "sentence": "The findings cover situations with varying dimensions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999959468841553,
                    "sentence": "From low to high.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958872795105,
                    "sentence": "And specifically tackle the dimensional cases using l1 sparsity regularization techniques.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963641166687,
                    "sentence": "In my view and based on what I know far about this topic area.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960064888,
                    "sentence": "The method that generates data typically performs better than the discriminative method in terms of both theoretical analysis and simulated scenarios.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999994158744812,
                    "sentence": "I found the paper to be well crafted with a flow in its structure and the theoretical outcomes seem reliable as well.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999929070472717,
                    "sentence": "However as I'm not an expert, in this field myself it's a bit challenging for me to fully evaluate how original these results are or what impacts they may have.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999905228614807,
                    "sentence": "Still I do have a thoughts to share;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999994695186615,
                    "sentence": "Please correct \"xi^{ ( ́ ́ ) }\" to \"xi^{ ( ́ ) }\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933242797852,
                    "sentence": "In line 94 of Equation (7) why not opt for \"mu\", over \"theta\"?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999940991401672,
                    "sentence": "It essentially signifies the mean log likelihood (excluding constants).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999930262565613,
                    "sentence": "The same logic applies to Equation (8).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999926090240479,
                    "sentence": "In equation (six) on line 95 of the document; substitute \"trace of Theta times hatSigma\", with \"trace of Theta hatSigma\" by removing the comma.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999924302101135,
                    "sentence": "In lines 98, to 104 is it supposed to be 'theta 1 hat' instead of 'theta 3 hat'?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999932050704956,
                    "sentence": "In Equation (7) why is there no dependence on \" c star\", in Equation (7)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999874234199524,
                    "sentence": "Sure I will provide you with the revised text shortly.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999929070472717,
                    "sentence": "Line 208 is lacking the definitions for \"Theta, to the power of d\" and \"Sigma times kappa.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999991774559021,
                    "sentence": "Please provide me with the text you would like me to paraphrase.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999991774559021,
                    "sentence": "Sure I will provide the paraphrased human text without explaining my process; \"Please remember to include a period before the phrase 'For any classifier', at Line 259.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999993622303009,
                    "sentence": "I recommend inserting a period before the phrase \"In this setting.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 12,
                    "completely_generated_prob": 0.9410928246234925
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999961283988688,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 3.871601131172968e-06,
                        "ai_paraphrased": 0.9999961283988688
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 3.871501131172998e-06,
                            "ai_paraphrased": 0.9999961283988688
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This study explores how quickly M estimators converge when estimating parameters in various models. Generative and discriminative ones are compared here. Generative models estimate the parameters of two sample sets and determine their difference; whereas discriminative models directly estimate this gap using Bayes' rule and logistic regression techniques. The authors establish convergence rates by introducing the idea of local separability to measure how effectively a loss function behaves as separable, across different criteria. The findings cover situations with varying dimensions. From low to high. And specifically tackle the dimensional cases using l1 sparsity regularization techniques. In my view and based on what I know far about this topic area. The method that generates data typically performs better than the discriminative method in terms of both theoretical analysis and simulated scenarios. I found the paper to be well crafted with a flow in its structure and the theoretical outcomes seem reliable as well. However as I'm not an expert, in this field myself it's a bit challenging for me to fully evaluate how original these results are or what impacts they may have. Still I do have a thoughts to share; \nPlease correct \"xi^{ ( ́ ́ ) }\" to \"xi^{ ( ́ ) }\".\nIn line 94 of Equation (7) why not opt for \"mu\", over \"theta\"? It essentially signifies the mean log likelihood (excluding constants). The same logic applies to Equation (8).\nIn equation (six) on line 95 of the document; substitute \"trace of Theta times hatSigma\", with \"trace of Theta hatSigma\" by removing the comma.\nIn lines 98, to 104 is it supposed to be 'theta 1 hat' instead of 'theta 3 hat'?\nIn Equation (7) why is there no dependence on \" c star\", in Equation (7)?\nSure I will provide you with the revised text shortly.\nLine 208 is lacking the definitions for \"Theta, to the power of d\" and \"Sigma times kappa.\"\nPlease provide me with the text you would like me to paraphrase.\nSure I will provide the paraphrased human text without explaining my process; \"Please remember to include a period before the phrase 'For any classifier', at Line 259.\"\nI recommend inserting a period before the phrase \"In this setting.\""
        }
    ]
}