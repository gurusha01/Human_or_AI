{
    "version": "2025-03-13-base",
    "scanId": "d4f43665-d11d-4593-a4c1-310e3a58034a",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999983906745911,
                    "sentence": "This document presents a method, for learning network embeddings in a manner.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979138374329,
                    "sentence": "The main achievements include; a.)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999983906745911,
                    "sentence": "Creating a function based on matrix tri factorization that maintains the graphs proximity and global node ranking simultaneously.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999969005584717,
                    "sentence": "B.)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980926513672,
                    "sentence": "Offering detailed explanations to justify the new objective function.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980330467224,
                    "sentence": "C.) Assessing the effectiveness of node embeddings derived from optimizing the function using a neural network across three real world datasets and various data mining activities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999966621398926,
                    "sentence": "Advantages include;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999972581863403,
                    "sentence": "The article showcases theoretical foundations and convincingly justifies the loss function based on maintaining proximity and global ranking integrity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982118606567,
                    "sentence": "The results from the experiments are consistent, across all the datasets and tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999962449073792,
                    "sentence": "Downsides;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "The paper places much emphasis on theoretical explanations and not enough focus is given to practical experiments in some areas, like Lemma 3..",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999983310699463,
                    "sentence": "From Line 169 to Line 184 doesn't directly contribute to the goal of the final function we're aiming for here.The focus on maximizing modularity as outlined in Equation (7) with alpha set at 1,is a side note and isn't part of the loss function we're working towards which makes it somewhat unrelated, to the main framework.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999985694885254,
                    "sentence": "Integrating node details into the structure seems quite simple at first glance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "One way to tackle this is by introducing a goal (similar to what was done in this study) which has shown to enhance performance based on the test outcomes; however there is room for improvement, in this area.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999987483024597,
                    "sentence": "The writing could use some enhancements in aspects.There should be presentations of experimental findings based on different evaluation metrics.It is also advisable for the authors to add another baseline like GCN (referencing Kipf and Wellings work at ICLR 2017) as it is an approach, for learning node embeddings using graph convolution networks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.9000234362273952
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999970895039005,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 2.910496099416194e-06,
                        "ai_paraphrased": 0.9999970895039005
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 2.910396099416224e-06,
                            "ai_paraphrased": 0.9999970895039005
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This document presents a method, for learning network embeddings in a manner. The main achievements include; a.) Creating a function based on matrix tri factorization that maintains the graphs proximity and global node ranking simultaneously. B.) Offering detailed explanations to justify the new objective function. C.) Assessing the effectiveness of node embeddings derived from optimizing the function using a neural network across three real world datasets and various data mining activities. \nAdvantages include; \nThe article showcases theoretical foundations and convincingly justifies the loss function based on maintaining proximity and global ranking integrity. \nThe results from the experiments are consistent, across all the datasets and tasks. \nDownsides; \nThe paper places much emphasis on theoretical explanations and not enough focus is given to practical experiments in some areas, like Lemma 3.. \nFrom Line 169 to Line 184 doesn't directly contribute to the goal of the final function we're aiming for here.The focus on maximizing modularity as outlined in Equation (7) with alpha set at 1,is a side note and isn't part of the loss function we're working towards which makes it somewhat unrelated, to the main framework. \nIntegrating node details into the structure seems quite simple at first glance. One way to tackle this is by introducing a goal (similar to what was done in this study) which has shown to enhance performance based on the test outcomes; however there is room for improvement, in this area. \nThe writing could use some enhancements in aspects.There should be presentations of experimental findings based on different evaluation metrics.It is also advisable for the authors to add another baseline like GCN (referencing Kipf and Wellings work at ICLR 2017) as it is an approach, for learning node embeddings using graph convolution networks. "
        }
    ]
}