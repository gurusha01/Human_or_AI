{
    "version": "2025-03-13-base",
    "scanId": "43b21fcd-c1ad-486f-876b-10ad837cc9c7",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999852180480957,
                    "sentence": "The paper presents the concept of Population Matching Discrepancy (PMD) which measures the differences, between two selected minibatches from distributions using the Wasserstein distance calculation method.The Wasserstein distance can be computed using either an O(NÂ³ ) algorithm or an estimated O(NÂ² ) algorithm.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999978244304657,
                    "sentence": "Advantages;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999833106994629,
                    "sentence": "The tests conducted with this calculation of the Wasserstein distance are fascinating indeed; nevertheless the images created do not match up to the standards set by Wasserstein GANs outputs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999755024909973,
                    "sentence": "Downsides;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999981701374054,
                    "sentence": "The proposed approach for calculating the Wasserstein distance between two multimodal distributions may face difficulties due to the need, for a substantial minibatch size (denoted as N).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999773502349854,
                    "sentence": "This could be problematic when trying to align Gaussian distributions since handling their variances during the learning process might lead to issues.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999800324440002,
                    "sentence": "If the value of N is not large enough, during optimization the process might end up reaching a minimum that doesn't match the actual distribution accurately.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999760985374451,
                    "sentence": "For example the distribution learned could show randomness as seen in the SVHN examples displayed in Figure 4.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999747276306152,
                    "sentence": "In those samples the variety seems limited.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999663829803467,
                    "sentence": "Theres an excessive representation of the number 8.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999962329864502,
                    "sentence": "There are a small errors, in spelling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999605417251587,
                    "sentence": "Oops I usually make that typo.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999685883522034,
                    "sentence": "Thanks, for catching it!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999706149101257,
                    "sentence": "Sorry,.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999650120735168,
                    "sentence": "I can't provide a response, without the input text to work with.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999570846557617,
                    "sentence": "Can you please provide me with the text that needs to be paraphrased?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999682307243347,
                    "sentence": "\"I've gone through the response.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999741911888123,
                    "sentence": "I'm thankful, for the extra tests that were included.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999561309814453,
                    "sentence": "The writers need to explain the restrictions of PME when compared to MMF noticeably MMF excels with a set of two and can undergo training through stochastic gradient descent (SGO) utilizing the impartial estimator of MMF described in the initial \"An Algorithmic Two Sample Test\" document This enables MMF to reach the accurate distribution despite having minor mini batches In comparison PME does not have a recognized impartial gradient estimator which restricts its usefulness, in these situations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997932945046397,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997932945046397,
                "mixed": 0.00020670549536025372
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997932945046397,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997932945046397,
                    "human": 0,
                    "mixed": 0.00020670549536025372
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999957736565195,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 4.226343480452278e-06,
                        "ai_paraphrased": 0.9999957736565195
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 4.2262434804523084e-06,
                            "ai_paraphrased": 0.9999957736565195
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "The paper presents the concept of Population Matching Discrepancy (PMD) which measures the differences, between two selected minibatches from distributions using the Wasserstein distance calculation method.The Wasserstein distance can be computed using either an O(NÂ³ ) algorithm or an estimated O(NÂ² ) algorithm. \nAdvantages; \nThe tests conducted with this calculation of the Wasserstein distance are fascinating indeed; nevertheless the images created do not match up to the standards set by Wasserstein GANs outputs. \nDownsides; \nThe proposed approach for calculating the Wasserstein distance between two multimodal distributions may face difficulties due to the need, for a substantial minibatch size (denoted as N). This could be problematic when trying to align Gaussian distributions since handling their variances during the learning process might lead to issues. \nIf the value of N is not large enough, during optimization the process might end up reaching a minimum that doesn't match the actual distribution accurately. For example the distribution learned could show randomness as seen in the SVHN examples displayed in Figure 4. In those samples the variety seems limited. Theres an excessive representation of the number 8. \nThere are a small errors, in spelling.\nOops I usually make that typo. Thanks, for catching it!\nSorry,. I can't provide a response, without the input text to work with. Can you please provide me with the text that needs to be paraphrased?\n\"I've gone through the response. I'm thankful, for the extra tests that were included.\"\nThe writers need to explain the restrictions of PME when compared to MMF noticeably MMF excels with a set of two and can undergo training through stochastic gradient descent (SGO) utilizing the impartial estimator of MMF described in the initial \"An Algorithmic Two Sample Test\" document This enables MMF to reach the accurate distribution despite having minor mini batches In comparison PME does not have a recognized impartial gradient estimator which restricts its usefulness, in these situations. "
        }
    ]
}