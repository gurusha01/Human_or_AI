{
    "version": "2025-03-13-base",
    "scanId": "b468487b-ea78-4c98-ab97-77daf47ce28f",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999984502792358,
                    "sentence": "This paper introduces a recurrent network strategy for sparse estimation that is influenced by the principles of sparse Bayesian learning (SBL).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982118606567,
                    "sentence": "The study showcases how a recurrent structure can efficiently execute a version of SBL and shows time dynamics for different parameters through simulation results; thereby supporting the integration of recurrent network design ideas into the architecture design process.This results in a network that seems to outperform traditional optimization methods, in simulations and practical scenarios.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999983310699463,
                    "sentence": "The main advantage of this study is its ability to make a difference through the use of a recurrent network for sparse estimationᅳa promising concept indeed!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979138374329,
                    "sentence": "The paper is impressively written; the authors offer explanations for their design decisions and conduct thorough numerical experiments that highlight the effectiveness of the technique, in solving intricate sparse decomposition problems.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999978542327881,
                    "sentence": "One significant flaw of the manuscript is that details regarding how it was implemented and specific experiments are placed in the supplementary material instead of the main paper itself which makes the main paper less precise overall.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999973497153966,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 2.650284603425316e-06,
                        "ai_paraphrased": 0.9999973497153966
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 2.650184603425346e-06,
                            "ai_paraphrased": 0.9999973497153966
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This paper introduces a recurrent network strategy for sparse estimation that is influenced by the principles of sparse Bayesian learning (SBL). The study showcases how a recurrent structure can efficiently execute a version of SBL and shows time dynamics for different parameters through simulation results; thereby supporting the integration of recurrent network design ideas into the architecture design process.This results in a network that seems to outperform traditional optimization methods, in simulations and practical scenarios. \nThe main advantage of this study is its ability to make a difference through the use of a recurrent network for sparse estimation—a promising concept indeed! The paper is impressively written; the authors offer explanations for their design decisions and conduct thorough numerical experiments that highlight the effectiveness of the technique, in solving intricate sparse decomposition problems. \nOne significant flaw of the manuscript is that details regarding how it was implemented and specific experiments are placed in the supplementary material instead of the main paper itself which makes the main paper less precise overall. "
        }
    ],
    "editorDocumentId": null
}