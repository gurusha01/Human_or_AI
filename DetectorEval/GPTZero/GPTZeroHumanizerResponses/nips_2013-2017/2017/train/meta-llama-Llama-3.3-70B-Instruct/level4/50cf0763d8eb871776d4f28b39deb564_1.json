{
    "version": "2025-03-13-base",
    "scanId": "7a6b3f44-f153-43f1-a308-ef3610c554df",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999972581863403,
                    "sentence": "This document explores how quickly M estimators converge when estimating parameters, in different model typesᅳgenerative and discriminative models are the main focus here.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977946281433,
                    "sentence": "In models the process involves estimating parameters from two separate sample sets and then determining their variance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999976754188538,
                    "sentence": "On the hand discriminative models estimate the difference directly using Bayes' rule and logistic regression.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999976754188538,
                    "sentence": "The authors establish convergence rates by introducing the idea of separability to measure how well a loss function shows separable behavior.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999964237213135,
                    "sentence": "The outcomes cover scenarios in both complex dimensions; the latter involves incorporating sparse regularization, with an L1 norm penalty term included in the model formulation.The experimental and theoretical evidence suggests that the method focused on generating data tends to perform compared to a discriminative approach overall.The paper is organized effectively with writing and solid theoretical underpinnings.However as someone not well versed in this area I lack the expertise to evaluate the novelty and significance of these discoveries.I do have a minor points to note;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999969005584717,
                    "sentence": "Line 75 needs to be adjusted to show $ x_i^{ ( 1} ) $.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961853027344,
                    "sentence": "In line 94 of equation (1) it might make sense to utilize the symbol $\\mu$, rather than $\\theta$ since it signifies the negative average log likelihood with respect to constants.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999996542930603,
                    "sentence": "A more intuitive choice, for representation purposes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9513041973114014,
                    "sentence": "In Equation 5, on line 95 of the document provided; Please ensure that $\\text {trace}( \\Theta\\hat{\\Sigma})$ is correctly noted without the inclusion of a comma.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9502538442611694,
                    "sentence": "It appears like we should substitute $\\theta 1^{'} $, with $\\theta 3^{'} $.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9196960926055908,
                    "sentence": "Line 102, in equation (9); The equation seems to not rely on $C^{star}$ and may benefit from explanation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9148036241531372,
                    "sentence": "Ensure that the notation $\\phi(t)$ remains uniform throughout.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8551099300384521,
                    "sentence": "Either as $\\Phi(t)$ or, in format.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5398590564727783,
                    "sentence": "Line 158 should have a period, after the term \"Irrepresentability.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.6465430855751038,
                    "sentence": "Line 208 does not include the definitions for $Θ and $Ʃĸ, in Lemma 3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.5671184062957764,
                    "sentence": "A dash should be added between \" Thresholding\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.39205214381217957,
                    "sentence": "I noticed that there's a period, before the phrase \"For any classifier.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.33050650358200073,
                    "sentence": "I noticed that the phrase \"In this setting\" is missing a period, before it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                }
            ],
            "completely_generated_prob": 0.8317150757516052,
            "class_probabilities": {
                "human": 0.16295700718998515,
                "ai": 0.8317150757516052,
                "mixed": 0.005327917058409546
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8317150757516052,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8317150757516052,
                    "human": 0.16295700718998515,
                    "mixed": 0.005327917058409546
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "pure_ai",
                    "result_message": "",
                    "confidence_score": 0.9999999998,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.9999999999,
                        "ai_paraphrased": 9.999999997e-11
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.9999999998,
                            "ai_paraphrased": 9.999999997e-11
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This document explores how quickly M estimators converge when estimating parameters, in different model types—generative and discriminative models are the main focus here. In models the process involves estimating parameters from two separate sample sets and then determining their variance. On the hand discriminative models estimate the difference directly using Bayes’ rule and logistic regression. The authors establish convergence rates by introducing the idea of separability to measure how well a loss function shows separable behavior. The outcomes cover scenarios in both complex dimensions; the latter involves incorporating sparse regularization, with an L1 norm penalty term included in the model formulation.The experimental and theoretical evidence suggests that the method focused on generating data tends to perform compared to a discriminative approach overall.The paper is organized effectively with writing and solid theoretical underpinnings.However as someone not well versed in this area I lack the expertise to evaluate the novelty and significance of these discoveries.I do have a minor points to note; \nLine 75 needs to be adjusted to show $ x_i^{ ( 1} ) $.\nIn line 94 of equation (1) it might make sense to utilize the symbol $\\mu$, rather than $\\theta$ since it signifies the negative average log likelihood with respect to constants. A more intuitive choice, for representation purposes. \nIn Equation 5, on line 95 of the document provided; Please ensure that $\\text {trace}( \\Theta\\hat{\\Sigma})$ is correctly noted without the inclusion of a comma. \nIt appears like we should substitute $\\theta 1^{'} $, with $\\theta 3^{'} $. \nLine 102, in equation (9); The equation seems to not rely on $C^{star}$ and may benefit from explanation. \nEnsure that the notation $\\phi(t)$ remains uniform throughout. Either as $\\Phi(t)$ or, in format. \nLine 158 should have a period, after the term \"Irrepresentability.\"\nLine 208 does not include the definitions for $Θ and $Σκ, in Lemma 3. \nA dash should be added between \" Thresholding\".\nI noticed that there's a period, before the phrase \"For any classifier.\"\nI noticed that the phrase \"In this setting\" is missing a period, before it."
        }
    ],
    "editorDocumentId": null
}