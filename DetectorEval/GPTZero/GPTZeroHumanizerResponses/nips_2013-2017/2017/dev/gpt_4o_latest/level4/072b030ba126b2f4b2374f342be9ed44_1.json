{
    "version": "2025-03-13-base",
    "scanId": "67563c6f-c1c0-4e11-a5dd-6cc309e01653",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999984502792358,
                    "sentence": "I am discussing the issue of optimizing finite sums through the SAGA framework in this paper which expands on Leblond et al.s (2017) research by integrating optimization with a focus, on incorporating non smooth separable regularization techniques.The key innovation lies in the approach suggested for managing smooth regularization while maintaining sparse updates as a core principle.I am intrigued by the method proposed for dividing the smooth regularization.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986290931702,
                    "sentence": "The analysis is mostly based on the model set up by Leblond et al.s work from 2017 and the evidence for the version is influenced by the method described in Mania et al.s research, from 2015.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999983310699463,
                    "sentence": "I have some observations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982714653015,
                    "sentence": "The definition of an \" read\" requires further clarification; What exactly does the symbol \\(\\hat{x}_ k\\) stand for and how is the value of \\( k \\) determined in this context?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998152256012,
                    "sentence": "Is this method comparable to the approaches of Lian et al (2016) and Liu and Wright (2015)?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980330467224,
                    "sentence": "What sets them apart, from each other?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982118606567,
                    "sentence": "The explanation for the form of the dissimilarities, between \\(\\hat{x}_\\text{{dt}}\\) and \\(xt\\) is not clearly articulated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979138374329,
                    "sentence": "In order to reach the linear convergence rate and speedup mentioned in the paper\" s findings it is important that the authors clearly articulate the underlying assumptions they have made.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999997615814209,
                    "sentence": "I noticed a minor comments and typos, in the text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "The description of ÃŽ\", on line 217 is inaccurate.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982118606567,
                    "sentence": "I couldn't find the source you mentioned.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999983310699463,
                    "sentence": "The work, on greedy SDCA is important and should be included in the references.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999920953546485,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 7.904645351496219e-06,
                        "ai_paraphrased": 0.9999920953546485
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 7.904545351496249e-06,
                            "ai_paraphrased": 0.9999920953546485
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "I am discussing the issue of optimizing finite sums through the SAGA framework in this paper which expands on Leblond et al.s (2017) research by integrating optimization with a focus, on incorporating non smooth separable regularization techniques.The key innovation lies in the approach suggested for managing smooth regularization while maintaining sparse updates as a core principle.I am intrigued by the method proposed for dividing the smooth regularization. The analysis is mostly based on the model set up by Leblond et al.s work from 2017 and the evidence for the version is influenced by the method described in Mania et al.s research, from 2015. \nI have some observations.\nThe definition of an \" read\" requires further clarification; What exactly does the symbol \\(\\hat{x}_ k\\) stand for and how is the value of \\( k \\) determined in this context ? Is this method comparable to the approaches of Lian et al (2016) and Liu and Wright (2015)? What sets them apart, from each other ?\nThe explanation for the form of the dissimilarities, between \\(\\hat{x}_\\text{{dt}}\\) and \\(xt\\) is not clearly articulated. \nIn order to reach the linear convergence rate and speedup mentioned in the paper\" s findings it is important that the authors clearly articulate the underlying assumptions they have made. \nI noticed a minor comments and typos, in the text.\nThe description of ÃŽ\", on line 217 is inaccurate. \nI couldn't find the source you mentioned.\nThe work, on greedy SDCA is important and should be included in the references.\n"
        }
    ]
}