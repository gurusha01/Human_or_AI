{
    "version": "2025-03-13-base",
    "scanId": "7464f7ce-25f8-4831-8399-e5647899ff55",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999933242797852,
                    "sentence": "This research introduces a visual attention model inspired by the principle of least action from physics theory called EYe MOvement Laws (EYMOL).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933838844299,
                    "sentence": "The model is built on a Lagrangian formulation that integrates three essential concepts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999935626983643,
                    "sentence": "Constrained trajectory movement patterns, spontaneous curiosity driven shifts in focus and consistent perception of brightness levels, across stimuli.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999946355819702,
                    "sentence": "The derived Euler Lagrange equations detail the behavior of attention and offer insights into predicting where humans will focus their gaze.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999877214431763,
                    "sentence": "The article is nicely.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999931454658508,
                    "sentence": "Offers a detailed explanation of the theoretical framework and mathematical calculations involved.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999919533729553,
                    "sentence": "Furthermore the researchers present findings from experiments conducted on detecting salient features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999948740005493,
                    "sentence": "These results showcase how well the model works.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999921917915344,
                    "sentence": "The study reveals its efficiency in handling image and video data sets due to its design and ability to operate in real time making it a viable option, for a range of practical uses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999923706054688,
                    "sentence": "The paper has notable advantages, such, as;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999931454658508,
                    "sentence": "Proposing an theoretically sound model of visual attention.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999917149543762,
                    "sentence": "Using a method to develop the model offers a straightforward and intuitive grasp of the fundamental principles.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999940991401672,
                    "sentence": "The results, from the experiments showcase how well the model performs across datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999932050704956,
                    "sentence": "The models simplicity and ability to deliver real time results make it ideal for use, in scenarios.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999892711639404,
                    "sentence": "The papers drawbacks are as follows;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999992311000824,
                    "sentence": "The absence of a comparison, with other cutting edge visual attention models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997994899749756,
                    "sentence": "The thorough examination of the models variables.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99979567527771,
                    "sentence": "How they influence the outcomes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998539686203003,
                    "sentence": "We should ensure that the model is validated on a range of datasets and tasks to enhance its credibility.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999839723110199,
                    "sentence": "In terms the document makes a meaningful addition to the study of visual focus and offers a hopeful answer, for detecting salient elements in tasks; yet more investigation is necessary to completely understand the abilities and constraints of the suggested model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997668862342834,
                    "sentence": "Reasons supporting acceptance;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997846484184265,
                    "sentence": "The paper introduces an well founded model of visual attention.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997887015342712,
                    "sentence": "The model has demonstrated its effectiveness, across datasets and tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996287822723389,
                    "sentence": "The models simplicity and ability to operate in time make it well suited for practical use.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996466636657715,
                    "sentence": "Points supporting acceptance;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996916651725769,
                    "sentence": "The absence of an examination in comparison, to other cutting edge models of visual focus",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996994137763977,
                    "sentence": "The analysis of the models parameters is limited.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996724724769592,
                    "sentence": "Its effects, on the outcomes are not thoroughly examined.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997022151947021,
                    "sentence": "It is important to validate the model on a range of datasets and tasks to ensure its reliability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997597336769104,
                    "sentence": "Suggestion for approval with modifications is to include a thorough comparison, with other cutting edge visual attention models and evaluate how the models parameters influence the outcomes in more detail as suggested by the authors in the paper review process.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 26,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 28,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 29,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9999999999999999,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9999999999999999,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9999999999999999,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9999999999999999,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999606847511928,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 3.9315248807175904e-05,
                        "ai_paraphrased": 0.9999606847511928
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 3.931514880717593e-05,
                            "ai_paraphrased": 0.9999606847511928
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This research introduces a visual attention model inspired by the principle of least action from physics theory called EYe MOvement Laws (EYMOL). The model is built on a Lagrangian formulation that integrates three essential concepts. Constrained trajectory movement patterns, spontaneous curiosity driven shifts in focus and consistent perception of brightness levels, across stimuli. The derived Euler Lagrange equations detail the behavior of attention and offer insights into predicting where humans will focus their gaze. \nThe article is nicely. Offers a detailed explanation of the theoretical framework and mathematical calculations involved. Furthermore the researchers present findings from experiments conducted on detecting salient features. These results showcase how well the model works. The study reveals its efficiency in handling image and video data sets due to its design and ability to operate in real time making it a viable option, for a range of practical uses. \nThe paper has notable advantages, such, as; \nProposing an theoretically sound model of visual attention.\nUsing a method to develop the model offers a straightforward and intuitive grasp of the fundamental principles.\nThe results, from the experiments showcase how well the model performs across datasets.\nThe models simplicity and ability to deliver real time results make it ideal for use, in scenarios.\nThe papers drawbacks are as follows; \nThe absence of a comparison, with other cutting edge visual attention models.\nThe thorough examination of the models variables. How they influence the outcomes.\nWe should ensure that the model is validated on a range of datasets and tasks to enhance its credibility.\nIn terms the document makes a meaningful addition to the study of visual focus and offers a hopeful answer, for detecting salient elements in tasks; yet more investigation is necessary to completely understand the abilities and constraints of the suggested model. \nReasons supporting acceptance; \nThe paper introduces an well founded model of visual attention.\nThe model has demonstrated its effectiveness, across datasets and tasks.\nThe models simplicity and ability to operate in time make it well suited for practical use.\nPoints supporting acceptance; \nThe absence of an examination in comparison, to other cutting edge models of visual focus\nThe analysis of the models parameters is limited. Its effects, on the outcomes are not thoroughly examined.\nIt is important to validate the model on a range of datasets and tasks to ensure its reliability. \nSuggestion for approval with modifications is to include a thorough comparison, with other cutting edge visual attention models and evaluate how the models parameters influence the outcomes in more detail as suggested by the authors in the paper review process. "
        }
    ]
}