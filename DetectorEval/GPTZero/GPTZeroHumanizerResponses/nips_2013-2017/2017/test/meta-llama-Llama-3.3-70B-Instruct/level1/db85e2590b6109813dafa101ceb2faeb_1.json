{
    "version": "2025-03-13-base",
    "scanId": "e48e0ff3-6388-4faf-8f19-59a0edcc3d9a",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999961853027344,
                    "sentence": "This study suggests a method for condensing deep neural networks by considering compression, from the beginning of the training phase itself The researchers introduce a technique that promotes the parameter matrix of each layer to possess a lower rank This enables the learning of more concise models The method is proven to attain superior compression rates compared to current leading techniques while maintaining prediction accuracy at a minimal loss.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960064888,
                    "sentence": "The paper is nicely.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961853027344,
                    "sentence": "Effectively outlines the reasons behind the suggested approach and how it was carried out in detail by the authors.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999950528144836,
                    "sentence": "They present an overview of previous research in neural network compression field pointing out the drawbacks of current techniques and the advantages of their method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960064888,
                    "sentence": "The results from experiments are striking as they were able to achieve compression rates exceeding 90% across complex architectures, like the 8 layer DecomposeMe network and the 50 layer ResNet.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999972581863403,
                    "sentence": "One of the positive aspects of the paper is its strengths.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982714653015,
                    "sentence": "A new and efficient method, for compressing neural networks has been suggested.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999983310699463,
                    "sentence": "A comprehensive examination of research and a detailed description of the approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982118606567,
                    "sentence": "The approach showcased experimental outcomes highlighting its effectiveness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982714653015,
                    "sentence": "There is a possibility of achieving savings, in both computing expenses and memory consumption.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980330467224,
                    "sentence": "Some drawbacks of the document are;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986886978149,
                    "sentence": "Not all neural networks and compression techniques may be suitable, for this approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999983906745911,
                    "sentence": "Careful adjustments may be needed when selecting hyperparameters, like the regularization level and energy threshold.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999927282333374,
                    "sentence": "The paper would be improved by delving into the balance, between compression rate, accuracy and computational expenses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999905824661255,
                    "sentence": "Reasons supporting approval;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999993085861206,
                    "sentence": "The article suggests an efficient method, for reducing the size of complex neural networks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999916553497314,
                    "sentence": "The results from the experiment are quite remarkable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999926090240479,
                    "sentence": "Show promising possibilities, for cutting down both computational expenses and memory usage.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999920129776001,
                    "sentence": "The method has the possibility to be broadly relevant and create an influence, in the realm of deep learning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999912977218628,
                    "sentence": "Reasons to oppose it;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999903440475464,
                    "sentence": "Not every neural network type and compression strategy may be suitable, for this approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999903440475464,
                    "sentence": "The article would be more helpful with an examination of the balance, between compression rate, precision and computational expenses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999988317489624,
                    "sentence": "Finding the hyperparameters can be tricky and might restrict how broadly the method can be used.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999871253967285,
                    "sentence": "In my opinion the paper adds a perspective to the realm of deep learning and compressions in neural networks and I suggest accepting it for publication.The methodology is original yet practical.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999898672103882,
                    "sentence": "Could bring about a notable change in this domain.Although there are a couple of drawbacks and areas, for improvement I believe these can be rectified with investigation and advancements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.9997938739332975,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997938739332975,
                "mixed": 0.00020612606670239523
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997938739332975,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997938739332975,
                    "human": 0,
                    "mixed": 0.00020612606670239523
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999967679642922,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 3.232035707900731e-06,
                        "ai_paraphrased": 0.9999967679642922
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 3.231935707900761e-06,
                            "ai_paraphrased": 0.9999967679642922
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This study suggests a method for condensing deep neural networks by considering compression, from the beginning of the training phase itself The researchers introduce a technique that promotes the parameter matrix of each layer to possess a lower rank This enables the learning of more concise models The method is proven to attain superior compression rates compared to current leading techniques while maintaining prediction accuracy at a minimal loss. \nThe paper is nicely. Effectively outlines the reasons behind the suggested approach and how it was carried out in detail by the authors. They present an overview of previous research in neural network compression field pointing out the drawbacks of current techniques and the advantages of their method. The results from experiments are striking as they were able to achieve compression rates exceeding 90% across complex architectures, like the 8 layer DecomposeMe network and the 50 layer ResNet. \nOne of the positive aspects of the paper is its strengths.\nA new and efficient method, for compressing neural networks has been suggested.\nA comprehensive examination of research and a detailed description of the approach.\nThe approach showcased experimental outcomes highlighting its effectiveness.\nThere is a possibility of achieving savings, in both computing expenses and memory consumption.\nSome drawbacks of the document are; \nNot all neural networks and compression techniques may be suitable, for this approach.\nCareful adjustments may be needed when selecting hyperparameters, like the regularization level and energy threshold. \nThe paper would be improved by delving into the balance, between compression rate, accuracy and computational expenses.\nReasons supporting approval; \nThe article suggests an efficient method, for reducing the size of complex neural networks.\nThe results from the experiment are quite remarkable. Show promising possibilities, for cutting down both computational expenses and memory usage.\nThe method has the possibility to be broadly relevant and create an influence, in the realm of deep learning.\nReasons to oppose it; \nNot every neural network type and compression strategy may be suitable, for this approach.\nThe article would be more helpful with an examination of the balance, between compression rate, precision and computational expenses. \nFinding the hyperparameters can be tricky and might restrict how broadly the method can be used. \nIn my opinion the paper adds a perspective to the realm of deep learning and compressions in neural networks and I suggest accepting it for publication.The methodology is original yet practical. Could bring about a notable change in this domain.Although there are a couple of drawbacks and areas, for improvement I believe these can be rectified with investigation and advancements. "
        }
    ]
}