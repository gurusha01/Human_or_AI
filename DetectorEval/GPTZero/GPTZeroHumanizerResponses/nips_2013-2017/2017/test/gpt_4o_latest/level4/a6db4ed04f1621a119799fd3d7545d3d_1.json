{
    "version": "2025-03-13-base",
    "scanId": "8c79af4e-7111-427f-b7df-abefd56d3d4b",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9998381733894348,
                    "sentence": "In this article introduces TraGru that extends LSTM and GR architecture approach distinct from conv LSTM and GR models by focusing on learning filters that vary by location, for each hidden state position TraGru accomplishes this by creating a flow pattern based on the current input and the preceding hidden state then adjusting the previous hidden states via bilinear sampling led by this flow pattern",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998902678489685,
                    "sentence": "The authors test their model on tasks related to creating videos using two sets of data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998292922973633,
                    "sentence": "MovingMNIST with three digits, at once and the HKOÃ¢ spearheaded nowcasting dataset Results from these tests show that Tra jGUR outperforms its convolutional competitors in terms of performance.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997865557670593,
                    "sentence": "Could you please provide details or specific inquiries?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997808933258057,
                    "sentence": "Have you explored the differences between Trajectory Gated Recurrent Unit (TraJGR) and Convolutional Gated Recurrent Unit (ConvGR) models with filter sizes than the typical 3, by 3 kernels?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997455477714539,
                    "sentence": "Is there a difference in load between TraSPRU and ConvGRu because of the warping operation used by TraSPRU?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996628165245056,
                    "sentence": "It would be useful to provide information on the parameter count and compute complexity as well as runtime, for the models tested in the experimental section.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997194409370422,
                    "sentence": "Why did they decide to train the model for a number of epochs instead of using early stopping techniques, for training optimization purposes?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996209144592285,
                    "sentence": "\"Could some models achieve better results if the training process was stopped earlier?\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995909333229065,
                    "sentence": "Excellence",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997175335884094,
                    "sentence": "The report seems to be well grounded in terms of its aspects.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997333288192749,
                    "sentence": "Clearness",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986780285835266,
                    "sentence": "The document is lucidthe paper is generally clear and understandable.. NeverthelessHowever it would be advantageousbeneficial to mentionwhich warping method was employedutilized to enhanceunderstandbetter grasp TraNNN for a thorough comprehensiona more comprehensive understanding.. AlsoIn addition the number of instancesexamples as well as the divisionssplits between trainingvalidationand testing sets, in the HKO sevenHKO seven dataset are not definitivelyclearly clarifiedstated..",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9986206889152527,
                    "sentence": "In the past some studies have looked into how warping can be used in video modeling like the \"Spatio video autoencoder with differentiable memory.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.997399091720581,
                    "sentence": "However this paper introduces a perspective on the topic by suggesting a comparison and contrast of TraJru, with these methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9987524151802063,
                    "sentence": "Final Thoughts",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9981682896614075,
                    "sentence": "Creating models that can effectively understand video content is still an area of research to explore further on it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9981318712234497,
                    "sentence": "This study presents a technique by suggesting a model that grasps both the filter support and filter weights in an attempt to advance video modeling in an intriguing way.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9981263875961304,
                    "sentence": "Nevertheless the assessment is presently constrained to an artificially generated dataset (MovingMNIST) and a particular nowcasting dataset.It would enhance the paper to showcase how this model enhances video representations for tasks like categorizing human actions, in common video datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.999974909846851,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 2.5090153149046625e-05,
                        "ai_paraphrased": 0.999974909846851
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 2.5090053149046655e-05,
                            "ai_paraphrased": 0.999974909846851
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "In this article introduces TraGru that extends LSTM and GR architecture approach distinct from conv LSTM and GR models by focusing on learning filters that vary by location, for each hidden state position TraGru accomplishes this by creating a flow pattern based on the current input and the preceding hidden state then adjusting the previous hidden states via bilinear sampling led by this flow pattern\nThe authors test their model on tasks related to creating videos using two sets of data. MovingMNIST with three digits, at once and the HKOÃ¢ÂÂ spearheaded nowcasting dataset Results from these tests show that Tra jGUR outperforms its convolutional competitors in terms of performance. \nCould you please provide details or specific inquiries?\nHave you explored the differences between Trajectory Gated Recurrent Unit (TraJGR) and Convolutional Gated Recurrent Unit (ConvGR) models with filter sizes than the typical 3, by 3 kernels? \nIs there a difference in load between TraSPRU and ConvGRu because of the warping operation used by TraSPRU? It would be useful to provide information on the parameter count and compute complexity as well as runtime, for the models tested in the experimental section. \nWhy did they decide to train the model for a number of epochs instead of using early stopping techniques, for training optimization purposes?\"Could some models achieve better results if the training process was stopped earlier?\"\nExcellence \nThe report seems to be well grounded in terms of its aspects. \nClearness \nThe document is lucidthe paper is generally clear and understandable.. NeverthelessHowever it would be advantageousbeneficial to mentionwhich warping method was employedutilized to enhanceunderstandbetter grasp TraNNN for a thorough comprehensiona more comprehensive understanding.. AlsoIn addition the number of instancesexamples as well as the divisionssplits between trainingvalidationand testing sets, in the HKO sevenHKO seven dataset are not definitivelyclearly clarifiedstated..\n \nIn the past some studies have looked into how warping can be used in video modeling like the \"Spatio video autoencoder with differentiable memory.\" However this paper introduces a perspective on the topic by suggesting a comparison and contrast of TraJru, with these methods. \nFinal Thoughts \nCreating models that can effectively understand video content is still an area of research to explore further on it. This study presents a technique by suggesting a model that grasps both the filter support and filter weights in an attempt to advance video modeling in an intriguing way. \nNevertheless the assessment is presently constrained to an artificially generated dataset (MovingMNIST) and a particular nowcasting dataset.It would enhance the paper to showcase how this model enhances video representations for tasks like categorizing human actions, in common video datasets. "
        }
    ]
}