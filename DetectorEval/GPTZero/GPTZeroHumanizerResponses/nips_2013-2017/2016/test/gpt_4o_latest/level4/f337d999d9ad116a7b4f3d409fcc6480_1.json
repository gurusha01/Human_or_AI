{
    "version": "2025-03-13-base",
    "scanId": "b0cc340e-cd69-4b89-854b-07b509d06a87",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999950528144836,
                    "sentence": "This research paper presents a regression model that aims to predict neural connections based on viral tracing data using various techniques such as nonnegativity constraint and spatial smoothness regularization along, with a low rank assumption and masking mechanism to handle uncertainty at the injection site effectively.The authors have successfully applied these methods to analyze tracer data and infer the connectivity patterns in an innovative way which contributes significantly to addressing a challenging scientific issue.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999954104423523,
                    "sentence": "The primary model involves a linear regression formula; y equals W times x plus Î·; where Î· is selected from a Gaussian distribution in a spherical shape.The matrix of weights denoted as W is limited to negative values and is represented probabilistically with a smooth prior that is spatially oriented.Additionally the model permits an assumption of low rank on the weight matrix which can greatly improve memory effectiveness, in extensive scenarios.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999954700469971,
                    "sentence": "While each component of this framework ( regression Laplacian regularized least squares, low rank constraints) has a strong foundation in existing literature this paper offers a comprehensive exploration and practical implementation of these techniques in addressing real world challenges.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958872795105,
                    "sentence": "The explanation of the model the simulated tests and the practical uses (, with video content) are notably lucid and effectively communicated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999919533729553,
                    "sentence": "When creating a function that considers both the error in reconstruction and the specific constraints of a domain directly could be reasonable; looking at it from a standpoint might uncover new possibilities and ties to existing research paths.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999874234199524,
                    "sentence": "For example Jonas and Kording tackled a connectomics issue by suggesting a model that's generative and probabilistic with hidden variables for every neuron.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999908804893494,
                    "sentence": "Even though their method focuses on modeling instead of regression like yours does the shared set of hidden variables could potentially act as a base, for your weight matrix.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999904036521912,
                    "sentence": "Moreover from a perspective the Gaussian noise model might not accurately represent the nonnegative aspect of fluorescence readings While assuming spherical covariance may be too limiting These simplifications can aid in computational efficiency and reasoning but require more, in depth exploration Lastly the orthogonal projector P_{Omega} seems to needlessly complicate the description by stating that the loss function focuses solely on visible voxels.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999808073043823,
                    "sentence": "Sorry I can't do that.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999765157699585,
                    "sentence": "The text, in Figure 3 is hard to decipher.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999786019325256,
                    "sentence": "Jonas et al.s study titled \"Automated Identification of Cell Types and Microcircuits, from Neural Connectomics\" was published by eLife journal backin 2015 with the reference e04250.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.999994651068609,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 5.348931391009438e-06,
                        "ai_paraphrased": 0.999994651068609
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 5.3488313910094685e-06,
                            "ai_paraphrased": 0.999994651068609
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This research paper presents a regression model that aims to predict neural connections based on viral tracing data using various techniques such as nonnegativity constraint and spatial smoothness regularization along, with a low rank assumption and masking mechanism to handle uncertainty at the injection site effectively.The authors have successfully applied these methods to analyze tracer data and infer the connectivity patterns in an innovative way which contributes significantly to addressing a challenging scientific issue. The primary model involves a linear regression formula; y equals W times x plus Î·; where Î· is selected from a Gaussian distribution in a spherical shape.The matrix of weights denoted as W is limited to negative values and is represented probabilistically with a smooth prior that is spatially oriented.Additionally the model permits an assumption of low rank on the weight matrix which can greatly improve memory effectiveness, in extensive scenarios. While each component of this framework ( regression Laplacian regularized least squares, low rank constraints) has a strong foundation in existing literature this paper offers a comprehensive exploration and practical implementation of these techniques in addressing real world challenges. The explanation of the model the simulated tests and the practical uses (, with video content) are notably lucid and effectively communicated. \nWhen creating a function that considers both the error in reconstruction and the specific constraints of a domain directly could be reasonable; looking at it from a standpoint might uncover new possibilities and ties to existing research paths. For example Jonas and Kording tackled a connectomics issue by suggesting a model that's generative and probabilistic with hidden variables for every neuron. Even though their method focuses on modeling instead of regression like yours does the shared set of hidden variables could potentially act as a base, for your weight matrix. Moreover from a perspective the Gaussian noise model might not accurately represent the nonnegative aspect of fluorescence readings While assuming spherical covariance may be too limiting These simplifications can aid in computational efficiency and reasoning but require more, in depth exploration Lastly the orthogonal projector P_{Omega} seems to needlessly complicate the description by stating that the loss function focuses solely on visible voxels. \nSorry I can't do that. \nThe text, in Figure 3 is hard to decipher. \nJonas et al.s study titled \"Automated Identification of Cell Types and Microcircuits, from Neural Connectomics\" was published by eLife journal backin 2015 with the reference e04250. "
        }
    ]
}