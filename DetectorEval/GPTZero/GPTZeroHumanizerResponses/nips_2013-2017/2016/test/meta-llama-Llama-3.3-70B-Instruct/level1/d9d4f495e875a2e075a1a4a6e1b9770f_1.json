{
    "version": "2025-03-13-base",
    "scanId": "e1b844af-345b-45d7-a0de-6994ea4fd380",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999987483024597,
                    "sentence": "This research paper introduces a method for predicting videos tailored for interactive agents like robots.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986886978149,
                    "sentence": "The authors suggest a video prediction model that considers actions and pixel motion to anticipate movements of objects not encountered before.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999985694885254,
                    "sentence": "The model undergoes training using a dataset of robot interactions comprising 59K sequences with 1..500K video frames.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979734420776,
                    "sentence": "Experiments show that this approach surpasses top performing methods, in both the quality and accuracy of video predictions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980926513672,
                    "sentence": "The paper is nicely written with an concise summary of the research done by the authors where they discuss the drawbacks of current methods and the innovations their approach brings to the table.T hey have explained the aspects of their model well and have described their experiments in detail.The outcomes are quite remarkable as they demonstrate that the model can accurately forecast video sequences beyond 10 time steps, into the future.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998152256012,
                    "sentence": "The papers notable qualities are;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999984502792358,
                    "sentence": "A new strategy, for video prediction has been put forward that focuses on representing pixel movement to enable predicting movements of unfamiliar objects.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982714653015,
                    "sentence": "\"The accumulation of a substantial database documenting robot interactions represents an advancement, in this field.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999980926513672,
                    "sentence": "In depth assessment of the suggested approach, with a comparison to previously established cutting edge methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999974966049194,
                    "sentence": "The writing style is straightforward and easy to understand in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998152256012,
                    "sentence": "The paper has some shortcomings, such, as;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982714653015,
                    "sentence": "Over time the models effectiveness diminishes as more uncertainty is encountered in the future.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986886978149,
                    "sentence": "The model doesn't directly capture an object centered depiction that could be a potentially fruitful avenue, for future exploration.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999845623970032,
                    "sentence": "The paper would be more informative with exploration of the possible practical uses of the suggested approach, beyond just video forecasting tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999801516532898,
                    "sentence": "In favor of acceptance proponents make points.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999818801879883,
                    "sentence": "The article introduces an important addition, to the realm of video prediction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999836087226868,
                    "sentence": "The experiments show that the new method works better, than cutting edge techniques.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999767541885376,
                    "sentence": "The paper is nicely.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999800324440002,
                    "sentence": "The authors offer a straightforward and concise summary of the relevant research and technical aspects.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999791979789734,
                    "sentence": "Reasons to consider accepting;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999619722366333,
                    "sentence": "Over time the models effectiveness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999768137931824,
                    "sentence": "This may restrict its usefulness, in specific situations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999560713768005,
                    "sentence": "The paper would be enhanced by exploring the possible practical uses of the method being suggested.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999789595603943,
                    "sentence": "The model may have a drawback in that it does not directly capture an object focused representation within it that could be essential, for specific tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999880790710449,
                    "sentence": "In my opinion; the paper makes an addition to the area of video forecasting and interactive agents and I suggest accepting it as it shows promise for broad usage; also creating a comprehensive database of robot interactions is a notable advancement, in this field; with some small adjustments to tackle the identified shortcomings; the paper could become even more robust.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997938739332978,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997938739332978,
                "mixed": 0.00020612606670239523
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997938739332978,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997938739332978,
                    "human": 0,
                    "mixed": 0.00020612606670239523
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999772594501086,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 2.2740549891263023e-05,
                        "ai_paraphrased": 0.9999772594501086
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 2.2740449891263054e-05,
                            "ai_paraphrased": 0.9999772594501086
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This research paper introduces a method for predicting videos tailored for interactive agents like robots. The authors suggest a video prediction model that considers actions and pixel motion to anticipate movements of objects not encountered before. The model undergoes training using a dataset of robot interactions comprising 59K sequences with 1..500K video frames. Experiments show that this approach surpasses top performing methods, in both the quality and accuracy of video predictions. \nThe paper is nicely written with an concise summary of the research done by the authors where they discuss the drawbacks of current methods and the innovations their approach brings to the table.T hey have explained the aspects of their model well and have described their experiments in detail.The outcomes are quite remarkable as they demonstrate that the model can accurately forecast video sequences beyond 10 time steps, into the future. \nThe papers notable qualities are; \nA new strategy, for video prediction has been put forward that focuses on representing pixel movement to enable predicting movements of unfamiliar objects. \n\"The accumulation of a substantial database documenting robot interactions represents an advancement, in this field.\"\nIn depth assessment of the suggested approach, with a comparison to previously established cutting edge methods. \nThe writing style is straightforward and easy to understand in the paper. \nThe paper has some shortcomings, such, as; \nOver time the models effectiveness diminishes as more uncertainty is encountered in the future. \nThe model doesn't directly capture an object centered depiction that could be a potentially fruitful avenue, for future exploration. \nThe paper would be more informative with exploration of the possible practical uses of the suggested approach, beyond just video forecasting tasks. \nIn favor of acceptance proponents make points.\nThe article introduces an important addition, to the realm of video prediction. \nThe experiments show that the new method works better, than cutting edge techniques. \nThe paper is nicely. The authors offer a straightforward and concise summary of the relevant research and technical aspects. \nReasons to consider accepting; \nOver time the models effectiveness. This may restrict its usefulness, in specific situations. \nThe paper would be enhanced by exploring the possible practical uses of the method being suggested. \nThe model may have a drawback in that it does not directly capture an object focused representation within it that could be essential, for specific tasks. \nIn my opinion; the paper makes an addition to the area of video forecasting and interactive agents and I suggest accepting it as it shows promise for broad usage; also creating a comprehensive database of robot interactions is a notable advancement, in this field; with some small adjustments to tackle the identified shortcomings; the paper could become even more robust. "
        }
    ]
}