{
    "version": "2025-03-13-base",
    "scanId": "c289e1a2-d273-4cfa-ab45-656dbe52f5dc",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999954700469971,
                    "sentence": "This study explores how a linear loss minimization challenge converges when trying to determine the settings of a universal ranking model based on graphs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999955296516418,
                    "sentence": "The model involves a walk influenced by node and edge weights determined through random walks using node and edge features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999954700469971,
                    "sentence": "Existing methods that rely on evaluations of the objective function are inadequate, for solving this optimization problem.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933838844299,
                    "sentence": "To overcome this limitation the authors suggest a two tiered strategy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999946355819702,
                    "sentence": "In the stage of their work they utilize a technique that gradually approaches the stable distribution of the Markov random walk process.The effectiveness of this approach is confirmed by the authors as they prove that the loss function value can be estimated accurately to any specified level of precision.Furthermore the researchers introduce a method based on gradients for tackling general optimization challenges with constraints that're not convex by nature.Utilizing an oracle in this process the researchers demonstrate its convergence towards reaching a stationary point, in addressing the problem at hand.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999994695186615,
                    "sentence": "The main significance is in adjusting the suggested method for situations of optimization where the functions value can only be calculated with a specific level of accuracy well known, to you beforehand.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999929070472717,
                    "sentence": "The writers establish the progression of this technique.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999931454658508,
                    "sentence": "Incorporate it into the second tier of their procedure.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999921321868896,
                    "sentence": "The document is nicely.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999993622303009,
                    "sentence": "The demonstrations seem sound; however I haven't thoroughly checked all of them myself.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999942183494568,
                    "sentence": "I am primarily worried that the methods for improving performance mentioned are mostly variations of those presented in a publication by Yurii Nesterov and Vladimir Spokoiny titled \"Random Gradient Free Minimization of Convex Functions\" from 2015 in Foundations of Computational Mathematics and the supervised PageRank algorithm has also been suggested before this study was conducted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999949336051941,
                    "sentence": "Additionally it might be helpful to add a section, to the paper since there is plenty of room for it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999942183494568,
                    "sentence": "In addition, to that suggestion I would advise putting the optimization issue in a perspective by portraying the analyzed algorithm as a particular case study This approach would enhance the placement of the innovation within the wider current practices and advancements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 13,
                    "completely_generated_prob": 0.9448919484304374
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999983908495903,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 1.6091504095915443e-06,
                        "ai_paraphrased": 0.9999983908495903
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 1.6090504095915743e-06,
                            "ai_paraphrased": 0.9999983908495903
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This study explores how a linear loss minimization challenge converges when trying to determine the settings of a universal ranking model based on graphs. The model involves a walk influenced by node and edge weights determined through random walks using node and edge features. Existing methods that rely on evaluations of the objective function are inadequate, for solving this optimization problem. To overcome this limitation the authors suggest a two tiered strategy. In the stage of their work they utilize a technique that gradually approaches the stable distribution of the Markov random walk process.The effectiveness of this approach is confirmed by the authors as they prove that the loss function value can be estimated accurately to any specified level of precision.Furthermore the researchers introduce a method based on gradients for tackling general optimization challenges with constraints that're not convex by nature.Utilizing an oracle in this process the researchers demonstrate its convergence towards reaching a stationary point, in addressing the problem at hand. The main significance is in adjusting the suggested method for situations of optimization where the functions value can only be calculated with a specific level of accuracy well known, to you beforehand. The writers establish the progression of this technique. Incorporate it into the second tier of their procedure. The document is nicely. The demonstrations seem sound; however I haven't thoroughly checked all of them myself. I am primarily worried that the methods for improving performance mentioned are mostly variations of those presented in a publication by Yurii Nesterov and Vladimir Spokoiny titled \"Random Gradient Free Minimization of Convex Functions\" from 2015 in Foundations of Computational Mathematics and the supervised PageRank algorithm has also been suggested before this study was conducted. Additionally it might be helpful to add a section, to the paper since there is plenty of room for it. In addition, to that suggestion I would advise putting the optimization issue in a perspective by portraying the analyzed algorithm as a particular case study This approach would enhance the placement of the innovation within the wider current practices and advancements. "
        }
    ]
}