{
    "version": "2025-03-13-base",
    "scanId": "d35dce18-a39c-4e0d-a3b3-85a718818ba7",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9998742341995239,
                    "sentence": "The authors use approximations to find nearest neighbors and select top K values to calculate attention weights in a Neural Turing Machine system.They conducted experiments that show this method does not hinder training performance but actually allows for training with problems.While this work may not be groundbreaking.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99981290102005,
                    "sentence": "Refer to section 3 of the memory networks paper (http;//arxiv.org/pdf /1410.3916.pdf).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998424649238586,
                    "sentence": "There are studies using memory networks now employing millions of memory items and hashing methods, for efficient searches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997075200080872,
                    "sentence": "However I haven't seen these methods used in writing memories !",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997290968894958,
                    "sentence": "While this paper might not be a groundbreaking concept the actual application and effectiveness of these techniques are worth noting and should be published for sure!",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994034171104431,
                    "sentence": "So my suggestion would be to accept the paper with a revisions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998626112937927,
                    "sentence": "The paper doesn't provide information for others to replicate its findings easily due to insufficient details in describing the tasks involved.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999900221824646,
                    "sentence": "Since the task code, from the NTM paper hasn't been made available and there isn't a standardized version of these tasks it's crucial for the authors to offer detailed explanations of how the tasks were formulated.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998970627784729,
                    "sentence": "Moreover I encourage the authors to make their experiment code accessible to enhance reproducibility.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999197721481323,
                    "sentence": "The paper doesn't fully cover the drawbacks of the suggested method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999225735664368,
                    "sentence": "What situations cause the approach to fail.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999140501022339,
                    "sentence": "Does it consistently meet expectations?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999229311943054,
                    "sentence": "Even though the authors portray their model as seamless it's crucial to highlight that the argmax (or Kargmax operation isn't inherently seamless.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999906420707703,
                    "sentence": "For instance when $ K $ is set to o̲n̲e̲ in the scenario that limits modifications to read only mode their approach is quite similar to the MemNN.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999927282333374,
                    "sentence": "WSH technique mentioned in a document found at http;//arxiv.org/pdf/.150030_880900.pdf (although without hashing) a method that was found to be less efficient than fully smooth models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999908804893494,
                    "sentence": "The question arises whether this difference in performance is due to the one modification limit or the specific nature of the tasks at hand.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999909400939941,
                    "sentence": "Conduct ing an, in depth examination of scenarios and exploring which types of tasks or configurations lead to successful training would greatly enhance the papers overall quality.The model created by the authors includes making choices during training without clearly accounting for them (unlike the method discussed in http;//arxiv.org./abs1511 07275).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999876618385315,
                    "sentence": "Though their ability to produce results using this approach is progress it's crucial to gain a deeper insight into the models constraints and the circumstances, in which it thrives or falters.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999790191650391,
                    "sentence": "I suggest that the authors consider removing section 3 from the paper and avoid categorizing the omniglot dataset, as \"non synthetic\" or \"real world.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.9000234362273952
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 9,
                    "completely_generated_prob": 0.9257822263275673
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997932945046398,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997932945046398,
                "mixed": 0.00020670549536025372
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997932945046398,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997932945046398,
                    "human": 0,
                    "mixed": 0.00020670549536025372
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999878351321968,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 1.2164867803126646e-05,
                        "ai_paraphrased": 0.9999878351321968
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 1.2164767803126677e-05,
                            "ai_paraphrased": 0.9999878351321968
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "The authors use approximations to find nearest neighbors and select top K values to calculate attention weights in a Neural Turing Machine system.They conducted experiments that show this method does not hinder training performance but actually allows for training with problems.While this work may not be groundbreaking. Refer to section 3 of the memory networks paper (http;//arxiv.org/pdf /1410.3916.pdf). There are studies using memory networks now employing millions of memory items and hashing methods, for efficient searches. However I haven't seen these methods used in writing memories ! While this paper might not be a groundbreaking concept the actual application and effectiveness of these techniques are worth noting and should be published for sure! So my suggestion would be to accept the paper with a revisions. \nThe paper doesn't provide information for others to replicate its findings easily due to insufficient details in describing the tasks involved. Since the task code, from the NTM paper hasn't been made available and there isn't a standardized version of these tasks it's crucial for the authors to offer detailed explanations of how the tasks were formulated. Moreover I encourage the authors to make their experiment code accessible to enhance reproducibility. \nThe paper doesn't fully cover the drawbacks of the suggested method. What situations cause the approach to fail. Does it consistently meet expectations? Even though the authors portray their model as seamless it's crucial to highlight that the argmax (or Kargmax operation isn't inherently seamless. For instance when $ K $ is set to o̲n̲e̲ in the scenario that limits modifications to read only mode their approach is quite similar to the MemNN. WSH technique mentioned in a document found at http;//arxiv.org/pdf/.150030_880900.pdf (although without hashing) a method that was found to be less efficient than fully smooth models. The question arises whether this difference in performance is due to the one modification limit or the specific nature of the tasks at hand. Conduct ing an, in depth examination of scenarios and exploring which types of tasks or configurations lead to successful training would greatly enhance the papers overall quality.The model created by the authors includes making choices during training without clearly accounting for them (unlike the method discussed in http;//arxiv.org./abs1511 07275). Though their ability to produce results using this approach is progress it's crucial to gain a deeper insight into the models constraints and the circumstances, in which it thrives or falters. \nI suggest that the authors consider removing section 3 from the paper and avoid categorizing the omniglot dataset, as \"non synthetic\" or \"real world.\""
        }
    ]
}