{
    "version": "2025-03-13-base",
    "scanId": "c8f76d7b-a6a9-4338-b48a-e61ecc319f62",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999797940254211,
                    "sentence": "This paper suggests an approach called 3DGAN (Three Dimensional Generative Adversarial Network) to produce 3 dimensional objects from a probabilistic framework by utilizing the latest advancements in volumetric convolutional networks and generative adversarial networks (GANs).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999797940254211,
                    "sentence": "Additionally the study presents 3DVaeGAN as an expansion of 3DGAN to learn how to convert a 2 image into a 3 dimensional object.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999775290489197,
                    "sentence": "The core concepts discussed in this paper revolve around the exploration of 3 object creation and generation through the utilization of generative adversarial networks (GANs).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999653697013855,
                    "sentence": "The authors have built their 3 GAN framework by building off the research conducted by Goodfellow and Radford in 2014 and 2016 respectively as well as contrasting their outcomes with studies, by Wu and Girdhar from previous years.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999403953552246,
                    "sentence": "This paper excels in producing notch 3 dimensional shapes and introduces an innovative method for translating a 2 dimensional image into a 3 dimensional object successfully while displaying outstanding results in identifying 3 dimensional objects tasks effectively by the way it presents an elaborate examination of the acquired representations such as visual representations showing the object vector and neurons, in the discriminator.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999681115150452,
                    "sentence": "The papers limitations stem from its dependence on a dataset of 3 dimensional objects that might not be easily accessible for all uses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999693632125854,
                    "sentence": "Furthermore the authors acknowledge the difficulty, in training the discriminator within their 3 GAN framework and address this by implementing an adaptive training approach to enhance the stability of the training process.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999553561210632,
                    "sentence": "Points supporting acceptance;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999728798866272,
                    "sentence": "The research paper suggests an inventive method, for creating and identifying 3 dimensional objects.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999650716781616,
                    "sentence": "The findings show results in recognizing 3 dimensional objects that are on par, with the performance of supervised learning approaches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999592900276184,
                    "sentence": "The writers offer an, in depth examination of the acquired knowledge representations that offer a glimpse into how the model operates.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999710917472839,
                    "sentence": "The article is nicely composed and well structured.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9970338940620422,
                    "sentence": "It's simple to track and grasp the information presented in it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9979404807090759,
                    "sentence": "Reasons, in favor of acceptance;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9978270530700684,
                    "sentence": "The report is based on a collection of 3 dimensional objects that might not be easily accessible, for every use case.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974838495254517,
                    "sentence": "Working through the training process can pose challenges; therefore the authors utilize a training approach to ensure stability in the training process.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9976359605789185,
                    "sentence": "The paper could be improved by including comparisons with other leading techniques, in 3 dimensional object recognition and creation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9966933727264404,
                    "sentence": "This study greatly advances our understanding of creating and identifying 3 objects with remarkable success, across various tasks mentioned in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9961806535720825,
                    "sentence": "The research paper is solid in terms of its aspects and is backed up by thorough theoretical analysis and practical results that support the arguments made in it The authors show meticulousness and integrity, in their assessment of both the positive aspects and limitations of their study.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9955176711082458,
                    "sentence": "The paper is written in an organized manner which makes it easy to comprehend and navigate through its content smoothly; the authors have included ample information, for a knowledgeable reader to replicate the results.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9963901042938232,
                    "sentence": "The research introduces a method for creating and identifying 3 dimensional objects with remarkable success across various assignments The writers incorporate past studies, on generative adversarial networks and 3 dimensional object design but introduce their unique and groundbreaking technique.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9963272213935852,
                    "sentence": "The research paper tackles an issue related to creating and identifying 3 dimensional objects, with notable advancements surpassing existing cutting edge techniques showcased in the findings presented within its pages It possesses the capability to influence various fields of application including computer vision robotics and graphics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997932945046396,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997932945046396,
                "mixed": 0.00020670549536025372
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997932945046396,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997932945046396,
                    "human": 0,
                    "mixed": 0.00020670549536025372
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999829465120222,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 1.705348797783709e-05,
                        "ai_paraphrased": 0.9999829465120222
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 1.705338797783712e-05,
                            "ai_paraphrased": 0.9999829465120222
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This paper suggests an approach called 3DGAN (Three Dimensional Generative Adversarial Network) to produce 3 dimensional objects from a probabilistic framework by utilizing the latest advancements in volumetric convolutional networks and generative adversarial networks (GANs). Additionally the study presents 3DVaeGAN as an expansion of 3DGAN to learn how to convert a 2 image into a 3 dimensional object. \nThe core concepts discussed in this paper revolve around the exploration of 3 object creation and generation through the utilization of generative adversarial networks (GANs). The authors have built their 3 GAN framework by building off the research conducted by Goodfellow and Radford in 2014 and 2016 respectively as well as contrasting their outcomes with studies, by Wu and Girdhar from previous years. \nThis paper excels in producing notch 3 dimensional shapes and introduces an innovative method for translating a 2 dimensional image into a 3 dimensional object successfully while displaying outstanding results in identifying 3 dimensional objects tasks effectively by the way it presents an elaborate examination of the acquired representations such as visual representations showing the object vector and neurons, in the discriminator. \nThe papers limitations stem from its dependence on a dataset of 3 dimensional objects that might not be easily accessible for all uses. Furthermore the authors acknowledge the difficulty, in training the discriminator within their 3 GAN framework and address this by implementing an adaptive training approach to enhance the stability of the training process. \nPoints supporting acceptance; \nThe research paper suggests an inventive method, for creating and identifying 3 dimensional objects. \nThe findings show results in recognizing 3 dimensional objects that are on par, with the performance of supervised learning approaches. \nThe writers offer an, in depth examination of the acquired knowledge representations that offer a glimpse into how the model operates. \nThe article is nicely composed and well structured. It's simple to track and grasp the information presented in it. \nReasons, in favor of acceptance; \nThe report is based on a collection of 3 dimensional objects that might not be easily accessible, for every use case. \nWorking through the training process can pose challenges; therefore the authors utilize a training approach to ensure stability in the training process. \nThe paper could be improved by including comparisons with other leading techniques, in 3 dimensional object recognition and creation. \nThis study greatly advances our understanding of creating and identifying 3 objects with remarkable success, across various tasks mentioned in the paper. \nThe research paper is solid in terms of its aspects and is backed up by thorough theoretical analysis and practical results that support the arguments made in it The authors show meticulousness and integrity, in their assessment of both the positive aspects and limitations of their study. \nThe paper is written in an organized manner which makes it easy to comprehend and navigate through its content smoothly; the authors have included ample information, for a knowledgeable reader to replicate the results. \nThe research introduces a method for creating and identifying 3 dimensional objects with remarkable success across various assignments The writers incorporate past studies, on generative adversarial networks and 3 dimensional object design but introduce their unique and groundbreaking technique. \nThe research paper tackles an issue related to creating and identifying 3 dimensional objects, with notable advancements surpassing existing cutting edge techniques showcased in the findings presented within its pages It possesses the capability to influence various fields of application including computer vision robotics and graphics. "
        }
    ]
}