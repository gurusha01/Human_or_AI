{
    "version": "2025-03-13-base",
    "scanId": "8795c17a-d67c-4709-9ee5-45e76322f704",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999892711639404,
                    "sentence": "This paper introduces a method, for Bayesian Optimization called the batch sequence approach and a variant of the Knowledge Gradient criterion named q Knowledge Gradient criterion after discussing related research and Gaussian processes in depth.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999889731407166,
                    "sentence": "The authors describe the q Knowledge Gradient criterion and explain its computational aspects similarly to the standard Knowledge Gradient criterion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999889135360718,
                    "sentence": "Additionally the study includes tests that show the effectiveness of q Knowledge Gradient compared to other advanced batch sequence Bayesian Optimization methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999825358390808,
                    "sentence": "This paper is really well.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999872446060181,
                    "sentence": "Deserves to be published in NIPS because of its potential to make a significant impact on society by advancing parallelization in Bayesian optimization algorithms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999986469745636,
                    "sentence": "However there are a couple of critiques; The paper could explore speed improvements from transitioning from sequential to batch sequence methods and there are some inaccuracies, in the literature reviews statements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999906420707703,
                    "sentence": "For example \" Krigging is found to be suitable for optimizing in parallel\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999915361404419,
                    "sentence": "Chevalier et al.s study of CL mix previously investigated integrating Expected Improvement based on posterior distributions.Natural gradient was utilized for maximizing q EI in the study \"Enhancing the multipoint Expected Improvement, for batch design\".Furthermore the study raises questions and comments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999829530715942,
                    "sentence": "Are sets A.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999938011169434,
                    "sentence": "Function f both compact and continuous?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999919533729553,
                    "sentence": "Why is it important to limit A to a Latin Hypercube Sample at the beginning?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999930262565613,
                    "sentence": "Does Algorithm 1 consider adjusting hyperparameters or updating using an approach?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999886751174927,
                    "sentence": "In Section 5 of the material provided to us on in the document that we've been reviewing together for a while now.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999902844429016,
                    "sentence": "It's a real page turner!.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999910593032837,
                    "sentence": "Do you think that the main goal of defining g is, about maximizing something or minimizing it instead?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999901056289673,
                    "sentence": "The clarity of the function g and the rate of change of the Cholesky factor might not be obvious, at first.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999896883964539,
                    "sentence": "Could benefit from further explanation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999895095825195,
                    "sentence": "It's probably like 1 and 1 over 3 than 3 over 7, for the Mat√©rn parameter.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999912977218628,
                    "sentence": "Could we fit the Gaussian processes in Figure 1 and the related experiments using various software packages instead?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 8,
                    "completely_generated_prob": 0.9187750751329665
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999979393717329,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 2.060628267144264e-06,
                        "ai_paraphrased": 0.9999979393717329
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 2.060528267144294e-06,
                            "ai_paraphrased": 0.9999979393717329
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This paper introduces a method, for Bayesian Optimization called the batch sequence approach and a variant of the Knowledge Gradient criterion named q Knowledge Gradient criterion after discussing related research and Gaussian processes in depth. The authors describe the q Knowledge Gradient criterion and explain its computational aspects similarly to the standard Knowledge Gradient criterion. Additionally the study includes tests that show the effectiveness of q Knowledge Gradient compared to other advanced batch sequence Bayesian Optimization methods. This paper is really well. Deserves to be published in NIPS because of its potential to make a significant impact on society by advancing parallelization in Bayesian optimization algorithms. However there are a couple of critiques; The paper could explore speed improvements from transitioning from sequential to batch sequence methods and there are some inaccuracies, in the literature reviews statements. For example \" Krigging is found to be suitable for optimizing in parallel\". Chevalier et al.s study of CL mix previously investigated integrating Expected Improvement based on posterior distributions.Natural gradient was utilized for maximizing q EI in the study \"Enhancing the multipoint Expected Improvement, for batch design\".Furthermore the study raises questions and comments.  \nAre sets A. Function f both compact and continuous? \nWhy is it important to limit A to a Latin Hypercube Sample at the beginning? \nDoes Algorithm 1 consider adjusting hyperparameters or updating using an approach? \nIn Section 5 of the material provided to us on in the document that we've been reviewing together for a while now. It's a real page turner!. Do you think that the main goal of defining g is, about maximizing something or minimizing it instead? \nThe clarity of the function g and the rate of change of the Cholesky factor might not be obvious, at first. Could benefit from further explanation. \nIt's probably like 1 and 1 over 3 than 3 over 7, for the Mat√©rn parameter. \nCould we fit the Gaussian processes in Figure 1 and the related experiments using various software packages instead? "
        }
    ],
    "editorDocumentId": null
}