{
    "version": "2025-03-13-base",
    "scanId": "e17ef1a3-550e-40cb-ba1e-d8a1343047f0",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9967048764228821,
                    "sentence": "This document introduces a method for supervised metric learning that uses the \"word movers distance\" [19] a transport distance that works with word embeddings from word2vec models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9980639815330505,
                    "sentence": "The new technique is flexible.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9970952868461609,
                    "sentence": "Can be used with any transport distance that relies on squared Euclidean distances following linear projection.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9975513219833374,
                    "sentence": "Besides refining performance, through learning the projection technique the method also develops a specific weighting system for individual words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9971347451210022,
                    "sentence": "This method of assigning weightings to words for document purposes entails adjusting the frequency of each word based on a calculated weight and then standardizing the word frequencies again afterward This paper presents an optimization technique for determining the values of the new metric suggested by the authors A thorough set of experiments showcases how well this approach works as it is tested against baseline methods, across multiple document sorting datasets using a kNN classifier built on the newly developed metric",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9977625012397766,
                    "sentence": "The research presents an practical expansion of the latest word movers distance method by demonstrating its efficiency in different kNN text categorization assignments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9974362254142761,
                    "sentence": "Nonetheless the impact could be restrained since a earth movers distance utilizing learning through a \"word centroid distance\" setup attains comparable outcomes, to the completely learned proposed distance as noted in the last two sections of Table 3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9980321526527405,
                    "sentence": "This implies that the primary technical advancements may not notably boost performance beyond the starting method grounded on established approaches.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999921977519989,
                    "sentence": "The assessment provided in Table 3 does not include a comparison between the \"word centroid embedding,\" which's the weighted average of word embeddings for the document and other metric learning methods like ITML and LMNN NCA.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999122619628906,
                    "sentence": "Additionally it's important to analyze how significant the individual word weights and projection matrix A are in this context.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999002814292908,
                    "sentence": "It would be helpful to test the impact of having each of these components active separately, on performance metrics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998912811279297,
                    "sentence": "The uniqueness of the document mainly comes from enhancing the measurement (Lines 156.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998658895492554,
                    "sentence": "175).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999859631061554,
                    "sentence": "The idea of metric learning in the earth movers distance is fascinating but offers a restricted contribution, on its own merit.The paper is well crafted and engaging to read; however there are a small points that need further explanation;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998592734336853,
                    "sentence": "Line 152 mentions \"The authors,\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998704195022583,
                    "sentence": "It doesn't specify which paper they are referring to (perhaps [references 2 and 3]?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999388456344604,
                    "sentence": ").",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997904896736145,
                    "sentence": "Equation 11 might need alpha and beta to have asterisks attached.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99989253282547,
                    "sentence": "It'd be useful if you specifically include near Line 170 that the optimization technique is relateds Sinkhorn scaling mentioned in Line 56 on.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9998684829252145,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.00013151707478551277,
                        "ai_paraphrased": 0.9998684829252145
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.00013151697478551279,
                            "ai_paraphrased": 0.9998684829252145
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This document introduces a method for supervised metric learning that uses the \"word movers distance\" [19] a transport distance that works with word embeddings from word2vec models. The new technique is flexible. Can be used with any transport distance that relies on squared Euclidean distances following linear projection. Besides refining performance, through learning the projection technique the method also develops a specific weighting system for individual words. This method of assigning weightings to words for document purposes entails adjusting the frequency of each word based on a calculated weight and then standardizing the word frequencies again afterward This paper presents an optimization technique for determining the values of the new metric suggested by the authors A thorough set of experiments showcases how well this approach works as it is tested against baseline methods, across multiple document sorting datasets using a kNN classifier built on the newly developed metric\nThe research presents an practical expansion of the latest word movers distance method by demonstrating its efficiency in different kNN text categorization assignments. Nonetheless the impact could be restrained since a earth movers distance utilizing learning through a \"word centroid distance\" setup attains comparable outcomes, to the completely learned proposed distance as noted in the last two sections of Table 3. This implies that the primary technical advancements may not notably boost performance beyond the starting method grounded on established approaches. \nThe assessment provided in Table 3 does not include a comparison between the \"word centroid embedding,\" which's the weighted average of word embeddings for the document and other metric learning methods like ITML and LMNN NCA. Additionally it's important to analyze how significant the individual word weights and projection matrix A are in this context. It would be helpful to test the impact of having each of these components active separately, on performance metrics. \nThe uniqueness of the document mainly comes from enhancing the measurement (Lines 156. 175). The idea of metric learning in the earth movers distance is fascinating but offers a restricted contribution, on its own merit.The paper is well crafted and engaging to read; however there are a small points that need further explanation;  \nLine 152 mentions \"The authors,\". It doesn't specify which paper they are referring to (perhaps [references 2 and 3]?).\nEquation 11 might need alpha and beta to have asterisks attached.\nIt'd be useful if you specifically include near Line 170 that the optimization technique is relateds Sinkhorn scaling mentioned in Line 56 on. "
        }
    ],
    "editorDocumentId": null
}