{
    "version": "2025-03-13-base",
    "scanId": "33e98500-1929-4967-b1eb-8bb7d23e9564",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999943971633911,
                    "sentence": "This document delves into the issue of interpreting barcode symbols in pictures by using a convolutional neural network (CNN).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958276748657,
                    "sentence": "The CNN is taught using data produced from an adversarial network (GAN) which is trained with unmarked images and includes a \"3D model.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999940395355225,
                    "sentence": "This model experiences learned alterations like blur effects and changes in lighting and background within the images it processes.The settings, for these alterations are fine tuned to trick the GAN discriminator.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999957084655762,
                    "sentence": "The CNN is trained using images created by the GAN and its effectiveness is evaluated against crafted features and training, with authentic images to showcase its superior decoding abilities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999940991401672,
                    "sentence": "While the suggested GAN design seems promising to me; I find the evaluation lacking in rigor which keeps me from giving my support to the papers findings.That being said it is striking that there was no comparison made with a GAN model making it challenging to gauge the advantages of this more organized approach.Furthermore it would be beneficial to explore the impact of merging generated and authentic images, on the objective.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999935626983643,
                    "sentence": "References that are important for detecting objects using images of 3 shapes can be found in the studies by Xingchao Peng and colleagues (ICCV 2015) as well as Francisco Mass and colleagues (CVPR 2016).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999949336051941,
                    "sentence": "These works showcase how similar ideas can be applied to problem areas beyond just decoding barcode markers on bees.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999947547912598,
                    "sentence": "While the current emphasis is on decoding barcode markers on bees which has its limitations in scope; applying this approach to fields like object detection from 3 dimensional models could enable more direct comparisons, with previous research efforts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999947547912598,
                    "sentence": "The writing in the paper could be clearer by improving the introduction to clearly state the papers contribution upfront.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999956488609314,
                    "sentence": "Some minor suggestions are to check the authenticity of the 3D model renders in Figure 3 and correct \"chapter\" to \"section\" on page 3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999959468841553,
                    "sentence": "It would also be helpful to specify the loss function used for the DCNN in Table 2 and provide an explanation, for the artifacts seen in the four images of Figure 9(a).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999978392647332,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 2.1607352668643782e-06,
                        "ai_paraphrased": 0.9999978392647332
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 2.160635266864408e-06,
                            "ai_paraphrased": 0.9999978392647332
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This document delves into the issue of interpreting barcode symbols in pictures by using a convolutional neural network (CNN). The CNN is taught using data produced from an adversarial network (GAN) which is trained with unmarked images and includes a \"3D model.\" This model experiences learned alterations like blur effects and changes in lighting and background within the images it processes.The settings, for these alterations are fine tuned to trick the GAN discriminator. The CNN is trained using images created by the GAN and its effectiveness is evaluated against crafted features and training, with authentic images to showcase its superior decoding abilities. \nWhile the suggested GAN design seems promising to me; I find the evaluation lacking in rigor which keeps me from giving my support to the papers findings.That being said it is striking that there was no comparison made with a GAN model making it challenging to gauge the advantages of this more organized approach.Furthermore it would be beneficial to explore the impact of merging generated and authentic images, on the objective. \nReferences that are important for detecting objects using images of 3 shapes can be found in the studies by Xingchao Peng and colleagues (ICCV 2015) as well as Francisco Mass and colleagues (CVPR 2016). These works showcase how similar ideas can be applied to problem areas beyond just decoding barcode markers on bees. While the current emphasis is on decoding barcode markers on bees which has its limitations in scope; applying this approach to fields like object detection from 3 dimensional models could enable more direct comparisons, with previous research efforts. \nThe writing in the paper could be clearer by improving the introduction to clearly state the papers contribution upfront. Some minor suggestions are to check the authenticity of the 3D model renders in Figure 3 and correct \"chapter\" to \"section\" on page 3. It would also be helpful to specify the loss function used for the DCNN in Table 2 and provide an explanation, for the artifacts seen in the four images of Figure 9(a)."
        }
    ],
    "editorDocumentId": null
}