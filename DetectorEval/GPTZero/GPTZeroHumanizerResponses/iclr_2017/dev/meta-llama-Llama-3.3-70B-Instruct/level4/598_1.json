{
    "version": "2025-03-13-base",
    "scanId": "a3a4e3d6-a0e5-4914-b50d-c3de4804afa5",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999924302101135,
                    "sentence": "This document introduces a system for recognizing speech that is based around a linear conditional random field approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999992847442627,
                    "sentence": "The node potentials in this system are calculated using a neural network (convnet) and the transition scores are based upon trained scalar values.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999927282333374,
                    "sentence": "Enough the convnet acoustic model produces scores for individual letters instead of phonemes, which reduces the need for specific expertise, during system training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999925494194031,
                    "sentence": "During the testing stage of the process various elements such as scores from a language model at the word level convolutional neural network node potentials learned transition scores between letters and a penalty for word insertions are combined to determine the possible word assumption.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999942779541016,
                    "sentence": "The model has the ability to be trained using input types, like raw audio waveforms, power spectra data or Mel Frequency Cepstral Coefficients (MFCC) using conditional maximum likelihood estimation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999993085861206,
                    "sentence": "The tests conducted on the Librispeech corpus show that the models accuracy stands at 7·two percent for the test set when utilizing MFCC features; it registers 9·four percent with power spectral features and 10·one percent, with the raw waveform data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999994695186615,
                    "sentence": "Here are areas where we excel;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999920725822449,
                    "sentence": "Creating a convnet from scratch using conditional maximum likelihood to achieve good results in an English speech recognition system with letter based acoustic models is quite interesting and shows promise, for future research endeavors.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999940991401672,
                    "sentence": "Areas, for improvement;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933838844299,
                    "sentence": "A notable aspect missing from the paper is the absence of background details and pertinent previous research that should be referenced.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999936819076538,
                    "sentence": "Besides the papers already mentioned on the authors should also take into account another noteworthy study, such as the 2016 Interspeech paper authored by Zhang and colleagues entitled \"Advancing End, to Esclate Speech Recognition through Deep Convolutional Neural Networks,\" which merits inclusion to bolster the papers thoroughness and precision.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.9000234362273952
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999979870259548,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 2.0129740451768632e-06,
                        "ai_paraphrased": 0.9999979870259548
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 2.012874045176893e-06,
                            "ai_paraphrased": 0.9999979870259548
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This document introduces a system for recognizing speech that is based around a linear conditional random field approach. The node potentials in this system are calculated using a neural network (convnet) and the transition scores are based upon trained scalar values. Enough the convnet acoustic model produces scores for individual letters instead of phonemes, which reduces the need for specific expertise, during system training. During the testing stage of the process various elements such as scores from a language model at the word level convolutional neural network node potentials learned transition scores between letters and a penalty for word insertions are combined to determine the possible word assumption. The model has the ability to be trained using input types, like raw audio waveforms, power spectra data or Mel Frequency Cepstral Coefficients (MFCC) using conditional maximum likelihood estimation. The tests conducted on the Librispeech corpus show that the models accuracy stands at 7·two percent for the test set when utilizing MFCC features; it registers 9·four percent with power spectral features and 10·one percent, with the raw waveform data. \nHere are areas where we excel; \nCreating a convnet from scratch using conditional maximum likelihood to achieve good results in an English speech recognition system with letter based acoustic models is quite interesting and shows promise, for future research endeavors. \nAreas, for improvement; \nA notable aspect missing from the paper is the absence of background details and pertinent previous research that should be referenced. Besides the papers already mentioned on the authors should also take into account another noteworthy study, such as the 2016 Interspeech paper authored by Zhang and colleagues entitled \"Advancing End, to Esclate Speech Recognition through Deep Convolutional Neural Networks,\" which merits inclusion to bolster the papers thoroughness and precision. "
        }
    ],
    "editorDocumentId": null
}