{
    "version": "2025-03-13-base",
    "scanId": "73d53f2d-36e0-422e-abfa-100651e08d43",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999871253967285,
                    "sentence": "The research paper introduces a creative model that uses a step, by step noise reduction technique to convert noise into model examples.The method involves a denoise process to diffusion based creative models but stands out in various important ways;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999870657920837,
                    "sentence": "The system uses a smaller amount of noise reduction processes which leads to a significant enhancement, in computational efficiency.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999872446060181,
                    "sentence": "In contrast to the diffusion method that goes backward in its process path directionwise initially jumps to q(z(t= 1)|x) and then continues forward in sync with the models trajectory instead of following a reverse path like the diffusion method does from t= T to t= 1.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999881386756897,
                    "sentence": "This structure allows the inference process to act as a minor disturbance around the generative model by nudging it closer, to the observed data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999986469745636,
                    "sentence": "Somewhat reminiscent of ladder networks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999892115592957,
                    "sentence": "It's worth mentioning that this model doesn't offer a way to estimate the log likelihood reliably.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999843835830688,
                    "sentence": "The concept discussed in this paper caught my attention and the visual output from the chain was quite impressive in terms of quality.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999854564666748,
                    "sentence": "The results of inpainting stood out to me especially because achieving one shot inpainting is usually not viable, within generative modeling frameworks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999871253967285,
                    "sentence": "However a persuasive comparison of log likelihood measures that doesn't depend on Parzen likelihood would make the argument more robust.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999890923500061,
                    "sentence": "The comments below offer an explanation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999825358390808,
                    "sentence": "Section 2;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7802900075912476,
                    "sentence": "The phrase \"theta zero also known as theta naught should be changed to \"theta zero's the.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.8817647695541382,
                    "sentence": "Speaking,\"theta(t)s value should be altered to \"theta(t)s value to become the.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7713154554367065,
                    "sentence": "\"We will be using the phrase 'which we will be doing' instead of 'what we will be using.'\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.7715310454368591,
                    "sentence": "I like how they figure out q(z to the power of 1 given x and then carry out inference following the generative chain in a similar way, to ladder networks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9863932132720947,
                    "sentence": "The sentence \"Q; Upon learning \" would be improved by adding a paragraph break to read as follows; \"Q; [paragraph break]\" Upon learning\".",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9879796504974365,
                    "sentence": "Section 4 paragraph 2;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9914872050285339,
                    "sentence": "The term \"master the art of reversing\" should be updated to \"master the art of reversing.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9948551058769226,
                    "sentence": "Section 4;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.988787055015564,
                    "sentence": "The phrase \"For each experiment\" has a mistake.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9863433837890625,
                    "sentence": "Needs to be changed to \"For each experiment.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9938260912895203,
                    "sentence": "The impact of the infusion rate, on the outcomes is uncertain.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9958681464195251,
                    "sentence": "Requires more exploration.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9971455931663513,
                    "sentence": "Section 5;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.996640682220459,
                    "sentence": "The claim that \"seems accurate in its models\" lacks support, from the evidence presented since it does not directly contrast with the findings of the Sohl Dickstein paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9973472356796265,
                    "sentence": "Figure 4 stands out.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9979917407035828,
                    "sentence": "Showcases intriguing findings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 25,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.8334993319023883,
            "class_probabilities": {
                "human": 0.16330659450764823,
                "ai": 0.8334993319023883,
                "mixed": 0.0031940735899633906
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.8334993319023883,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.8334993319023883,
                    "human": 0.16330659450764823,
                    "mixed": 0.0031940735899633906
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999218670563648,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 7.813294363524717e-05,
                        "ai_paraphrased": 0.9999218670563648
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 7.813284363524721e-05,
                            "ai_paraphrased": 0.9999218670563648
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "The research paper introduces a creative model that uses a step, by step noise reduction technique to convert noise into model examples.The method involves a denoise process to diffusion based creative models but stands out in various important ways; \nThe system uses a smaller amount of noise reduction processes which leads to a significant enhancement, in computational efficiency. \nIn contrast to the diffusion method that goes backward in its process path directionwise initially jumps to q(z(t= 1)|x) and then continues forward in sync with the models trajectory instead of following a reverse path like the diffusion method does from t= T to t= 1. This structure allows the inference process to act as a minor disturbance around the generative model by nudging it closer, to the observed data. Somewhat reminiscent of ladder networks. \nIt's worth mentioning that this model doesn't offer a way to estimate the log likelihood reliably. \nThe concept discussed in this paper caught my attention and the visual output from the chain was quite impressive in terms of quality. The results of inpainting stood out to me especially because achieving one shot inpainting is usually not viable, within generative modeling frameworks. However a persuasive comparison of log likelihood measures that doesn't depend on Parzen likelihood would make the argument more robust. \nThe comments below offer an explanation.\nSection 2; \nThe phrase \"theta zero also known as theta naught should be changed to \"theta zero's the.\"\nSpeaking,\"theta(t)s value should be altered to \"theta(t)s value to become the.\"\n\"We will be using the phrase 'which we will be doing' instead of 'what we will be using.'\"\n I like how they figure out q(z to the power of 1 given x and then carry out inference following the generative chain in a similar way, to ladder networks. \nThe sentence \"Q; Upon learning \" would be improved by adding a paragraph break to read as follows; \"Q; [paragraph break]\" Upon learning\".\nSection 4 paragraph 2; \nThe term \"master the art of reversing\" should be updated to \"master the art of reversing.\"\nSection 4; \nThe phrase \"For each experiment\" has a mistake. Needs to be changed to \"For each experiment.\"\nThe impact of the infusion rate, on the outcomes is uncertain. Requires more exploration. \nSection 5; \nThe claim that \"seems accurate in its models\" lacks support, from the evidence presented since it does not directly contrast with the findings of the Sohl Dickstein paper. \nFigure 4 stands out. Showcases intriguing findings. "
        }
    ],
    "editorDocumentId": null
}