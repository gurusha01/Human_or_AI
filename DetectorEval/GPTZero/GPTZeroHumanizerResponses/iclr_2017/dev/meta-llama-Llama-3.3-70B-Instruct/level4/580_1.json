{
    "version": "2025-03-13-base",
    "scanId": "9e6b64b5-c1dc-4617-ae38-18fb9049ae5b",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999832510948181,
                    "sentence": "The writers suggest a RNN design with linear features for language modeling to make the model easier to understand and possibly boost performance by storing frequently used sub sequence patterns.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999856352806091,
                    "sentence": "Even though the direct comparison with data is not impressive and lacks clear reasons for selecting the dataset along with a limited evaluation on a single dataset the authors show skillful methods, for studying model behavior by utilizing the linear features to gain insights that non linear RNN models cannot provide.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999855756759644,
                    "sentence": "In my opinion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999853372573853,
                    "sentence": "After considering the content of the paper closely enough to gauging its narrative appeal and valuable insights within the research field despite the less, than impressive outcomes mentioned earlier on in it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999841451644897,
                    "sentence": "Response;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999985933303833,
                    "sentence": "To improve the papers quality you might want to shorten the analysis experiments and delve deeper into discussing sequence models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999890923500061,
                    "sentence": "Some experiments, like 4.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999849796295166,
                    "sentence": "5 Seem more about showcasing how well the model can match the data than uncovering crucial characteristics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999852180480957,
                    "sentence": "With the decent perplexity outcomes it seems likely that the model effectively captures the data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999874234199524,
                    "sentence": "Exploring how LSTMs and GRUs fare against linear methods when handling data with complex structures such as nested parentheses could yield valuable insights even if the outcomes are not favorable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999821782112122,
                    "sentence": "It could shed light on the benefits of non linear methods, in tackling such tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999799728393555,
                    "sentence": "In the section, about researches should talk about Belanger and Kakades (2015) work as well.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999973475933075,
                    "sentence": "They use linear dynamics but emphasize quick and adaptable learning methods instead They looked at the singular vectors of the transition matrix which can be contrasted with what the authors did.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999971866607666,
                    "sentence": "Directly discussing Linear Dynamical Systems (LDS) in detail could be helpful for readers by delving into the comparisons that came up during the open review conversation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999719858169556,
                    "sentence": "One way to enhance understanding could be to highlight the connection between bias vectors and the columns of the Kalman gain matrix.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999975860118866,
                    "sentence": "Moreover consider looking into integrating Kalman smoothing, as an expansion, which involves estimating state vectors based on both past and future observations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999692440032959,
                    "sentence": "To improve interpretability and scalability for word level problems, in your text data analysis approach you may want to explore the concept of parameter sharing by representing each matrix as a combination of matrices that are sparse or convex in nature.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999972939491272,
                    "sentence": "This method can allow for characters to be represented as weights combining elements leading to a more understandable and potentially more scalable solution.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.9997932945046397,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997932945046397,
                "mixed": 0.00020670549536025372
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997932945046397,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997932945046397,
                    "human": 0,
                    "mixed": 0.00020670549536025372
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999953971749087,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 4.602825091316334e-06,
                        "ai_paraphrased": 0.9999953971749087
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 4.602725091316364e-06,
                            "ai_paraphrased": 0.9999953971749087
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "The writers suggest a RNN design with linear features for language modeling to make the model easier to understand and possibly boost performance by storing frequently used sub sequence patterns. Even though the direct comparison with data is not impressive and lacks clear reasons for selecting the dataset along with a limited evaluation on a single dataset the authors show skillful methods, for studying model behavior by utilizing the linear features to gain insights that non linear RNN models cannot provide. \nIn my opinion. After considering the content of the paper closely enough to gauging its narrative appeal and valuable insights within the research field despite the less, than impressive outcomes mentioned earlier on in it. \nResponse; \nTo improve the papers quality you might want to shorten the analysis experiments and delve deeper into discussing sequence models. Some experiments, like 4. 5 Seem more about showcasing how well the model can match the data than uncovering crucial characteristics. With the decent perplexity outcomes it seems likely that the model effectively captures the data. \nExploring how LSTMs and GRUs fare against linear methods when handling data with complex structures such as nested parentheses could yield valuable insights even if the outcomes are not favorable. It could shed light on the benefits of non linear methods, in tackling such tasks. \nIn the section, about researches should talk about Belanger and Kakades (2015) work as well. They use linear dynamics but emphasize quick and adaptable learning methods instead They looked at the singular vectors of the transition matrix which can be contrasted with what the authors did. \nDirectly discussing Linear Dynamical Systems (LDS) in detail could be helpful for readers by delving into the comparisons that came up during the open review conversation. One way to enhance understanding could be to highlight the connection between bias vectors and the columns of the Kalman gain matrix. Moreover consider looking into integrating Kalman smoothing, as an expansion, which involves estimating state vectors based on both past and future observations. \nTo improve interpretability and scalability for word level problems, in your text data analysis approach you may want to explore the concept of parameter sharing by representing each matrix as a combination of matrices that are sparse or convex in nature. This method can allow for characters to be represented as weights combining elements leading to a more understandable and potentially more scalable solution. "
        }
    ],
    "editorDocumentId": null
}