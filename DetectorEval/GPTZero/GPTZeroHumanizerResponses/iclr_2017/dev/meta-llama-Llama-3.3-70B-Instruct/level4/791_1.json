{
    "version": "2025-03-13-base",
    "scanId": "161814fb-4cd8-437d-a67d-e41d566a1431",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999955892562866,
                    "sentence": "This paper introduces a method for training visual representations without supervision using deep neural networks that focuses on patch contrasting to improve feature representations efficiently.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960064888,
                    "sentence": "In particular it promotes making the feature representations of patches within the image more alike than those from different images through optimizing the distance ratios of positive training pairs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963045120239,
                    "sentence": "The results from experiments show how effective this method is as an initial step, for supervised training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999925494194031,
                    "sentence": "Advantages;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999995231628418,
                    "sentence": "The suggested training goal is well supported and especially effective in capturing high level features that're invariant, to translation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999995768070221,
                    "sentence": "The technique has proven to be successful in setting up networks, for supervised learning on various sets of data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999943375587463,
                    "sentence": "Areas, for improvement;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999940991401672,
                    "sentence": "The technical method is quite similar to the concept of the \" network,\" as outlined by Dosovitski in 2015 in which extracting patches from a single image can be seen as a way to enhance the dataset much, like how positive sample augmentation works in the exemplar network.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999956488609314,
                    "sentence": "The way the study is presented seems misleading as it compares results achieved through tuning the entire network with supervised learning to exemplar convnets (Dosovitskiy 2015) which are based on unsupervised feature learning without fine tuning.This difference in approach makes the comparison unfair; it's possible that exemplar convnets could also show improvements with fine tuning included.A direct comparison is needed with and, without fine tuning using the architecture but varying the loss function to ensure the results are truly convincing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999938011169434,
                    "sentence": "Additionally it would be interesting to compare this approach with the \"What where\" autoencoder discussed by Zhao et al (2015) as showcased by Zhang et al at the ICML in 2016 on a scale.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999929666519165,
                    "sentence": "By leveraging cutting edge GPU technology like TITAN X it becomes plausible to train an AlexNet model and conduct a thorough assessment.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999945163726807,
                    "sentence": "However the proposed technique seems to have limitations when it comes to processing images.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999942183494568,
                    "sentence": "This is due to the tendency of patches within the image to exhibit similarities, which narrows its scope, for broader applications.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999947497758873,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 5.250224112619121e-06,
                        "ai_paraphrased": 0.9999947497758873
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 5.250124112619152e-06,
                            "ai_paraphrased": 0.9999947497758873
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This paper introduces a method for training visual representations without supervision using deep neural networks that focuses on patch contrasting to improve feature representations efficiently. In particular it promotes making the feature representations of patches within the image more alike than those from different images through optimizing the distance ratios of positive training pairs. The results from experiments show how effective this method is as an initial step, for supervised training. \nAdvantages; \nThe suggested training goal is well supported and especially effective in capturing high level features that're invariant, to translation. \nThe technique has proven to be successful in setting up networks, for supervised learning on various sets of data. \nAreas, for improvement; \nThe technical method is quite similar to the concept of the \" network,\" as outlined by Dosovitski in 2015 in which extracting patches from a single image can be seen as a way to enhance the dataset much, like how positive sample augmentation works in the exemplar network. \nThe way the study is presented seems misleading as it compares results achieved through tuning the entire network with supervised learning to exemplar convnets (Dosovitskiy 2015) which are based on unsupervised feature learning without fine tuning.This difference in approach makes the comparison unfair; it's possible that exemplar convnets could also show improvements with fine tuning included.A direct comparison is needed with and, without fine tuning using the architecture but varying the loss function to ensure the results are truly convincing. \nAdditionally it would be interesting to compare this approach with the \"What where\" autoencoder discussed by Zhao et al (2015) as showcased by Zhang et al at the ICML in 2016 on a scale. By leveraging cutting edge GPU technology like TITAN X it becomes plausible to train an AlexNet model and conduct a thorough assessment. However the proposed technique seems to have limitations when it comes to processing images. This is due to the tendency of patches within the image to exhibit similarities, which narrows its scope, for broader applications. "
        }
    ],
    "editorDocumentId": null
}