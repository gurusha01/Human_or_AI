{
    "version": "2025-03-13-base",
    "scanId": "9a3de06a-152d-4644-8d78-6c5269eddc4d",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999927282333374,
                    "sentence": "Key Points, from the Papers Assertions and Impact",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999953508377075,
                    "sentence": "The article introduces a method for training to develop a generative model in the form of a Markov chain that refines an initial random noise sample into a top notch sample that aligns with the desired distribution, over time by removing noise progressively.The technique known as \"infusion training\" entails drawing from a varied chain compared to the model chain employed for generation wherein details from the example used for training are incorporated into the chain.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999994695186615,
                    "sentence": "The writers argue that using this method can generate top notch samples with just a few steps and back it up with experiments on different datasets like MNIST and CIFAR-10 as well, as Toronto Face Database and Celeb A.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999887347221375,
                    "sentence": "Main Factors Behind Them",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933242797852,
                    "sentence": "After reviewing the paper and considering the key factors involved in the decision making process, I have chosen to accept it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999993085861206,
                    "sentence": "The article addresses an compelling issue, in the realm of generative models - the challenge of mastering a transition operator capable of producing top notch samples efficiently.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999926686286926,
                    "sentence": "The method suggested in the paper fits within the existing body of literature as it expands upon prior research, on denosing autoencoders and generative stochastic networks while also incorporating Markov chain Monte Carlo techniques.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933242797852,
                    "sentence": "The document gives an precise description of how the infusion training process works.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999993622303009,
                    "sentence": "It covers the mathematical framework and the setup for experiments, in detail.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999950528144836,
                    "sentence": "Reasons, for Support",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999915957450867,
                    "sentence": "The document presents reasons backing the effectiveness of the infusion training method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933242797852,
                    "sentence": "The authors conduct an examination of the infusion training process by deriving the minimum log likelihood of the generative model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9943477511405945,
                    "sentence": "The authors showcase their findings across various datasets to highlight the success of the infusion training method, in producing diverse and top notch samples.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9952268004417419,
                    "sentence": "The authors in this study assess their method against existing research on models, like GAN and VAE to show that their approach yields comparable outcomes.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9899212121963501,
                    "sentence": "More.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9790760278701782,
                    "sentence": "Queries",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9872974157333374,
                    "sentence": "In order to enhance the paper more.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9954266548156738,
                    "sentence": "I would appreciate it if we could include the following suggestions;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9944000840187073,
                    "sentence": "A thorough examination of the infusion rate schedule is needed as the authors highlight its significance in the success of the approach but fail to delve into an analysis, on selecting the most favorable schedule.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9912882447242737,
                    "sentence": "1 There is a request for experiments on larger datasets, in the article despite the authors showcasing the approachs effectiveness on various datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.988669216632843,
                    "sentence": "The authors not analyze their method in relation to GAN and VAE but also suggest exploring its performance compared to different generative models, like normalizing flows and autoregressive models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9667660593986511,
                    "sentence": "I have a questions that I'd love for the authors to address;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9753467440605164,
                    "sentence": "How do the writers decide on the schedule, for administering infusions based on a specific set of data?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9501955509185791,
                    "sentence": "Could the writers elaborate further on how the infusion training method can generate top notch samples with steps involved?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9498507976531982,
                    "sentence": "How does the authors' method connect to studies on generative models like the recent research, on denoise diffusion models?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 24,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9989379277322354,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9989379277322354,
                "mixed": 0.001062072267764499
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9989379277322354,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9989379277322354,
                    "human": 0,
                    "mixed": 0.001062072267764499
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9971975777287667,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.002802422271233348,
                        "ai_paraphrased": 0.9971975777287667
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.002802422171233348,
                            "ai_paraphrased": 0.9971975777287667
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "Key Points, from the Papers Assertions and Impact\nThe article introduces a method for training to develop a generative model in the form of a Markov chain that refines an initial random noise sample into a top notch sample that aligns with the desired distribution, over time by removing noise progressively.The technique known as \"infusion training\" entails drawing from a varied chain compared to the model chain employed for generation wherein details from the example used for training are incorporated into the chain. The writers argue that using this method can generate top notch samples with just a few steps and back it up with experiments on different datasets like MNIST and CIFAR‐10 as well, as Toronto Face Database and Celeb A. \nMain Factors Behind Them \nAfter reviewing the paper and considering the key factors involved in the decision making process， I have chosen to accept it. \nThe article addresses an compelling issue, in the realm of generative models – the challenge of mastering a transition operator capable of producing top notch samples efficiently. \nThe method suggested in the paper fits within the existing body of literature as it expands upon prior research, on denosing autoencoders and generative stochastic networks while also incorporating Markov chain Monte Carlo techniques. \nThe document gives an precise description of how the infusion training process works. It covers the mathematical framework and the setup for experiments, in detail. \nReasons, for Support \nThe document presents reasons backing the effectiveness of the infusion training method.\nThe authors conduct an examination of the infusion training process by deriving the minimum log likelihood of the generative model. \nThe authors showcase their findings across various datasets to highlight the success of the infusion training method, in producing diverse and top notch samples. \nThe authors in this study assess their method against existing research on models, like GAN and VAE to show that their approach yields comparable outcomes. \nMore. Queries\nIn order to enhance the paper more. I would appreciate it if we could include the following suggestions; \nA thorough examination of the infusion rate schedule is needed as the authors highlight its significance in the success of the approach but fail to delve into an analysis, on selecting the most favorable schedule. \n1 There is a request for experiments on larger datasets, in the article despite the authors showcasing the approachs effectiveness on various datasets. \nThe authors not analyze their method in relation to GAN and VAE but also suggest exploring its performance compared to different generative models, like normalizing flows and autoregressive models. \nI have a questions that I'd love for the authors to address; \nHow do the writers decide on the schedule, for administering infusions based on a specific set of data? \nCould the writers elaborate further on how the infusion training method can generate top notch samples with steps involved? \nHow does the authors’ method connect to studies on generative models like the recent research, on denoise diffusion models? "
        }
    ],
    "editorDocumentId": null
}