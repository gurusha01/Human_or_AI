{
    "version": "2025-03-13-base",
    "scanId": "46e09a35-dcb5-4bf5-9105-87a4beb0f1d7",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999945163726807,
                    "sentence": "The writers suggest using a RNN with straightforward dynamics for language modeling to improve model interpretability and potentially boost performance by storing dynamics for common sub sequences efficiently but the results, from a standard task are not very impressive quantitatively.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999949336051941,
                    "sentence": "The dataset selection is a bit unusual as one dataset is analyzed.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999948143959045,
                    "sentence": "The authors have presented a variety of methods for examining the models performance that may not be practical, for a non linear RNN.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999956488609314,
                    "sentence": "In general I suggest approving the document despite its findings.It is a piece, to peruse and adds value to the current research discussion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999971389770508,
                    "sentence": "Could you please provide some feedback?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967217445374,
                    "sentence": "The paper would benefit from cutting down on the number of analysis experiments and delving deeper into discussing sequence models.As some experiments provided insights others such as those in Section 4 point six appeared to mainly confirm the models compatibility, with the data rather than uncovering any groundbreaking or significant features.Since the perplexity outcomes are reasonable it is evident that the model aligns well with the data.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999964833259583,
                    "sentence": "Using LSTMs and GRUs is great for language tasks that deal with structures like nested parentheses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999962449073792,
                    "sentence": "It would have been helpful to test your model against linear approaches, in these scenarios.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999962449073792,
                    "sentence": "Don't hesitate to share outcomesᅳfinding that non linear methods work better would still be intriguing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999951720237732,
                    "sentence": "In the work section make sure to talk about the research by Belanger and Kakade (2015).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982118606567,
                    "sentence": "Even though their goals of creating quick and scalable learning algorithms may be different from your focus on hidden state changes and straightforward credit allocation, for predicting future events based on past information they also use linear dynamics and assess the models performance using the singular vectors of the transition matrixᅳa point worth emphasizing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979734420776,
                    "sentence": "In terms and for a broader understanding by readers like yourself.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "It might be useful to delve deeper into the studies about linear dynamical systems (commonly known as LDS).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999966621398926,
                    "sentence": "This topic has been previously explored in the openreview forum.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "I suggest incorporating those discussions into your paper for added insight and clarity.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999972581863403,
                    "sentence": "To illustrate highlighting the connection between the bias vectors in your model and the columns of the Kalman gain matrix could be beneficial, for your audiences comprehension.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999975562095642,
                    "sentence": "When it comes to LDS discussions like this one about Kalman filtering in your models contextᅳit's worth noting that within an LDS setup there's room, for incorporating Kalman smoothing well; this involves deducing state vectors based not just the past.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999973177909851,
                    "sentence": "Also future observations combined together effectively.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999975562095642,
                    "sentence": "Consider looking into whether each matrix in your model could be shown as a sparse or convex mix of a group of matrices.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999996542930603,
                    "sentence": "This kind of parameter sharing may increase clarity since characters would then be depicted by the dimensional values utilized to mix the dictionary elements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967813491821,
                    "sentence": "Moreover this method might boost scalability, for tasks at the word level.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.99999643992941,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 3.5600705900315404e-06,
                        "ai_paraphrased": 0.99999643992941
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 3.5599705900315702e-06,
                            "ai_paraphrased": 0.99999643992941
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "The writers suggest using a RNN with straightforward dynamics for language modeling to improve model interpretability and potentially boost performance by storing dynamics for common sub sequences efficiently but the results, from a standard task are not very impressive quantitatively. The dataset selection is a bit unusual as one dataset is analyzed. The authors have presented a variety of methods for examining the models performance that may not be practical, for a non linear RNN. \nIn general I suggest approving the document despite its findings.It is a piece, to peruse and adds value to the current research discussion. \nCould you please provide some feedback?\nThe paper would benefit from cutting down on the number of analysis experiments and delving deeper into discussing sequence models.As some experiments provided insights others such as those in Section 4 point six appeared to mainly confirm the models compatibility, with the data rather than uncovering any groundbreaking or significant features.Since the perplexity outcomes are reasonable it is evident that the model aligns well with the data. \nUsing LSTMs and GRUs is great for language tasks that deal with structures like nested parentheses. It would have been helpful to test your model against linear approaches, in these scenarios. Don't hesitate to share outcomes—finding that non linear methods work better would still be intriguing. \nIn the work section make sure to talk about the research by Belanger and Kakade (2015). Even though their goals of creating quick and scalable learning algorithms may be different from your focus on hidden state changes and straightforward credit allocation, for predicting future events based on past information they also use linear dynamics and assess the models performance using the singular vectors of the transition matrix—a point worth emphasizing. \nIn terms and for a broader understanding by readers like yourself. It might be useful to delve deeper into the studies about linear dynamical systems (commonly known as LDS). This topic has been previously explored in the openreview forum. I suggest incorporating those discussions into your paper for added insight and clarity. To illustrate highlighting the connection between the bias vectors in your model and the columns of the Kalman gain matrix could be beneficial, for your audiences comprehension. \nWhen it comes to LDS discussions like this one about Kalman filtering in your models context—it's worth noting that within an LDS setup there's room, for incorporating Kalman smoothing well; this involves deducing state vectors based not just the past. Also future observations combined together effectively. \nConsider looking into whether each matrix in your model could be shown as a sparse or convex mix of a group of matrices. This kind of parameter sharing may increase clarity since characters would then be depicted by the dimensional values utilized to mix the dictionary elements. Moreover this method might boost scalability, for tasks at the word level. "
        }
    ],
    "editorDocumentId": null
}