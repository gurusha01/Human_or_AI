{
    "version": "2025-03-13-base",
    "scanId": "64265964-a876-4d77-ab4f-a1919d291ac1",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999476075172424,
                    "sentence": "This article presents a method for training visual representations with deep neural networks that does not require supervision and is based on patch contrast analysis.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999620914459229,
                    "sentence": "In particular this method promotes the idea that feature representations of patches from the image should be more similar than those from different images.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999953031539917,
                    "sentence": "The focus of the optimization is on the ratios of distances between training pairs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999533891677856,
                    "sentence": "Experimental findings support the effectiveness of this approach as a starting point, for training tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999662041664124,
                    "sentence": "Advantages;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999475479125977,
                    "sentence": "The goal of training is compelling since advanced features show consistency, in translation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999469518661499,
                    "sentence": "The suggested approaches demonstrate their efficacy in setting up networks for supervised training, on various datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999480247497559,
                    "sentence": "Areas, for improvement;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999458193778992,
                    "sentence": "The techniques exhibit similarities to the \"exemplar network \" as described by Dosovitski in 2015.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999217391014099,
                    "sentence": "Taking sections from an image can be likened to a method of data enhancement akin, to how positive samples (the exemplar itself) were augmented in Dosovitskis work from 2015.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999002814292908,
                    "sentence": "The comparisons made in the research paper could be misleading as the results reported are based on tuning the entire network with supervision compared to Table 2 where the exemplar convnets results are obtained through unsupervised feature learning without fine tuning the network with labeled samples but only training a classifier based on the features.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998973608016968,
                    "sentence": "This might skew the comparison unfairly as its possible that exemplar convnets could also show enhancements, with fine tuning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998658895492554,
                    "sentence": "The experimental findings lack conviction without straightforward comparisons, such as direct head to head assessments, with and without fine tuning utilizing identical architectures but varied loss functions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998852014541626,
                    "sentence": "When comparing it to the \"What/Where\" autoencoder (Zhao et al., 2015) it would be beneficial to test out the suggested approach on a scale setting like in the study by Zhang et al (ICML 2016 on \"Enhancing Supervised Neural Networks with Unsupervised Objectives for Large Scale Image Classification\").",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999912679195404,
                    "sentence": "Given that training an AlexNet is doable with GPUs, like TITAN X level ones; running these tests could really enhance the research paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999234676361084,
                    "sentence": "The suggested approach seems to be most beneficial for real life photographs because patches, within the image are expected to have similarities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999913473838721,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 8.652616127813898e-06,
                        "ai_paraphrased": 0.9999913473838721
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 8.652516127813929e-06,
                            "ai_paraphrased": 0.9999913473838721
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This article presents a method for training visual representations with deep neural networks that does not require supervision and is based on patch contrast analysis. In particular this method promotes the idea that feature representations of patches from the image should be more similar than those from different images. The focus of the optimization is on the ratios of distances between training pairs. Experimental findings support the effectiveness of this approach as a starting point, for training tasks. \nAdvantages; \nThe goal of training is compelling since advanced features show consistency, in translation. \nThe suggested approaches demonstrate their efficacy in setting up networks for supervised training, on various datasets. \nAreas, for improvement; \nThe techniques exhibit similarities to the \"exemplar network \" as described by Dosovitski in 2015. Taking sections from an image can be likened to a method of data enhancement akin, to how positive samples (the exemplar itself) were augmented in Dosovitskis work from 2015.\nThe comparisons made in the research paper could be misleading as the results reported are based on tuning the entire network with supervision compared to Table 2 where the exemplar convnets results are obtained through unsupervised feature learning without fine tuning the network with labeled samples but only training a classifier based on the features. This might skew the comparison unfairly as its possible that exemplar convnets could also show enhancements, with fine tuning. The experimental findings lack conviction without straightforward comparisons, such as direct head to head assessments, with and without fine tuning utilizing identical architectures but varied loss functions. \nWhen comparing it to the \"What/Where\" autoencoder (Zhao et al., 2015) it would be beneficial to test out the suggested approach on a scale setting like in the study by Zhang et al (ICML 2016 on \"Enhancing Supervised Neural Networks with Unsupervised Objectives for Large Scale Image Classification\"). Given that training an AlexNet is doable with GPUs, like TITAN X level ones; running these tests could really enhance the research paper. \nThe suggested approach seems to be most beneficial for real life photographs because patches, within the image are expected to have similarities. "
        }
    ],
    "editorDocumentId": null
}