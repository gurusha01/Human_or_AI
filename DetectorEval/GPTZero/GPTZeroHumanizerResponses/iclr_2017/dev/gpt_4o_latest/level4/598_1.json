{
    "version": "2025-03-13-base",
    "scanId": "632e3957-dd12-4e44-99c6-026713424d4b",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9997663497924805,
                    "sentence": "This study introduces a speech recognition system based on a linear conditional random field structure from beginning to end.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997263550758362,
                    "sentence": "A convolutional neural network (convnet) is utilized to calculate node potentials while trained scalar values represent transition scores.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997007250785828,
                    "sentence": "The convnets acoustic model produces scores for letters of phonemes to lessen the need, for specialized expertise during system training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997103810310364,
                    "sentence": "When making predictions in this context of the task at hand the system considers factors such as scores from a language model at the word level along with the potentials of nodes in a convolutional neural network transition scores learned from letters to letters and a penalty for inserting words.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997568726539612,
                    "sentence": "It then identifies the likely word based on these combined factors.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997694492340088,
                    "sentence": "The training process can involve using raw audio waveforms power spectra data or MFCC features, with maximum likelihood estimation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997434616088867,
                    "sentence": "During the tests on the Librispeech dataset it was found that the model performed with a word error rate (WER) which was 7..e yearn about percent when using MFCC features on the clean test data set; 9..e yearn about percent, with power features; and 10.. One percent when using raw waveform inputs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997667670249939,
                    "sentence": "Advantages",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998126029968262,
                    "sentence": "Creating a speech recognition system for English by training a convnet from scratch using maximum likelihood with graphemic acoustic models instead of phonetic ones shows potential, for future research endeavors.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996593594551086,
                    "sentence": "Downsides",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997695088386536,
                    "sentence": "The paper doesn't provide background information and overlooks citing a few important previous studies mentioned before in my feedback comments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997101426124573,
                    "sentence": "Moreover to the sources already noted in my remarks the authors should also include a reference to a 2016 Interspeech paper by Zhang et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995719194412231,
                    "sentence": "titled \"Advancing End, to end Speech Recognition using Deep Convolutional Neural Networks.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 7,
                    "completely_generated_prob": 0.9103421900070616
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999763504119362,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 2.3649588063721305e-05,
                        "ai_paraphrased": 0.9999763504119362
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 2.3649488063721335e-05,
                            "ai_paraphrased": 0.9999763504119362
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This study introduces a speech recognition system based on a linear conditional random field structure from beginning to end. A convolutional neural network (convnet) is utilized to calculate node potentials while trained scalar values represent transition scores. The convnets acoustic model produces scores for letters of phonemes to lessen the need, for specialized expertise during system training. When making predictions in this context of the task at hand the system considers factors such as scores from a language model at the word level along with the potentials of nodes in a convolutional neural network transition scores learned from letters to letters and a penalty for inserting words. It then identifies the likely word based on these combined factors. The training process can involve using raw audio waveforms power spectra data or MFCC features, with maximum likelihood estimation. During the tests on the Librispeech dataset it was found that the model performed with a word error rate (WER) which was 7..e yearn about percent when using MFCC features on the clean test data set; 9..e yearn about percent, with power features; and 10.. One percent when using raw waveform inputs. \nAdvantages  \nCreating a speech recognition system for English by training a convnet from scratch using maximum likelihood with graphemic acoustic models instead of phonetic ones shows potential, for future research endeavors. \nDownsides  \nThe paper doesn't provide background information and overlooks citing a few important previous studies mentioned before in my feedback comments. Moreover to the sources already noted in my remarks the authors should also include a reference to a 2016 Interspeech paper by Zhang et al. titled \"Advancing End, to end Speech Recognition using Deep Convolutional Neural Networks.\""
        }
    ],
    "editorDocumentId": null
}