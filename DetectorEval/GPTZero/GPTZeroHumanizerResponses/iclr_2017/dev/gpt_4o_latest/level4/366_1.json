{
    "version": "2025-03-13-base",
    "scanId": "74abeadb-2bbe-492e-81c2-01c1a1108766",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999335408210754,
                    "sentence": "The writers present NVI as a way of making inferences for LDA variations and compare it with traditional inference methods like CGS and online SVI, in NVI LDA experiments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999378323554993,
                    "sentence": "Furthermore they use NVI in another model called ProdLDa.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999401569366455,
                    "sentence": "Its not clear whether this model has been discussed before in the field of topic modeling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999178051948547,
                    "sentence": "I think the direction of this work is quite interesting and NVI seems like an approach for LDA analysis.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999534487724304,
                    "sentence": "However the results of the experiments mix up the models effects with the inference methods effects making it hard to determine the influence of NVI.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999963104724884,
                    "sentence": "Additionally the paper doesn't delve into hyper parameter selection, which is known to have an impact on how well topic models perform.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999794363975525,
                    "sentence": "This missing discussion raises concerns, about when the proposed method is expected to do well.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999983549118042,
                    "sentence": "Is it feasible to create datasets with different Dirichlet distributions to test if the suggested approach can accurately identify the correct parameters, in diverse scenarios?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999753832817078,
                    "sentence": "Figure 1 shows a bit of confusion.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999809265136719,
                    "sentence": "Is it referring to what came or what comes after it talks about sparsity and labels its y axis as \"log p(topic proportions)\" which makes things a bit unclear.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999756813049316,
                    "sentence": "Section 3 point 2 raised a question about the clarity of the term \"unmodal in softmax basis.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999749660491943,
                    "sentence": "To illustrate with an example.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999728202819824,
                    "sentence": "A Dirichlet distribution on a K simplex with a concentration parameter of a/K where a is less than 1 is considered to be multimodal, in nature.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999765753746033,
                    "sentence": "Wouldn't the same principle apply to softmax basis in cases where there is multimodality present?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999763369560242,
                    "sentence": "The results that were presented do not include error bars, which raises the question of whether the observed differencesre statistically significant or not.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999591708183289,
                    "sentence": "I can't provide a response, without the input text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999362230300903,
                    "sentence": "Could you please provide me with the text you would like me to paraphrase?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999568462371826,
                    "sentence": "Could you please provide some feedback on the comments?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999730587005615,
                    "sentence": "In equation (2) it is suggested to avoid labeling the term as \"error\"; alternative terms, like \"reconstruction accuracy'' or \"negative reconstruction error'' might be more suitable.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999669194221497,
                    "sentence": "The idea of employing an inference network existed before this research was conducted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999675154685974,
                    "sentence": "Can be observed in the Helmholtz machine.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.9997932945046398,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997932945046398,
                "mixed": 0.00020670549536025372
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997932945046398,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997932945046398,
                    "human": 0,
                    "mixed": 0.00020670549536025372
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.999994822516706,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 5.17748329391588e-06,
                        "ai_paraphrased": 0.999994822516706
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 5.17738329391591e-06,
                            "ai_paraphrased": 0.999994822516706
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "The writers present NVI as a way of making inferences for LDA variations and compare it with traditional inference methods like CGS and online SVI, in NVI LDA experiments. Furthermore they use NVI in another model called ProdLDa. Its not clear whether this model has been discussed before in the field of topic modeling. \nI think the direction of this work is quite interesting and NVI seems like an approach for LDA analysis. However the results of the experiments mix up the models effects with the inference methods effects making it hard to determine the influence of NVI. Additionally the paper doesn't delve into hyper parameter selection, which is known to have an impact on how well topic models perform. This missing discussion raises concerns, about when the proposed method is expected to do well. \nIs it feasible to create datasets with different Dirichlet distributions to test if the suggested approach can accurately identify the correct parameters, in diverse scenarios? \nFigure 1 shows a bit of confusion. Is it referring to what came or what comes after it talks about sparsity and labels its y axis as \"log p(topic proportions)\" which makes things a bit unclear. \nSection 3 point 2 raised a question about the clarity of the term \"unmodal in softmax basis.\" To illustrate with an example. A Dirichlet distribution on a K simplex with a concentration parameter of α/K where α is less than 1 is considered to be multimodal, in nature. Wouldn't the same principle apply to softmax basis in cases where there is multimodality present? \nThe results that were presented do not include error bars, which raises the question of whether the observed differencesre statistically significant or not. \nI can't provide a response, without the input text. Could you please provide me with the text you would like me to paraphrase?\nCould you please provide some feedback on the comments?\nIn equation (2) it is suggested to avoid labeling the term as \"error\"; alternative terms, like \"reconstruction accuracy'' or \"negative reconstruction error'' might be more suitable. \nThe idea of employing an inference network existed before this research was conducted. Can be observed in the Helmholtz machine. "
        }
    ],
    "editorDocumentId": null
}