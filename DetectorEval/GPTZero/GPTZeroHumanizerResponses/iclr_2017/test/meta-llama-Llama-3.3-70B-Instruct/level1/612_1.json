{
    "version": "2025-03-13-base",
    "scanId": "305b914c-346f-4c4a-a152-12a31b5df64d",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999993443489075,
                    "sentence": "The research paper suggests a method for predicting the next frame in video sequences by anticipating changes between frames instead of predicting pixel values directly resulting in clearer outcomes with a more compact prediction model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999992251396179,
                    "sentence": "Moreover the authors present an evaluation procedure that involves providing generated frames to a classifier trained on authentic sequences to assess how well distinctive features are preserved.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999991059303284,
                    "sentence": "Their approach surpasses models on the UCF 101 dataset while also being more resource efficient, in terms of parameters and computational expenses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977946281433,
                    "sentence": "Choice",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "Based on two factors - the papers well founded approach within existing literature and its support of claims, with accurate and scientifically robust results - I have chosen to approve this submission.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999997615814209,
                    "sentence": "Arguments, in favor",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "The study addresses an issue in predicting future frames by presenting a model that works with affine transformations instead of directly predicting pixel values like other methods do The rationale, behind this approach is sound as it overcomes the drawbacks of current techniques The authors offer a coherent and straightforward description of their model which consists of an affine transform extractor predictor and multi step prediction processThe results, from the experiment show how well the suggested approach works when compared to advanced models both qualitatively and quantitatively.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999982714653015,
                    "sentence": "More Feedback Needed",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999989867210388,
                    "sentence": "To enhance the paper more effectively in terms of analysis and depth of their methods restrictions; the authors should delve into aspects like the potential undervaluing of transformations because of employing MSE as a metric criterion...",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "Queries, for the Writers",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "Could you please help me better grasp the content of the paper by addressing these questions?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999989867210388,
                    "sentence": "Could you please share information, about how the affine transform extractor is applied in practice and explain the considerations behind selecting the patch size and stride values?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999992251396179,
                    "sentence": "How do you intend to tackle the issue of underestimating transformations because of using Mean Squared Error (MSE) as a criterion?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998927116394,
                    "sentence": "Have you thought about trying out evaluation methods like using various classifiers or assessing the produced frames on different tasks such, as object detection or segmentation?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999956207133032,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 4.379286696868599e-06,
                        "ai_paraphrased": 0.9999956207133032
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 4.379186696868629e-06,
                            "ai_paraphrased": 0.9999956207133032
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "\nThe research paper suggests a method for predicting the next frame in video sequences by anticipating changes between frames instead of predicting pixel values directly resulting in clearer outcomes with a more compact prediction model. Moreover the authors present an evaluation procedure that involves providing generated frames to a classifier trained on authentic sequences to assess how well distinctive features are preserved. Their approach surpasses models on the UCF 101 dataset while also being more resource efficient, in terms of parameters and computational expenses. \nChoice\nBased on two factors – the papers well founded approach within existing literature and its support of claims, with accurate and scientifically robust results – I have chosen to approve this submission. \nArguments, in favor\nThe study addresses an issue in predicting future frames by presenting a model that works with affine transformations instead of directly predicting pixel values like other methods do The rationale, behind this approach is sound as it overcomes the drawbacks of current techniques The authors offer a coherent and straightforward description of their model which consists of an affine transform extractor predictor and multi step prediction processThe results, from the experiment show how well the suggested approach works when compared to advanced models both qualitatively and quantitatively. \nMore Feedback Needed \nTo enhance the paper more effectively in terms of analysis and depth of their methods restrictions; the authors should delve into aspects like the potential undervaluing of transformations because of employing MSE as a metric criterion​​​​​...\nQueries, for the Writers \nCould you please help me better grasp the content of the paper by addressing these questions?\nCould you please share information, about how the affine transform extractor is applied in practice and explain the considerations behind selecting the patch size and stride values? \nHow do you intend to tackle the issue of underestimating transformations because of using Mean Squared Error (MSE) as a criterion? \nHave you thought about trying out evaluation methods like using various classifiers or assessing the produced frames on different tasks such, as object detection or segmentation? "
        }
    ],
    "editorDocumentId": null
}