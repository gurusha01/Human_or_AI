{
    "version": "2025-03-13-base",
    "scanId": "56974a40-53ad-4999-95de-5ced75bd78ef",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999867677688599,
                    "sentence": "This document suggests a method for translating data points into a space with dimensions while striving to maintain a level of similarity, between them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999802708625793,
                    "sentence": "The idea shared is not as groundbreaking as suggested because various pre trained embeddings like autoencoders and word embedding models have been using techniques for a while to represent items in a space with low dimensions that naturally encode their similarities.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999982476234436,
                    "sentence": "Moreover After looking into how this applies to word and context embeddings it's clear that the method shows similarities to a function, for similarity described in \"An Easy Word Embedding Model for Replacing Words\" by Melamud et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999781250953674,
                    "sentence": "published in 2015.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999815821647644,
                    "sentence": "Henceforth an accurate statement of originality is necessaryᅳone that places the research in the context of previous studies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999882578849792,
                    "sentence": "Furthermore improvements could be made to the assessment methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999984860420227,
                    "sentence": "There are standards available for evaluating word embeddings, in specific contexts, such as;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999941701465423,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 5.82985345768931e-06,
                        "ai_paraphrased": 0.9999941701465423
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 5.8297534576893405e-06,
                            "ai_paraphrased": 0.9999941701465423
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This document suggests a method for translating data points into a space with dimensions while striving to maintain a level of similarity, between them. \nThe idea shared is not as groundbreaking as suggested because various pre trained embeddings like autoencoders and word embedding models have been using techniques for a while to represent items in a space with low dimensions that naturally encode their similarities. Moreover After looking into how this applies to word and context embeddings it's clear that the method shows similarities to a function, for similarity described in \"An Easy Word Embedding Model for Replacing Words\" by Melamud et al. published in 2015. Henceforth an accurate statement of originality is necessary—one that places the research in the context of previous studies. \nFurthermore improvements could be made to the assessment methods. There are standards available for evaluating word embeddings, in specific contexts, such as; "
        }
    ],
    "editorDocumentId": null
}