{
    "version": "2025-03-13-base",
    "scanId": "e0732a1b-74ad-435e-9883-41265db8c518",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999915361404419,
                    "sentence": "Sorry for the submission of my review I wanted to begin by offering my apologies for the delay.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999921917915344,
                    "sentence": "This research delves into exploring how a reading comprehension model (, AS Reader) can be adapted through different experiments and the use of a sizable artificial dataset to better suit a target dataset.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999913573265076,
                    "sentence": "Far as I know the writers carry out various transfer learning tests but I am not completely sure, about the specifics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999932050704956,
                    "sentence": "It seems like the tests include;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999943375587463,
                    "sentence": "Training the model using an artificial dataset and assessing its effectiveness, on smaller target datasets (section 4 point 2).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999932646751404,
                    "sentence": "Training the model first with an artificial dataset and then refining it with a portion of examples from the specific dataset before testing it with the rest of the datasets examples is the process outlined in section 4\\.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999934434890747,
                    "sentence": "Multiple models undergo training using various subsets, for refinement purposes and their effectiveness is evaluated against models that are randomly initialized and refined (section 4\\.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999922513961792,
                    "sentence": "3).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999943375587463,
                    "sentence": "Before fine tuning the model on a subset of target examples and evaluating its performance on the remaining examples as detailed in section 4(section 4) it is important to first pre train the model using a large artificial dataset and selectively reset either the embedding or encoder component to random initialization to understand the significance of pre training, in each component.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999945759773254,
                    "sentence": "Understanding the outcomes is tough because the test set is made up of parts and tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999938607215881,
                    "sentence": "The performance results can be a mix of averages, across tasks or specific task performances.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999935626983643,
                    "sentence": "Adding deviations would make things clearer and give a better overall picture.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999943971633911,
                    "sentence": "It would also help to explain what \"best validation\" really means.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999926090240479,
                    "sentence": "The project seems engaging and modest; however the way it is presented could be enhanced through simplification of the arrangement.The authors bring attention to a finding, in section 4.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999932646751404,
                    "sentence": "There are some problems like unexplained acronyms such as GRV and CBT and some typos (\"benifits\" on the second page and \"subsubset‚Äù, on the sixth page).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.999998360068147,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 1.639931852937675e-06,
                        "ai_paraphrased": 0.999998360068147
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 1.6398318529377052e-06,
                            "ai_paraphrased": 0.999998360068147
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "Sorry for the submission of my review I wanted to begin by offering my apologies for the delay. \nThis research delves into exploring how a reading comprehension model (, AS Reader) can be adapted through different experiments and the use of a sizable artificial dataset to better suit a target dataset. \nFar as I know the writers carry out various transfer learning tests but I am not completely sure, about the specifics. It seems like the tests include; \nTraining the model using an artificial dataset and assessing its effectiveness, on smaller target datasets (section 4 point 2).\nTraining the model first with an artificial dataset and then refining it with a portion of examples from the specific dataset before testing it with the rest of the datasets examples is the process outlined in section 4\\. Multiple models undergo training using various subsets, for refinement purposes and their effectiveness is evaluated against models that are randomly initialized and refined (section 4\\. 3).\nBefore fine tuning the model on a subset of target examples and evaluating its performance on the remaining examples as detailed in section 4‚Äã‚Äã‚Äã‚Äã‚Äã(section 4‚Äã‚Äã‚Äã‚Äã) it is important to first pre train the model using a large artificial dataset and selectively reset either the embedding or encoder component to random initialization to understand the significance of pre training, in each component. \nUnderstanding the outcomes is tough because the test set is made up of parts and tasks. The performance results can be a mix of averages, across tasks or specific task performances. Adding deviations would make things clearer and give a better overall picture. It would also help to explain what \"best validation\" really means. \nThe project seems engaging and modest; however the way it is presented could be enhanced through simplification of the arrangement.The authors bring attention to a finding, in section 4. \nThere are some problems like unexplained acronyms such as GRV and CBT and some typos (\"benifits\" on the second page and \"subsubset‚Äù, on the sixth page)."
        }
    ],
    "editorDocumentId": null
}