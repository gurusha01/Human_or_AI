{
    "version": "2025-03-13-base",
    "scanId": "521635ee-013b-4913-9d0f-a39ceb85c6e6",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999921321868896,
                    "sentence": "Here is my review.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933242797852,
                    "sentence": "This article presents a type of recurrent neural network called the Chaos Free Network (CFR) which is simpler than the usual gated models such as LSTMs and GRUs but still performs well in word level language tasks, with stable and understandable behavior.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999994158744812,
                    "sentence": "The article delves into an examination of the dynamics of CFNs and establishes that its hidden states consistently converge to zero when no input is presentᅳa departure from the erratic patterns seen in LSTMs and GRUs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933838844299,
                    "sentence": "Results from experiments on the Penn Treebank and Text8 datasets show that CFNs perform on par with LSTMs with fewer parameters.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999932050704956,
                    "sentence": "Furthermore the authors point out how easy it is to interpret CFNs dynamics and suggest that its simplicity could pave the way for a mathematical comprehension and potential enhancements, for tasks that require long term dependencies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999879002571106,
                    "sentence": "Verdict reached.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999991774559021,
                    "sentence": "Approved.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999931454658508,
                    "sentence": "The article argues convincingly for approval based on its introduction of a streamlined RNN design that performs similarly to well known models, with solid theoretical and practical support provided throughout the study.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999938011169434,
                    "sentence": "In an approach to designing recurrent neural networks (RNNs) the CFNs emphasize simplicity and clarity, over the intricate nature of LSTMs and GRUs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999938011169434,
                    "sentence": "The thorough theoretical analysis and convincing results demonstrate that CFNs perform as well as LSTMs in language modeling tasks while maintaining scientific rigor.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999951720237732,
                    "sentence": "Here are some points to consider; Points, in favor",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999994158744812,
                    "sentence": "The paper is firmly grounded in existing research as it tackles the enduring problem of behaviors in RNN models with a proposal, for a chaos free solution that enhances both the theoretical foundation and real world application of RNN technology.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999932050704956,
                    "sentence": "The CFNs predictable dynamics are solidly supported by proofs and their effectiveness is showcased through experiments using standard datasets.This comparison, with LSTMs and GRUs is done fairly as the models are trained with parameter counts and initialization methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999993085861206,
                    "sentence": "Interpretability is a strength of the CFNs compared to traditional RNN models because their dynamics are more understandable and predictable.This quality is highly beneficial for research well as practical use cases, in various domains.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999924898147583,
                    "sentence": "Ways to enhance your work.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999935626983643,
                    "sentence": "When looking at the picture of assessing performance in language modeling at the word level in research findings show promise but examining how CFNs perform in tasks that involve long range connections, like translation or forecasting time series data could further enhance the papers credibility by exploring potential limitations as speculated by the authors themselves.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999935030937195,
                    "sentence": "A study on ablation delving into the effects of design decisions such as the specific gating mechanisms could offer more profound insights, into how well the CFNs perform.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999938607215881,
                    "sentence": "The paper mainly contrasts CFNs with LSTMs and GRUs.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999994158744812,
                    "sentence": "Should also consider comparing them to newer models like Transformer based architectures to provide a broader perspective on CFNs performance, in sequence modeling.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999939799308777,
                    "sentence": "Queries, for the Writers",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999940991401672,
                    "sentence": "How well does CFNeural fare in tasks that involve longer term connections;, for example; document level language prediction or forecasting time series data?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999952912330627,
                    "sentence": "Is it possible to use the simplicity of CFNs to enhance training effectiveness or cut down on expenses in comparison, to LSTMs and GRUs?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999955892562866,
                    "sentence": "Have you tried using CFNs layers stacked together to better understand intricate relationships as mentioned in the conclusion?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999995768070221,
                    "sentence": "To sum up this paper adds value to the field by presenting a straightforward RNN design that can compete well with existing models despite opportunities, for additional research.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999972955816152,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 2.7044183847304788e-06,
                        "ai_paraphrased": 0.9999972955816152
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 2.7043183847305086e-06,
                            "ai_paraphrased": 0.9999972955816152
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "Here is my review.\n\nThis article presents a type of recurrent neural network called the Chaos Free Network (CFR) which is simpler than the usual gated models such as LSTMs and GRUs but still performs well in word level language tasks, with stable and understandable behavior. The article delves into an examination of the dynamics of CFNs and establishes that its hidden states consistently converge to zero when no input is present—a departure from the erratic patterns seen in LSTMs and GRUs. Results from experiments on the Penn Treebank and Text8 datasets show that CFNs perform on par with LSTMs with fewer parameters. Furthermore the authors point out how easy it is to interpret CFNs dynamics and suggest that its simplicity could pave the way for a mathematical comprehension and potential enhancements, for tasks that require long term dependencies. \nVerdict reached. Approved.\nThe article argues convincingly for approval based on its introduction of a streamlined RNN design that performs similarly to well known models, with solid theoretical and practical support provided throughout the study. \nIn an approach to designing recurrent neural networks (RNNs) the CFNs emphasize simplicity and clarity, over the intricate nature of LSTMs and GRUs. \nThe thorough theoretical analysis and convincing results demonstrate that CFNs perform as well as LSTMs in language modeling tasks while maintaining scientific rigor. \nHere are some points to consider; Points, in favor \nThe paper is firmly grounded in existing research as it tackles the enduring problem of behaviors in RNN models with a proposal, for a chaos free solution that enhances both the theoretical foundation and real world application of RNN technology. \nThe CFNs predictable dynamics are solidly supported by proofs and their effectiveness is showcased through experiments using standard datasets.This comparison, with LSTMs and GRUs is done fairly as the models are trained with parameter counts and initialization methods. \nInterpretability is a strength of the CFNs compared to traditional RNN models because their dynamics are more understandable and predictable.This quality is highly beneficial for research well as practical use cases, in various domains. \nWays to enhance your work.\nWhen looking at the picture of assessing performance in language modeling at the word level in research findings show promise but examining how CFNs perform in tasks that involve long range connections, like translation or forecasting time series data could further enhance the papers credibility by exploring potential limitations as speculated by the authors themselves. \nA study on ablation delving into the effects of design decisions such as the specific gating mechanisms could offer more profound insights, into how well the CFNs perform. \nThe paper mainly contrasts CFNs with LSTMs and GRUs. Should also consider comparing them to newer models like Transformer based architectures to provide a broader perspective on CFNs performance, in sequence modeling. \nQueries, for the Writers\nHow well does CFNeural fare in tasks that involve longer term connections;, for example; document level language prediction or forecasting time series data? \nIs it possible to use the simplicity of CFNs to enhance training effectiveness or cut down on expenses in comparison, to LSTMs and GRUs? \nHave you tried using CFNs layers stacked together to better understand intricate relationships as mentioned in the conclusion? \nTo sum up this paper adds value to the field by presenting a straightforward RNN design that can compete well with existing models​ despite opportunities, for additional research​. "
        }
    ],
    "editorDocumentId": null
}