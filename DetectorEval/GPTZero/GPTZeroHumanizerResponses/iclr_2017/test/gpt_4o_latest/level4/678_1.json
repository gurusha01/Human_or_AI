{
    "version": "2025-03-13-base",
    "scanId": "4b4b6273-5ef2-4787-bbe8-05d31edb3a1d",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999905824661255,
                    "sentence": "I'm sorry for the delay, in getting to you with this review.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999924898147583,
                    "sentence": "In this study findings show how they conducted a set of tests to move the training process of a comprehension model called AS Reader from a vast artificial database, to a smaller dataset focused on a specific subject area.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999926090240479,
                    "sentence": "From what I gather about the transfer learning experiments conducted far.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999931454658508,
                    "sentence": "Although I'm not entirely confident, in all the specifics.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999939799308777,
                    "sentence": "The system undergoes training on a synthetic dataset and then undergoes assessment, on smaller target datasets as detailed in Section 4 of the document.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999994695186615,
                    "sentence": "The model was initially trained with a synthetic dataset like in the earlier test; however it was later adjusted using a limited number of samples from the specific dataset before undergoing testing with the remaining examples, from that datasets target set.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999932050704956,
                    "sentence": "Multiple models were trained using sets of fine tuning samples and their outcomes were matched against those of models that started with random initialization and then underwent adjustments (Section 4·).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999992311000824,
                    "sentence": "The model undergoes pre training more using a vast synthetic dataset as a foundation for its architecture comprising both an embedding component and an encoder component.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999921917915344,
                    "sentence": "I this study each element is periodically reset to a starting point to assess the impact of pre training on individual components.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999929070472717,
                    "sentence": "Following this evaluation process the model receives refinement through fine tuning on a limited selection of samples from the desired dataset and subsequent testing, on the remaining target examples as outlined in Section 4.`.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999908804893494,
                    "sentence": "The paper can be difficult to follow because of how the test set's put together with different subtasks being included in it and sometimes showing the average performance across them while at other times highlighting specific subtask performance instead.The results reported in some cases seem to represent the performance, across various models.I suggest including deviations to show a clearer view of result variations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999892711639404,
                    "sentence": "Could you please explain what is meant by the term \" validation\"?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999893307685852,
                    "sentence": "I would like to have an understanding of its intended meaning.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999871850013733,
                    "sentence": "I find this to be a thought humble addition to the discussion.However I believe that enhancing the clarity of the presentation might be beneficial by simplifying the experimental arrangement.The conclusion that resonates with me the most is found towards the conclusion of Section 4(point) 2 where they delve into the distinctions, among the datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999855756759644,
                    "sentence": "\"Minor feedback;\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999822974205017,
                    "sentence": "Some abbreviations, like GRUs and BTs are left unexplained in the text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999765753746033,
                    "sentence": "Typographical errors were found in the document.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999822378158569,
                    "sentence": "\"Benfits\" on page 2 and \"subsubset”, on page 6.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.9997938739332977,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997938739332977,
                "mixed": 0.00020612606670239523
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997938739332977,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997938739332977,
                    "human": 0,
                    "mixed": 0.00020612606670239523
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999970971770789,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 2.902822921146699e-06,
                        "ai_paraphrased": 0.9999970971770789
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 2.9027229211467288e-06,
                            "ai_paraphrased": 0.9999970971770789
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "I'm sorry for the delay, in getting to you with this review. \nIn this study findings show how they conducted a set of tests to move the training process of a comprehension model called AS Reader from a vast artificial database, to a smaller dataset focused on a specific subject area. \nFrom what I gather about the transfer learning experiments conducted far. Although I'm not entirely confident, in all the specifics.\nThe system undergoes training on a synthetic dataset and then undergoes assessment, on smaller target datasets as detailed in Section 4​ of the document. \nThe model was initially trained with a synthetic dataset like in the earlier test; however it was later adjusted using a limited number of samples from the specific dataset before undergoing testing with the remaining examples, from that datasets target set. Multiple models were trained using sets of fine tuning samples and their outcomes were matched against those of models that started with random initialization and then underwent adjustments (Section 4·). \nThe model undergoes pre training more using a vast synthetic dataset as a foundation for its architecture comprising both an embedding component and an encoder component. I this study each element is periodically reset to a starting point to assess the impact of pre training on individual components. Following this evaluation process the model receives refinement through fine tuning on a limited selection of samples from the desired dataset and subsequent testing, on the remaining target examples as outlined in Section 4.`. \nThe paper can be difficult to follow because of how the test set's put together with different subtasks being included in it and sometimes showing the average performance across them while at other times highlighting specific subtask performance instead.The results reported in some cases seem to represent the performance, across various models.I suggest including deviations to show a clearer view of result variations. Could you please explain what is meant by the term \" validation\"? I would like to have an understanding of its intended meaning.\nI find this to be a thought humble addition to the discussion.However I believe that enhancing the clarity of the presentation might be beneficial by simplifying the experimental arrangement.The conclusion that resonates with me the most is found towards the conclusion of Section 4(point) 2 where they delve into the distinctions, among the datasets. \n\"Minor feedback;\"\nSome abbreviations, like GRUs and BTs are left unexplained in the text. \nTypographical errors were found in the document. \"Benfits\" on page 2 and \"subsubset”, on page 6. "
        }
    ],
    "editorDocumentId": null
}