{
    "version": "2025-03-13-base",
    "scanId": "c7ff35fc-bb09-4fc8-b670-5415d44240a6",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "The writers have made comprehensive changes to the document in response to several of my initial reservations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999976754188538,
                    "sentence": "The revised edition is also more coherent and simpler to grasp.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999975562095642,
                    "sentence": "I now endorse this updated version, for approval.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999973177909851,
                    "sentence": "Have adjusted my rating accordingly.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999973773956299,
                    "sentence": "This study presents an approach, to understanding LSTM models that are frequently noted for being challenging to interpret effectively.The authors suggest a method to break down the predictions made by an LSTM in a question answer scenario into scores that highlight the importance of words.These scores are then applied to create patterns that can pinpoint answers using a matching process.On the WikiMovies dataset the new pattern matching technique achieves accuracy results to those of a typical LSTM model this showcasing the methods efficiency.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999996542930603,
                    "sentence": "The reason I am drawn to this work is because the clarity of LSTMs still poses a challenge that needs to be addressed openly and effectively maintained.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999971389770508,
                    "sentence": "Furthermore the remarkable success of the pattern matching method was quite impressive.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999969005584717,
                    "sentence": "Nevertheless there are some parts of the pattern extraction procedure that lack elaboration and the assessment is confined to a very particular task focusing solely on word level predictions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999969005584717,
                    "sentence": "I suggest considering the paper for acceptance in its state but suggest that the authors offer more details, on their methodology to potentially contribute to NLP research community advancements.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999978542327881,
                    "sentence": "I appreciate your thoughts.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999964833259583,
                    "sentence": "It's good to hear from you.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999323487281799,
                    "sentence": "Could you please offer a thorough explanation of the particular QA tasks being discussed prior, to section 33?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999287128448486,
                    "sentence": "It seems unclear at that point that the responses refer to entities within the document.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999411106109619,
                    "sentence": "Section 4 in the document discusses whether the softmax output is making predictions based on a 0 or 2 value, such, as determining if a word is the correct answer or not.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999261498451233,
                    "sentence": "Please explain what the P and Q vectors stand for in Section 4 of your research paper in relation to transforming the underlying state into a two dimensional vector, for the purpose of binary classification?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999894380569458,
                    "sentence": "How does the effectiveness of the pattern matching technique change when using cutoff constants?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999050498008728,
                    "sentence": "In Section 5 do you have any questions, in the dataset where the answersre not specific named entities or objects?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998932480812073,
                    "sentence": "How can we modify the suggested method to suit tasks that don't involve making predictions at the word level.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998814463615417,
                    "sentence": "Like extending it to tasks at the sentence level such, as sentiment analysis?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                }
            ],
            "completely_generated_prob": 0.9999999999999999,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9999999999999999,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9999999999999999,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9999999999999999,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999952419626208,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 4.758037379214499e-06,
                        "ai_paraphrased": 0.9999952419626208
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 4.757937379214529e-06,
                            "ai_paraphrased": 0.9999952419626208
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "The writers have made comprehensive changes to the document in response to several of my initial reservations. The revised edition is also more coherent and simpler to grasp. I now endorse this updated version, for approval. Have adjusted my rating accordingly. \nThis study presents an approach, to understanding LSTM models that are frequently noted for being challenging to interpret effectively.The authors suggest a method to break down the predictions made by an LSTM in a question answer scenario into scores that highlight the importance of words.These scores are then applied to create patterns that can pinpoint answers using a matching process.On the WikiMovies dataset the new pattern matching technique achieves accuracy results to those of a typical LSTM model this showcasing the methods efficiency. \nThe reason I am drawn to this work is because the clarity of LSTMs still poses a challenge that needs to be addressed openly and effectively maintained. Furthermore the remarkable success of the pattern matching method was quite impressive. Nevertheless there are some parts of the pattern extraction procedure that lack elaboration and the assessment is confined to a very particular task focusing solely on word level predictions. I suggest considering the paper for acceptance in its state but suggest that the authors offer more details, on their methodology to potentially contribute to NLP research community advancements. \nI appreciate your thoughts. It's good to hear from you.\nCould you please offer a thorough explanation of the particular QA tasks being discussed prior, to section 33? It seems unclear at that point that the responses refer to entities within the document. \nSection 4 in the document discusses whether the softmax output is making predictions based on a 0 or 2 value, such, as determining if a word is the correct answer or not. \nPlease explain what the P and Q vectors stand for in Section 4 of your research paper in relation to transforming the underlying state into a two dimensional vector, for the purpose of binary classification? \nHow does the effectiveness of the pattern matching technique change when using cutoff constants? \nIn Section 5 do you have any questions, in the dataset where the answersre not specific named entities or objects? \nHow can we modify the suggested method to suit tasks that don't involve making predictions at the word level. Like extending it to tasks at the sentence level such, as sentiment analysis? "
        }
    ],
    "editorDocumentId": null
}