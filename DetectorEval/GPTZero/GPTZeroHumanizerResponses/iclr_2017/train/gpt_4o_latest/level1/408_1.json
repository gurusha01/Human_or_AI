{
    "version": "2025-03-13-base",
    "scanId": "e6270aec-1b38-4422-8098-19d6b221c1b1",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "Key Points of Contribution",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999990463256836,
                    "sentence": "This study focuses on the challenge of creating acoustic word embeddings that convert speech sections into consistent vectors for activities, like speech retrieval and recognition.The writers introduce a multi perspective method that simultaneously develops embeddings for acoustic sequences and their related character sequences through deep bidirectional LSTMs and multi view contrastive losses.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999991059303284,
                    "sentence": "The article presents types of loss functions such as fixed margin and cost sensitive losses and assesses their performance on tasks like word distinction and similarity measurement across different perspectives and scenarios in spoken and written queries show that the new method surpasses previous techniques, in distinguishing words acoustically and shows potential in diverse view tasks by emphasizing the value of multi view embeddings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999989867210388,
                    "sentence": "Decision has been approved.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999989867210388,
                    "sentence": "The main reasons for accepting the paper are its multi view approach that is well supported and addresses a gap in existing research and the convincing empirical evidence showing significant enhancements compared to previous techniques.The study is conducted with a methodological framework including comprehensive experiments and, in depth analyses to substantiate its findings.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "Reasons, for Support",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999990463256836,
                    "sentence": "The paper addresses an overlooked issue of creating embeddings that encompass both acoustic and orthographic details together in a comprehensive manner within the research space.The rationale behind this choice aligns well with existing literature since earlier studies primarily concentrated on either embeddings alone or disregarded the connection, between acoustic and orthographic representations altogether.The introduction of a view perspective serves as a logical and creative progression that fills these existing voids.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998927116394,
                    "sentence": "The authors have employed bidirectional LSTMs and contrastive losses effectively considering the nature of the data they are working with in their study on methodological rigor.They have thoroughly examined loss functions and architectures, in a systematic manner to offer a comprehensive assessment.The incorporation of a cost loss to measure orthographic edit distances reflects careful consideration and supports the objective of enhancing word similarity tasks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999986290931702,
                    "sentence": "Ways to Enhance Your Work",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999991059303284,
                    "sentence": "The paper should clarify its objectives effectively by streamlining the discussion of multiple objectives like obj 2 and obj3 to help readers unfamiliar with contrastive learning better understand the differences, between them; a summary table outlining the main characteristics of each objective would be beneficial.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999990463256836,
                    "sentence": "The paper mainly discusses evaluating tasks within the core of a matter; however it would be beneficial to enhance the study by incorporating findings related to practical applications, like identifying spoken terms or recognizing speech patterns.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998927116394,
                    "sentence": "This could offer proof of the embeddings real world usefulness.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960064888,
                    "sentence": "Phonetic Oversight Mentioned by the Authors involves considering the use of sequences, for guidance suggesting that conducting a small scale study or evaluation comparing orthographic and phonetic oversight could offer valuable perspectives.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958872795105,
                    "sentence": "The paper employs negative sampling to calculate contrastive losses but suggests considering advanced sampling methods like hard negative mining for enhancing embeddings and warranting a discussion, on it.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999967217445374,
                    "sentence": "Questions to Ask Writers",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999997615814209,
                    "sentence": "How well do the word representations perform with words that haven't been encountered before in speech recognition or search activities, in the real world?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "Have you tried out this method on more varied sets of data?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "Could you explain further why using the cost loss did not lead to notable enhancements in distinguishing words during tasks even though it was effective, in tasks related to word similarity?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999975562095642,
                    "sentence": "How much do the outcomes change based upon the hyperparameters chosená…³like the difference, in losses or the quantity of LSTM layers used?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999972581863403,
                    "sentence": "In general this paper provides an addition to the area of acoustic word embeddings and stands out as a promising contender, for approval.The recommendations put forth are geared towards improving the clarity and effectiveness of the research.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999954714856171,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 4.528514382929871e-06,
                        "ai_paraphrased": 0.9999954714856171
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 4.528414382929901e-06,
                            "ai_paraphrased": 0.9999954714856171
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "\nKey Points of Contribution\nThis study focuses on the challenge of creating acoustic word embeddings that convert speech sections into consistent vectors for activities, like speech retrieval and recognition.The writers introduce a multi perspective method that simultaneously develops embeddings for acoustic sequences and their related character sequences through deep bidirectional LSTMs and multi view contrastive losses. The article presents types of loss functions such as fixed margin and cost sensitive losses and assesses their performance on tasks like word distinction and similarity measurement across different perspectives and scenarios in spoken and written queries show that the new method surpasses previous techniques, in distinguishing words acoustically and shows potential in diverse view tasks by emphasizing the value of multi view embeddings. \nDecision has been approved.\nThe main reasons for accepting the paper are its multi view approach that is well supported and addresses a gap in existing research and the convincing empirical evidence showing significant enhancements compared to previous techniques.The study is conducted with a methodological framework including comprehensive experiments and, in depth analyses to substantiate its findings. \nReasons, for Support \nThe paper addresses an overlooked issue of creating embeddings that encompass both acoustic and orthographic details together in a comprehensive manner within the research space.The rationale behind this choice aligns well with existing literature since earlier studies primarily concentrated on either embeddings alone or disregarded the connection, between acoustic and orthographic representations altogether.The introduction of a view perspective serves as a logical and creative progression that fills these existing voids. \nThe authors have employed bidirectional LSTMs and contrastive losses effectively considering the nature of the data they are working with in their study on methodological rigor.They have thoroughly examined loss functions and architectures, in a systematic manner to offer a comprehensive assessment.The incorporation of a cost loss to measure orthographic edit distances reflects careful consideration and supports the objective of enhancing word similarity tasks. \n\nWays to Enhance Your Work\nThe paper should clarify its objectives effectively by streamlining the discussion of multiple objectives like obj 2 and obj3 to help readers unfamiliar with contrastive learning better understand the differences, between them; a summary table outlining the main characteristics of each objective would be beneficial. \nThe paper mainly discusses evaluating tasks within the core of a matter; however it would be beneficial to enhance the study by incorporating findings related to practical applications, like identifying spoken terms or recognizing speech patterns. This could offer proof of the embeddings real world usefulness. \nPhonetic Oversight Mentioned by the Authors involves considering the use of sequences, for guidance suggesting that conducting a small scale study or evaluation comparing orthographic and phonetic oversight could offer valuable perspectives. \nThe paper employs negative sampling to calculate contrastive losses but suggests considering advanced sampling methods like hard negative mining for enhancing embeddings and warranting a discussion, on it. \nQuestions to Ask Writers \nHow well do the word representations perform with words that haven't been encountered before in speech recognition or search activities, in the real world ? Have you tried out this method on more varied sets of data? \nCould you explain further why using the cost loss did not lead to notable enhancements in distinguishing words during tasks even though it was effective, in tasks related to word similarity? \nHow much do the outcomes change based upon the hyperparameters chosenâ€”like the difference, in losses or the quantity of LSTM layers used? \nIn general this paper provides an addition to the area of acoustic word embeddings and stands out as a promising contender, for approval.The recommendations put forth are geared towards improving the clarity and effectiveness of the research. "
        }
    ],
    "editorDocumentId": null
}