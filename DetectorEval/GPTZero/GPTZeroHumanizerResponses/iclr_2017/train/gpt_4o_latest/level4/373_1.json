{
    "version": "2025-03-13-base",
    "scanId": "78ef3523-f6f8-4534-a688-7301cde0a76a",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.4648027718067169,
                    "sentence": "The writers introduce types of transfer learning techniques to neural network models for use, in various natural language processing tagging assignments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.4225695729255676,
                    "sentence": "The realm of task learning is extensive; however the suggested methods do not seem notably groundbreaking in terms of machine learning perspective.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5050320029258728,
                    "sentence": "Elements of a standard NLP framework are distributed among various tasks based upon the specific task requirement, at hand.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6585330367088318,
                    "sentence": "The uniqueness primarily comes from the structure used in NLP tagging assignments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.46891239285469055,
                    "sentence": "The results of the experiment show that the suggested method works well in situations where there is not labeled data available (see Figure 2).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.606706976890564,
                    "sentence": "Nevertheless applying it on a scale only shows minor enhancements as shown in Table 3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.6062746047973633,
                    "sentence": "The findings presented in Figure 2 raise some doubts; it appears that the authors kept the structure constant while adjusting the quantity of labeled information used in their study.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5639222860336304,
                    "sentence": "Overall the paper is nicely.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                },
                {
                    "generated_prob": 0.5060926675796509,
                    "sentence": "It seems like the new ideas are limited and the experiment testing is not very impressive.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": false
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.11111110864197542
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.02318840472169716
                }
            ],
            "completely_generated_prob": 0.0890032676306125,
            "class_probabilities": {
                "human": 0.9108455152503582,
                "ai": 0.0890032676306125,
                "mixed": 0.00015121711902932612
            },
            "average_generated_prob": 0,
            "predicted_class": "human",
            "confidence_score": 0.9108455152503582,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.0890032676306125,
                    "human": 0.9108455152503582,
                    "mixed": 0.00015121711902932612
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {},
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written entirely by a human.",
            "document_classification": "HUMAN_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "The writers introduce types of transfer learning techniques to neural network models for use, in various natural language processing tagging assignments. \nThe realm of task learning is extensive; however the suggested methods do not seem notably groundbreaking in terms of machine learning perspective. Elements of a standard NLP framework are distributed among various tasks based upon the specific task requirement, at hand. \nThe uniqueness primarily comes from the structure used in NLP tagging assignments. \nThe results of the experiment show that the suggested method works well in situations where there is not labeled data available (see Figure 2). Nevertheless applying it on a scale only shows minor enhancements as shown in Table 3. \nThe findings presented in Figure 2 raise some doubts; it appears that the authors kept the structure constant while adjusting the quantity of labeled information used in their study. \nOverall the paper is nicely. It seems like the new ideas are limited and the experiment testing is not very impressive. "
        }
    ],
    "editorDocumentId": null
}