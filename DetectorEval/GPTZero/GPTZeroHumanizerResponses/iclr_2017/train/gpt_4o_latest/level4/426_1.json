{
    "version": "2025-03-13-base",
    "scanId": "d478c5a2-a9e2-418f-a15f-102d94a85ab5",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999985694885254,
                    "sentence": "This study delves into the synchronization of word representations, in languages when the embeddings are trained separately in single language environments.The method tackles an applicable issue since there are potential situations where this approach could be valuable.While the paper is overall well developed the assessment seems constrained.Introducing a robust real world application would have enhanced the research.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999983906745911,
                    "sentence": "The concept of Softmax being inverted is truly intriguing.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999985694885254,
                    "sentence": "There are a couple of concerns that need attention in an updated draft of this paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999983310699463,
                    "sentence": "The paper fails to mention the study by Haghigh et al.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999987483024597,
                    "sentence": "titled \"Learning Bilingual Lexicons from Monolingual Corporations \" which seems to be a prior research piece concerning the application of CCA for bilingual alignment purposes in the current context.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999985694885254,
                    "sentence": "This study and its significance in relation, to the approach need to be addressed in further detail.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999987483024597,
                    "sentence": "1 Also worth mentioning is the work by Hermann and Blunsom (2013) titled \" distributed representations without word alignment,\" which appears to be a suitable reference, for acquiring multilingual word embeddings using aligned multilingual datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999984502792358,
                    "sentence": "The studies could have been more interesting if they had involved a range of language pairs instead of just concentrating on European/Romance languages.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999983906745911,
                    "sentence": "The emphasis on meeting orthogonality criteria appears to be related to the notion of employing a Mahalanobisdistance or covariance matrix for acquiring these mappings, which could benefit from further discussion, in this regard.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988675117493,
                    "sentence": "When thinking about how to describe aligning words, across languages accurately than using the term \"translation (performance/etc.)",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999988079071045,
                    "sentence": "it seems like this term may not fully capture the complexity of the process and could benefit from a more precise description.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999987483024597,
                    "sentence": "The abstract incorrectly cites Mikolov so it needs correction.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999963306602285,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 3.669339771538318e-06,
                        "ai_paraphrased": 0.9999963306602285
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 3.669239771538348e-06,
                            "ai_paraphrased": 0.9999963306602285
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This study delves into the synchronization of word representations, in languages when the embeddings are trained separately in single language environments.The method tackles an applicable issue since there are potential situations where this approach could be valuable.While the paper is overall well developed the assessment seems constrained.Introducing a robust real world application would have enhanced the research. \nThe concept of Softmax being inverted is truly intriguing. \nThere are a couple of concerns that need attention in an updated draft of this paper.\nThe paper fails to mention the study by Haghigh et al. titled \"Learning Bilingual Lexicons from Monolingual Corporations \" which seems to be a prior research piece concerning the application of CCA for bilingual alignment purposes in the current context. This study and its significance in relation, to the approach need to be addressed in further detail. \n1 Also worth mentioning is the work by Hermann and Blunsom (2013) titled \" distributed representations without word alignment,\" which appears to be a suitable reference, for acquiring multilingual word embeddings using aligned multilingual datasets. \nThe studies could have been more interesting if they had involved a range of language pairs instead of just concentrating on European/Romance languages. \nThe emphasis on meeting orthogonality criteria appears to be related to the notion of employing a Mahalanobisdistance or covariance matrix for acquiring these mappings, which could benefit from further discussion, in this regard. \nWhen thinking about how to describe aligning words, across languages accurately than using the term \"translation (performance/etc.) it seems like this term may not fully capture the complexity of the process and could benefit from a more precise description. \nThe abstract incorrectly cites Mikolov so it needs correction. "
        }
    ],
    "editorDocumentId": null
}