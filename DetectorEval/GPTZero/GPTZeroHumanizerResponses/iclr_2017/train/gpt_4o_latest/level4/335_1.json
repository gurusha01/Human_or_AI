{
    "version": "2025-03-13-base",
    "scanId": "539781e8-ea86-44fa-ac52-7fcc08a9f5dc",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.99993896484375,
                    "sentence": "This document presents a framework based on information theory for self guided learning that focuses on maximizing the connection between input and output data known as the infomax principle.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999538064002991,
                    "sentence": "The writers suggest a two stage method to tackle this issue; Initially breaking down the goal into two smaller problems using an approximate approach to mutual information analysis and finding direct solutions for each part.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999696612358093,
                    "sentence": "These solutions serve as starting points, for the solution and are further improved through a gradient descent technique.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999313354492188,
                    "sentence": "Although the theoretical basis and calculations discussed in the paper seem solid overall there are opportunities to enhance the clarity and structure of the content.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999579787254333,
                    "sentence": "One suggestion is to start by offering a summary of the key findings and outlining the approach to derivations rather than diving into a detailed step by step explanation for each equation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999604821205139,
                    "sentence": "The intricate derivations could potentially complicate the points of the results so it might be beneficial to postpone them to later sections or include them in an appendix, for easier comprehension.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999505877494812,
                    "sentence": "Here are a few key areas that the writers might consider discussing;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999669194221497,
                    "sentence": "In the paragraph on page 4 of the document mentioned above it states that maximizing I(X; R ) will lead to maximization of I(Y; R ) and I(X Y ^ U ).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999540448188782,
                    "sentence": "The connection between the former and the latter is clear due to Equation 2.20 as indicated in the text.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999785423278809,
                    "sentence": "However the relationship between I(X; R ) and I(X Y ^ U ) is indirectly linked through Equation 2.21.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999978244304657,
                    "sentence": "Considering this difference can you provide a rationale, for asserting that maximizing the former automatically maximizes the latter?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999817609786987,
                    "sentence": "In the paragraph, before Section 222 states that dropout is employed to avoid overfitting and could be seen as an effort to decrease the rank of the weight matrix; yet no additional details are given to back up this claim Could you explain why this perspective is valid?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999676942825317,
                    "sentence": "On the part of page 9 it says \"We will explore ways to achieve the best solution for C in two particular scenarios.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999794363975525,
                    "sentence": "My interpretation is that the approach doesn't promise to find the best solution for C in those situations because of the nonconvexe nature of Equation 2s constraint (which is a quadratic equality) leading to only a local optimum being possible instead of a global one.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999983012676239,
                    "sentence": "If there's uncertainty about achieving optimality and we can't guarantee it happening every time as per your request, for clarification.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9998877176965216,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.00011228230347837152,
                        "ai_paraphrased": 0.9998877176965216
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.00011228220347837156,
                            "ai_paraphrased": 0.9998877176965216
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This document presents a framework based on information theory for self guided learning that focuses on maximizing the connection between input and output data known as the infomax principle. The writers suggest a two stage method to tackle this issue; Initially breaking down the goal into two smaller problems using an approximate approach to mutual information analysis and finding direct solutions for each part. These solutions serve as starting points, for the solution and are further improved through a gradient descent technique. \nAlthough the theoretical basis and calculations discussed in the paper seem solid overall there are opportunities to enhance the clarity and structure of the content. One suggestion is to start by offering a summary of the key findings and outlining the approach to derivations rather than diving into a detailed step by step explanation for each equation. The intricate derivations could potentially complicate the points of the results so it might be beneficial to postpone them to later sections or include them in an appendix, for easier comprehension. \nHere are a few key areas that the writers might consider discussing; \nIn the paragraph on page 4 of the document mentioned above it states that maximizing I(X ; R ) will lead to maximization of I(Y ; R ) and I(X Y ^ U ). The connection between the former and the latter is clear due to Equation 2.20 as indicated in the text. However the relationship between I(X ; R ) and I(X Y ^ U ) is indirectly linked through Equation 2.21. Considering this difference can you provide a rationale, for asserting that maximizing the former automatically maximizes the latter ?\nIn the paragraph, before Section 222 states that dropout is employed to avoid overfitting and could be seen as an effort to decrease the rank of the weight matrix; yet no additional details are given to back up this claim Could you explain why this perspective is valid? \nOn the part of page 9 it says \"We will explore ways to achieve the best solution for C in two particular scenarios.\" My interpretation is that the approach doesn't promise to find the best solution for C in those situations because of the nonconvexe nature of Equation 2s constraint (which is a quadratic equality) leading to only a local optimum being possible instead of a global one. If there's uncertainty about achieving optimality and we can't guarantee it happening every time as per your request, for clarification. "
        }
    ],
    "editorDocumentId": null
}