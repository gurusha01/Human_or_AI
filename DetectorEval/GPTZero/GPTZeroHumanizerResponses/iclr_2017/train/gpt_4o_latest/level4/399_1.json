{
    "version": "2025-03-13-base",
    "scanId": "8a6b6692-2159-4d3d-be5d-7851e6d256a4",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999958872795105,
                    "sentence": "This document presents a technique to boost the parameter count in a layer substantially without escalating computational expenses beyond those of current cutting edge models or even reducing them further if possible.The method involves utilizing an array of experts made up of smaller networks with only a select few being activated based on adaptative gating network mechanisms.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999958872795105,
                    "sentence": "The idea is easy to grasp.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960660934448,
                    "sentence": "What sets it apart is how the gating network is structured - its focused on two goals.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999961853027344,
                    "sentence": "One is to make sure all experts play their part (importance).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960064888,
                    "sentence": "The other is to evenly spread out the workload, across them (load).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999994158744812,
                    "sentence": "The paper also discusses two methods designed for enhancing the batch size handled by each specialist in order to maximize GPU parallelization capabilities Experiments using the suggested approach on RNNs for a language modeling assignment indicate its superior performance compared to the state of the art results with notably reduced computational requirements by strategically utilizing a significantly larger parameter space.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999993085861206,
                    "sentence": "Additionally findings from machine translation experiments show that a model with, than 30 times the parameter count can outshine existing techniques while utilizing only half of the computational resources effectively.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999861717224121,
                    "sentence": "Here are a few thoughts I'd like to share about the paper;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999865293502808,
                    "sentence": "The presentation definitely needs some work to enhance its clarity and effectiveness in conveying the message across to the readers !",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999904632568359,
                    "sentence": "Even though the paper is quite lengthy at 11 pages (I feel that's a bit too much) there is a need for a stronger justification and a simpler explanation in Section 3.The equation mentioned in Equation 8 definitely deserves more attention and elaboration than it currently receives in the document.There could be space freed up by relocating detailed information about experiments such as architecture and training specifics to an appendix, for those who are interested.Additionally the experiments section could flow better by concluding one experiment before moving on to the one.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999924302101135,
                    "sentence": "The writing also has some problems, like the sudden conclusion of Section 3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999931454658508,
                    "sentence": "The paper seems to leave out references related to conditional computation, such, as",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 11,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997938739332977,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997938739332977,
                "mixed": 0.00020612606670239523
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997938739332977,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997938739332977,
                    "human": 0,
                    "mixed": 0.00020612606670239523
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999963517240755,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 3.648275924490892e-06,
                        "ai_paraphrased": 0.9999963517240755
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 3.6481759244909216e-06,
                            "ai_paraphrased": 0.9999963517240755
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This document presents a technique to boost the parameter count in a layer substantially without escalating computational expenses beyond those of current cutting edge models or even reducing them further if possible.The method involves utilizing an array of experts made up of smaller networks with only a select few being activated based on adaptative gating network mechanisms. The idea is easy to grasp. What sets it apart is how the gating network is structured – its focused on two goals. One is to make sure all experts play their part (importance). The other is to evenly spread out the workload, across them (load). \nThe paper also discusses two methods designed for enhancing the batch size handled by each specialist in order \tto maximize GPU parallelization capabilities Experiments using the suggested approach on RNNs for a language modeling assignment indicate its superior performance compared to the state of the art results with notably reduced computational requirements by strategically utilizing a significantly larger parameter space. Additionally findings from machine translation experiments show that a model with, than 30 times the parameter count can outshine existing techniques while utilizing only half of the computational resources effectively. \nHere are a few thoughts I'd like to share about the paper;   \nThe presentation definitely needs some work to enhance its clarity and effectiveness in conveying the message across to the readers ! Even though the paper is quite lengthy at 11 pages (I feel that's a bit too much) there is a need for a stronger justification and a simpler explanation in Section 3.The equation mentioned in Equation 8 definitely deserves more attention and elaboration than it currently receives in the document.There could be space freed up by relocating detailed information about experiments such as architecture and training specifics to an appendix, for those who are interested.Additionally the experiments section could flow better by concluding one experiment before moving on to the one. The writing also has some problems, like the sudden conclusion of Section 3​.   \nThe paper seems to leave out references related to conditional computation, such, as "
        }
    ],
    "editorDocumentId": null
}