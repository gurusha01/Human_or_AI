{
    "version": "2025-03-13-base",
    "scanId": "dae8888e-2bd4-4c8e-acda-905b2cb285b6",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999961256980896,
                    "sentence": "This study introduces an approach to binary autoencoders by reframing the goal as minimizing the maximum reconstruction error over the training data based on the observed intermediate representations.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999995768070221,
                    "sentence": "One significant discovery is that this approach results in a problem that's bi concave and can be efficiently solved using alternating minimization methods.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999943971633911,
                    "sentence": "A substantial contribution, at the heart of this research paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999960660934448,
                    "sentence": "The authors back up their method with experiments that show improved results for single hidden layer autoencoders in comparison, to a traditional technique.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999923706054688,
                    "sentence": "The experimental part of the paper is a bit restricted because there is already plenty of research on autoencoders with versions that perform better than simple methods like denoising autoencoders without extra complications involved in them; however the papers analysis sets the stage for creating a new learning method for an age old issue which makes it a fascinating subject, for conversation.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999971044741786,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 2.895525821485083e-06,
                        "ai_paraphrased": 0.9999971044741786
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 2.895425821485113e-06,
                            "ai_paraphrased": 0.9999971044741786
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This study introduces an approach to binary autoencoders by reframing the goal as minimizing the maximum reconstruction error over the training data based on the observed intermediate representations. One significant discovery is that this approach results in a problem that's bi concave and can be efficiently solved using alternating minimization methods. A substantial contribution, at the heart of this research paper. The authors back up their method with experiments that show improved results for single hidden layer autoencoders in comparison, to a traditional technique. \nThe experimental part of the paper is a bit restricted because there is already plenty of research on autoencoders with versions that perform better than simple methods like denoising autoencoders without extra complications involved in them; however the papers analysis sets the stage for creating a new learning method for an age old issue which makes it a fascinating subject, for conversation. "
        }
    ],
    "editorDocumentId": null
}