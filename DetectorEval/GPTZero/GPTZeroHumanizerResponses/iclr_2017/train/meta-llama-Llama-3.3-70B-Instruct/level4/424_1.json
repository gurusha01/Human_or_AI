{
    "version": "2025-03-13-base",
    "scanId": "c3064290-9acf-4583-9610-0e90c23865ce",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999986290931702,
                    "sentence": "This study delves into how adjusting model parameters while training and employing a smoothed objective function for optimization are related concepts explored in the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999983906745911,
                    "sentence": "While the description of the gradient g in Equations 4 to 7 may be ambiguous Equation 8 is clear and Section 2 point 3 effectively shows how minimizing the smoothed loss is equivalent to training with Gaussian parameter noise, for certain smoothing functions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999979734420776,
                    "sentence": "The authors build upon this idea by introducing smoothing functions to create a more intricate cooling effect that can be utilized with modern neural network designs like deep ReLU networks and LSTM recurrent networks.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "Nevertheless the resulting cooling effect displayed in Section 4 might seem paradoxical; the Binomial (or Bernoulli ) parameter rises from 0 (indicating identity layers ) to 1 ( indicating deterministic ReLU layers) hinting at an initial introduction of noise, by the network that could potentially reverse the cooling effect.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999974966049194,
                    "sentence": "The practical methods of annealing implementation seem to be crafted and tailored for specific purposes; for instance Algorithm 1 outlines a detailed 9 step procedure for deciding unit activation at every layer.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999998152256012,
                    "sentence": "Considering the application of the smoothing framework to annealing in the authors' work it might have been helpful to include a portion, in the paper that delves into examining uncomplicated models utilizing elementary smoothing techniques.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999974370002747,
                    "sentence": "It would be interesting to observe cases where the perturbation methods based on the smoothing concept excel over heuristic perturbation methods, in optimization tasks to showcase the efficacy of the suggested approach.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999835255082843,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 1.6474491715693897e-05,
                        "ai_paraphrased": 0.9999835255082843
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 1.6474391715693927e-05,
                            "ai_paraphrased": 0.9999835255082843
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This study delves into how adjusting model parameters while training and employing a smoothed objective function for optimization are related concepts explored in the paper. While the description of the gradient g in Equations 4 to 7 may be ambiguous Equation 8 is clear and Section 2 point 3 effectively shows how minimizing the smoothed loss is equivalent to training with Gaussian parameter noise, for certain smoothing functions. \nThe authors build upon this idea by introducing smoothing functions to create a more intricate cooling effect that can be utilized with modern neural network designs like deep ReLU networks and LSTM recurrent networks. Nevertheless the resulting cooling effect displayed in Section 4 might seem paradoxical; the Binomial (or Bernoulli ) parameter rises from 0 (indicating identity layers ) to 1 ( indicating deterministic ReLU layers) hinting at an initial introduction of noise, by the network that could potentially reverse the cooling effect. \nThe practical methods of annealing implementation seem to be crafted and tailored for specific purposes; for instance Algorithm 1 outlines a detailed 9 step procedure for deciding unit activation at every layer. Considering the application of the smoothing framework to annealing in the authorsâ€™ work it might have been helpful to include a portion, in the paper that delves into examining uncomplicated models utilizing elementary smoothing techniques. It would be interesting to observe cases where the perturbation methods based on the smoothing concept excel over heuristic perturbation methods, in optimization tasks to showcase the efficacy of the suggested approach. "
        }
    ],
    "editorDocumentId": null
}