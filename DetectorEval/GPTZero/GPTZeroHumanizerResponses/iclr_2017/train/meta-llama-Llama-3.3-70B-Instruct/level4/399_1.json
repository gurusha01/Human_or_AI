{
    "version": "2025-03-13-base",
    "scanId": "9554e627-8afa-4f7d-b043-11361ed8564e",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999849200248718,
                    "sentence": "This research article introduces a method to significantly boost the number of parameters in a single layer while keeping computational efficiency on par, with or surpassing existing cutting edge models known as state of the art (SOTA).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999855756759644,
                    "sentence": "The main idea is centered around utilizing a group of experts (MoE) made up of small networks that are selectively activated through a gating network.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999772906303406,
                    "sentence": "While the concept seems simple at glance the real breakthrough is, in how the gating network is crafted.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999856352806091,
                    "sentence": "Its tailored to meet two crucial goals efficiently utilizing all experts (importance) and evenly distributing the computational workload among them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999829530715942,
                    "sentence": "Moreover the article presents two methods designed to boost the volume of data processed by specialists at a time in order o maximize parallel processing on GPUs.Experimental findings show the effectiveness of the suggested method in enhancing performance of neural networks (RNNs), for language modeling tasks.This outperforms state of the art models while reducing computation significantly.This improvement is creditedto using a number of parameters selectively.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999852180480957,
                    "sentence": "Moreover findings from experiments on machine translation indicate that a model containing, than 30 times the parameters can surpass state of the art models while using only half the computational resources effectively.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999687075614929,
                    "sentence": "Here are some recommendations to enhance the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999679923057556,
                    "sentence": "The writers could improve how they present the information by giving an easier to understand explanation in Section 3..",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999626278877258,
                    "sentence": "It's a part of the paper that needs more attention to detail.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999701976776123,
                    "sentence": "Like explaining Equation 8 in more depth would be beneficial.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999702572822571,
                    "sentence": "One way to do this could be moving all the details about the setup and training process, to the appendix so that the main narrative stays on track with the key points.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999738931655884,
                    "sentence": "Also it would help if they restructured the experiment section so that each experiment is fully explained before moving on to the one for better clarity and understanding.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999757409095764,
                    "sentence": "Furthermore some small writing mistakes need to be addressed towards the conclusion of Section 3.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999818205833435,
                    "sentence": "The research paper needs to include references about conditional computation to give a more complete background, for the study.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 4,
                    "completely_generated_prob": 0.8708627247549962
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 6,
                    "completely_generated_prob": 0.9000234362273952
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999940965362515,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 5.903463748597684e-06,
                        "ai_paraphrased": 0.9999940965362515
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 5.903363748597714e-06,
                            "ai_paraphrased": 0.9999940965362515
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This research article introduces a method to significantly boost the number of parameters in a single layer while keeping computational efficiency on par, with or surpassing existing cutting edge models known as state of the art (SOTA). The main idea is centered around utilizing a group of experts (MoE) made up of small networks that are selectively activated through a gating network. While the concept seems simple at glance the real breakthrough is, in how the gating network is crafted. Its tailored to meet two crucial goals efficiently utilizing all experts (importance) and evenly distributing the computational workload among them. \nMoreover the article presents two methods designed to boost the volume of data processed by specialists at a time in order o maximize parallel processing on GPUs.Experimental findings show the effectiveness of the suggested method in enhancing performance of neural networks (RNNs), for language modeling tasks.This outperforms state of the art models while reducing computation significantly.This improvement is creditedto using a number of parameters selectively. Moreover findings from experiments on machine translation indicate that a model containing, than 30 times the parameters can surpass state of the art models while using only half the computational resources effectively. \nHere are some recommendations to enhance the paper.\nThe writers could improve how they present the information by giving an easier to understand explanation in Section 3.. It's a part of the paper that needs more attention to detail. Like explaining Equation 8 in more depth would be beneficial. One way to do this could be moving all the details about the setup and training process, to the appendix so that the main narrative stays on track with the key points. Also it would help if they restructured the experiment section so that each experiment is fully explained before moving on to the one for better clarity and understanding. Furthermore some small writing mistakes need to be addressed towards the conclusion of Section 3. \nThe research paper needs to include references about conditional computation to give a more complete background, for the study. "
        }
    ],
    "editorDocumentId": null
}