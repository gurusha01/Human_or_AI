{
    "version": "2025-03-13-base",
    "scanId": "ab5aa557-b607-4666-8b75-cfef5a511eeb",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9623028039932251,
                    "sentence": "The writers introduce a version of TensorFlow Fold that allows for carrying out computations without changing the computation graph structure itself.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.953210175037384,
                    "sentence": "They achieve this by creating a scheduler represented as a TensorFlow computational graph that can take in descriptions of graphs as input and process them accordingly.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9493649005889893,
                    "sentence": "This method brings about benefits, in scenarios where computations differ for each specific data point as demonstrated through the TreeRNN model.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9486241936683655,
                    "sentence": "They conduct experiments comparing this approach to using fixed batches with graph setups and batch sizes of 1.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9239960312843323,
                    "sentence": "The score is 7 because it doesn't compare with another method where a fresh TensorFlow graph is created for every dynamic batch to handle non uniform batches using standard TensorFlow features instead of depending on the suggested scheduling algorithm.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 5,
                    "completely_generated_prob": 0.8871651474786718
                }
            ],
            "completely_generated_prob": 0.7922638265983674,
            "class_probabilities": {
                "human": 0.20756912123631469,
                "ai": 0.7922638265983674,
                "mixed": 0.00016705216531779266
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.7922638265983674,
            "confidence_category": "medium",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.7922638265983674,
                    "human": 0.20756912123631469,
                    "mixed": 0.00016705216531779266
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9984973647200182,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 0.0015026352799818008,
                        "ai_paraphrased": 0.9984973647200182
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 0.0015026351799818007,
                            "ai_paraphrased": 0.9984973647200182
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is moderately confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "The writers introduce a version of TensorFlow Fold that allows for carrying out computations without changing the computation graph structure itself. They achieve this by creating a scheduler represented as a TensorFlow computational graph that can take in descriptions of graphs as input and process them accordingly. This method brings about benefits, in scenarios where computations differ for each specific data point as demonstrated through the TreeRNN model. They conduct experiments comparing this approach to using fixed batches with graph setups and batch sizes of 1. The score is 7 because it doesn't compare with another method where a fresh TensorFlow graph is created for every dynamic batch to handle non uniform batches using standard TensorFlow features instead of depending on the suggested scheduling algorithm. "
        }
    ],
    "editorDocumentId": null
}