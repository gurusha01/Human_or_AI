{
    "version": "2025-03-13-base",
    "scanId": "a51d625a-58b5-4cf9-8593-ca150f13c8f5",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9999834299087524,
                    "sentence": "This research builds upon the advancements of reinforcement learning in complex state spaces by integrating deep neural networks as function estimators to unveil a new algorithm that showcases exceptional capabilities in uncharted 3D settings with unprocessed sensory inputs and showcases improved adaptability across diverse objectives and settingsᅳmaking a mark by clinching the top spot, in the Visual Doom AI challenge.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999889731407166,
                    "sentence": "The algorithms main idea is to use simple observations like ammunition or health from the game engine as a target for prediction with supervision in mind.The prediction process depends on a goal vector and the action currently taken.By training the system the best course of action, for the situation is determined by selecting the action that yields the highest expected result based on the intended goal.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999896287918091,
                    "sentence": "Unlike the feature representations updated with new information autonomouslyᅳthis learning method involves supervision without any temporal difference (TD) related connection, between the current states predictions and those of the subsequent states.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999862313270569,
                    "sentence": "The writers expand upon studies that forecast upcoming scenarios within reinforcement learning and objective oriented function approximations as discussed in section 2 of the paper.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999856352806091,
                    "sentence": "The main highlights of this research involve emphasizing Monte Carlo estimation techniques and the use of metrics for forecasting purposes along, with goal parameters and a thorough practical assessment compared to relevant earlier studies.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999879002571106,
                    "sentence": "The authors not compare the Visual Doom AI but also show how their algorithm can adapt to minor goal adjustments without needing additional training sessions effortlessly in their research paper The writing is excellent and the practical findings are convincing which greatly enriches the field.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999876022338867,
                    "sentence": "Some small ways we could enhance our discussion involve touching on the estimation during training that assumes an on policy setting while gaining knowledge from a replay buffer system.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999899864196777,
                    "sentence": "It's important to recognize the algorithms dependence on metadata like details about predictable aspects of sensory input and to openly address the drawbacks of this method.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999890327453613,
                    "sentence": "Especially its possible inefficacy in environments, without such data points.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                }
            ],
            "completely_generated_prob": 1,
            "class_probabilities": {
                "human": 0,
                "ai": 1,
                "mixed": 0
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 1,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 1,
                    "human": 0,
                    "mixed": 0
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.999997252133453,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 2.7478665469438827e-06,
                        "ai_paraphrased": 0.999997252133453
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 2.7477665469439125e-06,
                            "ai_paraphrased": 0.999997252133453
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "This research builds upon the advancements of reinforcement learning in complex state spaces by integrating deep neural networks as function estimators to unveil a new algorithm that showcases exceptional capabilities in uncharted 3D settings with unprocessed sensory inputs and showcases improved adaptability across diverse objectives and settings—making a mark by clinching the top spot, in the Visual Doom AI challenge. \nThe algorithms main idea is to use simple observations like ammunition or health from the game engine as a target for prediction with supervision in mind.The prediction process depends on a goal vector and the action currently taken.By training the system the best course of action, for the situation is determined by selecting the action that yields the highest expected result based on the intended goal. Unlike the feature representations updated with new information autonomously—this learning method involves supervision without any temporal difference (TD) related connection, between the current states predictions and those of the subsequent states. \nThe writers expand upon studies that forecast upcoming scenarios within reinforcement learning and objective oriented function approximations as discussed in section 2 of the paper. The main highlights of this research involve emphasizing Monte Carlo estimation techniques and the use of metrics for forecasting purposes along, with goal parameters and a thorough practical assessment compared to relevant earlier studies. \nThe authors not compare the Visual Doom AI but also show how their algorithm can adapt to minor goal adjustments without needing additional training sessions effortlessly in their research paper The writing is excellent and the practical findings are convincing which greatly enriches the field. \nSome small ways we could enhance our discussion involve touching on the estimation during training that assumes an on policy setting while gaining knowledge from a replay buffer system. It's important to recognize the algorithms dependence on metadata like details about predictable aspects of sensory input and to openly address the drawbacks of this method. Especially its possible inefficacy in environments, without such data points. "
        }
    ],
    "editorDocumentId": null
}