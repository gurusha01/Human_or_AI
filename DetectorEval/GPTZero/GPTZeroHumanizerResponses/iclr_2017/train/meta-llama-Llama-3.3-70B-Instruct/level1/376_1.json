{
    "version": "2025-03-13-base",
    "scanId": "c01d7282-896f-45a5-a6e8-d15fda5a0634",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.9996288418769836,
                    "sentence": "Key.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9990203976631165,
                    "sentence": "Contributions of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9994622468948364,
                    "sentence": "The study explores how well different types of Recurrent Neural Network ( RNN ) designs can handle training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9995429515838623,
                    "sentence": "This includes RNNs, Long Short Term Memory ( LSTM ) networks, Gated Recurrent Units ( GRUs ) as well, as two new designs called the Update Gate RNN ( UGRNN ) and the Intersection RNN (+ RNN ).",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996523261070251,
                    "sentence": "The writers argue that through training all popular RNN structures reach similar limits in terms of task performance and capacity per unit; the apparent superiority of gated models over basic RNN models is mainly attributed to variations in ease of training rather, than capacity differences.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996259212493896,
                    "sentence": "Important Factors",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996216893196106,
                    "sentence": "After reviewing the paper I have chosen to accept it for two main reasons;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996527433395386,
                    "sentence": "The report offers an insightful analysis of the capabilities and adaptability of different RNN structuresá…³a key factor, in grasping the pros and cons of such models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9993342757225037,
                    "sentence": "The writers present a wealth of data to back up their arguments by showcasing various tasks and structures that underline the strength of their conclusions.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999083936214447,
                    "sentence": "Reasons, in Favor",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9988446831703186,
                    "sentence": "The research findings are noteworthy as they question the prevailing belief that gated RNN models outperform vanilla RNN models solely based their structure design differences.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9984924793243408,
                    "sentence": "Than that perspective the authors argue that the variation in effectiveness between these two types of models is mainly due to differences in their trainability.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999946355819702,
                    "sentence": "This insight carries implications, for how RNN models are designed and trained indicating that straightforward architectures could suffice for various tasks and emphasizing the need to enhance training methods rather than making architectures more complex.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999940395355225,
                    "sentence": "The research papers approach to experiments seems reliable as it includes fine tuning of hyperparameters and assesses various tasks and architectures.The findings are well explained and straightforward to comprehend through the use of charts and tables that back up the authors' arguments.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999942779541016,
                    "sentence": "More Input Wanted; Further Thoughts and Inquiries",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999950528144836,
                    "sentence": "To enhance the paper more",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999970197677612,
                    "sentence": "Could you offer an examination of the UGRNN and + RNN structures in the novel?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999972581863403,
                    "sentence": "It would be helpful to understand the reasons, behind their development and the decisions made in their design process.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999966621398926,
                    "sentence": "To better showcase the strength of the results you could include tasks or datasets, in the experimental assessment.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999957084655762,
                    "sentence": "Lets delve deeper into how these findings can influence the implementation and training of RNN models.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999963045120239,
                    "sentence": "I'm curious, about the questions the authors will cover in their response.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999968409538269,
                    "sentence": "How do the writers intend to expand their research to tackle intricate assignments or datasets that involve longer term connections or subtle language patterns?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999997615814209,
                    "sentence": "Could the writers offer explanation, on the design decisions made for the UGRNN and + RNN structures and how they connect with other RNN models currently in use?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999977350234985,
                    "sentence": "What are the authors views on how their discoveries will influence the advancement of RNN designs or training methods and what potential paths do they envision for this study, in the future?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 10,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 15,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 22,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 23,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997932945046397,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997932945046397,
                "mixed": 0.00020670549536025372
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997932945046397,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997932945046397,
                    "human": 0,
                    "mixed": 0.00020670549536025372
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999489039793102,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 5.1096020689798494e-05,
                        "ai_paraphrased": 0.9999489039793102
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 5.109592068979852e-05,
                            "ai_paraphrased": 0.9999489039793102
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "Key. Contributions of the Paper\nThe study explores how well different types of Recurrent Neural Network ( RNN ) designs can handle training. This includes RNNs, Long Short Term Memory ( LSTM ) networks, Gated Recurrent Units ( GRUs ) as well, as two new designs called the Update Gate RNN ( UGRNN ) and the Intersection RNN (+ RNN ). The writers argue that through training all popular RNN structures reach similar limits in terms of task performance and capacity per unit; the apparent superiority of gated models over basic RNN models is mainly attributed to variations in ease of training rather, than capacity differences. \nImportant Factors \nAfter reviewing the paper I have chosen to accept it for two main reasons; \nThe report offers an insightful analysis of the capabilities and adaptability of different RNN structuresâ€”a key factor, in grasping the pros and cons of such models. \nThe writers present a wealth of data to back up their arguments by showcasing various tasks and structures that underline the strength of their conclusions. \nReasons, in Favor\nThe research findings are noteworthy as they question the prevailing belief that gated RNN models outperform vanilla RNN models solely based their structure design differences. Than that perspective the authors argue that the variation in effectiveness between these two types of models is mainly due to differences in their trainability. This insight carries implications, for how RNN models are designed and trained indicating that straightforward architectures could suffice for various tasks and emphasizing the need to enhance training methods rather than making architectures more complex. \nThe research papers approach to experiments seems reliable as it includes fine tuning of hyperparameters and assesses various tasks and architectures.The findings are well explained and straightforward to comprehend through the use of charts and tables that back up the authorsâ€™ arguments. \nMore Input Wanted; Further Thoughts and Inquiries\nTo enhance the paper more \nCould you offer an examination of the UGRNN and + RNN structures in the novel? It would be helpful to understand the reasons, behind their development and the decisions made in their design process. \nTo better showcase the strength of the results you could include tasks or datasets, in the experimental assessment. \nLets delve deeper into how these findings can influence the implementation and training of RNN models. \nI'm curious, about the questions the authors will cover in their response.\nHow do the writers intend to expand their research to tackle intricate assignments or datasets that involve longer term connections or subtle language patterns? \nCould the writers offer explanation, on the design decisions made for the UGRNN and + RNN structures and how they connect with other RNN models currently in use? \nWhat are the authors views on how their discoveries will influence the advancement of RNN designs or training methods and what potential paths do they envision for this study, in the future? "
        }
    ],
    "editorDocumentId": null
}