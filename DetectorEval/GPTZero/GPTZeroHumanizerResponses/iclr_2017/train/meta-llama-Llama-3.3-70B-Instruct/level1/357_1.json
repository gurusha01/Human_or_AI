{
    "version": "2025-03-13-base",
    "scanId": "dc285460-688b-4185-ac29-5d543f0fba15",
    "documents": [
        {
            "sentences": [
                {
                    "generated_prob": 0.99992436170578,
                    "sentence": "A Brief Overview of the Paper",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999529123306274,
                    "sentence": "The research introduces a neural network known as Motion Content Network (MCnet) to anticipate forthcoming frames in real life video sequences effectively.The network divides the videos motion and content into encoder pathways to enhance future frame prediction accuracy.The motion encoder focuses on capturing the scenes dynamics while the content encoder extracts crucial spatial features from individual frames.This end, to end trainable network has the capability to forecast frames ahead seamlessly.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9996560215950012,
                    "sentence": "Choice",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999451041221619,
                    "sentence": "\"I have chosen to approve this document.\"",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999547004699707,
                    "sentence": "The rationale, behind the decision",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999594688415527,
                    "sentence": "The article addresses a defined issue within the realm of computer vision by focusing on forecasting upcoming frames, in real life video sequences.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999594688415527,
                    "sentence": "The method is well supported and situated within the existing body of research with a delineation of the drawbacks of prior approaches and how the new method overcomes them.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.99994295835495,
                    "sentence": "The article presents experimental findings that include both numerical and descriptive evaluations in comparison, to standard methods to showcase the efficiency of the suggested strategy.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9997850060462952,
                    "sentence": "Presenting Points of View",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999372363090515,
                    "sentence": "The document gives an comprehensive overview of the suggested design framework which encompasses the motion and content encoders as well as the integration layers and the decoder component.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9998577833175659,
                    "sentence": "The results from experiments showcase the efficiency of the proposed method with top notch performance on standard datasets.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999781847000122,
                    "sentence": "Furthermore the paper conducts an in depth analysis of the findings including an assessment of camera movement effects and a comparison, with a copy and paste reference point.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999984622001648,
                    "sentence": "More Feedback Available",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.999991238117218,
                    "sentence": "To enhance the paper more effectively I recommend that the authors take into account the following points;",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999934434890747,
                    "sentence": "Can you please share information, about the training process?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999935030937195,
                    "sentence": "It would be helpful to know about the optimization algorithm and the specific hyperparameter configurations used during training.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999915361404419,
                    "sentence": "To better showcase the effectiveness of the suggested method adding qualitative outcomes, like representations of the anticipated frames would be beneficial.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999940395355225,
                    "sentence": "When considering the suggested approachs uses one might think of scenarios, like video monitoring or self driving vehicles.",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999905228614807,
                    "sentence": "Queries, for the Writers",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999940991401672,
                    "sentence": "Could you share information, about the computing resources needed to develop the suggested network structure?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999956488609314,
                    "sentence": "How does the suggested approach deal, with situations involving camera movement or obstruction?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                },
                {
                    "generated_prob": 0.9999933838844299,
                    "sentence": "Any thoughts, on broadening the suggested approach to handle video prediction tasks like forecasting upcoming frames in videos featuring intricate backgrounds or ever changing scenes?",
                    "perplexity": 0,
                    "highlight_sentence_for_ai": true
                }
            ],
            "paragraphs": [
                {
                    "start_sentence_index": 0,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 1,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 2,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 3,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 4,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 5,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 6,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 7,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 8,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 9,
                    "num_sentences": 3,
                    "completely_generated_prob": 0.850090677245877
                },
                {
                    "start_sentence_index": 12,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 13,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 14,
                    "num_sentences": 2,
                    "completely_generated_prob": 0.8254776901813464
                },
                {
                    "start_sentence_index": 16,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 17,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 18,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 19,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 20,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                },
                {
                    "start_sentence_index": 21,
                    "num_sentences": 1,
                    "completely_generated_prob": 0.8181818033057853
                }
            ],
            "completely_generated_prob": 0.9997932945046397,
            "class_probabilities": {
                "human": 0,
                "ai": 0.9997932945046397,
                "mixed": 0.00020670549536025372
            },
            "average_generated_prob": 1,
            "predicted_class": "ai",
            "confidence_score": 0.9997932945046397,
            "confidence_category": "high",
            "confidence_scores_raw": {
                "identity": {
                    "ai": 0.9997932945046397,
                    "human": 0,
                    "mixed": 0.00020670549536025372
                }
            },
            "confidence_thresholds_raw": {
                "identity": {
                    "ai": {
                        "reject": 0.7,
                        "low": 0.75,
                        "medium": 0.92
                    },
                    "human": {
                        "reject": 0.7,
                        "low": 0.82,
                        "medium": 0.9126934656800181
                    },
                    "mixed": {
                        "reject": 0.7,
                        "low": 0.8,
                        "medium": 0.88
                    }
                }
            },
            "overall_burstiness": 0,
            "writing_stats": {},
            "subclass": {
                "ai": {
                    "predicted_class": "ai_paraphrased",
                    "result_message": "We are highly confident that this text has been rewritten by AI, an AI paraphraser or AI bypasser",
                    "confidence_score": 0.9999877731271919,
                    "confidence_category": "high",
                    "class_probabilities": {
                        "pure_ai": 1.2226872808115058e-05,
                        "ai_paraphrased": 0.9999877731271919
                    },
                    "confidence_scores_raw": {
                        "identity": {
                            "pure_ai": 1.2226772808115088e-05,
                            "ai_paraphrased": 0.9999877731271919
                        }
                    },
                    "confidence_thresholds_raw": {
                        "identity": {
                            "pure_ai": {
                                "reject": 0.7,
                                "low": 0.75,
                                "medium": 0.92
                            },
                            "ai_paraphrased": {
                                "reject": 0.85,
                                "low": 0.9,
                                "medium": 0.95
                            }
                        }
                    }
                },
                "human": {},
                "mixed": {}
            },
            "result_message": "Our detector is highly confident that the text is written by AI.",
            "document_classification": "AI_ONLY",
            "version": "2025-03-13-base",
            "language": "en",
            "pageNumber": 0,
            "inputText": "A Brief Overview of the Paper \nThe research introduces a neural network known as Motion Content Network (MCnet) to anticipate forthcoming frames in real life video sequences effectively.The network divides the videos motion and content into encoder pathways to enhance future frame prediction accuracy.The motion encoder focuses on capturing the scenes dynamics while the content encoder extracts crucial spatial features from individual frames.This end, to end trainable network has the capability to forecast frames ahead seamlessly. \nChoice\n\"I have chosen to approve this document.\"\nThe rationale, behind the decision\nThe article addresses a defined issue within the realm of computer vision by focusing on forecasting upcoming frames, in real life video sequences. \nThe method is well supported and situated within the existing body of research with a delineation of the drawbacks of prior approaches and how the new method overcomes them. \nThe article presents experimental findings that include both numerical and descriptive evaluations in comparison, to standard methods to showcase the efficiency of the suggested strategy. \nPresenting Points of View\nThe document gives an comprehensive overview of the suggested design framework which encompasses the motion and content encoders as well as the integration layers and the decoder component. The results from experiments showcase the efficiency of the proposed method with top notch performance on standard datasets. Furthermore the paper conducts an in depth analysis of the findings including an assessment of camera movement effects and a comparison, with a copy and paste reference point. \nMore Feedback Available \nTo enhance the paper more effectively I recommend that the authors take into account the following points; \nCan you please share information, about the training process? It would be helpful to know about the optimization algorithm and the specific hyperparameter configurations used during training. \nTo better showcase the effectiveness of the suggested method adding qualitative outcomes, like representations of the anticipated frames would be beneficial. \nWhen considering the suggested approachs uses one might think of scenarios, like video monitoring or self driving vehicles. \nQueries, for the Writers\nCould you share information, about the computing resources needed to develop the suggested network structure? \nHow does the suggested approach deal, with situations involving camera movement or obstruction? \nAny thoughts, on broadening the suggested approach to handle video prediction tasks like forecasting upcoming frames in videos featuring intricate backgrounds or ever changing scenes? "
        }
    ],
    "editorDocumentId": null
}