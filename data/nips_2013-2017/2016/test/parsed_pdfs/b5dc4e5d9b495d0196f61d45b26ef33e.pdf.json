{
  "name" : "b5dc4e5d9b495d0196f61d45b26ef33e.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Homotopy Smoothing for Non-Smooth Problems with Lower Complexity than $O(1/\\epsilon)$",
    "authors" : [ "Yi Xu", "Yan Yan", "Qihang Lin", "Tianbao Yang" ],
    "emails" : [ "tianbao-yang}@uiowa.edu,", "yan.yan-3@student.uts.edu.au" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "In this paper, we consider the following optimization problem:\nmin x∈Ω1 F (x) , f(x) + g(x) (1)\nwhere g(x) is a convex (but not necessarily smooth) function, Ω1 is a closed convex set and f(x) is a convex but non-smooth function which can be explicitly written as\nf(x) = max u∈Ω2 〈Ax, u〉 − φ(u) (2)\nwhere Ω2 ⊂ Rm is a closed convex bounded set, A ∈ Rm×d and φ(u) is a convex function, and 〈·, ·〉 is scalar product. This family of non-smooth optimization problems has applications in numerous domains, e.g., machine learning and statistics [7], image processing [6], cone programming [11], and etc. Several first-order methods have been developed for solving such non-smooth optimization\n∗The first two authors make equal contributions. The work of Y. Yan was done when he was a visiting student at Department of Computer Science of the University of Iowa.\n1Õ() suppresses a logarithmic factor.\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nproblems including the primal-dual methods [15, 6], Nesterov’s smoothing algorithm [16] 2, and they can achieve O(1/ ) iteration complexity for finding an -optimal solution, which is faster than the corresponding black-box lower complexity bounds by an order of magnitude.\nIn this paper, we propose a novel homotopy smoothing (HOPS) algorithm for solving the problem in (1) that achieves a lower iteration complexity than O(1/ ). In particular, the iteration complexity of HOPS is given by Õ(1/ 1−θ), where θ ∈ (0, 1] captures the local sharpness (defined shortly) of the objective function around the optimal solutions. The proposed HOPS algorithm builds on the Nesterov’s smoothing technique, i.e., approximating the non-smooth function f(x) by a smooth function and optimizing the smoothed function to a desired accuracy level.\nThe striking difference between HOPS and Nesterov’s smoothing algorithm is that Nesterov uses a fixed small smoothing parameter that renders a sufficiently accurate approximation of the nonsmooth function f(x), while HOPS adopts a homotopy strategy for setting the value of the smoothing parameter. It starts from a relatively large smoothing parameter and gradually decreases the smoothing parameter in a stage-wise manner until the smoothing parameter reaches a level that gives a sufficiently good approximation of the non-smooth objective function. The benefit of using a homotopy strategy is that a larger smoothing parameter yields a smaller smoothness constant and hence a lower iteration complexity for smoothed problems in earlier stages. For smoothed problems in later stages with larger smoothness constants, warm-start can help reduce the number of iterations to converge. As a result, solving a series of smoothed approximations with a smoothing parameter from large to small and with warm-start is faster than solving one smoothed approximation with a very small smoothing parameter. To the best of our knowledge, this is the first work that rigorously analyzes such a homotopy smoothing algorithm and establishes its theoretical guarantee on lower iteration complexities. The keys to our analysis of lower iteration complexity are (i) to leverage a global error inequality (Lemma 1) [21] that bounds the distance of a solution to the sublevel set by a multiple of the functional distance; and (ii) to explore a local error bound condition to bound the multiplicative factor."
    }, {
      "heading" : "2 Related Work",
      "text" : "In this section, we review some related work for solving the considered family of non-smooth optimization problems.\nIn the seminal paper by Nesterov [16], he proposed a smoothing technique for a family of structured non-smooth optimization problems as in (1) with g(x) being a smooth function and f(x) given in (2). By adding a strongly convex prox function in terms of u with a smoothing parameter µ into the definition of f(x), one can obtain a smoothed approximation of the original objective function. Then he developed an accelerated gradient method with an O(1/t2) convergence rate for the smoothed objective function with t being the number of iterations, which implies anO(1/t) convergence rate for the original objective function by setting µ ≈ c/t with c being a constant. The smoothing technique has been exploited to solving problems in machine learning, statistics, cone programming [7, 11, 24].\nThe primal-dual style of first-order methods treat the problem as a convex-concave minimization problem, i.e.,\nmin x∈Ω1 max u∈Ω2\ng(x) + 〈Ax, u〉 − φ(u)\nNemirovski [15] proposed a mirror prox method, which has a convergence rate ofO(1/t) by assuming that both g(x) and φ(u) are smooth functions. Chambolle & Pock [6] designed first-order primal-dual algorithms, which tackle g(x) and φ(u) using proximal mapping and achieve the same convergence rate of O(1/t) without assuming smoothness of g(x) and φ(u). When g(x) or φ(u) is strongly convex, their algorithms achieve O(1/t2) convergence rate. The effectiveness of their algorithms was demonstrated on imaging problems. Recently, the primal-dual style of first-order methods have been employed to solve non-smooth optimization problems in machine learning where both the loss function and the regularizer are non-smooth [22]. Lan et al. [11] also considered Nemirovski’s prox method for solving cone programming problems.\nThe key condition for us to develop an improved convergence is closely related to local error bounds (LEB) [17] and more generally the Kurdyka-Łojasiewicz property [12, 4]. The LEB characterizes\n2The algorithm in [16] was developed for handling a smooth component g(x), which can be extended to handling a non-smooth component g(x) whose proximal mapping is easy to compute.\nthe relationship between the distance of a local solution to the optimal set and the optimality gap of the solution in terms of objective value. The Kurdyka-Łojasiewicz property characterizes that property of a function that whether it can be made “sharp” by some transformation. Recently, these conditions/properties have been explored for feasible descent methods [13], non-smooth optimization [8], gradient and subgradient methods [10, 21]. It is notable that our local error bound condition is different from the one used in [13, 25] which bounds the distance of a point to the optimal set by the norm of the projected or proximal gradient at that point instead of the functional distance, consequentially it requires some smoothness assumption about the objective function. By contrast, the local error bound condition in this paper covers a much broad family of functions and thus it is more general. Recent work [14, 23] have shown that the error bound in [13, 25] is a special case of our considered error bound with θ = 1/2. Two mostly related work leveraging a similar error bound to ours are discussed in order. Gilpin et al. [8] considered the two-person zero-sum games, which is a special case of (1) with g(x) and φ(u) being zeros and Ω1 and Ω2 being polytopes. The present work is a non-trivial generalization of their work that leads to improved convergence for a much broader family of non-smooth optimization problems. In particular, their result is just a special case of our result when the constant θ that captures the local sharpness is one for problems whose epigraph is a polytope. Recently, Yang & Lin [21] proposed a restarted subgradient method by exploring the local error bound condition or more generally the Kurdyka-Łojasiewicz property, resulting in an Õ(1/ 2(1−θ)) iteration complexity with the same constant of θ. In contrast, our result is an improved iteration complexity of Õ(1/ 1−θ).\nIt is worth emphasizing that the proposed homotopy smoothing technique is different from recently proposed homotopy methods for sparse learning (e.g., `1 regularized least-squares problem [20]), though a homotopy strategy on an involved parameter is also employed to boost the convergence. In particular, the involved parameter in the homotopy methods for sparse learning is the regularization parameter before the `1 regularization, while the parameter in the present work is the introduced smoothing parameter. In addition, the benefit of starting from a relatively large regularization parameter in sparse learning is the sparsity of the solution, which makes it possible to explore the restricted strong convexity for proving faster convergence. We do not make such assumption of the data and we are mostly interested in that when both f(x) and g(x) are non-smooth. Finally, we note that a similar homotopy (a.k.a continuation) strategy is employed in Nesterov’s smoothing algorithm for solving an `1 norm minimization problem subject to a constraint for recovering a sparse solution [3]. However, we would like to draw readers’ attention to that they did not provide any theoretical guarantee on the iteration complexity of the homotopy strategy and consequentially their implementation is ad-hoc without guidance from theory. More importantly, our developed algorithms and theory apply to a much broader family of problems."
    }, {
      "heading" : "3 Preliminaries",
      "text" : "We present some preliminaries in this section. Let ‖x‖ denote the Euclidean norm on the primal variable x. A function h(x) is L-smooth in terms of ‖ · ‖, if ‖∇h(x) −∇h(y)‖ ≤ L‖x − y‖. Let ‖u‖+ denote a norm on the dual variable, which is not necessarily the Euclidean norm. Denote by ω+(u) a 1-strongly convex function of u in terms of ‖ · ‖+. For the optimization problem in (1), we let Ω∗, F∗ denote the set of optimal solutions and optimal value, respectively, and make the following assumption throughout the paper. Assumption 1. For a convex minimization problem (1), we assume (i) there exist x0 ∈ Ω1 and 0 ≥ 0 such that F (x0) −minx∈Ω1 F (x) ≤ 0; (ii) f(x) is characterized as in (2), where φ(u) is a convex function; (iii) There exists a constant D such that maxu∈Ω2 ω+(u) ≤ D2/2; (iv) Ω∗ is a non-empty convex compact set. Note that: 1) Assumption 1(i) assumes that the objective function is lower bounded; 2) Assumption 1(iii) assumes that Ω2 is a bounded set, which is also required in [16].\nIn addition, for brevity we assume that g(x) is simple enough 3 such that the proximal mapping defined below is easy to compute similar to [6]:\nPλg(x) = min z∈Ω1\n1 2 ‖z − x‖2 + λg(z) (3)\n3If g(x) is smooth, this assumption can be relaxed. We will defer the discussion and result on a smooth function g(x) to the supplement.\nRelying on the proximal mapping, the key updates in the optimization algorithms presented below take the following form:\nΠcv,λg(x) = arg min z∈Ω1\nc 2 ‖z − x‖2 + 〈v, z〉+ λg(z) (4)\nFor any x ∈ Ω1, let x∗ denote the closest optimal solution in Ω∗ to x measured in terms of ‖ · ‖, i.e., x∗ = arg minz∈Ω∗ ‖z − x‖2, which is unique because Ω∗ is a non-empty convex compact set We denote by L the -level set of F (x) and by S the -sublevel set of F (x), respectively, i.e.,\nL = {x ∈ Ω1 : F (x) = F∗ + }, S = {x ∈ Ω1 : F (x) ≤ F∗ + } It follows from [18] (Corollary 8.7.1) that the sublevel set S is bounded for any ≥ 0 and so as the level set L due to that Ω∗ is bounded. Define dist(L ,Ω∗) to be the maximum distance of points on the level set L to the optimal set Ω∗, i.e.,\ndist(L ,Ω∗) = max x∈L\n[ dist(x,Ω∗) , min\nz∈Ω∗ ‖x− z‖\n] . (5)\nDue to that L and Ω∗ are bounded, dist(L ,Ω∗) is also bounded. Let x† denote the closest point in the -sublevel set to x, i.e.,\nx† = arg min z∈S ‖z − x‖2 (6)\nIt is easy to show that x† ∈ L when x /∈ S (using the KKT condition)."
    }, {
      "heading" : "4 Homotopy Smoothing",
      "text" : ""
    }, {
      "heading" : "4.1 Nesterov’s Smoothing",
      "text" : "We first present the Nesterov’s smoothing technique and accelerated proximal gradient methods for solving the smoothed problem due to that the proposed algorithm builds upon these techniques. The idea of smoothing is to construct a smooth function fµ(x) that well approximates f(x). Nesterov considered the following function\nfµ(x) = max u∈Ω2 〈Ax, u〉 − φ(u)− µω+(u)\nIt was shown in [16] that fµ(x) is smooth w.r.t ‖ · ‖ and its smoothness parameter is given by Lµ = 1 µ‖A‖ 2 where ‖A‖ is defined by ‖A‖ = max‖x‖≤1 max‖u‖+≤1〈Ax, u〉. Denote by\nuµ(x) = arg max u∈Ω2 〈Ax, u〉 − φ(u)− µω+(u)\nThe gradient of fµ(x) is computed by ∇fµ(x) = A>uµ(x). Then\nfµ(x) ≤ f(x) ≤ fµ(x) + µD2/2 (7) From the inequality above, we can see that when µ is very small, fµ(x) gives a good approximation of f(x). This motivates us to solve the following composite optimization problem\nmin x∈Ω1 Fµ(x) , fµ(x) + g(x)\nMany works have studied such an optimization problem [2, 19] and the best convergence rate is given by O(Lµ/t2), where t is the total number of iterations. We present a variant of accelerated proximal gradient (APG) methods in Algorithm 1 that works even with ‖x‖ replaced with a general norm as long as its square is strongly convex. We make several remarks about Algorithm 1: (i) the variant here is similar to Algorithm 3 in [19] and the algorithm proposed in [16] except that the prox function d(x) is replaced by ‖x− x0‖2/2 in updating the sequence of zk, which is assumed to be σ1-strongly convex w.r.t ‖ · ‖; (ii) If ‖ · ‖ is simply the Euclidean norm, a simplified algorithm with only one update in (4) can be used (e.g., FISTA [2]); (iii) if Lµ is difficult to compute, we can use the backtracking trick (see [2, 19]).\nThe following theorem states the convergence result for APG.\nTheorem 2. ([19]) Let θk = 2k+2 , αk = 2 k+1 , k ≥ 0 or αk+1 = θk+1 =\n√ θ4k+4θ 2 k−θ 2 k\n2 , k ≥ 0. For any x ∈ Ω1, we have\nFµ(xt)− Fµ(x) ≤ 2Lµ‖x− x0‖2\nt2 (8)\nAlgorithm 1 An Accelerated Proximal Gradient Method: APG(x0, t, Lµ) 1: Input: the number of iterations t, the initial solution x0, and the smoothness constant Lµ 2: Let θ0 = 1, V−1 = 0, Γ−1 = 0, z0 = x0 3: Let αk and θk be two sequences given in Theorem 2. 4: for k = 0, . . . , t− 1 do 5: Compute yk = (1− θk)xk + θkzk 6: Compute vk = ∇fµ(yk), Vk = Vk−1 + vkαk , and Γk = Γk−1 + 1 αk\n7: Compute zk+1 = Π Lµ/σ1 Vk,Γkg (x0) and xk+1 = Π Lµ vk,g(yk) 8: end for 9: Output: xt\nCombining the above convergence result with the relation in (7), we can establish the iteration complexity of Nesterov’s smoothing algorithm for solving the original problem (1). Corollary 3. For any x ∈ Ω1, we have\nF (xt)− F (x) ≤ µD2/2 + 2Lµ‖x− x0‖2\nt2 (9)\nIn particular in order to have F (xt) ≤ F∗ + , it suffices to set µ ≤ D2 and t ≥ 2D‖A‖‖x0−x∗‖\n, where x∗ is an optimal solution to (1)."
    }, {
      "heading" : "4.2 Homotopy Smoothing",
      "text" : "From the convergence result in (9), we can see that in order to obtain a very accurate solution, we have to set µ - the smoothing parameter - to be a very small value, which will cause the blow-up of the second term because Lµ ∝ 1/µ. On the other hand, if µ is set to be a relatively large value, then t can be set to be a relatively small value to match the first term in the R.H.S. of (9), which may lead to a not sufficiently accurate solution. It seems that the O(1/ ) is unbeatable. However, if we adopt a homotopy strategy, i.e., starting from a relatively large value µ and optimizing the smoothed function with a certain number of iterations t such that the second term in (9) matches the first term, which will give F (xt) − F (x∗) ≤ O(µ). Then we can reduce the value of µ by a constant factor b > 1 and warm-start the optimization process from xt. The key observation is that although µ decreases and Lµ increases, the other term ‖x∗ − xt‖ is also reduced compared to ‖x∗ − x0‖, which could cancel the blow-up effect caused by increased Lµ. As a result, we expect to use the same number of iterations to optimize the smoothed function with a smaller µ such that F (x2t)− F (x∗) ≤ O(µ/b). To formalize our observation, we need the following key lemma. Lemma 1 ([21]). For any x ∈ Ω1 and > 0, we have\n‖x− x† ‖ ≤ dist(x† ,Ω∗) (F (x)− F (x† ))\nwhere x† ∈ S is the closest point in the -sublevel set to x as defined in (6).\nThe lemma is proved in [21]. We include its proof in the supplement. If we apply the above bound into (9), we will see in the proof of the main theorem (Theorem 5) that the number of iterations t for solving each smoothed problem is roughly O(dist(L ,Ω∗) ), which will be lower than O( 1 ) in light of the local error bound condition given below. Definition 4 (Local error bound (LEB)). A function F (x) is said to satisfy a local error bound condition if there exist θ ∈ (0, 1] and c > 0 such that for any x ∈ S\ndist(x,Ω∗) ≤ c(F (x)− F∗)θ (10) Remark: In next subsection, we will discuss the relationship with other types of conditions and show that a broad family of non-smooth functions (including almost all commonly seen functions in machine learning) obey the local error bound condition. The exponent constant θ can be considered as a local sharpness measure of the function. Figure 1 illustrates the sharpness of F (x) = |x|p for p = 1, 1.5, and 2 around the optimal solutions and their corresponding θ.\nWith the local error bound condition, we can see that dist(L ,Ω∗) ≤ c θ, θ ∈ (0, 1]. Now, we are ready to present the homotopy smoothing algorithm and its convergence guarantee under the\n−0.1 −0.05 0 0.05 0.1 0\n0.02\n0.04\n0.06\n0.08\n0.1\nx\nF (x\n)\n|x|, θ=1 |x| 1.5 , θ=2/3 |x| 2 , θ=0.5\nlocal error bound condition. The HOPS algorithm is presented in Algorithm 2, which starts from a relatively large smoothing parameter µ = µ1 and gradually reduces µ by a factor of b > 1 after running a number t of iterations of APG with warm-start. The iteration complexity of HOPS is established in Theorem 5. We include the proof in the supplement. Theorem 5. Suppose Assumption 1 holds and F (x) obeys the local error bound condition. Let HOPS run with t = O( 2bcD‖A‖ 1−θ ) ≥ 2bcD‖A‖ 1−θ iterations for each stage, and m = dlogb( 0 )e. Then F (xm) − F∗ ≤ 2 . Hence, the iteration complexity for achieving an 2 -optimal solution is 2bcD‖A‖ 1−θ dlogb( 0 )e in the worst-case."
    }, {
      "heading" : "4.3 Local error bounds and Applications",
      "text" : "In this subsection, we discuss the local error bound condition and its application in non-smooth optimization problems.\nThe Hoffman’s bound and finding a point in a polyhedron. A polyhedron can be expressed as P = {x ∈ Rd;B1x ≤ b1, B2x = b2}. The Hoffman’s bound [17] is expressed as\ndist(x,P) ≤ c(‖(B1x− b1)+‖+ ‖B2x− b2‖),∃c > 0 (11) where [s]+ = max(0, s). This can be considered as the error bound for the polyhedron feasibility problem, i.e., finding a x ∈ P , which is equivalent to\nmin x∈Rd F (x) ,\n[ ‖(B1x− b1)+‖+ ‖B2x− b2‖ = max\nu∈Ω2 〈B1x− b1, u1〉+ 〈B2x− b2, u2〉 ] where u = (u>1 , u > 2 ) > and Ω2 = {u|u1 0, ‖u1‖ ≤ 1, ‖u2‖ ≤ 1}. If there exists a x ∈ P , then F∗ = 0. Thus the Hoffman’s bound in (11) implies a local error bound (10) with θ = 1. Therefore, the HOPS has a linear convergence for finding a feasible solution in a polyhedron. If we let ω+(u) = 1 2‖u‖ 2 then D2 = 2 so that the iteration complexity is 2 √ 2bcmax(‖B1‖, ‖B2‖)dlogb( 0 )e.\nCone programming. Let U, V denote two vector spaces. Given a linear opearator E : U → V ∗ 4, a closed convex set Ω ⊆ U , and a vector e ∈ V ∗, and a closed convex cone K ⊆ V , the general constrained cone linear system (cone programing) consists of finding a vector x ∈ Ω such that Ex− e ∈ K∗. Lan et al. [11] have considered Nesterov’s smoothing algorithm for solving the cone programming problem with O(1/ ) iteration complexity. The problem can be cast into a non-smooth optimization problem:\nmin x∈Ω F (x) ,\n[ dist(Ex− e,K∗) = max\n‖u‖≤1,u∈−K 〈Ex− e, u〉 ] Assume that e ∈ Range(E)−K∗, then F∗ = 0. Burke et al. [5] have considered the error bound for such problems and their results imply that there exists c > 0 such that dist(x,Ω∗) ≤ c(F (x)− F∗) as long as ∃x ∈ Ω, s.t. Ex − e ∈ int(K∗), where Ω∗ denotes the optimal solution set. Therefore, the HOPS also has a linear convergence for cone programming. Considering that both U and V are Euclidean spaces, we set ω+(u) = 12‖u‖\n2 then D2 = 1. Thus, the iteraction complexity of HOPS for finding an 2 -solution is 2bc‖E‖dlogb( 0 )e. Non-smooth regularized empirical loss (REL) minimization in Machine Learning The REL consists of a sum of loss functions on the training data and a regularizer, i.e.,\nmin x∈Rd\nF (x) , 1\nn n∑ i=1 `(x>ai, yi) + λg(x)\n4V ∗ represents the dual space of V . The notations and descriptions are adopted from [11].\nwhere (ai, yi), i = 1, . . . , n denote pairs of a feature vector and a label of training data. Non-smooth loss functions include hinge loss `(z, y) = max(0, 1− yz), absolute loss `(z, y) = |z − y|, which can be written as the max structure in (2). Non-smooth regularizers include e.g., g(x) = ‖x‖1, g(x) = ‖x‖∞. These loss functions and regularizers are essentially piecewise linear functions, whose epigraph is a polyhedron. The error bound condition has been developed for such kind of problems [21]. In particular, if F (x) has a polyhedral epigraph, then there exists c > 0 such that dist(x,Ω∗) ≤ c(F (x)− F∗) for any x ∈ Rd. It then implies HOPS has an O(log( 0/ )) iteration complexity for solving a non-smooth REL minimization with a polyhedral epigraph. Yang et al. [22] has also considered such non-smooth problems, but they only have O(1/ ) iteration complexity.\nWhen F (x) is essentially locally strongly convex [9] in terms of ‖ · ‖ such that 5\ndist2(x,Ω∗) ≤ 2\nσ (F (x)− F∗),∀x ∈ S (12)\nthen we can see that the local error bound holds with θ = 1/2, which implies the iteration complexity of HOPS is Õ( 1√ ), which is up to a logarithmic factor the same as the result in [6] for a strongly\nconvex function. However, here only local strong convexity is sufficient and there is no need to develop a different algorithm and different analysis from the non-strongly convex case as done in [6]. For example, one can consider F (x) = ‖Ax− y‖pp = ∑n i=1 |a>i x− yi|p, p ∈ (1, 2), which satisfies (12) according to [21].\nThe Kurdyka-Łojasiewicz (KL) property. The definition of KL property is given below. Definition 6. The function F (x) is said to have the KL property at x∗ ∈ Ω∗ if there exist η ∈ (0,∞], a neighborhood U of x∗ and a continuous concave function ϕ : [0, η)→ R+ such that i) ϕ(0) = 0, ϕ is continuous on (0, η), ii) for all s ∈ (0, η), ϕ′(s) > 0, iii) and for all x ∈ U ∪ {x : F (x∗) < F (x) < F (x∗) + η}, the KL inequality ϕ′(F (x)− F (x∗))‖∂F (x)‖ ≥ 1 holds.\nThe function ϕ is called the desingularizing function of F at x∗, which makes the function F (x) sharp by reparameterization. An important desingularizing function is in the form of ϕ(s) = cs1−β for some c > 0 and β ∈ [0, 1), which gives the KL inequality ‖∂F (x)‖ ≥ 1c(1−β) (F (x)− F (x∗)) β . It has been established that the KL property is satisfied by a wide class of non-smooth functions definable in an o-minimal structure [4]. Semialgebraic functions and (globally) subanalytic functions are for instance definable in their respective classes. While the definition of KL property involves a neighborhood U and a constant η, in practice many convex functions satisfy the above property with U = Rd and η = ∞ [1]. The proposition below shows that a function with the KL property with a desingularizing function ϕ(s) = cs1−β obeys the local error bound condition in (10) with θ = 1− β ∈ (0, 1], which implies an iteration complexity of Õ(1/ θ) of HOPS for optimizing such a function. Proposition 1. (Theorem 5 [10]) Let F (x) be a proper, convex and lower-semicontinuous function that satisfies KL property at x∗ and U be a neighborhood of x∗. For all x ∈ U ∩ {x : F (x∗) < F (x) < F (x∗)+η}, if ‖∂F (x)‖ ≥ 1c(1−β) (F (x)−F (x∗)) β , then dist(x,Ω∗) ≤ c(F (x)−F∗)1−β ."
    }, {
      "heading" : "4.4 Primal-Dual Homotopy Smoothing (PD-HOPS)",
      "text" : "Finally, we note that the required number of iterations per-stage t for finding an accurate solution depends on an unknown constant c and sometimes θ. Thus, an inappropriate setting of t may lead to a less accurate solution. In practice, it can be tuned to obtain the fastest convergence. A way to eschew the tuning is to consider a primal-dual homotopy smoothing (PD-HOPS). Basically, we also apply the homotopy smoothing to the dual problem:\nmax u∈Ω2 Φ(u) , −φ(u) + min x∈Ω1 〈A>u, x〉+ g(x)\nDenote by Φ∗ the optimal value of the above problem. Under some mild conditions, it is easy to see that Φ∗ = F∗. By extending the analysis and result to the dual problem, we can obtain that F (xs) − F∗ ≤ + s and Φ∗ − Φ(us) ≤ + s after the s-th stage with a sufficient number of iterations per-stage. As a result, we get F (xs) − Φ(us) ≤ 2( + s). Therefore, we can use the duality gap F (xs) − Φ(us) as a certificate to monitor the progress of optimization. As long as the above inequality holds, we restart the next stage. Then with at most m = dlogb( 0/ )e epochs\n5This is true if g(x) is strongly convex or locally strongly convex.\nAPG-D 4918 (2.44±0.22) 28600 (11.19±0.26) 179204 (924.37±59.67) 1726043 (9032.69±539.01) 1967 (6.85±0.08) 8622 (30.36±0.11) APG-F 3277 (1.33±0.01) 19444 (7.69±0.07) 14150 (40.90±2.28) 91380 (272.45±14.56) 1115 (3.76±0.06) 4151 (9.16±0.10)\nHOPS-D 1012 (0.44±0.02) 4101 (1.67±0.01) 3542 (13.77±0.13) 4501 (17.38±0.10) 224 (1.36±0.02) 313 (1.51±0.03) HOPS-F 1009 (0.46±0.02) 4102 (1.69±0.04) 2206 (6.99±0.15) 3905 (16.52±0.08) 230 (0.91±0.01) 312 (1.23±0.01)\nPD-HOPS 846 (0.36±0.01) 3370 (1.27±0.02) 2538 (7.97±0.13) 3605 (11.39±0.10) 124 (0.45±0.01) 162 (0.64±0.01)\nwe get F (xm) − Φ(um) ≤ 2( + m) ≤ 4 . Similarly, we can show that PD-HOPS enjoys an Õ(max{1/ 1−θ, 1/ 1−θ̃}) iteration complexity, where θ̃ is the exponent constant in the local error bound of the objective function for dual problem. For example, for linear classification problems with a piecewise linear loss and `1 norm regularizer we can have θ = 1 and θ̃ = 1, and PD-HOPS enjoys a linear convergence. Due to the limitation of space, we defer the details of PD-HOPS and its analysis into the supplement."
    }, {
      "heading" : "5 Experimental Results",
      "text" : "In this section, we present some experimental results to demonstrate the effectiveness of HOPS and PD-HOPS by comparing with two state-of-the-art algorithms, the first-order Primal-Dual (PD) method [6] and the Nesterov’s smoothing with Accelerated Proximal Gradient (APG) methods. For APG, we implement two variants, where APG-D refers to the variant with the dual averaging style of update on one sequence of points (i.e., Algorithm 1) and APG-F refers to the variant of the FISTA style [2]. Similarly, we also implement the two variants for HOPS. We conduct experiments for solving three problems: (1) an `1-norm regularized hinge loss for linear classification on the w1a dataset 6; (2) a total variation based ROF model for image denoising on the Cameraman picture 7; (3) a nuclear norm regularized absolute error minimization for low-rank and sparse matrix decomposition on a synthetic data. More details about the formulations and experimental setup can be found in the supplement.\nTo make fair comparison, we stop each algorithm when the optimality gap is less than a given and count the number of iterations and the running time that each algorithm requires. The optimal value is obtained by running PD with a sufficiently large number of iterations such that the duality gap is very small. We present the comparison of different algorithms on different tasks in Table 1, where for PD-HOPS we only report the results of using the faster variant of APG, i.e., APG-F. We repeat each algorithm 10 times for solving a particular problem and then report the averaged running time in second and the corresponding standard deviations. The running time of PD-HOPS only accounts the time for updating the primal variable since the updates for the dual variable are fully decoupled from the primal updates and can be carried out in parallel. From the results, we can see that (i) HOPS converges consistently faster than their APG variants especially when is small; (ii) PD-HOPS allows for choosing the number of iterations at each epoch automatically, yielding faster convergence speed than HOPS with manual tuning; (iii) both HOPS and PD-HOPS are significantly faster than PD."
    }, {
      "heading" : "6 Conclusions",
      "text" : "In this paper, we have developed a homotopy smoothing (HOPS) algorithm for solving a family of structured non-smooth optimization problems with formal guarantee on the iteration complexities. We show that the proposed HOPS can achieve a lower iteration complexity of Õ(1/ 1−θ) with θ ∈ (0, 1] for obtaining an -optimal solution under a mild local error bound condition. The experimental results on three different tasks demonstrate the effectiveness of HOPS.\nAcknowlegements We thank the anonymous reviewers for their helpful comments. Y. Xu and T. Yang are partially supported by National Science Foundation (IIS-1463988, IIS-1545995).\n6https://www.csie.ntu.edu.tw/∼cjlin/libsvmtools/datasets/ 7http://pages.cs.wisc.edu/∼swright/TVdenoising/"
    } ],
    "references" : [ {
      "title" : "Proximal alternating minimization and projection methods for nonconvex problems: An approach based on the kurdyka-lojasiewicz",
      "author" : [ "H. Attouch", "J. Bolte", "P. Redont", "A. Soubeyran" ],
      "venue" : "inequality. Math. Oper. Res.,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2010
    }, {
      "title" : "A fast iterative shrinkage-thresholding algorithm for linear inverse problems",
      "author" : [ "A. Beck", "M. Teboulle" ],
      "venue" : "SIAM J. Img. Sci.,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2009
    }, {
      "title" : "Nesta: A fast and accurate first-order method for sparse recovery",
      "author" : [ "S. Becker", "J. Bobin", "E.J. Candès" ],
      "venue" : "SIAM J. Img. Sci.,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2011
    }, {
      "title" : "The łojasiewicz inequality for nonsmooth subanalytic functions with applications to subgradient dynamical systems",
      "author" : [ "J. Bolte", "A. Daniilidis", "A. Lewis" ],
      "venue" : "SIAM J. Optim.,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2006
    }, {
      "title" : "A unified analysis of hoffman’s bound via fenchel duality",
      "author" : [ "J.V. Burke", "P. Tseng" ],
      "venue" : "SIAM J. Optim.,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1996
    }, {
      "title" : "A first-order primal-dual algorithm for convex problems with applications to imaging",
      "author" : [ "A. Chambolle", "T. Pock" ],
      "venue" : "J. Math. Img. Vis.,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2011
    }, {
      "title" : "Smoothing proximal gradient method for general structured sparse regression",
      "author" : [ "X. Chen", "Q. Lin", "S. Kim", "J.G. Carbonell", "E.P. Xing" ],
      "venue" : "Ann. Appl. Stat., 6(2):719–752,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2012
    }, {
      "title" : "First-order algorithm with log(1/epsilon) convergence for epsilonequilibrium in two-person zero-sum games",
      "author" : [ "A. Gilpin", "J. Peña", "T. Sandholm" ],
      "venue" : "Math. Program.,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2012
    }, {
      "title" : "Local strong convexity and local lipschitz continuity of the gradient of convex functions",
      "author" : [ "R. Goebel", "R.T. Rockafellar" ],
      "venue" : "J. Convex Anal.,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2008
    }, {
      "title" : "From error bounds to the complexity of first-order descent methods for convex functions",
      "author" : [ "J.P.B.S. Jerome Bolte", "Trong Phong Nguyen" ],
      "venue" : "CoRR, abs/1510.08234,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2015
    }, {
      "title" : "Primal-dual first-order methods with O(1/e) iteration-complexity for cone programming",
      "author" : [ "G. Lan", "Z. Lu", "R.D.C. Monteiro" ],
      "venue" : "Math. Program.,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2011
    }, {
      "title" : "Ensembles semi-analytiques",
      "author" : [ "S. Łojasiewicz" ],
      "venue" : "Institut des Hautes Etudes Scientifiques,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1965
    }, {
      "title" : "Error bounds and convergence analysis of feasible descent methods: a general approach",
      "author" : [ "Z.-Q. Luo", "P. Tseng" ],
      "venue" : "Ann. Oper. Res.,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1993
    }, {
      "title" : "Linear convergence of first order methods for non-strongly convex optimization",
      "author" : [ "I. Necoara", "Y. Nesterov", "F. Glineur" ],
      "venue" : "CoRR, abs/1504.06298,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2015
    }, {
      "title" : "Prox-method with rate of convergence o(1/t) for variational inequalities with lipschitz continuous monotone operators and smooth convex-concave saddle point problems",
      "author" : [ "A. Nemirovski" ],
      "venue" : "SIAM J. Optim.,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2005
    }, {
      "title" : "Smooth minimization of non-smooth functions",
      "author" : [ "Y. Nesterov" ],
      "venue" : "Math. Program.,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2005
    }, {
      "title" : "Error bounds in mathematical programming",
      "author" : [ "J. Pang" ],
      "venue" : "Math. Program.,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1997
    }, {
      "title" : "Convex Analysis. Princeton mathematical series",
      "author" : [ "R. Rockafellar" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1970
    }, {
      "title" : "On accelerated proximal gradient methods for convex-concave optimization",
      "author" : [ "P. Tseng" ],
      "venue" : "SIAM J. Optim.,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2008
    }, {
      "title" : "A proximal-gradient homotopy method for the sparse least-squares problem",
      "author" : [ "L. Xiao", "T. Zhang" ],
      "venue" : "SIAM J. Optim.,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2013
    }, {
      "title" : "Rsg: Beating subgradient method without smoothness and strong convexity",
      "author" : [ "T. Yang", "Q. Lin" ],
      "venue" : null,
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2016
    }, {
      "title" : "An efficient primal-dual prox method for non-smooth optimization",
      "author" : [ "T. Yang", "M. Mahdavi", "R. Jin", "S. Zhu" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2014
    }, {
      "title" : "New analysis of linear convergence of gradient-type methods via unifying error bound conditions",
      "author" : [ "H. Zhang" ],
      "venue" : null,
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2016
    }, {
      "title" : "Smoothing multivariate performance measures",
      "author" : [ "X. Zhang", "A. Saha", "S. Vishwanathan" ],
      "venue" : "JMLR, 13(Dec):3623–3680,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2012
    }, {
      "title" : "A unified approach to error bounds for structured convex optimization problems",
      "author" : [ "Z. Zhou", "A.M.-C. So" ],
      "venue" : "CoRR, abs/1512.03518,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : ", machine learning and statistics [7], image processing [6], cone programming [11], and etc.",
      "startOffset" : 34,
      "endOffset" : 37
    }, {
      "referenceID" : 5,
      "context" : ", machine learning and statistics [7], image processing [6], cone programming [11], and etc.",
      "startOffset" : 56,
      "endOffset" : 59
    }, {
      "referenceID" : 10,
      "context" : ", machine learning and statistics [7], image processing [6], cone programming [11], and etc.",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 14,
      "context" : "problems including the primal-dual methods [15, 6], Nesterov’s smoothing algorithm [16] 2, and they can achieve O(1/ ) iteration complexity for finding an -optimal solution, which is faster than the corresponding black-box lower complexity bounds by an order of magnitude.",
      "startOffset" : 43,
      "endOffset" : 50
    }, {
      "referenceID" : 5,
      "context" : "problems including the primal-dual methods [15, 6], Nesterov’s smoothing algorithm [16] 2, and they can achieve O(1/ ) iteration complexity for finding an -optimal solution, which is faster than the corresponding black-box lower complexity bounds by an order of magnitude.",
      "startOffset" : 43,
      "endOffset" : 50
    }, {
      "referenceID" : 15,
      "context" : "problems including the primal-dual methods [15, 6], Nesterov’s smoothing algorithm [16] 2, and they can achieve O(1/ ) iteration complexity for finding an -optimal solution, which is faster than the corresponding black-box lower complexity bounds by an order of magnitude.",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 20,
      "context" : "The keys to our analysis of lower iteration complexity are (i) to leverage a global error inequality (Lemma 1) [21] that bounds the distance of a solution to the sublevel set by a multiple of the functional distance; and (ii) to explore a local error bound condition to bound the multiplicative factor.",
      "startOffset" : 111,
      "endOffset" : 115
    }, {
      "referenceID" : 15,
      "context" : "In the seminal paper by Nesterov [16], he proposed a smoothing technique for a family of structured non-smooth optimization problems as in (1) with g(x) being a smooth function and f(x) given in (2).",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 6,
      "context" : "The smoothing technique has been exploited to solving problems in machine learning, statistics, cone programming [7, 11, 24].",
      "startOffset" : 113,
      "endOffset" : 124
    }, {
      "referenceID" : 10,
      "context" : "The smoothing technique has been exploited to solving problems in machine learning, statistics, cone programming [7, 11, 24].",
      "startOffset" : 113,
      "endOffset" : 124
    }, {
      "referenceID" : 23,
      "context" : "The smoothing technique has been exploited to solving problems in machine learning, statistics, cone programming [7, 11, 24].",
      "startOffset" : 113,
      "endOffset" : 124
    }, {
      "referenceID" : 14,
      "context" : "Nemirovski [15] proposed a mirror prox method, which has a convergence rate ofO(1/t) by assuming that both g(x) and φ(u) are smooth functions.",
      "startOffset" : 11,
      "endOffset" : 15
    }, {
      "referenceID" : 5,
      "context" : "Chambolle & Pock [6] designed first-order primal-dual algorithms, which tackle g(x) and φ(u) using proximal mapping and achieve the same convergence rate of O(1/t) without assuming smoothness of g(x) and φ(u).",
      "startOffset" : 17,
      "endOffset" : 20
    }, {
      "referenceID" : 21,
      "context" : "Recently, the primal-dual style of first-order methods have been employed to solve non-smooth optimization problems in machine learning where both the loss function and the regularizer are non-smooth [22].",
      "startOffset" : 200,
      "endOffset" : 204
    }, {
      "referenceID" : 10,
      "context" : "[11] also considered Nemirovski’s prox method for solving cone programming problems.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "The key condition for us to develop an improved convergence is closely related to local error bounds (LEB) [17] and more generally the Kurdyka-Łojasiewicz property [12, 4].",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 11,
      "context" : "The key condition for us to develop an improved convergence is closely related to local error bounds (LEB) [17] and more generally the Kurdyka-Łojasiewicz property [12, 4].",
      "startOffset" : 164,
      "endOffset" : 171
    }, {
      "referenceID" : 3,
      "context" : "The key condition for us to develop an improved convergence is closely related to local error bounds (LEB) [17] and more generally the Kurdyka-Łojasiewicz property [12, 4].",
      "startOffset" : 164,
      "endOffset" : 171
    }, {
      "referenceID" : 15,
      "context" : "The algorithm in [16] was developed for handling a smooth component g(x), which can be extended to handling a non-smooth component g(x) whose proximal mapping is easy to compute.",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 12,
      "context" : "Recently, these conditions/properties have been explored for feasible descent methods [13], non-smooth optimization [8], gradient and subgradient methods [10, 21].",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 7,
      "context" : "Recently, these conditions/properties have been explored for feasible descent methods [13], non-smooth optimization [8], gradient and subgradient methods [10, 21].",
      "startOffset" : 116,
      "endOffset" : 119
    }, {
      "referenceID" : 9,
      "context" : "Recently, these conditions/properties have been explored for feasible descent methods [13], non-smooth optimization [8], gradient and subgradient methods [10, 21].",
      "startOffset" : 154,
      "endOffset" : 162
    }, {
      "referenceID" : 20,
      "context" : "Recently, these conditions/properties have been explored for feasible descent methods [13], non-smooth optimization [8], gradient and subgradient methods [10, 21].",
      "startOffset" : 154,
      "endOffset" : 162
    }, {
      "referenceID" : 12,
      "context" : "It is notable that our local error bound condition is different from the one used in [13, 25] which bounds the distance of a point to the optimal set by the norm of the projected or proximal gradient at that point instead of the functional distance, consequentially it requires some smoothness assumption about the objective function.",
      "startOffset" : 85,
      "endOffset" : 93
    }, {
      "referenceID" : 24,
      "context" : "It is notable that our local error bound condition is different from the one used in [13, 25] which bounds the distance of a point to the optimal set by the norm of the projected or proximal gradient at that point instead of the functional distance, consequentially it requires some smoothness assumption about the objective function.",
      "startOffset" : 85,
      "endOffset" : 93
    }, {
      "referenceID" : 13,
      "context" : "Recent work [14, 23] have shown that the error bound in [13, 25] is a special case of our considered error bound with θ = 1/2.",
      "startOffset" : 12,
      "endOffset" : 20
    }, {
      "referenceID" : 22,
      "context" : "Recent work [14, 23] have shown that the error bound in [13, 25] is a special case of our considered error bound with θ = 1/2.",
      "startOffset" : 12,
      "endOffset" : 20
    }, {
      "referenceID" : 12,
      "context" : "Recent work [14, 23] have shown that the error bound in [13, 25] is a special case of our considered error bound with θ = 1/2.",
      "startOffset" : 56,
      "endOffset" : 64
    }, {
      "referenceID" : 24,
      "context" : "Recent work [14, 23] have shown that the error bound in [13, 25] is a special case of our considered error bound with θ = 1/2.",
      "startOffset" : 56,
      "endOffset" : 64
    }, {
      "referenceID" : 7,
      "context" : "[8] considered the two-person zero-sum games, which is a special case of (1) with g(x) and φ(u) being zeros and Ω1 and Ω2 being polytopes.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 20,
      "context" : "Recently, Yang & Lin [21] proposed a restarted subgradient method by exploring the local error bound condition or more generally the Kurdyka-Łojasiewicz property, resulting in an Õ(1/ 2(1−θ)) iteration complexity with the same constant of θ.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 19,
      "context" : ", `1 regularized least-squares problem [20]), though a homotopy strategy on an involved parameter is also employed to boost the convergence.",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 2,
      "context" : "a continuation) strategy is employed in Nesterov’s smoothing algorithm for solving an `1 norm minimization problem subject to a constraint for recovering a sparse solution [3].",
      "startOffset" : 172,
      "endOffset" : 175
    }, {
      "referenceID" : 15,
      "context" : "Note that: 1) Assumption 1(i) assumes that the objective function is lower bounded; 2) Assumption 1(iii) assumes that Ω2 is a bounded set, which is also required in [16].",
      "startOffset" : 165,
      "endOffset" : 169
    }, {
      "referenceID" : 5,
      "context" : "In addition, for brevity we assume that g(x) is simple enough 3 such that the proximal mapping defined below is easy to compute similar to [6]:",
      "startOffset" : 139,
      "endOffset" : 142
    }, {
      "referenceID" : 17,
      "context" : ", L = {x ∈ Ω1 : F (x) = F∗ + }, S = {x ∈ Ω1 : F (x) ≤ F∗ + } It follows from [18] (Corollary 8.",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 15,
      "context" : "fμ(x) = max u∈Ω2 〈Ax, u〉 − φ(u)− μω+(u) It was shown in [16] that fμ(x) is smooth w.",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 1,
      "context" : "Many works have studied such an optimization problem [2, 19] and the best convergence rate is given by O(Lμ/t(2)), where t is the total number of iterations.",
      "startOffset" : 53,
      "endOffset" : 60
    }, {
      "referenceID" : 18,
      "context" : "Many works have studied such an optimization problem [2, 19] and the best convergence rate is given by O(Lμ/t(2)), where t is the total number of iterations.",
      "startOffset" : 53,
      "endOffset" : 60
    }, {
      "referenceID" : 18,
      "context" : "We make several remarks about Algorithm 1: (i) the variant here is similar to Algorithm 3 in [19] and the algorithm proposed in [16] except that the prox function d(x) is replaced by ‖x− x0‖(2)/2 in updating the sequence of zk, which is assumed to be σ1-strongly convex w.",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 15,
      "context" : "We make several remarks about Algorithm 1: (i) the variant here is similar to Algorithm 3 in [19] and the algorithm proposed in [16] except that the prox function d(x) is replaced by ‖x− x0‖(2)/2 in updating the sequence of zk, which is assumed to be σ1-strongly convex w.",
      "startOffset" : 128,
      "endOffset" : 132
    }, {
      "referenceID" : 1,
      "context" : ", FISTA [2]); (iii) if Lμ is difficult to compute, we can use the backtracking trick (see [2, 19]).",
      "startOffset" : 8,
      "endOffset" : 11
    }, {
      "referenceID" : 1,
      "context" : ", FISTA [2]); (iii) if Lμ is difficult to compute, we can use the backtracking trick (see [2, 19]).",
      "startOffset" : 90,
      "endOffset" : 97
    }, {
      "referenceID" : 18,
      "context" : ", FISTA [2]); (iii) if Lμ is difficult to compute, we can use the backtracking trick (see [2, 19]).",
      "startOffset" : 90,
      "endOffset" : 97
    }, {
      "referenceID" : 18,
      "context" : "([19]) Let θk = 2 k+2 , αk = 2 k+1 , k ≥ 0 or αk+1 = θk+1 = √ θ4 k+4θ 2 k−θ 2 k 2 , k ≥ 0.",
      "startOffset" : 1,
      "endOffset" : 5
    }, {
      "referenceID" : 16,
      "context" : "The Hoffman’s bound [17] is expressed as dist(x,P) ≤ c(‖(B1x− b1)+‖+ ‖B2x− b2‖),∃c > 0 (11) where [s]+ = max(0, s).",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 10,
      "context" : "[11] have considered Nesterov’s smoothing algorithm for solving the cone programming problem with O(1/ ) iteration complexity.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 4,
      "context" : "[5] have considered the error bound for such problems and their results imply that there exists c > 0 such that dist(x,Ω∗) ≤ c(F (x)− F∗) as long as ∃x ∈ Ω, s.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 10,
      "context" : "The notations and descriptions are adopted from [11].",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 20,
      "context" : "The error bound condition has been developed for such kind of problems [21].",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 21,
      "context" : "[22] has also considered such non-smooth problems, but they only have O(1/ ) iteration complexity.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 8,
      "context" : "When F (x) is essentially locally strongly convex [9] in terms of ‖ · ‖ such that 5 dist(2)(x,Ω∗) ≤ 2 σ (F (x)− F∗),∀x ∈ S (12)",
      "startOffset" : 50,
      "endOffset" : 53
    }, {
      "referenceID" : 5,
      "context" : "then we can see that the local error bound holds with θ = 1/2, which implies the iteration complexity of HOPS is Õ( 1 √ ), which is up to a logarithmic factor the same as the result in [6] for a strongly convex function.",
      "startOffset" : 185,
      "endOffset" : 188
    }, {
      "referenceID" : 5,
      "context" : "However, here only local strong convexity is sufficient and there is no need to develop a different algorithm and different analysis from the non-strongly convex case as done in [6].",
      "startOffset" : 178,
      "endOffset" : 181
    }, {
      "referenceID" : 20,
      "context" : "For example, one can consider F (x) = ‖Ax− y‖p = ∑n i=1 |ai x− yi|, p ∈ (1, 2), which satisfies (12) according to [21].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 3,
      "context" : "It has been established that the KL property is satisfied by a wide class of non-smooth functions definable in an o-minimal structure [4].",
      "startOffset" : 134,
      "endOffset" : 137
    }, {
      "referenceID" : 0,
      "context" : "While the definition of KL property involves a neighborhood U and a constant η, in practice many convex functions satisfy the above property with U = R and η = ∞ [1].",
      "startOffset" : 162,
      "endOffset" : 165
    }, {
      "referenceID" : 9,
      "context" : "(Theorem 5 [10]) Let F (x) be a proper, convex and lower-semicontinuous function that satisfies KL property at x∗ and U be a neighborhood of x∗.",
      "startOffset" : 11,
      "endOffset" : 15
    }, {
      "referenceID" : 5,
      "context" : "5 Experimental Results In this section, we present some experimental results to demonstrate the effectiveness of HOPS and PD-HOPS by comparing with two state-of-the-art algorithms, the first-order Primal-Dual (PD) method [6] and the Nesterov’s smoothing with Accelerated Proximal Gradient (APG) methods.",
      "startOffset" : 221,
      "endOffset" : 224
    }, {
      "referenceID" : 1,
      "context" : ", Algorithm 1) and APG-F refers to the variant of the FISTA style [2].",
      "startOffset" : 66,
      "endOffset" : 69
    } ],
    "year" : 2016,
    "abstractText" : "In this paper, we develop a novel homotopy smoothing (HOPS) algorithm for solving a family of non-smooth problems that is composed of a non-smooth term with an explicit max-structure and a smooth term or a simple non-smooth term whose proximal mapping is easy to compute. The best known iteration complexity for solving such non-smooth optimization problems is O(1/ ) without any assumption on the strong convexity. In this work, we will show that the proposed HOPS achieved a lower iteration complexity of Õ(1/ 1−θ) 1with θ ∈ (0, 1] capturing the local sharpness of the objective function around the optimal solutions. To the best of our knowledge, this is the lowest iteration complexity achieved so far for the considered non-smooth optimization problems without strong convexity assumption. The HOPS algorithm employs Nesterov’s smoothing technique and Nesterov’s accelerated gradient method and runs in stages, which gradually decreases the smoothing parameter in a stage-wise manner until it yields a sufficiently good approximation of the original function. We show that HOPS enjoys a linear convergence for many well-known non-smooth problems (e.g., empirical risk minimization with a piece-wise linear loss function and `1 norm regularizer, finding a point in a polyhedron, cone programming, etc). Experimental results verify the effectiveness of HOPS in comparison with Nesterov’s smoothing algorithm and the primal-dual style of first-order methods.",
    "creator" : null
  }
}