{
  "name" : "5a7f963e5e0504740c3a6b10bb6d4fa5.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Tractable Operations for Arithmetic Circuits of Probabilistic Models",
    "authors" : [ "Yujia Shen", "Adnan Darwiche" ],
    "emails" : [ "yujias@cs.ucla.edu", "aychoi@cs.ucla.edu", "darwiche@cs.ucla.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Arithmetic circuits (ACs) have been a central representation for probabilistic graphical models, such as Bayesian networks and Markov networks. On the reasoning side, some state-of-the-art approaches for exact inference are based on compiling probabilistic graphical models into arithmetic circuits [Darwiche, 2003]; see also Darwiche [2009, chapter 12]. Such approaches can exploit parametric structure (such as determinism and context-specific independence), allowing inference to scale sometimes to models with very high treewidth, which are beyond the scope of classical inference algorithms such as variable elimination and jointree. For example, the ace system for compiling ACs [Chavira and Darwiche, 2008] was the only system in the UAI’08 evaluation of probabilistic reasoning systems to exactly solve all 250 networks in a challenging (very high-treewidth) suite of relational models [Darwiche et al., 2008].\nOn the learning side, arithmetic circuits have become a popular representation for learning from data, as they are tractable for certain probabilistic queries. For example, there are algorithms for learning ACs of Bayesian networks [Lowd and Domingos, 2008], ACs of Markov networks [Lowd and Rooshenas, 2013, Bekker et al., 2015] and Sum-Product Networks (SPNs) [Poon and Domingos, 2011], among other related representations.1\nDepending on their properties, different classes of ACs are tractable for different queries and operations. Among these queries are maximum a posteriori (MAP) inference,2 which is an NP-complete problem, and evaluating the partition function, which is a PP-complete problem (more intractable). Among operations, the multiplication of two ACs stands out as particularly important, being a primitive operation in some approaches to incremental or adaptive inference [Delcher et al., 1995, Acar et al., 2008], bottom-up compilation of probabilistic graphical models [Choi et al., 2013], and some search-based approaches to structure learning [Bekker et al., 2015].\n1SPNs can be converted into ACs (and vice-versa) with linear size and time [Rooshenas and Lowd, 2014]. 2This is also known as most probable explanation (MPE) inference [Pearl, 1988].\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nIn this paper, we investigate the tractability of two fundamental operations on arithmetic circuits: multiplying two ACs and summing out a variable from an AC. We show that both operations are intractable for some influential ACs that have been employed in the probabilistic reasoning and learning literatures. We then consider a recently proposed sub-class of ACs, called the Probabilistic Sentential Decision Diagram (PSDD) [Kisa et al., 2014]. We show that PSDDs support a polytime multiplication operation, which makes them suitable for a broader class of applications. We also show that PSDDs do not support a polytime summing-out operation (a primitive operation for messagepassing inference algorithms). We empirically illustrate the advantages of PSDDs compared to other AC representations, for compiling probabilistic graphical models. Previous approaches for compiling probabilistic models into ACs are based on encoding these models into auxiliary logical representations, such as a Sentential Decision Diagram (SDD) or a deterministic DNNF circuits, which are then converted to an AC [Chavira and Darwiche, 2008, Choi et al., 2013]. PSDDs are a direct representation of probability distributions, bypassing the overhead of intermediate logical representations, and leading to more efficient compilations in some cases. Most importantly though, this approach lends itself to a significantly simpler compilation algorithm: represent each factor of a given model as a PSDD, and then multiply the factors using PSDD multiplication.\nThis paper is organized as follows. In Section 2, we review arithmetic circuits (ACs) as a representation of probability distributions, including PSDDs in particular. In Section 3, we introduce a polytime multiplication operator for PSDDs, and in Section 4, we show that there is no polytime sum-out operator for PSDDs. In Section 5, we propose a simple compilation algorithm for PSDDs based on the multiply operator, which we evaluate empirically. We discuss related work in Section 6 and finally conclude in Section 7. Proofs of theorems are available in the Appendix."
    }, {
      "heading" : "2 Representing Distributions Using Arithmetic Circuits",
      "text" : "We start with the definition of factors, which include distributions as a special case.\nDefinition 1 (Factor) A factor f(X) over variables X maps each instantiation x of variables X into a non-negative number f(x). The factor represents a distribution when P x f(x) = 1. We define the value of a factor at a partial instantiation y, where Y ✓ X, as f(y) = P\nz f(yz), where Z = X \\Y. When the factor is a distribution, f(y) corresponds to the probability of evidence y. We also define the MAP instantiation of a factor as argmax\nx f(x), which corresponds to the most likely instantiation when the factor is a distribution.\nThe classical, tabular representation of a factor f(X) is exponential in the number of variables X. However, one can represent such factors more compactly using arithmetic circuits.\nDefinition 2 (Arithmetic Circuit) An arithmetic circuit AC(X) over variables X is a rooted DAG whose internal nodes are labeled with + or ⇤ and whose leaf nodes are labeled with either indicator variables\nx or non-negative parameters ✓. The value of the circuit at instantiation x, denoted AC(x), is obtained by assigning indicator\nx the value 1 if x is compatible with instantiation x and 0 otherwise, then evaluating the circuit in the standard way. The circuit AC(X) represents factor f(X) iff AC(x) = f(x) for each instantiation x.\nA tractable arithmetic circuit allows one to efficiently answer certain queries about the factor it represents. We next discuss two properties that lead to tractable arithmetic circuits. The first is decomposability [Darwiche, 2001b], which was used for probabilistic reasoning in [Darwiche, 2003].\nDefinition 3 (Decomposability) Let n be a node in an arithmetic circuit AC(X). The variables of n, denoted vars(n), are the variables X 2 X with some indicator\nx\nappearing at or under node\nn. An arithmetic circuit is decomposable iff every pair of children c1 and c2 of a ⇤-node satisfies vars(c1) \\ vars(c2) = ;.\nThe second property is determinism [Darwiche, 2001a], which was also employed for probabilistic reasoning in Darwiche [2003].\nDefinition 4 (Determinism) An arithmetic circuit AC(X) is deterministic iff each +-node has at most one non-zero input when the circuit is evaluated under any instantiation x of the variables X.\nA third property called smoothness is also desirable as it simplifies the statement of certain AC algorithms, but is less important for tractability as it can be enforced in polytime [Darwiche, 2001a].\nDefinition 5 (Smoothness) An arithmetic circuit AC(X) is smooth iff it contains at least one indicator for each variable in X, and for each child c of +-node n, we have vars(n) = vars(c).\nDecomposability and determinism lead to tractability in the following sense. Let Pr(X) be a distribution represented by a decomposable, deterministic and smooth arithmetic circuit AC(X). Then one can compute the following queries in time that is linear in the size of circuit AC(X): the probability of any partial instantiation, Pr(y), where Y ✓ X [Darwiche, 2003] and the most likely instantiation, argmax\nx Pr(x) [Chan and Darwiche, 2006]. The decision problems of these queries are known to be PP-complete and NP-complete for Bayesian networks [Roth, 1996, Shimony, 1994].\n**\n* *\n+\n+ + * * * *\na a b ba aab| ab | ab| ab |\nAdditional methods are discussed in Darwiche [2009, chapter 12].\nThis work is motivated by the following limitation of these tractable circuits, which may narrow their applicability in probabilistic reasoning and learning.\nDefinition 6 (Multiplication) The product of two arithmetic circuits AC1(X) and AC2(X) is an arithmetic circuit AC(X) such that AC(x) = AC1(x)AC2(x) for every instantiation x.\nTheorem 1 Computing the product of two decomposable ACs is NP-hard if the product is also decomposable. Computing the product of two decomposable and deterministic ACs is NP-hard if the\nproduct is also decomposable and deterministic.\nWe now investigate a newly introduced class of tractable ACs, called the Probabilistic Sentential Decision Diagram (PSDD) [Kisa et al., 2014]. In particular, we show that this class of circuits admits a tractable product operation and then explore an application of this operation to exact inference in probabilistic graphical models.\nPSDDs were motivated by the need to represent probability distributions Pr(X) with many instantiations x attaining zero probability, Pr(x) = 0. Consider the distribution Pr(X) in Figure 2(a) for an example. The first step in constructing a PSDD for this distribution is to construct a special Boolean circuit that captures its zero entries; see Figure 2(b). The Boolean circuit captures zero entries in the following sense. For each instantiation x, the circuit evaluates to 0 at instantiation x iff Pr(x) = 0. The second and final step of constructing a PSDD amounts to parameterizing this Boolean circuit (e.g., by learning them from data), by including a local distribution on the inputs of each or-gate; see Figure 2(c).\nThe Boolean circuit underlying a PSDD is known as a Sentential Decision Diagram (SDD) [Darwiche, 2011]. These circuits satisfy specific syntactic and semantic properties based on a binary tree, called a vtree, whose leaves correspond to variables; see Figure 2(d). The following definition of SDD circuits is a based on the one given by Darwiche [2011] and uses a different notation.\nDefinition 7 (SDD) An SDD normalized for a vtree v is a Boolean circuit defined as follows. If v is a leaf node labeled with variable X , then the SDD is either X , ¬X , ? or an or-gate with inputs X and ¬X . If v is an internal vtree node, then the SDD has the structure in Figure 3, where p1, . . . , pn are SDDs normalized for the left child vl and s1, . . . , sn are SDDs normalized for the right child vr. Moreover, the circuits p1, . . . , pn are consistent, mutually exclusive and exhaustive.\np1 s1 p2 s2\n· · ·\np n s n\n· · ·↵1 ↵2 ↵ n\nFigure 3: Each (p i , s i ,↵ i ) is called an element of the or-gate, where the p i ’s are called primes and the s i ’s are called subs. Moreover,P\ni\n↵ i = 1 and exactly one p i\nevaluates to 1 under any circuit input.\nSDD circuits alternate between or-gates and and-gates. Their andgates have two inputs each. The or-gates of these circuits are such that at most one input will be high under any circuit input. An SDD circuit may produce a 1-output for every possible input (i.e., the circuit represents the function true). These circuits arise when representing strictly positive distributions (with no zero entries).\nA PSDD is obtained by including a distribution ↵1, . . . ,↵n on the inputs of each or-gate; see Figure 3. The semantics of PSDDs are given in [Kisa et al., 2014].3 We next provide an alternative semantics, which is based on converting a PSDD into an arithmetic circuit.\nDefinition 8 (ACs of PSDDs) The arithmetic circuit of a PSDD is obtained as follows. Leaf nodes x and ? are converted into\nx\nand 0,\nrespectively. Each and-gate is converted into a ⇤-node. Each or-node with children c1, . . . , cn and corresponding parameters ↵1, . . . ,↵n is converted into a +-node with children ↵1 ⇤ c1, . . . , ↵n ⇤ cn.\nTheorem 2 The arithmetic circuit of a PSDD represents the distribution induced by the PSDD. Moreover, the arithmetic circuit is decom-\nposable and deterministic.\n4\nThe PSDD is a complete and canonical representation of probability distributions. That is, PSDDs can represent any distribution, and there is a unique PSDD for that distribution (under some conditions). A variety of probabilistic queries are tractable on PSDDs, including that of computing the probability of a partial variable instantiation and the most likely instantiation. Moreover, the maximum likelihood parameter estimates of a PSDD are unique given complete data, and these parameters can be computed efficiently using closed-form estimates; see [Kisa et al., 2014] for details. Finally, PSDDs have been used to learn distributions over combinatorial objects, including rankings and permutations [Choi et al., 2015], paths and games [Choi et al., 2016]. In these applications, the Boolean circuit underlying a PSDD captures variable instantiations that correspond to combinatorial objects, while its parameterization induces a distribution over these objects.\nAs a concrete example, PSDDs were used to induce distributions over the permutations of n items as follows. We have a variable X\nij for each i, j 2 {1, . . . , n} denoting that item i is at position j in the permutation. Clearly, not all instantiations of these variables correspond to (valid) permutations. An SDD circuit is then constructed, which outputs 1 iff the corresponding input corresponds to a valid permutation. Each parameterization of this SDD circuit leads to a distribution on permutations and these parameterizations can be learned from data; see Choi et al. [2015].\n3Let x be an instantiation of PSDD variables. If the SDD circuit outputs 0 at input x, then Pr(x) = 0. Otherwise, traverse the circuit top-down, visiting the (unique) high input of each visited or-node, and all inputs of each visited and-node. Then Pr(x) is the product of parameters visited during the traversal process.\n4The arithmetic circuit also satisfies a minor weakening of smoothness with the same effect as smoothness."
    }, {
      "heading" : "3 Multiplying Two PSDDs",
      "text" : "Factors and their operations are fundamental to probabilistic inference, whether exact or approximate [Darwiche, 2009, Koller and Friedman, 2009]. Consider two of the most basic operations on factors: (1) computing the product of two factors and (2) summing out a variable from a factor. With these operations, one can directly implement various inference algorithms, including variable elimination, the jointree algorithm, and message-passing algorithms such as loopy belief propagation. Typically, tabular representations (and their sparse variations) are used to represent factors and implement the above algorithms; see Larkin and Dechter [2003], Sanner and McAllester [2005], Chavira and Darwiche [2007] for some alternatives.\nMore generally, factor multiplication is useful for online or incremental reasoning with probabilistic models. In some applications, we may not have access to all factors of a model beforehand, to compile as a jointree or an arithmetic circuit. For example, when learning the structure of a Markov network from data [Bekker et al., 2015], we may want to introduce and remove candidate factors from a model, while evaluating the changes to the log likelihood. Certain realizations of generalized belief propagation also require the multiplication of factors [Yedidia et al., 2005, Choi and Darwiche, 2011]. In these realizations, one can use factor multiplication to enforce dependencies between factors that have been relaxed to make inference more tractable, albeit less accurate.\nWe next discuss PSDD multiplication, while deferring summing out to the following section.\nAlgorithm 1 Multiply(n1, n2, v) input: PSDDs n1, n2 normalized for vtree v output: PSDD n and constant  main: 1: n, k cachem(n1, n2), cachec(n1, n2) . check if previously computed 2: if n 6= null then return (n, k) . return previously cached result 3: else if v is a leaf then (n,) BaseCase(n1, n2) . n1, n2 are literals, ? or simple or-gates 4: else . n1 and n2 have the structure in Figure 3 5: , {}, 0 . initialization 6: for all elements (p, s,↵) of n1 do . see Figure 3 7: for all elements (q, r, ) of n2 do . see Figure 3 8: (m1, k1) Multiply(p, q, vl) . recursively multiply primes p and q 9: if k1 6= 0 then . if (m1, k1) is not a trivial factor 10: (m2, k2) Multiply(s, r, vr) . recursively multiply subs s and r 11: ⌘ k1 · k2 · ↵ · . compute weight of element (m1,m2) 12:  + ⌘ . aggregate weights of elements 13: add (m1,m2, ⌘) to 14: {(m1,m2, ⌘/) | (m1,m2, ⌘) 2 } . normalize parameters of 15: n unique PSDD node with elements . cache lookup for unique nodes 16: cachem(n1, n2) n 17: cachec(n1, n2)  . store results in cache 18: return (n,)\nOur first observation is that the product of two distributions is generally not a distribution, but a factor. Moreover, a factor f(X) can always be represented by a distribution Pr(X) and a constant  such that f(x) =  · Pr(x). Hence, our proposed multiplication method will output a PSDD together with a constant, as given in Algorithm 1. This algorithm uses three caches, one for storing constants (cachec), another for storing circuits (cachem), and a third used to implement Line 15.5 This line ensures that the PSDD has no duplicate structures of the form given in Figure 3. The description of function BaseCase() on Line 3 is available in the Appendix. It appears inside the proof of the following theorem, which establishes the soundness and complexity of the given algorithm.\nTheorem 3 Algorithm 1 outputs a PSDD n normalized for vtree v. Moreover, if Pr1(X) and Pr2(X) are the distributions of input PSDDs n1 and n2, and Pr(X) is the distribution of output PSDD n, then Pr1(x)Pr2(x) =  · Pr(x) for every instantiation x. Finally, Algorithm 1 takes time O(s1s2), where s1 and s2 are the sizes of input PSDDs.\n5The cache key of a PSDD node in Figure 3 is based on the (unique) ID’s of nodes pi/si and parameters ↵i.\nWe will later discuss an application of PSDD multiplication to probabilistic inference, in which we cascade these multiplication operations. In particular, we end up multiplying two factors f1 and f2, represented by PSDDs n1 and n2 and the corresponding constants 1 and 2. We use Algorithm 1 for this purpose, multiplying PSDDs n1 and n2 (distributions), to yield a PSDD n (distribution) and a constant . The factor f1f2 will then correspond to PSDD n and constant  · 1 · 2.\nA\nG F K\nE C\nB J H\nI D\nA\nG K H D\nA\nG\nB\nH D\nX ✓ Z is obtained as follows. Successively remove every maximal subtree v0 whose variables are outside X, while replacing the parent of v0 with its sibling.\nFigure 4 depicts a vtree and two of its projections. When compiling a probabilistic graphical model into a PSDD, we first construct a vtree v over all variables in the model. We then compile each factor f(X) into a PSDD, using the projection of v on variables X. We finally multiply the PSDDs of these factors. We will revisit these steps later."
    }, {
      "heading" : "4 Summing-Out a Variable in a PSDD",
      "text" : "We now discuss the summing out of variables from distributions represented by arithmetic circuits.\nDefinition 10 (Sum Out) Summing-out a variable X 2 X from factor f(X) results in another factor over variables Y = X \\ {X}, denoted by P X f and defined as: ⇣P X f ⌘ (y) def = P x f(x,y).\nWhen the factor is a distribution (i.e., normalized), the sum out operation corresponds to marginalization. Together with multiplication, summing out provides a direct implementation of algorithms such as variable elimination and those based on message passing.\nJust like multiplication, summing out is also intractable for a common class of arithmetic circuits.\nTheorem 4 The sum-out operation on decomposable and deterministic ACs is NP-hard, assuming the output is also decomposable and deterministic.\nThis theorem does not preclude the possibility that the resulting AC is of polynomial size with respect to the size of the input AC—it just says that the computation is intractable. Summing out is also intractable on PSDDs, but the result is stronger here as the size of the output can be exponential.\nTheorem 5 There exists a class of factors f(X) and variable X 2 X, such that n = |X| can be arbitrarily large, f(X) has a PSDD whose size is linear in n, while the PSDD of P X\nf has size exponential in n for every vtree.\nOnly the multiplication operation is needed to compile probabilistic graphical models into arithmetic circuits. Even for inference algorithms that require summing out variables, such as variable elimination, summing out can still be useful, even if intractable, since the size of resulting arithmetic circuit will not be larger than a tabular representation."
    }, {
      "heading" : "5 Compiling Probabilistic Graphical Models into PSDDs",
      "text" : "Even though PSDDs form a strict subclass of decomposable and deterministic ACs (and satisfy stronger properties), one can still provide the following classical guarantee on PSDD size.\nTheorem 6 The interaction graph of factors f1(X1), . . . , fn(Xn) has nodes corresponding to variables X1 [ . . . [Xn and an edge between two variables iff they appear in the same factor. There is a PSDD for the product f1 . . . fn whose size is O(m · exp(w)), where m is the number of variables and w is its treewidth.\nThis theorem provides an upper bound on the size of PSDD compilations for both Bayesian and Markov networks. An analogous guarantee is available for SDD circuits of propositional models, using a special type of vtree known as a decision vtree [Oztok and Darwiche, 2014]. We next discuss our experiments, which focused on the compilation of Markov networks using decision vtrees.\nTo compile a Markov network, we first construct a decision vtree using a known technique.6 For each factor of the network, we project the vtree on the factor variables, and then compile the factor into a PSDD. This can be done in time linear in the factor size, but we omit the details here. We finally multiply the obtained PSDDs. The order of multiplication is important to the overall efficiency of the compilation approach. The order we used is as follows. We assign each PSDD to the lowest vtree node containing the PSDD variables, and then multiply PSDDs in the order that we encounter them as we traverse the vtree bottom-up (this is analogous to compiling CNFs in Choi et al. [2013]).\nTable 1 summarizes our results. We compiled Markov networks into three types of arithmetic circuits. The first compilation (AC1) is to decomposable and deterministic ACs using ace [Chavira and Darwiche, 2008].7 The second compilation (AC2) is also to decomposable and deterministic ACs, but using the approach proposed in Choi et al. [2013]. The third compilation is to PSDDs as discussed above. The first two approaches are based on reducing the inference problem into a weighted model counting problem. In particular, these approaches encode the network using Boolean expressions, which are compiled to logical representations (d-DNNF or SDD), from which an arithmetic circuit is induced. The systems underlying these approaches are quite complex and are the result of many years of engineering. In contrast, the proposed compilation to PSDDs does not rely on an intermediate representation or additional boxes, such as d-DNNF or SDD compilers.\nThe benchmarks in Table 1 are from the UAI-14 Inference Competition.8 We selected all networks over binary variables in the MAR track, and report a network only if at least one approach successfully compiled it (given time and space limits of 30 minutes and 16GB). We report the size (the number of edges) and time spent for each compilation. First, we note that for all benchmarks that compiled to both PSDD and AC2 (based on SDDs), the PSDD size is always smaller. This can be attributed in part to the fact that reductions to weighted model counting represent parameters explicitly as variables, which are retained throughout the compilation process. In contrast, PSDD parameters are annotated on its edges. More interestingly, when we multiply two PSDD factors, the parameters of the inputs may not persist in the output PSDD. That is, the PSDD only maintains enough parameters to represent the resulting distribution, which further explains the size differences.\nIn the Promedus benchmarks, we also see that in all but 5 cases, the compiled PSDD is smaller than AC1. However, several Grids benchmarks were compilable to AC1, but failed to compile to AC2 or PSDD, given the time and space limits. On the other hand, we were able to compile some of the relational benchmarks to PSDD, which did not compile to AC1 and compiled partially to AC2."
    }, {
      "heading" : "6 Related Work",
      "text" : "Tabular representations and their sparse variations (e.g., Larkin and Dechter [2003]) are typically used to represent factors for probabilistic inference and learning. Rules and decision trees are more succinct representations for modeling context-specific independence, although they are not much more amenable to exact inference compared to tabular representations [Boutilier et al., 1996, Friedman and Goldszmidt, 1998]. Domain specific representations have been proposed, e.g., in computer vision\n6We used the minic2d package which is available at reasoning.cs.ucla.edu/minic2d/. 7The ace system is publicly available at http://reasoning.cs.ucla.edu/ace/. 8 http://www.hlt.utdallas.edu/~vgogate/uai14-competition/index.html\n[Felzenszwalb and Huttenlocher, 2006], to allow for more efficient factor operations. Algebraic Decision Diagrams (ADDs) and Algebraic Sentential Decision Diagrams (ASDDs) can also be used to multiply two factors in polytime [Bahar et al., 1993, Herrmann and de Barros, 2013], but their sizes can grow quickly with repeated multiplications: ADDs have a distinct node for each possible value of a factor/distribution. Since ADDs also support a polytime summing-out operation, ADDs are more commonly used in the context of variable elimination [Sanner and McAllester, 2005, Chavira and Darwiche, 2007], and in message passing algorithms [Gogate and Domingos, 2013]. Probabilistic Decision Graphs (PDGs) and AND/OR Multi-Valued Decision Diagrams (AOMDD) support a polytime multiply operator, and also have treewidth upper bounds when compiling probabilistic graphical models [Jaeger, 2004, Mateescu et al., 2008]. Both PDGs and AOMDDs can be viewed as sub-classes of PSDDs that branch on variables instead of sentences as is the case with PSDDs—this distinction can lead to exponential reductions in size [Xue et al., 2012, Bova, 2016]."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We considered the tractability of multiplication and summing-out operators for arithmetic circuits (ACs), as tractable representations of factors and distributions. We showed that both operations are intractable for deterministic and decomposable ACs (under standard complexity theoretic assumptions). We also showed that for a sub-class of ACs, known as PSDDs, a polytime multiplication operator is supported. Moreover, we showed that PSDDs do not support summing-out in polytime (unconditionally). Finally, we illustrated the utility of PSDD multiplication, providing a relatively simple but effective algorithm for compiling probabilistic graphical models into PSDDs."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was partially supported by NSF grant #IIS-1514253 and ONR grant #N00014-15-1-2339."
    } ],
    "references" : [ {
      "title" : "Adaptive inference on general graphical models",
      "author" : [ "U.A. Acar", "A.T. Ihler", "R.R. Mettu", "Ö. Sümer" ],
      "venue" : null,
      "citeRegEx" : "Acar et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Acar et al\\.",
      "year" : 2008
    }, {
      "title" : "Algebraic decision diagrams and their applications",
      "author" : [ "R.I. Bahar", "E.A. Frohm", "C.M. Gaona", "G.D. Hachtel", "E. Macii", "A. Pardo", "F. Somenzi" ],
      "venue" : "In ICCAD,",
      "citeRegEx" : "Bahar et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Bahar et al\\.",
      "year" : 1993
    }, {
      "title" : "Tractable learning for complex probability queries",
      "author" : [ "J. Bekker", "J. Davis", "A. Choi", "A. Darwiche", "G. Van den Broeck" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Bekker et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Bekker et al\\.",
      "year" : 2015
    }, {
      "title" : "Context-specific independence in Bayesian networks",
      "author" : [ "C. Boutilier", "N. Friedman", "M. Goldszmidt", "D. Koller" ],
      "venue" : "In UAI,",
      "citeRegEx" : "Boutilier et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Boutilier et al\\.",
      "year" : 1996
    }, {
      "title" : "SDDs are exponentially more succinct than OBDDs",
      "author" : [ "S. Bova" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "Bova.,? \\Q2016\\E",
      "shortCiteRegEx" : "Bova.",
      "year" : 2016
    }, {
      "title" : "On the robustness of most probable explanations",
      "author" : [ "H. Chan", "A. Darwiche" ],
      "venue" : "In UAI,",
      "citeRegEx" : "Chan and Darwiche.,? \\Q2006\\E",
      "shortCiteRegEx" : "Chan and Darwiche.",
      "year" : 2006
    }, {
      "title" : "Compiling Bayesian networks using variable elimination",
      "author" : [ "M. Chavira", "A. Darwiche" ],
      "venue" : "In IJCAI,",
      "citeRegEx" : "Chavira and Darwiche.,? \\Q2007\\E",
      "shortCiteRegEx" : "Chavira and Darwiche.",
      "year" : 2007
    }, {
      "title" : "On probabilistic inference by weighted model counting",
      "author" : [ "M. Chavira", "A. Darwiche" ],
      "venue" : "AIJ,",
      "citeRegEx" : "Chavira and Darwiche.,? \\Q2008\\E",
      "shortCiteRegEx" : "Chavira and Darwiche.",
      "year" : 2008
    }, {
      "title" : "Relax, compensate and then recover",
      "author" : [ "A. Choi", "A. Darwiche" ],
      "venue" : "NFAI, volume 6797 of LNCF,",
      "citeRegEx" : "Choi and Darwiche.,? \\Q2011\\E",
      "shortCiteRegEx" : "Choi and Darwiche.",
      "year" : 2011
    }, {
      "title" : "Compiling probabilistic graphical models using sentential decision diagrams",
      "author" : [ "A. Choi", "D. Kisa", "A. Darwiche" ],
      "venue" : "In ECSQARU,",
      "citeRegEx" : "Choi et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Choi et al\\.",
      "year" : 2013
    }, {
      "title" : "Tractable learning for structured probability spaces: A case study in learning preference distributions",
      "author" : [ "A. Choi", "G. Van den Broeck", "A. Darwiche" ],
      "venue" : "In IJCAI,",
      "citeRegEx" : "Choi et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Choi et al\\.",
      "year" : 2015
    }, {
      "title" : "Structured features in naive Bayes classification",
      "author" : [ "A. Choi", "N. Tavabi", "A. Darwiche" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "Choi et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Choi et al\\.",
      "year" : 2016
    }, {
      "title" : "On the tractable counting of theory models and its application to truth maintenance and belief revision",
      "author" : [ "A. Darwiche" ],
      "venue" : "Journal of Applied Non-Classical Logics,",
      "citeRegEx" : "Darwiche.,? \\Q2001\\E",
      "shortCiteRegEx" : "Darwiche.",
      "year" : 2001
    }, {
      "title" : "Decomposable negation normal form",
      "author" : [ "A. Darwiche" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "Darwiche.,? \\Q2001\\E",
      "shortCiteRegEx" : "Darwiche.",
      "year" : 2001
    }, {
      "title" : "A differential approach to inference in Bayesian networks",
      "author" : [ "A. Darwiche" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "Darwiche.,? \\Q2003\\E",
      "shortCiteRegEx" : "Darwiche.",
      "year" : 2003
    }, {
      "title" : "Modeling and Reasoning with Bayesian Networks",
      "author" : [ "A. Darwiche" ],
      "venue" : null,
      "citeRegEx" : "Darwiche.,? \\Q2009\\E",
      "shortCiteRegEx" : "Darwiche.",
      "year" : 2009
    }, {
      "title" : "SDD: A new canonical representation of propositional knowledge bases",
      "author" : [ "A. Darwiche" ],
      "venue" : "In IJCAI,",
      "citeRegEx" : "Darwiche.,? \\Q2011\\E",
      "shortCiteRegEx" : "Darwiche.",
      "year" : 2011
    }, {
      "title" : "A knowledge compilation",
      "author" : [ "A. Darwiche", "P. Marquis" ],
      "venue" : "map. JAIR,",
      "citeRegEx" : "Darwiche and Marquis.,? \\Q2002\\E",
      "shortCiteRegEx" : "Darwiche and Marquis.",
      "year" : 2002
    }, {
      "title" : "Results from the probabilistic inference evaluation of UAI-08",
      "author" : [ "A. Darwiche", "R. Dechter", "A. Choi", "V. Gogate", "L. Otten" ],
      "venue" : null,
      "citeRegEx" : "Darwiche et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Darwiche et al\\.",
      "year" : 2008
    }, {
      "title" : "Logarithmic-time updates and queries in probabilistic networks",
      "author" : [ "A.L. Delcher", "A.J. Grove", "S. Kasif", "J. Pearl" ],
      "venue" : "In UAI,",
      "citeRegEx" : "Delcher et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Delcher et al\\.",
      "year" : 1995
    }, {
      "title" : "Efficient belief propagation for early",
      "author" : [ "P.F. Felzenszwalb", "D.P. Huttenlocher" ],
      "venue" : "vision. IJCV,",
      "citeRegEx" : "Felzenszwalb and Huttenlocher.,? \\Q2006\\E",
      "shortCiteRegEx" : "Felzenszwalb and Huttenlocher.",
      "year" : 2006
    }, {
      "title" : "Learning bayesian networks with local structure. In Learning in graphical models, pages 421–459",
      "author" : [ "N. Friedman", "M. Goldszmidt" ],
      "venue" : null,
      "citeRegEx" : "Friedman and Goldszmidt.,? \\Q1998\\E",
      "shortCiteRegEx" : "Friedman and Goldszmidt.",
      "year" : 1998
    }, {
      "title" : "Structured message passing",
      "author" : [ "V. Gogate", "P.M. Domingos" ],
      "venue" : "In UAI,",
      "citeRegEx" : "Gogate and Domingos.,? \\Q2013\\E",
      "shortCiteRegEx" : "Gogate and Domingos.",
      "year" : 2013
    }, {
      "title" : "Algebraic sentential decision diagrams in symbolic probabilistic planning",
      "author" : [ "R.G. Herrmann", "L.N. de Barros" ],
      "venue" : "In Proceedings of the Brazilian Conference on Intelligent Systems (BRACIS),",
      "citeRegEx" : "Herrmann and Barros.,? \\Q2013\\E",
      "shortCiteRegEx" : "Herrmann and Barros.",
      "year" : 2013
    }, {
      "title" : "Probabilistic decision graphs — combining verification and AI techniques for probabilistic inference",
      "author" : [ "M. Jaeger" ],
      "venue" : "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems,",
      "citeRegEx" : "Jaeger.,? \\Q2004\\E",
      "shortCiteRegEx" : "Jaeger.",
      "year" : 2004
    }, {
      "title" : "Probabilistic sentential decision diagrams",
      "author" : [ "D. Kisa", "G. Van den Broeck", "A. Choi", "A. Darwiche" ],
      "venue" : "In KR,",
      "citeRegEx" : "Kisa et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kisa et al\\.",
      "year" : 2014
    }, {
      "title" : "Probabilistic Graphical Models: Principles and Techniques",
      "author" : [ "D. Koller", "N. Friedman" ],
      "venue" : null,
      "citeRegEx" : "Koller and Friedman.,? \\Q2009\\E",
      "shortCiteRegEx" : "Koller and Friedman.",
      "year" : 2009
    }, {
      "title" : "Bayesian inference in the presence of determinism",
      "author" : [ "D. Larkin", "R. Dechter" ],
      "venue" : "In AISTATS,",
      "citeRegEx" : "Larkin and Dechter.,? \\Q2003\\E",
      "shortCiteRegEx" : "Larkin and Dechter.",
      "year" : 2003
    }, {
      "title" : "Learning arithmetic circuits",
      "author" : [ "D. Lowd", "P.M. Domingos" ],
      "venue" : "In UAI, pages 383–392,",
      "citeRegEx" : "Lowd and Domingos.,? \\Q2008\\E",
      "shortCiteRegEx" : "Lowd and Domingos.",
      "year" : 2008
    }, {
      "title" : "Learning Markov networks with arithmetic circuits",
      "author" : [ "D. Lowd", "A. Rooshenas" ],
      "venue" : "In AISTATS,",
      "citeRegEx" : "Lowd and Rooshenas.,? \\Q2013\\E",
      "shortCiteRegEx" : "Lowd and Rooshenas.",
      "year" : 2013
    }, {
      "title" : "AND/OR multi-valued decision diagrams (AOMDDs) for graphical models",
      "author" : [ "R. Mateescu", "R. Dechter", "R. Marinescu" ],
      "venue" : "J. Artif. Intell. Res. (JAIR),",
      "citeRegEx" : "Mateescu et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Mateescu et al\\.",
      "year" : 2008
    }, {
      "title" : "On compiling CNF into decision-DNNF",
      "author" : [ "U. Oztok", "A. Darwiche" ],
      "venue" : "In CP,",
      "citeRegEx" : "Oztok and Darwiche.,? \\Q2014\\E",
      "shortCiteRegEx" : "Oztok and Darwiche.",
      "year" : 2014
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference",
      "author" : [ "J. Pearl" ],
      "venue" : "MK,",
      "citeRegEx" : "Pearl.,? \\Q1988\\E",
      "shortCiteRegEx" : "Pearl.",
      "year" : 1988
    }, {
      "title" : "Sum-product networks: A new deep architecture",
      "author" : [ "H. Poon", "P.M. Domingos" ],
      "venue" : "In UAI,",
      "citeRegEx" : "Poon and Domingos.,? \\Q2011\\E",
      "shortCiteRegEx" : "Poon and Domingos.",
      "year" : 2011
    }, {
      "title" : "Learning sum-product networks with direct and indirect variable interactions",
      "author" : [ "A. Rooshenas", "D. Lowd" ],
      "venue" : "In ICML,",
      "citeRegEx" : "Rooshenas and Lowd.,? \\Q2014\\E",
      "shortCiteRegEx" : "Rooshenas and Lowd.",
      "year" : 2014
    }, {
      "title" : "On the hardness of approximate reasoning",
      "author" : [ "D. Roth" ],
      "venue" : "Artif. Intell.,",
      "citeRegEx" : "Roth.,? \\Q1996\\E",
      "shortCiteRegEx" : "Roth.",
      "year" : 1996
    }, {
      "title" : "Affine algebraic decision diagrams (AADDs) and their application to structured probabilistic inference",
      "author" : [ "S. Sanner", "D.A. McAllester" ],
      "venue" : "In IJCAI,",
      "citeRegEx" : "Sanner and McAllester.,? \\Q2005\\E",
      "shortCiteRegEx" : "Sanner and McAllester.",
      "year" : 2005
    }, {
      "title" : "Finding MAPs for belief networks is NP-hard",
      "author" : [ "S.E. Shimony" ],
      "venue" : "Artif. Intell.,",
      "citeRegEx" : "Shimony.,? \\Q1994\\E",
      "shortCiteRegEx" : "Shimony.",
      "year" : 1994
    }, {
      "title" : "NC-algorithms for operations on binary decision diagrams",
      "author" : [ "D. Sieling", "I. Wegener" ],
      "venue" : "Parallel Processing Letters,",
      "citeRegEx" : "Sieling and Wegener.,? \\Q1993\\E",
      "shortCiteRegEx" : "Sieling and Wegener.",
      "year" : 1993
    }, {
      "title" : "Basing decisions on sentences in decision diagrams",
      "author" : [ "Y. Xue", "A. Choi", "A. Darwiche" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "Xue et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Xue et al\\.",
      "year" : 2012
    }, {
      "title" : "Constructing free-energy approximations and generalized belief propagation algorithms",
      "author" : [ "J. Yedidia", "W. Freeman", "Y. Weiss" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "Yedidia et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Yedidia et al\\.",
      "year" : 2005
    } ],
    "referenceMentions" : [ {
      "referenceID" : 14,
      "context" : "On the reasoning side, some state-of-the-art approaches for exact inference are based on compiling probabilistic graphical models into arithmetic circuits [Darwiche, 2003]; see also Darwiche [2009, chapter 12].",
      "startOffset" : 155,
      "endOffset" : 171
    }, {
      "referenceID" : 7,
      "context" : "For example, the ace system for compiling ACs [Chavira and Darwiche, 2008] was the only system in the UAI’08 evaluation of probabilistic reasoning systems to exactly solve all 250 networks in a challenging (very high-treewidth) suite of relational models [Darwiche et al.",
      "startOffset" : 46,
      "endOffset" : 74
    }, {
      "referenceID" : 18,
      "context" : "For example, the ace system for compiling ACs [Chavira and Darwiche, 2008] was the only system in the UAI’08 evaluation of probabilistic reasoning systems to exactly solve all 250 networks in a challenging (very high-treewidth) suite of relational models [Darwiche et al., 2008].",
      "startOffset" : 255,
      "endOffset" : 278
    }, {
      "referenceID" : 28,
      "context" : "For example, there are algorithms for learning ACs of Bayesian networks [Lowd and Domingos, 2008], ACs of Markov networks [Lowd and Rooshenas, 2013, Bekker et al.",
      "startOffset" : 72,
      "endOffset" : 97
    }, {
      "referenceID" : 33,
      "context" : ", 2015] and Sum-Product Networks (SPNs) [Poon and Domingos, 2011], among other related representations.",
      "startOffset" : 40,
      "endOffset" : 65
    }, {
      "referenceID" : 9,
      "context" : ", 2008], bottom-up compilation of probabilistic graphical models [Choi et al., 2013], and some search-based approaches to structure learning [Bekker et al.",
      "startOffset" : 65,
      "endOffset" : 84
    }, {
      "referenceID" : 2,
      "context" : ", 2013], and some search-based approaches to structure learning [Bekker et al., 2015].",
      "startOffset" : 64,
      "endOffset" : 85
    }, {
      "referenceID" : 34,
      "context" : "(1)SPNs can be converted into ACs (and vice-versa) with linear size and time [Rooshenas and Lowd, 2014].",
      "startOffset" : 77,
      "endOffset" : 103
    }, {
      "referenceID" : 32,
      "context" : "(2)This is also known as most probable explanation (MPE) inference [Pearl, 1988].",
      "startOffset" : 67,
      "endOffset" : 80
    }, {
      "referenceID" : 25,
      "context" : "We then consider a recently proposed sub-class of ACs, called the Probabilistic Sentential Decision Diagram (PSDD) [Kisa et al., 2014].",
      "startOffset" : 115,
      "endOffset" : 134
    }, {
      "referenceID" : 14,
      "context" : "The first is decomposability [Darwiche, 2001b], which was used for probabilistic reasoning in [Darwiche, 2003].",
      "startOffset" : 94,
      "endOffset" : 110
    }, {
      "referenceID" : 14,
      "context" : "Then one can compute the following queries in time that is linear in the size of circuit AC(X): the probability of any partial instantiation, Pr(y), where Y ✓ X [Darwiche, 2003] and the most likely instantiation, argmax",
      "startOffset" : 161,
      "endOffset" : 177
    }, {
      "referenceID" : 14,
      "context" : "A number of methods have been proposed for compiling a Bayesian network into a decomposable, deterministic and smooth AC that represents its distribution [Darwiche, 2003].",
      "startOffset" : 154,
      "endOffset" : 170
    }, {
      "referenceID" : 7,
      "context" : "Another method yields circuits that can sometimes be exponentially smaller, and is implemented in the publicly available ace system [Chavira and Darwiche, 2008]; see also Darwiche et al.",
      "startOffset" : 132,
      "endOffset" : 160
    }, {
      "referenceID" : 25,
      "context" : "We now investigate a newly introduced class of tractable ACs, called the Probabilistic Sentential Decision Diagram (PSDD) [Kisa et al., 2014].",
      "startOffset" : 122,
      "endOffset" : 141
    }, {
      "referenceID" : 16,
      "context" : "The Boolean circuit underlying a PSDD is known as a Sentential Decision Diagram (SDD) [Darwiche, 2011].",
      "startOffset" : 86,
      "endOffset" : 102
    }, {
      "referenceID" : 25,
      "context" : "The semantics of PSDDs are given in [Kisa et al., 2014].",
      "startOffset" : 36,
      "endOffset" : 55
    }, {
      "referenceID" : 25,
      "context" : "Moreover, the maximum likelihood parameter estimates of a PSDD are unique given complete data, and these parameters can be computed efficiently using closed-form estimates; see [Kisa et al., 2014] for details.",
      "startOffset" : 177,
      "endOffset" : 196
    }, {
      "referenceID" : 10,
      "context" : "Finally, PSDDs have been used to learn distributions over combinatorial objects, including rankings and permutations [Choi et al., 2015], paths and games [Choi et al.",
      "startOffset" : 117,
      "endOffset" : 136
    }, {
      "referenceID" : 2,
      "context" : "For example, when learning the structure of a Markov network from data [Bekker et al., 2015], we may want to introduce and remove candidate factors from a model, while evaluating the changes to the log likelihood.",
      "startOffset" : 71,
      "endOffset" : 92
    }, {
      "referenceID" : 31,
      "context" : "An analogous guarantee is available for SDD circuits of propositional models, using a special type of vtree known as a decision vtree [Oztok and Darwiche, 2014].",
      "startOffset" : 134,
      "endOffset" : 160
    }, {
      "referenceID" : 7,
      "context" : "The first compilation (AC1) is to decomposable and deterministic ACs using ace [Chavira and Darwiche, 2008].",
      "startOffset" : 79,
      "endOffset" : 107
    }, {
      "referenceID" : 20,
      "context" : "[Felzenszwalb and Huttenlocher, 2006], to allow for more efficient factor operations.",
      "startOffset" : 0,
      "endOffset" : 37
    }, {
      "referenceID" : 22,
      "context" : "Since ADDs also support a polytime summing-out operation, ADDs are more commonly used in the context of variable elimination [Sanner and McAllester, 2005, Chavira and Darwiche, 2007], and in message passing algorithms [Gogate and Domingos, 2013].",
      "startOffset" : 218,
      "endOffset" : 245
    } ],
    "year" : 2016,
    "abstractText" : "We consider tractable representations of probability distributions and the polytime operations they support. In particular, we consider a recently proposed arithmetic circuit representation, the Probabilistic Sentential Decision Diagram (PSDD). We show that PSDDs support a polytime multiplication operator, while they do not support a polytime operator for summing-out variables. A polytime multiplication operator makes PSDDs suitable for a broader class of applications compared to classes of arithmetic circuits that do not support multiplication. As one example, we show that PSDD multiplication leads to a very simple but effective compilation algorithm for probabilistic graphical models: represent each model factor as a PSDD, and then multiply them.",
    "creator" : null
  }
}