{
  "name" : "0e9fa1f3e9e66792401a6972d477dcc3.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Measuring the reliability of MCMC inference with bidirectional Monte Carlo",
    "authors" : [ "Roger B. Grosse", "Siddharth Ancha", "Daniel M. Roy" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "Markov chain Monte Carlo (MCMC) is one of the main workhorses of probabilistic inference, but it is notoriously hard to measure the quality of approximate posterior samples. This challenge is particularly salient in black box inference methods, which can hide details and obscure inference failures. In this work, we extend the recently introduced bidirectional Monte Carlo [GGA15] technique to evaluate MCMC-based posterior inference algorithms. By running annealed importance sampling (AIS) chains both from prior to posterior and vice versa on simulated data, we upper bound in expectation the symmetrized KL divergence between the true posterior distribution and the distribution of approximate samples. We integrate our method into two probabilistic programming languages, WebPPL [GS] and Stan [CGHL+ p], and validate it on several models and datasets. As an example of how our method be used to guide the design of inference algorithms, we apply it to study the effectiveness of different model representations in WebPPL and Stan."
    }, {
      "heading" : "1 Introduction",
      "text" : "Markov chain Monte Carlo (MCMC) is one of the most important classes of probabilistic inference methods and underlies a variety of approaches to automatic inference [e.g. LTBS00; GMRB+08; GS; CGHL+ p]. Despite its widespread use, it is still difficult to rigorously validate the effectiveness of an MCMC inference algorithm. There are various heuristics for diagnosing convergence, but reliable quantitative measures are hard to find. This creates difficulties both for end users of automatic inference systems and for experienced researchers who develop models and algorithms.\nIn this paper, we extend the recently proposed bidirectional Monte Carlo (BDMC) [GGA15] method to evaluate certain kinds of MCMC-based inference algorithms by bounding the symmetrized KL divergence (Jeffreys divergence) between the distribution of approximate samples and the true posterior distribution. Specifically, our method is applicable to algorithms which can be viewed as importance sampling over an extended state space, such as annealed importance sampling (AIS; [Nea01]) or sequential Monte Carlo (SMC; [MDJ06]). BDMC was proposed as a method for accurately estimating the log marginal likelihood (log-ML) on simulated data by sandwiching the true value between stochastic upper and lower bounds which converge in the limit of infinite computation. These log-likelihood values were used to benchmark marginal likelihood estimators. We show that it can also be used to measure the accuracy of approximate posterior samples obtained from algorithms like AIS or SMC. More precisely, we refine the analysis of [GGA15] to derive an estimator which upper bounds in expectation the Jeffreys divergence between the distribution of approximate samples and the true posterior distribution. We show that this upper bound is quite accurate on some toy distributions for which both the true Jeffreys divergence and the upper bound can be computed exactly. We refer to our method of bounding the Jeffreys divergence by sandwiching the log-ML as Bounding Divergences with REverse Annealing (BREAD).\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nWhile our method is only directly applicable to certain algorithms such as AIS or SMC, these algorithms involve many of the same design choices as traditional MCMC methods, such as the choice of model representation (e.g. whether to collapse out certain variables), or the choice of MCMC transition operators. Therefore, the ability to evaluate AIS-based inference should also yield insights which inform the design of MCMC inference algorithms more broadly.\nOne additional hurdle must be overcome to use BREAD to evaluate posterior inference: the method yields rigorous bounds only for simulated data because it requires an exact posterior sample. One would like to be sure that the results on simulated data accurately reflect the accuracy of posterior inference on the real-world data of interest. We present a protocol for using BREAD to diagnose inference quality on real-world data. Specifically, we infer hyperparameters on the real data, simulate data from those hyperparameters, measure inference quality on the simulated data, and validate the consistency of the inference algorithm’s behavior between the real and simulated data. (This protocol is somewhat similar in spirit to the parametric bootstrap [ET98].)\nWe integrate BREAD into the tool chains of two probabilistic programming languages: WebPPL [GS] and Stan [CGHL+ p]. Both probabilistic programming systems can be used as automatic inference software packages, where the user provides a program specifying a joint probabilistic model over observed and unobserved quantities. In principle, probabilistic programming has the potential to put the power of sophisticated probabilistic modeling and efficient statistical inference into the hands of non-experts, but realizing this vision is challenging because it is difficult for a non-expert user to judge the reliability of results produced by black-box inference. We believe BREAD provides a rigorous, general, and automatic procedure for monitoring the quality of posterior inference, so that the user of a probabilistic programming language can have confidence in the accuracy of the results. Our approach to evaluating probabilistic programming inference is closely related to independent work [CTM16] that is also based on the ideas of BDMC. We discuss the relationships between both methods in Section 4.\nIn summary, this work includes four main technical contributions. First, we show that BDMC yields an estimator which upper bounds in expectation the Jeffreys divergence of approximate samples from the true posterior. Second, we present a technique for exactly computing both the true Jeffreys divergence and the upper bound on small examples, and show that the upper bound is often a good match in practice. Third, we propose a protocol for using BDMC to evaluate the accuracy of approximate inference on real-world datasets. Finally, we extend both WebPPL and Stan to implement BREAD, and validate BREAD on a variety of probabilistic models in both frameworks. As an example of how BREAD can be used to guide modeling and algorithmic decisions, we use it to analyze the effectiveness of different representations of a matrix factorization model in both WebPPL and Stan."
    }, {
      "heading" : "2 Background",
      "text" : ""
    }, {
      "heading" : "2.1 Annealed Importance Sampling",
      "text" : "Annealed importance sampling (AIS; [Nea01]) is a Monte Carlo algorithm commonly used to estimate (ratios of) normalizing constants. More carefully, fix a sequence of T distributions p1, . . . , pT , with pt(x) = ft(x)/Zt. The final distribution in the sequence, pT , is called the target distribution; the first distribution, p1, is called the initial distribution. It is required that one can obtain one or more exact samples from p1.1 Given a sequence of reversible MCMC transition operators T1, . . . , TT , where Tt leaves pt invariant, AIS produces a (nonnegative) unbiased estimate of ZT /Z1 as follows: first, we sample a random initial state x1 from p1 and set the initial weight w1 = 1. For every stage t 2 we update the weight w and sample the state xt according to\nwt wt 1 ft(xt 1)\nft 1(xt 1) xt sample from Tt (x |xt 1) . (1)\nNeal [Nea01] justified AIS by showing that it is a simple importance sampler over an extended state space (see Appendix A for a derivation in our notation). From this analysis, it follows that the weight wT is an unbiased estimate of the ratio ZT /Z1. Two trivial facts are worth highlighting: when Z1\n1Traditionally, this has meant having access to an exact sampler. However, in this work, we sometimes have access to a sample from p1, but not a sampler.\nis known, Z1wT is an unbiased estimate of ZT , and when ZT is known, wT /ZT is an unbiased estimate of 1/Z1. In practice, it is common to repeat the AIS procedure to produce K independent estimates and combine these by simple averaging to reduce the variance of the overall estimate.\nIn most applications of AIS, the normalization constant ZT for the target distribution pT is the focus of attention, and the initial distribution p1 is chosen to have a known normalization constant Z1. Any sequence of intermediate distributions satisfying a mild domination criterion suffices to produce a valid estimate, but in typical applications, the intermediate distributions are simply defined to be geometric averages ft(x) = f1(x)1 tfT (x) t , where the t are monotonically increasing parameters with 1 = 0 and T = 1. (An alternative approach is to average moments [GMS13].)\nIn the setting of Bayesian posterior inference over parameters ✓ and latent variables z given some fixed observation y, we take f1(✓, z) = p(✓, z) to be the prior distribution (hence Z1 = 1), and we take fT (✓, z) = p(✓, z,y) = p(✓, z) p(y |✓, z). This can be viewed as the unnormalized posterior distribution, whose normalizing constant ZT = p(y) is the marginal likelihood. Using geometric averaging, the intermediate distributions are then\nft(✓, z) = p(✓, z) p(y |✓, z) t . (2) In addition to moment averaging, reasonable intermediate distributions can be produced in the Bayesian inference setting by conditioning on a sequence of increasing subsets of data; this insight relates AIS to the seemingly different class of sequential Monte Carlo (SMC) methods [MDJ06]."
    }, {
      "heading" : "2.2 Stochastic lower bounds on the log partition function ratio",
      "text" : "AIS produces a nonnegative unbiased estimate ˆR of the ratio R = ZT /Z1 of partition functions. Unfortunately, because such ratios often vary across many orders of magnitude, it frequently happens that ˆR underestimates R with overwhelming probability, while occasionally taking extremely large values. Correspondingly, the variance may be extremely large, or even infinite.\nFor these reasons, it is more meaningful to estimate logR. Unfortunately, the logarithm of a nonnegative unbiased estimate (such as the AIS estimate) is, in general, a biased estimator of the log estimand. More carefully, let ˆA be a nonnegative unbiased estimator for A = E[ ˆA]. Then, by Jensen’s inequality, E[log ˆA]  logE[ ˆA] = logA, and so log ˆA is a lower bound on logA in expectation. The estimator log ˆA satisfies another important property: by Markov’s inequality for nonnegative random variables, Pr(log ˆA > logA+ b) < e b, and so log ˆA is extremely unlikely to overestimate logA by any appreciable number of nats. These observations motivate the following definition [BGS15]: a stochastic lower bound on X is an estimator ˆX satisfying E[ ˆX]  X and Pr( ˆX > X + b) < e b. Stochastic upper bounds are defined analogously. The above analysis shows that log ˆA is a stochastic lower bound on logA when ˆA is a nonnegative unbiased estimate of A, and, in particular, log ˆR is a stochastic lower bound on logR. (It is possible to strengthen the tail bound by combining multiple samples [GBD07].)"
    }, {
      "heading" : "2.3 Reverse AIS and Bidirectional Monte Carlo",
      "text" : "Upper and lower bounds are most useful in combination, as one can then sandwich the true value. As described above, AIS produces a stochastic lower bound on the ratio R; many other algorithms do as well. Upper bounds are more challenging to obtain. The key insight behind bidirectional Monte Carlo (BDMC; [GGA15]) is that, provided one has an exact sample from the target distribution pT , one can run AIS in reverse to produce a stochastic lower bound on logRrev = logZ1/ZT , and therefore a stochastic upper bound on logR = logRrev. (In fact, BDMC is a more general framework which allows a variety of partition function estimators, but we focus on AIS for pedagogical purposes.)\nMore carefully, for t = 1, . . . , T , define p̃t = pT t+1 and ˜Tt = TT t+1. Then p̃1 corresponds to our original target distribution pT and p̃T corresponds to our original initial distribution p1. As before, ˜Tt leaves p̃t invariant. Consider the estimate produced by AIS on the sequence of distributions p̃1, . . . , p̃T and corresponding MCMC transition operators ˜T1, . . . , ˜TT . (In this case, the forward chain of AIS corresponds to the reverse chain described in Section 2.1.) The resulting estimate ˆRrev is a nonnegative unbiased estimator of Rrev. It follows that log ˆRrev is a stochastic lower bound on logRrev, and therefore log ˆR 1rev is a stochastic upper bound on logR = logR 1rev. BDMC is\nsimply the combination of this stochastic upper bound with the stochastic lower bound of Section 2.2. Because AIS is a consistent estimator of the partition function ratio under the assumption of ergodicity [Nea01], the two bounds converge as T ! 1; therefore, given enough computation, BDMC can sandwich logR to arbitrary precision. Returning to the setting of Bayesian inference, given some fixed observation y, we can apply BDMC provided we have exact samples from both the prior distribution p(✓, z) and the posterior distribution p(✓, z|y). In practice, the prior is typically easy to sample from, but it is typically infeasible to generate exact posterior samples. However, in models where we can tractably sample from the joint distribution p(✓, z,y), we can generate exact posterior samples for simulated observations using the elementary fact that\np(y) p(✓, z|y) = p(✓, z,y) = p(✓, z) p(y|✓, z). (3) In other words, if one ancestrally samples ✓, z, and y, this is equivalent to first generating a dataset y and then sampling (✓, z) exactly from the posterior. Therefore, for simulated data, one has access to a single exact posterior sample; this is enough to obtain stochastic upper bounds on logR = log p(y)."
    }, {
      "heading" : "2.4 WebPPL and Stan",
      "text" : "We focus on two particular probabilistic programming packages. First, we consider WebPPL [GS], a lightweight probabilistic programming language built on Javascript, and intended largely to illustrate some of the important ideas in probabilistic programming. Inference is based on Metropolis–Hastings (M–H) updates to a program’s execution trace, i.e. a record of all stochastic decisions made by the program. WebPPL has a small and clean implementation, and the entire implementation is described in an online tutorial on probabilistic programming [GS].\nSecond, we consider Stan [CGHL+ p], a highly engineered automatic inference system which is widely used by statisticians and is intended to scale to large problems. Stan is based on the No U-Turn Sampler (NUTS; [HG14]), a variant of Hamiltonian Monte Carlo (HMC; [Nea+11]) which chooses trajectory lengths adaptively. HMC can be significantly more efficient than M–H over execution traces because it uses gradient information to simultaneously update multiple parameters of a model, but is less general because it requires a differentiable likelihood. (In particular, this disallows discrete latent variables unless they are marginalized out analytically.)"
    }, {
      "heading" : "3 Methods",
      "text" : "There are at least two criteria we would desire from a sampling-based approximate inference algorithm in order that its samples be representative of the true posterior distribution: we would like the approximate distribution q(✓, z;y) to cover all the high-probability regions of the posterior p(✓, z |y), and we would like it to avoid placing probability mass in low-probability regions of the posterior. The former criterion motivates measuring the KL divergence DKL(p(✓, z |y) k q(✓, z;y)), and the latter criterion motivates measuring DKL(q(✓, z;y) k p(✓, z |y)). If we desire both simultaneously, this motivates paying attention to the Jeffreys divergence, defined as DJ(qkp) = DKL(qkp) + DKL(pkq). In this section, we present Bounding Divergences with Reverse Annealing (BREAD), a technique for using BDMC to bound the Jeffreys divergence from the true posterior on simulated data, combined with a protocol for using this technique to analyze sampler accuracy on real-world data."
    }, {
      "heading" : "3.1 Upper bounding the Jeffreys divergence in expectation",
      "text" : "We now present our technique for bounding the Jeffreys divergence between the target distribution and the distribution of approximate samples produced by AIS. In describing the algorithm, we revert to the abstract state space formalism of Section 2.1, since the algorithm itself does not depend on any structure specific to posterior inference (except for the ability to obtain an exact sample). We first repeat the derivation from [GGA15] of the bias of the stochastic lower bound log ˆR. Let v = (x1, . . . ,xT 1) denote all of the variables sampled in AIS before the final stage; the final state xT corresponds to the approximate sample produced by AIS. We can write the distributions over the forward and reverse AIS chains as:\nqfwd(v,xT ) = qfwd(v) qfwd(xT |v) (4) qrev(v,xT ) = pT (xT ) qrev(v |xT ). (5)\nThe distribution of approximate samples qfwd(xT ) is obtained by marginalizing out v. Note that sampling from qrev requires sampling exactly from pT , so strictly speaking, BREAD is limited to those cases where one has at least one exact sample from pT — such as simulated data from a probabilistic model (see Section 2.3).\nThe expectation of the estimate log ˆR of the log partition function ratio is given by:\nE[log ˆR] = Eqfwd(v,xT )  log\nfT (xT ) qrev(v |xT ) Z1 qfwd(v,xT )\n(6)\n= logZT logZ1 DKL(qfwd(xT ) qfwd(v |xT ) k pT (xT ) qrev(v |xT )) (7)  logZT logZ1 DKL(qfwd(xT ) k pT (xT )). (8)\n(Note that qfwd(v |xT ) is the conditional distribution of the forward chain, given that the final state is xT .) The inequality follows because marginalizing out variables cannot increase the KL divergence.\nWe now go beyond the analysis in [GGA15], to bound the bias in the other direction. The expectation of the reverse estimate ˆRrev is\nE[log ˆRrev] = Eqrev(xT ,v)  log\nZ1 qfwd(v,xT ) fT (xT ) qrev(v |xT )\n(9)\n= logZ1 logZT DKL(pT (xT ) qrev(v|xT ) k qfwd(xT ) qfwd(v |xT )) (10)  logZ1 logZT DKL(pT (xT ) k qfwd(xT )). (11)\nAs discussed above, log ˆR and log ˆR 1rev can both be seen as estimators of log ZTZ1 , the former of which is a stochastic lower bound, and the latter of which is a stochastic upper bound. Consider the gap between these two bounds, ˆB , log ˆR 1rev log ˆR. It follows from Eqs. (8) and (11) that, in expectation, ˆB upper bounds the Jeffreys divergence\nJ , DJ(pT (xT ), qfwd(xT )) , DKL(pT (xT ) k qfwd(xT )) + DKL(qfwd(xT ) k pT (xT )) (12) between the target distribution pT and the distribution qfwd(pT ) of approximate samples.\nAlternatively, if one happens to have some other lower bound L or upper bound U on logR, then one can bound either of the one-sided KL divergences by running only one direction of AIS. Specifically, from Eq. (8), E[U log ˆR] DKL(qfwd(xT ) k pT (xT )), and from Eq. (11), E[log ˆR 1rev L] DKL(pT (xT ) k qfwd(xT )).\nHow tight is the expectation B , E[ ˆB] as an upper bound on J ? We evaluated both B and J exactly on some toy distributions and found them to be a fairly good match. Details are given in Appendix B."
    }, {
      "heading" : "3.2 Application to real-world data",
      "text" : "So far, we have focused on the setting of simulated data, where it is possible to obtain an exact posterior sample, and then to rigorously bound the Jeffreys divergence using BDMC. However, we are more likely to be interested in evaluating the performance of inference on real-world data, so we would like to simulate data which resembles a real-world dataset of interest. One particular difficulty is that, in Bayesian analysis, hyperparameters are often assigned non-informative or weakly informative priors, in order to avoid biasing the inference. This poses a challenge for BREAD, as datasets generated from hyperparameters sampled from such priors (which are often very broad) can be very dissimilar to real datasets, and hence conclusions from the simulated data may not generalize.\nIn order to generate simulated datasets which better match a real-world dataset of interest, we adopt the following heuristic scheme: we first perform approximate posterior inference on the real-world dataset. Let ˆ⌘real denote the estimated hyperparameters. We then simulate parameters and data from the forward model p(✓ | ˆ⌘real)p(D| ˆ⌘real,✓). The forward AIS chain is run on D in the usual way. However, to initialize the reverse chain, we first start with (ˆ⌘real,✓), and then run some number of MCMC transitions which preserve p(⌘,✓ |D), yielding an approximate posterior sample (⌘?,✓?). In general, (⌘?,✓?) will not be an exact posterior sample, since ˆ⌘real was not sampled from p(⌘ |D). However, the true hyperparameters ˆ⌘real which generated D ought to be in a region of high posterior mass unless the prior p(⌘) concentrates most of its mass away from ˆ⌘real. Therefore, we expect even a small number of MCMC steps to produce a plausible posterior sample. This motivates our use of (⌘?,✓?) in place of an exact posterior sample. We validate this procedure in Section 5.1.2."
    }, {
      "heading" : "4 Related work",
      "text" : "Much work has been devoted to the diagnosis of Markov chain convergence (e.g. [CC96; GR92; BG98]). Diagnostics have been developed both for estimating the autocorrelation function of statistics of interest (which determines the number of effective samples from an MCMC chain) and for diagnosing whether Markov chains have reached equilibrium. In general, convergence diagnostics cannot confirm convergence; they can only identify particular forms of non-convergence. By contrast, BREAD can rigorously demonstrate convergence in the simulated data setting.\nThere has also been much interest in automatically configuring parameters of MCMC algorithms. Since it is hard to reliably summarize the performance of an MCMC algorithm, such automatic configuration methods typically rely on method-specific analyses. For instance, Roberts and Rosenthal [RR01] showed that the optimal acceptance rate of Metropolis–Hastings with an isotropic proposal distribution is 0.234 under fairly general conditions. M–H algorithms are sometimes tuned to achieve this acceptance rate, even in situations where the theoretical analysis doesn’t hold. Rigorous convergence measures might enable more direct optimization of algorithmic hyperparameters.\nGorham and Mackey [GM15] presented a method for directly estimating the quality of a set of approximate samples, independently of how those samples were obtained. This method has strong guarantees under a strong convexity assumption. By contrast, BREAD makes no assumptions about the distribution itself, so its mathematical guarantees (for simulated data) are applicable even to multimodal or badly conditioned posteriors.\nIt has been observed that heating and cooling processes yield bounds on log-ratios of partition functions by way of finite difference approximations to thermodynamic integration. Neal [Nea96] used such an analysis to motivate tempered transitions, an MCMC algorithm based on heating and cooling a distribution. His analysis cannot be directly applied to measuring convergence, as it assumed equilibrium at each temperature. Jarzynski [Jar97] later gave a non-equilibrium analysis which is equivalent to that underlying AIS [Nea01].\nWe have recently learned of independent work [CTM16] which also builds on BDMC to evaluate the accuracy of posterior inference in a probabilistic programming language. In particular, CusumanoTowner and Mansinghka [CTM16] define an unbiased estimator for a quantity called the subjective divergence. The estimator is equivalent to BDMC except that the reverse chain is initialized from an arbitrary reference distribution, rather than the true posterior. In [CTM16], the subjective divergence is shown to upper bound the Jeffreys divergence when the true posterior is used; this is equivalent to our analysis in Section 3.1. Much less is known about subjective divergence when the reference distribution is not taken to be the true posterior. (Our approximate sampling scheme for hyperparameters can be viewed as a kind of reference distribution.)"
    }, {
      "heading" : "5 Experiments",
      "text" : "In order to experiment with BREAD, we extended both WebPPL and Stan to run forward and reverse AIS using the sequence of distributions defined in Eq. (2). The MCMC transition kernels were the standard ones provided by both platforms. Our first set of experiments was intended to validate that BREAD can be used to evaluate the accuracy of posterior inference in realistic settings. Next, we used BREAD to explore the tradeoffs between two different representations of a matrix factorization model in both WebPPL and Stan."
    }, {
      "heading" : "5.1 Validation",
      "text" : "As described above, BREAD returns rigorous bounds on the Jeffreys divergence only when the data are sampled from the model distribution. Here, we address three ways in which it could potentially give misleading results. First, the upper bound B may overestimate the true Jeffreys divergence J . Second, results on simulated data may not correspond to results on real-world data if the simulated data are not representative of the real-world data. Finally, the fitted hyperparameter procedure of Section 3.2 may not yield a sample sufficiently representative of the true posterior p(✓,⌘ |D). The first issue, about the accuracy of the bound, is addressed in Appendix B.1.1; the bound appears to be fairly close to the true Jeffreys divergence on some toy distributions. We address the other two issues in this section. In particular, we attempted to validate that the behavior of the method on simulated\ndata is consistent with that on real data, and that the fitted-hyperparameter samples can be used as a proxy for samples from the posterior. All experiments in this section were performed using Stan."
    }, {
      "heading" : "5.1.1 Validating consistency of inference behavior between real and simulated data",
      "text" : "To validate BREAD in a realistic setting, we considered five models based on examples from the Stan manual [Sta], and chose a publicly available real-world dataset for each model. These models include: linear regression, logistic regression, matrix factorization, autoregressive time series modeling, and mixture-of-Gaussians clustering. See Appendix C for model details and Stan source code.\nIn order to validate the use of simulated data as a proxy for real data in the context of BREAD, we fit hyperparameters to the real-world datasets and simulated data from those hyperparameters, as described in Section 3.2. In Fig. 1 and Appendix D, we show the distributions of forward and reverse AIS estimates on simulated data and forward AIS estimates on real-world data, based on 100 AIS chains for each condition.2 Because the distributions of AIS estimates included many outliers, we visualize quartiles of the estimates rather than means.3 The real and simulated data need not have the same marginal likelihood, so the AIS estimates for real and simulated data are shifted vertically based on the largest forward AIS estimate obtained for each model. For all five models under consideration, the forward AIS curves were nearly identical (up to a vertical shift), and the distributions of AIS estimates were very similar at each number of AIS steps. (An example where the forward AIS curves failed to match up due to model misspecification is given in Appendix D.) Since the inference behavior appears to match closely between the real and simulated data, we conclude that data simulated using fitted hyperparameters can be a useful proxy for real data when evaluating inference algorithms."
    }, {
      "heading" : "5.1.2 Validating the approximate posterior over hyperparameters",
      "text" : "As described in Section 3.2, when we simulate data from fitted hyperparameters, we use an approximate (rather than exact) posterior sample (⌘?,✓?) to initialize the reverse chain. Because of this, BREAD is not mathematically guaranteed to upper bound the Jeffreys divergence even on the simulated data. In order to determine the effect of this approximation in practice, we repeated the procedure of Section 5.1.1 for all five models, but varying S, the number of MCMC steps used to obtain (⌘?,✓?), with S 2 {10, 100, 1000, 10000}. The reverse AIS estimates are shown in Fig. 1 and Appendix D. (We do not show the forward AIS estimates because these are unaffected by S.) In all five cases, the reverse AIS curves were statistically indistinguishable. This validates our use of fitted hyperparameters, as it suggests that the use of approximate samples of hyperparameters has little impact on the reverse AIS upper bounds.\n2The forward AIS chains are independent, while the reverse chains share an initial state. 3Normally, such outliers are not a problem for AIS, because one averages the weights wT , and this average is insensitive to extremely small values. Unfortunately, the analysis of Section 3.1 does not justify such averaging, so we report estimates corresponding to individual AIS chains."
    }, {
      "heading" : "5.2 Scientific findings produced by BREAD",
      "text" : "Having validated various aspects of BREAD, we applied it to investigate the choice of model representation in Stan and WebPPL. During our investigation, we also uncovered a bug in WebPPL, indicating the potential usefulness of BREAD as a means of testing the correctness of an implementation."
    }, {
      "heading" : "5.2.1 Comparing model representations",
      "text" : "Many models can be written in more than one way, for example by introducing or collapsing latent variables. Performance of probabilistic programming languages can be sensitive to such choices of representation, and the representation which gives the best performance may vary from one language to another. We consider the matrix factorization model described above, which we now specify in more detail. We approximate an N ⇥ D matrix Y as a low rank matrix, the product of matrices U and V with dimensions N ⇥ K and K ⇥ D respectively (where K < min(N,D)). We use a spherical Gaussian observation model, and spherical Gaussian priors on U and V:\nuik ⇠ N (0, 2u) vkj ⇠ N (0, 2v) yij | ui,vj ⇠ N (u>i vj , 2) We can also collapse U to obtain the model vkj ⇠ N (0, 2v) and yi | V ⇠ N (0, uV>V + I). In general, collapsing variables can help MCMC samplers mix faster at the expense of greater computational cost per update. The precise tradeoff can depend on the size of the model and dataset, the choice of MCMC algorithm, and the underlying implementation, so it would be useful to have a quantitative criterion to choose between them.\nWe fixed the values of all hyperparameters to 1, and set N = 50, K = 5 and D = 25. We ran BREAD on both platforms (Stan and WebPPL) and for both formulations (collapsed and uncollapsed) (see Fig. 2). The simulated data and exact posterior sample were shared between all conditions in order to make the results directly comparable."
    }, {
      "heading" : "As predicted, the collapsed sampler resulted in slower updates but faster convergence (in terms of",
      "text" : "the number of steps). However, the per-iteration convergence benefit of collapsing was much larger in WebPPL than in Stan (perhaps because of the different underlying inference algorithm). Overall, the tradeoff between efficiency and convergence speed appears to favour the uncollapsed version in Stan, and the collapsed version in WebPPL (see Fig. 2(b)). (Note that this result holds only for our particular choice of problem size; the tradeoff may change given different model or dataset sizes.) Hence BREAD can provide valuable insights into the tricky question of which representations of models to choose to achieve faster convergence."
    }, {
      "heading" : "5.2.2 Debugging",
      "text" : "Mathematically, the forward and reverse AIS chains yield lower and upper bounds on log p(y) with high probability; if this behavior is not observed, that indicates a bug. In our experimentation with WebPPL, we observed a case where the reverse AIS chain yielded estimates significantly lower than those produced by the forward chain, inconsistent with the theoretical guarantee. This led us to find a subtle bug in how WebPPL sampled from a multivariate Gaussian distribution (which had the effect that the exact posterior samples used to initialize the reverse chain were incorrect).4 These days, while many new probabilistic programming languages are emerging and many are in active development, such debugging capabilities provided by BREAD can potentially be very useful.\n4Issue: https://github.com/probmods/webppl/issues/473"
    } ],
    "references" : [ {
      "title" : "General methods for monitoring convergence of iterative simulations",
      "author" : [ "S.P. Brooks", "A. Gelman" ],
      "venue" : "Journal of Computational and Graphical Statistics",
      "citeRegEx" : "Brooks and Gelman.,? \\Q1998\\E",
      "shortCiteRegEx" : "Brooks and Gelman.",
      "year" : 1998
    }, {
      "title" : "Accurate and conservative estimates of MRF log-likelihood using reverse annealing",
      "author" : [ "Y. Burda", "R.B. Grosse", "R. Salakhutdinov" ],
      "venue" : "Artificial Intelligence and Statistics",
      "citeRegEx" : "Burda et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Burda et al\\.",
      "year" : 2015
    }, {
      "title" : "Markov chain Monte Carlo convergence diagnostics: a comparative review",
      "author" : [ "M.K. Cowles", "B.P. Carlin" ],
      "venue" : "Journal of the American Statistical Association",
      "citeRegEx" : "Cowles and Carlin.,? \\Q1996\\E",
      "shortCiteRegEx" : "Cowles and Carlin.",
      "year" : 1996
    }, {
      "title" : "Quantifying the probable approximation error of probabilistic inference programs",
      "author" : [ "M.F. Cusumano-Towner", "V.K. Mansinghka" ],
      "venue" : null,
      "citeRegEx" : "Cusumano.Towner and Mansinghka.,? \\Q2016\\E",
      "shortCiteRegEx" : "Cusumano.Towner and Mansinghka.",
      "year" : 2016
    }, {
      "title" : "An Introduction to the Bootstrap",
      "author" : [ "B. Efron", "R.J. Tibshirani" ],
      "venue" : null,
      "citeRegEx" : "Efron and Tibshirani.,? \\Q1998\\E",
      "shortCiteRegEx" : "Efron and Tibshirani.",
      "year" : 1998
    }, {
      "title" : "Studies in lower bounding probability of evidence using the Markov inequality",
      "author" : [ "V. Gogate", "B. Bidyuk", "R. Dechter" ],
      "venue" : "In: Conference on Uncertainty in AI",
      "citeRegEx" : "Gogate et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Gogate et al\\.",
      "year" : 2007
    }, {
      "title" : "Sandwiching the marginal likelihood with bidirectional Monte Carlo",
      "author" : [ "R.B. Grosse", "Z. Ghahramani", "R.P. Adams" ],
      "venue" : null,
      "citeRegEx" : "Grosse et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Grosse et al\\.",
      "year" : 2015
    }, {
      "title" : "Measuring sample quality with Stein’s method",
      "author" : [ "J. Gorham", "L. Mackey" ],
      "venue" : "Neural Information Processing Systems",
      "citeRegEx" : "Gorham and Mackey.,? \\Q2015\\E",
      "shortCiteRegEx" : "Gorham and Mackey.",
      "year" : 2015
    }, {
      "title" : "Church: a language for generative models",
      "author" : [ "N.D. Goodman", "V.K. Mansinghka", "D.M. Roy", "K. Bonawitz", "J.B. Tenenbaum" ],
      "venue" : "In: Conference on Uncertainty in AI",
      "citeRegEx" : "Goodman et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Goodman et al\\.",
      "year" : 2008
    }, {
      "title" : "Annealing between distributions by averaging moments",
      "author" : [ "R. Grosse", "C.J. Maddison", "R. Salakhutdinov" ],
      "venue" : "Neural Information Processing Systems",
      "citeRegEx" : "Grosse et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Grosse et al\\.",
      "year" : 2013
    }, {
      "title" : "Inference from iterative simulation using multiple sequences",
      "author" : [ "A. Gelman", "D.B. Rubin" ],
      "venue" : "Statistical Science",
      "citeRegEx" : "Gelman and Rubin.,? \\Q1992\\E",
      "shortCiteRegEx" : "Gelman and Rubin.",
      "year" : 1992
    }, {
      "title" : "The No-U-turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo",
      "author" : [ "M.D. Homan", "A. Gelman" ],
      "venue" : "J. Mach. Learn. Res",
      "citeRegEx" : "Homan and Gelman.,? \\Q2014\\E",
      "shortCiteRegEx" : "Homan and Gelman.",
      "year" : 2014
    }, {
      "title" : "Equilibrium free-energy differences from non-equilibrium measurements: a master-equation approach",
      "author" : [ "C. Jarzynski" ],
      "venue" : "Physical Review E",
      "citeRegEx" : "Jarzynski.,? \\Q1997\\E",
      "shortCiteRegEx" : "Jarzynski.",
      "year" : 1997
    }, {
      "title" : "Sequential Monte Carlo samplers",
      "author" : [ "P. del Moral", "A. Doucet", "A. Jasra" ],
      "venue" : "Journal of the Royal Statistical Society: Series B (Statistical Methodology)",
      "citeRegEx" : "Moral et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Moral et al\\.",
      "year" : 2006
    }, {
      "title" : "MCMC using Hamiltonian dynamics",
      "author" : [ "R.M. Neal" ],
      "venue" : "Handbook of Markov Chain Monte Carlo",
      "citeRegEx" : "Neal,? \\Q2011\\E",
      "shortCiteRegEx" : "Neal",
      "year" : 2011
    }, {
      "title" : "Annealed importance sampling",
      "author" : [ "R.M. Neal" ],
      "venue" : "Statistics and Computing",
      "citeRegEx" : "Neal.,? \\Q2001\\E",
      "shortCiteRegEx" : "Neal.",
      "year" : 2001
    }, {
      "title" : "Sampling from multimodal distributions using tempered transitions",
      "author" : [ "R.M. Neal" ],
      "venue" : "Statistics and Computing",
      "citeRegEx" : "Neal.,? \\Q1996\\E",
      "shortCiteRegEx" : "Neal.",
      "year" : 1996
    }, {
      "title" : "Optimal scaling for various Metropolis–Hastings algorithms",
      "author" : [ "G.O. Roberts", "J.S. Rosenthal" ],
      "venue" : "Statistical Science",
      "citeRegEx" : "Roberts and Rosenthal.,? \\Q2001\\E",
      "shortCiteRegEx" : "Roberts and Rosenthal.",
      "year" : 2001
    } ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "Markov chain Monte Carlo (MCMC) is one of the main workhorses of probabilistic inference, but it is notoriously hard to measure the quality of approximate posterior samples. This challenge is particularly salient in black box inference methods, which can hide details and obscure inference failures. In this work, we extend the recently introduced bidirectional Monte Carlo [GGA15] technique to evaluate MCMC-based posterior inference algorithms. By running annealed importance sampling (AIS) chains both from prior to posterior and vice versa on simulated data, we upper bound in expectation the symmetrized KL divergence between the true posterior distribution and the distribution of approximate samples. We integrate our method into two probabilistic programming languages, WebPPL [GS] and Stan [CGHL+ p], and validate it on several models and datasets. As an example of how our method be used to guide the design of inference algorithms, we apply it to study the effectiveness of different model representations in WebPPL and Stan.",
    "creator" : null
  }
}