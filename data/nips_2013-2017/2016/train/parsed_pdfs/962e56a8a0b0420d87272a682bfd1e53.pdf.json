{
  "name" : "962e56a8a0b0420d87272a682bfd1e53.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Deconvolving Feedback Loops in Recommender Systems",
    "authors" : [ "Ayan Sinha", "David F. Gleich", "Karthik Ramani" ],
    "emails" : [ "sinhayan@mit.edu", "dgleich@purdue.edu", "ramani@purdue.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Recommender systems have been helpful to users for making decisions in diverse domains such as movies, wines, food, news among others [19, 23]. However, it is well known that the interface of these systems affect the users’ opinion, and hence, their ratings of items [7, 24].Thus, broadly speaking, a user’s rating of an item is either his or her intrinsic preference or the influence of the recommender system (RS) on the user [2]. As these ratings implicitly affect recommendations to other users through feedback, it is critical to quantify the role of feedback in content personalization [22]. Thus the primary motivating question for this paper is: Given only a user-item rating matrix, is it possible to infer whether any preference values are influenced by a RS? Secondary questions include: Which preference values are influenced and to what extent by the RS? Furthermore, how do we recover the true preference value of an item to a user?\nWe develop an algorithm to answer these questions using the singular value decomposition (SVD) of the observed ratings matrix (Section 2). The genesis of this algorithm follows by viewing the observed ratings at any point of time as union of true ratings and recommendations:\nRobs = Rtrue + Rrecom (1) where Robs is the observed rating matrix at a given instant of time, Rtrue is the rating matrix due to users’ true preferences of items (along with any external influences such as ads, friends, and so on) and Rrecom is the rating matrix which indicates the RS’s contribution to the observed ratings. Our more formal goal is to recover Rtrue from Robs. But this is impossible without strong modeling assumptions; any rating is just as likely to be a true rating as due to the system.\nThus, we make strong, but plausible assumptions about a RS. In essence, these assumptions prescribe a precise model of the recommender and prevent its effects from completely dominating the future.\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nWith these assumptions, we are able to mathematically relate Rtrue and Robs. This enables us to find the centered rating matrix Rtrue (up to scaling). We caution readers that these assumptions are designed to create a model that we can tractably analyze, and they should not be considered limitations of our ideas. Indeed, the strength of this simplistic model is that we can use its insights and predictions to analyze far more complex real-world data. One example of this model is that the notion of Rtrue is a convenient fiction that represents some idealized, unperturbed version of the ratings matrix. Our model and theory suggests that Rtrue ought to have some relationship with the observed ratings, Robs. By studying these relationships, we will show that we gain useful insights into the strength of various feedback and recommendation processes in real-data.\nIn that light, we use our theory to develop a heuristic, but accurate, metric to quantitatively infer the influence of a RS (or any set of feedback effects) on a ratings matrix (Section 3). Additionally, we propose a metric for evaluating the influence of a recommender system on each user-item rating pair. Aggregating these scores over all users helps identify putative highly recommended items. The final metrics for a RS provide insight into the quality of recommendations and argue that Netflix had a better recommender than MovieLens, for example. This score is also sensitive to all cases where we have ground-truth knowledge about feedback processes akin to recommenders in the data."
    }, {
      "heading" : "2 Deconvolving feedback",
      "text" : "We first state equations ans assumptions under which the true rating matrix is recoverable (or deconvolvable) from the observed matrix, and provide an algorithm to deconvolve using the SVD."
    }, {
      "heading" : "2.1 A model recommender system",
      "text" : "Consider a ratings matrix R of dimension m × n where m is the number of users and n is the number of items being rated. Users are denoted by subscript u, and items are denoted by subscript i, i.e., Ru,i denotes user u’s rating for item i. As stated after equation (1), our objective is to decouple Rtrue from Rrecom given the matrix Robs. Although this problem seems intractable, we list a series of assumptions under which a closed form solution of Rtrue is deconvolvable from Robs alone.\nAssumption 1 The feedback in the RS occurs through the iterative process involving the observed ratings and an item-item similarity matrix S: 1\nRobs = Rtrue + H (RobsS). (2)\nHere indicates Hadamard, or entrywise product, given as: (H R)u,i = Hu,i · Ru,i. This assumption is justified because in many collaborative filtering techniques, Rrecom is a function of the observed ratings Robs and the item-item similarity matrix, S . The matrix H is an indicator matrix over a set of items where the user followed the recommendation and agreed with it. This matrix is essentially completely unknown and is essentially unknowable without direct human interviews. The model RS equation (2) then iteratively updates Robs based on commonly rated items by users. This key idea is illustrated in Figure 1. The recursion progressively fills all missing entries in matrix Robs starting from Rtrue. The recursions do not update Rtrue in our model of a RS. If we were to explicitly consider the state of matrix Robs after k iterations, Rk+1obs we get:\nRk+1obs = Rtrue + H (k) (RkobsSk) = Rtrue + H(k) (( Rtrue + H(k−1) (Rk−1obs Sk−1) ) Sk ) = . . . (3)\nHere Sk is the item-item similarity matrix induced by the observed matrix at state k. The above equation 3 is naturally initialized as R1obs = Rtrue along with the constraint S1 = Strue, i.e, the similarity\n1For an user-user similarities, Ŝ, the derivations in this paper can be extended by considering the expression: RTobs = R T true + HT (RTobsŜ). We restrict to item-item similarity which is more popular in practice.\nmatrix at the first iteration is the similarity matrix induced by the matrix of true preferences, Rtrue. Thus, we see that Robs is an implicit function of Rtrue and the set of similarity matrices Sk,Sk−1, . . .S1. Assumption 2 Hadamard product H(k) is approximated with a probability parameter αk ∈ (0, 1].\nWe model the selection matrix H(k) and it’s Hadamard problem in expectation and replace the successive matrices H(k) with independent Bernoulli random matrices with probability αk. Taking the expectation allows us to replace the matrix H(k) with the probability parameter αk itself:\nRk+1obs = Rtrue + αk(R k obsSk) = Rtrue + αk (( Rtrue + αk−1(Rk−1obs Sk−1) ) Sk ) = . . . (4)\nThe set of Sk,Sk−1, · · · are apriori unknown. We are now faced with the task of constructing a valid similarity metric. Towards this end, we make our next assumption.\nAssumption 3 The user mean R̄u in the observed and true matrix are roughly equal: R̄ (obs) u ≈ R̄ (true) u . The Euclidean item norms ‖Ri‖ are also roughly equal: ‖R(obs)i ‖ ≈ ‖R (true) i ‖.\nThese assumptions are justified because ultimately we are interested in relative preferences of items for a user and unbiased relative ratings of items by users. These can be achieved by centering users and the normalizing item ratings, respectively, in the true and observed ratings matrices. We quantitatively investigate this assumption in the supplementary material. Using this assumption, the similarity metric then becomes:\nS(i, j) = ∑\nu∈U(Ru,i − R̄u)(Ru, j − R̄u)√∑ u∈U(Ru,i − R̄u)2 √∑ u∈U(Ru, j − R̄u)2\n(5)\nThis metric is known as the adjusted cosine similarity, and preferred over cosine similarity because it mitigates the effect of rating schemes over users [25]. Using the relations R̃u,i = Ru,i − R̄u, and,R̂u,i = R̃u,i ‖R̃i‖ = Ru,i−R̄u√∑ u∈U (Ru,i−R̄u)2 , the expression of our recommender (4) becomes:\nR̂obs = R̂true(I + f1(a1)R̂ T trueR̂true + f2(a2)(R̂ T trueR̂true) 2 + f3(a3)(R̂ T trueR̂true) 3 + . . .) (6)\nHere, f1, f2, f3 . . . are functions of the probability parameters ak = [α1, α2, . . . αk, . . .] of the form fz(az) = cαc11 α c2 1 . . . α ck k . . . such that ∑ k ck = z, and c is a constant. The proof of equation 6 is in the supplementary material. We see that the centering and normalization results in R̂obs being explicitly represented in terms of R̂true and coefficients f (a). It is now possible to recover R̂true, but the coefficients f (a) are apriori unknown. Thus, our next assumption. Assumption 4 fz(az) = αz, i.e., the coefficients of the series (6) are induced by powers of a constant probability parameter α ∈ (0, 1].\nNote that in recommender (3), Robs becomes denser with every iteration, and hence the higher order Hadamard products in the series fill fewer missing terms. The effect of absorbing the unknowable probability parameters, αk’s into single probability parameter α is similar. Powers of α, produce successively less of an impact, just as in the true model. The governing expression now becomes:\nR̂obs = R̂true(I + αR̂ T trueR̂true + α 2(R̂TtrueR̂true) 2 + α3(R̂TtrueR̂true) 3 + . . .) (7)\nIn order to ensure convergence of this equation, we make our final assumption.\nAssumption 5 The spectral radius of the similarity matrix αR̂TtrueR̂true is less than 1.\nThis assumption enables us to write the infinite series representing R̂obs, R̂true(I + αR̂ T trueR̂true + α2(R̂TtrueR̂true)2 +α3(R̂ T trueR̂true)3 + . . .) as (1−αR̂ T trueR̂true)−1. It states that given α, we scale the matrix R̂TtrueR̂true such that the spectral radius of αR̂ T trueR̂true is less than 1 2. Then we are then able to recover R̂Ttrue up to a scaling constant.\nDiscussion of assumptions. We now briefly discuss the implications of our assumptions. First, assumption 1 states the recommender model. Assumption 2 states that we are modeling expected\n2See [10] for details on scaling similarity matrices to ensure convergence\nbehavior rather than actual behavior. Assumptions 3-5 are key to our method working. They essentially state that the RS’s effects are limited in scope so that they cannot dominate the world. This has a few interpretations on real-world data. The first would be that we are considering the impact of the RS over a short time span. The second would be that the recommender effects are essentially second-order and that there is some other true effect which dominates them. We discuss the mechanism of solving equation 7 using the above set of five assumptions next."
    }, {
      "heading" : "2.2 The algorithm for deconvolving feedback loops",
      "text" : "Theorem 1 Assuming the RS follows (7), α is between 0 and 1, and the singular value decomposition of the observed rating matrix is, R̂obs = UΣobsVT , the deconvolved matrix Rtrue of true ratings is given as UΣtrueVT , where the Σtrue is a diagonal matrix with elements:\nσtruei = −1\n2ασobsi +\n√ 1\n4α2(σobsi ) 2\n+ 1 α\n(8)\nThe proof of the theorem is in the supplementary material. In practical applications, the feedback loops are deconvolved by taking a truncated-SVD (low rank approximation) instead of the complete decomposition. In this process, we naturally concede accuracy for performance. We consider the matrix of singular values Σ̃obs to only contain the k largest singular values (the other singular values are replaced by zero). We now state Algorithm 1 for deconvolving feedback loops. The algorithm is simple to compute as it just involves a singular value decomposition of the observed ratings matrix."
    }, {
      "heading" : "3 Results and recommender system scoring",
      "text" : "We tested our approach for deconvolving feedback loops on synthetic RS, and designed a metric to identify the ratings most affected by the RS. We then use the same automated technique to study real-world ratings data, and find that the metric is able to identify items influenced by a RS.\nAlgorithm 1 Deconvolving Feedback Loops Input: Robs, α, k, where Robs is observed ratings matrix, α is parameter governing feedback loops\nand k is number of singular values Output: R̂true, True rating matrix"
    }, {
      "heading" : "3.1 Synthetic data simulating a real-world recommender system",
      "text" : "We use item response theory to generate a sparse true rating matrix Rtrue using a model related to that in [12]. Let au be the center of user u’s rating scale, and bu be the rating sensitivity of user u. Let ti be the intrinsic score of item i. We generate a user-item rating matrix as:\nRu,i = L[au + buti + ηu,i] (9)\nwhere L[ω] is the discrete levels function assigning a score in the range 1 to 5: L[ω] = max(min(round(ω), 5), 1) and ηu,i is a noise parameter. In our experiment, we draw au ∼ N(3, 1), bu ∼ N(0.5, 0.5), tu ∼ N(0.1, 1), and ηu,i ∼ N(0, 1), where N is a standard normal, and is a noise parameter. We sample these ratings uniformly at random by specifying a desired level of rating sparsity γ which serves as the input, Rtrue, to our RS. We then run a cosine similarity based RS, progressively increasing the density of the rating matrix. The unknown ratings are iteratively updated\nusing the standard item-item collaborative filtering technique [8] as Rk+1u,i = ∑ j∈i(ski, j R k u, j)∑\nj∈i(|ski, j |) , where k\nis the iteration number and R0 = Rtrue, and the similarity measure at the kth iteration is given as ski, j = ∑ u∈U Rku,i R k u, j√∑\nu∈U (Rku,i)2 √∑ u∈U (Rku, j)2 . After the kth iteration, each synthetic user accepts the top r recommen-\ndations with probability proportional to (Rk+1u,i ) e, where e is an exponent controlling the frequency of acceptance. We fix the number of iterative updates to be 10, r to be 10 and the resulting rating matrix is Robs. We deconvolve Robs as per Algorithm 1 to output R̂true. Recall, R̂true is user-centered and item-normalized. In the absence of any recommender effects Rrecom, the expectation is that R̂true is perfectly correlated with R̂obs. The absence of a linear correlation hints at factors extraneous to the user, i.e., the recommender. Thus, we plot R̂true (the deconvolved ratings) against the R̂obs, and search for characteristic signals that exemplify recommender effects (see Figure 2a and inset)."
    }, {
      "heading" : "3.2 A metric to assess a recommender system",
      "text" : "We develop an algorithm guided by the intuition that deviation of ratings from a straight line suggest recommender effects (Algorithm 2). The procedure is visually elucidated in Figure 2. We consider fitting a line to the observed and deconvolved (equivalently estimated true) ratings; however, our experiments indicate that least square fit of a straight line in the presence of severe recommender effects is not robust. The outliers in our formulation correspond to recommended items. Hence, we use random sample consensus or the RANSAC method [11] to fit a straight line on a per item basis\n(Figure 2b). All these straight lines are translated and rotated so as to coincide with the y-axis as displayed in Figure 2c. Observe that the data points corresponding to recommended ratings pop out as a bump along the x-axis. Thus, the effect of the RANSAC and rotation is to place the ratings into a precise location. Next, the ratings are scaled so as to make the maximum absolute values of the rotated and translated R̆true, R̆obs, values to be equal (Figure 2d).\nThe scores we design are to measure “extent” into the x-axis. But we want to consider some allowable vertical displacement. The final score we assign is given by fitting a hyperbola through each rating viewed as a point: R̆true, R̆obs. A straight line of slope, θ = 1 passing through the origin is fixed as an asymptote to all hyperbolas. The vertex of this hyperbola serves as the score of the corresponding data point. The higher the value of the vertex of the associated hyperbola to a data point, the more likely is the data point to be recommended item. Using the relationship between slope of asymptote, and vertex of hyperbola, the score s(R̆true, R̆obs) is given by:\ns(R̆true, R̆obs) = real( √ R̆2true − R̆ 2 obs) (10)\nWe set the slope of the asymptote, θ = 1, because the maximum magnitudes of R̆true, R̆obs are equal (see Figure 2 d,e). The overall algorithm is stated in the supplementary material. Scores are zero if the point is inside the hyperbola with vertex 0."
    }, {
      "heading" : "3.3 Identifying high recommender effects in the synthetic system",
      "text" : "We display the ROC curve of our algorithm to identify recommended products in our synthetic simulation by varying the sparsity, γ in Rtrue (Figure 3a), varying α (Figure 3b), and varying exponent e (Figure 3c) for acceptance probability. The dimensions of the rating matrix is fixed at [1000, 100] with 1000 users and 100 items. Decreasing α as well as γ has adversarial effects on the ROC curve, and hence, AUC values, as is natural. The fact that high values of α produce more discriminative deconvolved ratings is clearly illustrated in Figure 2 f. Additionally, Figure 3 d shows that the calculated score varies linearly with the true score as we change the recommender exponent, e, color coded in the legend. Overall, our algorithm is remarkably successful in extracting recommended items from Robs without any additional information. Also, we can score the overall impact of the RS (see the upcoming section RS scores) and it accurately tracks the true effect of the RS."
    }, {
      "heading" : "3.4 Real data",
      "text" : "In this subsection we validate our approach for deconvolving feedback loops on a real-world RS. First, we demonstrate that the deconvolved ratings are able to distinguish datasets that use a RS against those that do not. Second, we specify a metric that reflects the extent of RS effects on the final ratings matrix. Finally, we validate that the score returned by our algorithm is indicative of the recommender effects on a per item basis. We use α = 1 in all experiments because it models the case when the recommender effects are strong and thus produces the highest discriminative effect between the observed and true ratings (see Figure 2 f). This is likely to be the most useful as our model is only an approximation.\nDatasets. Table 1 lists all the datasets we use to validate our approach for deconvolving a RS (from [21, 4, 13]). The columns detail name of the dataset, number of users, the number of items, the lower threshold for number of ratings per item (RPI) considered in the input ratings matrix and the number of singular vectors k (as many as possible based on the limits of computer memory), respectively. The datasets are briefly discussed in the supplementary material.\nClassification of ratings matrix.\nAn example of the types of insights our method enables is shown in Figure 4. This figure shows four density plots of the estimated true ratings (y-axis) compared with the observed ratings (x-axis) for two datasets, Jester and Netflix. Higher density is indicated by darker shades in the scatter plot of observed and deconvolved ratings. If there is no RS, then these should be highly correlated. If there is a system with feedback loops, we should see a dispersive plot. In the first plot (Jester) we see the results for a real-world system without any RS or feedback loops; the second plot (Netflix) shows the results on the Netflix ratings matrix, which did have a RS impacting the data. A similar phenomenon is observed in the third and fourth plots corresponding to the MusicLab dataset in Figure 4. We display the density plot of observed (y-axis) vs. deconvolved or expected true (x-axis) ratings for all datasets considered in our evaluation in the supplementary material.\nRecommender system scores. The RS scores we displayed in Table 1 are based on the fraction of ratings with non-zero score (using the score metric (10)). Recall that a zero score indicates that the data point lies outside the associated hyperbola and does not suffer from recommender effect. Hence, the RS score is indicative of the fraction of ratings affected by the recommender. Looking at Table 1, we see that the two Jester datasets have low RS scores validating that the Jester dataset did not run a RS. The MusicLab datasets show a weak effect because they do not include any type of item-item recommender. Nevertheless, the strong social influence condition scored higher for a RS because the simple download count feedback will elicit comparable effects. These cases give us confidence in our scores because we have a clear understanding of feedback processes in the true data. Interestingly, the RS score progressively increases for the three versions of the MovieLens datasets: MovieLens-100K, MovieLens-1M and MovieLens-10M. This is expected as the RS effects would have progressively accrued over time in these datasets. Note that Netflix is also lower than Movielens, indicating that Net-\nflix’s recommender likely correlated better with users’ true tastes. The RS scores associated with alcohol datasets (RateBeer, BeerAdvocate and Wine Ratings) are higher compared to the Fine Foods dataset. This is surprising. We conjecture that this effect is due to common features that correlate with evaluations of alcohol such as the age of wine or percentage of alcohol in beer.\nRanking of items based on recommendation score. We associate a RS rating to each item as our mean score of an item over all users. All items are ranked in ascending order of RS score and we\nfirst look at items with low RS scores. The Netflix dataset comprises of movies as well as television shows. We expect that television shows are less likely to be affected by a RS because each season of a T.V. show requires longer time commitment, and they have their own following. To validate this expectation, we first identify all T.V. shows in the ranked list and compute the number of occurrences of a T.V. show in equally spaced bins of size 840. Figure 5 shows a bar chart for the number of occurrences and we see that there are ≈ 90 T.V.shows in the first bin (or top 840 items as per the score). This is highest compared to all bins and the number of occurrences progressively decrease as we move further down the list, validating our expectation. Also unsurprisingly, the seasons of the popular sitcom Friends comprised of 10 out of the top 20 T.V. seasons with lowest RS scores. It is also expected that the Season 1 of a T.V. show is more likely to be recommended relative to subsequent seasons. We identified the top 40 T.V shows with multiple (at least 2) seasons, and observed that 31 of these have a higher RS score for Season 1 relative to Season 2. The 9 T.V. shows where the converse is true are mostly comedies like Coupling, That 70’s Show etc., for which the seasons can be viewed independently of each other. Next, we looked at items with high RS score. At the time the dataset was released, Netflix operated exclusively in the U.S., and one plausible use is that immigrants might use Netflix’s RS to watch movies from their native country. We specifically looked at Indian films in the ranked list to validate this expectation. Figure 5b shows a bar chart similar to the one plotted for T.V. shows and we observe an increasing trend along the ranked list for the number of occurrences of Indian films. The movie with lowest recommendation score is Lagaan, the only Indian movie to be nominated for the Oscars in last 25 years."
    }, {
      "heading" : "4 Discussion, related work and future work",
      "text" : "Discussion:In this paper we propose a mechanism to deconvolve feedback effects on RS, similar in spirit to the network deconvolution method to distinguish direct dependencies in biological networks [10, 3]. Indeed, our approach can be viewed as a generalization of their methods for general rectangular matrices. We do so by only considering a ratings matrix at a given instant of time. Our approach depends on a few reasonable assumptions that enable us to create a tractable model of a RS. When we evaluate the resulting methods on synthetic and real-world datasets, we find that we are able to assess the degree of influence that a RS has had on those ratings. This analysis is also easy to compute and just involves a singular value decomposition of the ratings matrix.\nRelated Work: User feedback in collaborative filtering systems is categorized as either explicit feedback which includes input by users regarding their interest in products [1], or implicit feedback such as purchase and browsing history, search patterns, etc. [14]. Both types of feedback affect the item-item or user-user similarities used in the collaborative filtering algorithm for predicting future recommendations [16]. There has been a considerable amount of work on incorporating the information from these types of user feedback mechanisms in collaborative filtering algorithms in order to improve and personalize recommendations [15, 6]. Here, we do not focus on improving collaborative filtering algorithms for recommender systems by studying user feedback, but instead, our thrust is to recover each user’s true preference of an item devoid of any rating bias introduced by the recommender system due to feedback. Another line of work based on user feedback in recommender systems is related to understanding the exploration and exploitation tradeoff [20] associated with the training feedback loop in collaborative filtering algorithms [9]. This line of research evaluates ‘what-if’ scenarios such as evaluating the performance of alternative collaborative filtering models or, adapting the algorithm based on user-click feedbacks to maximize reward, using approaches like the multi-armed bandit setting [17, 18] or counterfactual learning systems [5]. In contrast, we tackle the problem of recovering the true ratings matrix if feedback loops were absent.\nFuture Work: In the future we wish to analyze the effect of feeding the derived deconvolved ratings without putative feedback effects back into the RS. Some derivatives of our method include setting the parameters considered unknown in our current approach with known values (such as S ) if known a priori. Incorporating temporal information at different snapshots of time while deconvolving the feedback loops is also an interesting line of future work. From another viewpoint, our approach can serve as a supplement to the active learning community to unbias the data and reveal additional insights regarding feedback loops considered in this paper. Overall, we believe that deconvolving feedback loops opens new gateways for understanding ratings and recommendations.\nAcknowledgements: David Gleich would like to acknowledge the support of the NSF via awards CAREER CCF-1149756, IIS-1422918, IIS-1546488, and the Center for Science of Information STC, CCF-093937, as well as the support of DARPA SIMPLEX."
    } ],
    "references" : [ {
      "title" : "Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions",
      "author" : [ "G. Adomavicius", "A. Tuzhilin" ],
      "venue" : "IEEE Trans. on Knowl. and Data Eng.,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2005
    }, {
      "title" : "Rate it again: Increasing recommendation accuracy by user re-rating",
      "author" : [ "X. Amatriain", "J.M. Pujol", "N. Tintarev", "N. Oliver" ],
      "venue" : "In RecSys, pp",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2009
    }, {
      "title" : "Barabási. Network link prediction by global silencing of indirect correlations",
      "author" : [ "B. Barzel", "A.-L" ],
      "venue" : "Nature biotechnology,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2013
    }, {
      "title" : "The Netflix prize",
      "author" : [ "J. Bennett", "S. Lanning" ],
      "venue" : "In Proceedings of the KDD Cup Workshop,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2007
    }, {
      "title" : "Counterfactual reasoning and learning systems: The example of computational advertising",
      "author" : [ "L. Bottou", "J. Peters", "J. Quiñonero-Candela", "D.X. Charles", "D.M. Chickering", "E. Portugaly", "D. Ray", "P. Simard", "E. Snelson" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2013
    }, {
      "title" : "Recommender systems based on user reviews: the state of the art",
      "author" : [ "L. Chen", "G. Chen", "F. Wang" ],
      "venue" : "User Modeling and User-Adapted Interaction,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2015
    }, {
      "title" : "Is seeing believing?: How recommender system interfaces affect users",
      "author" : [ "D. Cosley", "S.K. Lam", "I. Albert", "J.A. Konstan", "J. Riedl" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2003
    }, {
      "title" : "Item-based top-n recommendation algorithms",
      "author" : [ "M. Deshpande", "G. Karypis" ],
      "venue" : "ACM Trans. Inf. Syst.,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2004
    }, {
      "title" : "Internet advertising and the generalized second-price auction: Selling billions of dollars worth of keywords",
      "author" : [ "B. Edelman", "M. Ostrovsky", "M. Schwarz" ],
      "venue" : "American Economic Review,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2007
    }, {
      "title" : "Network deconvolution as a general method to distinguish direct dependencies in networks",
      "author" : [ "S. Feizi", "D. Marbach", "M. Medard", "M. Kellis" ],
      "venue" : "Nature Biotechnology,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2013
    }, {
      "title" : "Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography",
      "author" : [ "M.A. Fischler", "R.C. Bolles" ],
      "venue" : "Commun. ACM,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1981
    }, {
      "title" : "Rank aggregation via nuclear norm minimization",
      "author" : [ "D.F. Gleich", "L.-H. Lim" ],
      "venue" : "In KDD, pp",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2011
    }, {
      "title" : "Eigentaste: A constant time collaborative filtering algorithm",
      "author" : [ "K. Goldberg", "T. Roeder", "D. Gupta", "C. Perkins" ],
      "venue" : "Inf. Retr.,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2001
    }, {
      "title" : "Collaborative filtering for implicit feedback datasets",
      "author" : [ "Y. Hu", "Y. Koren", "C. Volinsky" ],
      "venue" : "In ICDM, pp",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2008
    }, {
      "title" : "Comparison of implicit and explicit feedback from an online music recommendation service",
      "author" : [ "G. Jawaheer", "M. Szomszor", "P. Kostkova" ],
      "venue" : "In Proceedings of the Workshop on Information Heterogeneity and Fusion in Recommender Systems,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2010
    }, {
      "title" : "Temporal diversity in recommender systems",
      "author" : [ "N. Lathia", "S. Hailes", "L. Capra", "X. Amatriain" ],
      "venue" : "In SIGIR, pp",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2010
    }, {
      "title" : "A contextual-bandit approach to personalized news article recommendation",
      "author" : [ "L. Li", "W. Chu", "J. Langford", "R.E. Schapire" ],
      "venue" : "In WWW,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2010
    }, {
      "title" : "Exploitation and exploration in a performance based contextual advertising system",
      "author" : [ "W. Li", "X. Wang", "R. Zhang", "Y. Cui", "J. Mao", "R. Jin" ],
      "venue" : "In KDD, pp",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2010
    }, {
      "title" : "Amazon.com recommendations: Item-to-item collaborative filtering",
      "author" : [ "G. Linden", "B. Smith", "J. York" ],
      "venue" : "IEEE Internet Computing,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2003
    }, {
      "title" : "Exploration and exploitation in organizational learning",
      "author" : [ "J.G. March" ],
      "venue" : "Organiz. Science,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1991
    }, {
      "title" : "From amateurs to connoisseurs: Modeling the evolution of user expertise through online reviews",
      "author" : [ "J.J. McAuley", "J. Leskovec" ],
      "venue" : "In WWW,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2013
    }, {
      "title" : "Effective use of knowledge management systems: A process model of content ratings and credibility indicators",
      "author" : [ "R.S. Poston", "C. Speier" ],
      "venue" : "MIS Quarterly,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2005
    }, {
      "title" : "Recommender Systems Handbook",
      "author" : [ "F. Ricci", "L. Rokach", "B. Shapira", "P.B. Kantor" ],
      "venue" : null,
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2010
    }, {
      "title" : "Experimental study of inequality and unpredictability in an artificial cultural",
      "author" : [ "M.J. Salganik", "P.S. Dodds", "D.J. Watts" ],
      "venue" : "market. Science,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2006
    }, {
      "title" : "Item-based collaborative filtering recommendation algorithms",
      "author" : [ "B. Sarwar", "G. Karypis", "J. Konstan", "J. Riedl" ],
      "venue" : "In WWW, pp",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2001
    } ],
    "referenceMentions" : [ {
      "referenceID" : 18,
      "context" : "Recommender systems have been helpful to users for making decisions in diverse domains such as movies, wines, food, news among others [19, 23].",
      "startOffset" : 134,
      "endOffset" : 142
    }, {
      "referenceID" : 22,
      "context" : "Recommender systems have been helpful to users for making decisions in diverse domains such as movies, wines, food, news among others [19, 23].",
      "startOffset" : 134,
      "endOffset" : 142
    }, {
      "referenceID" : 6,
      "context" : "However, it is well known that the interface of these systems affect the users’ opinion, and hence, their ratings of items [7, 24].",
      "startOffset" : 123,
      "endOffset" : 130
    }, {
      "referenceID" : 23,
      "context" : "However, it is well known that the interface of these systems affect the users’ opinion, and hence, their ratings of items [7, 24].",
      "startOffset" : 123,
      "endOffset" : 130
    }, {
      "referenceID" : 1,
      "context" : "Thus, broadly speaking, a user’s rating of an item is either his or her intrinsic preference or the influence of the recommender system (RS) on the user [2].",
      "startOffset" : 153,
      "endOffset" : 156
    }, {
      "referenceID" : 21,
      "context" : "As these ratings implicitly affect recommendations to other users through feedback, it is critical to quantify the role of feedback in content personalization [22].",
      "startOffset" : 159,
      "endOffset" : 163
    }, {
      "referenceID" : 24,
      "context" : "This metric is known as the adjusted cosine similarity, and preferred over cosine similarity because it mitigates the effect of rating schemes over users [25].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 9,
      "context" : "2See [10] for details on scaling similarity matrices to ensure convergence",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 11,
      "context" : "We use item response theory to generate a sparse true rating matrix Rtrue using a model related to that in [12].",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 7,
      "context" : "The unknown ratings are iteratively updated using the standard item-item collaborative filtering technique [8] as Rk+1 u,i = ∑ j∈i(si, j R k u, j) ∑ j∈i(|si, j |) , where k is the iteration number and R0 = Rtrue, and the similarity measure at the kth iteration is given as si, j = ∑ u∈U Ru,i R k u, j √∑ u∈U (Ru,i)(2) √∑ u∈U (Ru, j)(2) .",
      "startOffset" : 107,
      "endOffset" : 110
    }, {
      "referenceID" : 10,
      "context" : "Hence, we use random sample consensus or the RANSAC method [11] to fit a straight line on a per item basis",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 20,
      "context" : "Table 1 lists all the datasets we use to validate our approach for deconvolving a RS (from [21, 4, 13]).",
      "startOffset" : 91,
      "endOffset" : 102
    }, {
      "referenceID" : 3,
      "context" : "Table 1 lists all the datasets we use to validate our approach for deconvolving a RS (from [21, 4, 13]).",
      "startOffset" : 91,
      "endOffset" : 102
    }, {
      "referenceID" : 12,
      "context" : "Table 1 lists all the datasets we use to validate our approach for deconvolving a RS (from [21, 4, 13]).",
      "startOffset" : 91,
      "endOffset" : 102
    }, {
      "referenceID" : 9,
      "context" : "Discussion:In this paper we propose a mechanism to deconvolve feedback effects on RS, similar in spirit to the network deconvolution method to distinguish direct dependencies in biological networks [10, 3].",
      "startOffset" : 198,
      "endOffset" : 205
    }, {
      "referenceID" : 2,
      "context" : "Discussion:In this paper we propose a mechanism to deconvolve feedback effects on RS, similar in spirit to the network deconvolution method to distinguish direct dependencies in biological networks [10, 3].",
      "startOffset" : 198,
      "endOffset" : 205
    }, {
      "referenceID" : 0,
      "context" : "Related Work: User feedback in collaborative filtering systems is categorized as either explicit feedback which includes input by users regarding their interest in products [1], or implicit feedback such as purchase and browsing history, search patterns, etc.",
      "startOffset" : 173,
      "endOffset" : 176
    }, {
      "referenceID" : 15,
      "context" : "Both types of feedback affect the item-item or user-user similarities used in the collaborative filtering algorithm for predicting future recommendations [16].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 14,
      "context" : "There has been a considerable amount of work on incorporating the information from these types of user feedback mechanisms in collaborative filtering algorithms in order to improve and personalize recommendations [15, 6].",
      "startOffset" : 213,
      "endOffset" : 220
    }, {
      "referenceID" : 5,
      "context" : "There has been a considerable amount of work on incorporating the information from these types of user feedback mechanisms in collaborative filtering algorithms in order to improve and personalize recommendations [15, 6].",
      "startOffset" : 213,
      "endOffset" : 220
    }, {
      "referenceID" : 19,
      "context" : "Another line of work based on user feedback in recommender systems is related to understanding the exploration and exploitation tradeoff [20] associated with the training feedback loop in collaborative filtering algorithms [9].",
      "startOffset" : 137,
      "endOffset" : 141
    }, {
      "referenceID" : 8,
      "context" : "Another line of work based on user feedback in recommender systems is related to understanding the exploration and exploitation tradeoff [20] associated with the training feedback loop in collaborative filtering algorithms [9].",
      "startOffset" : 223,
      "endOffset" : 226
    }, {
      "referenceID" : 16,
      "context" : "This line of research evaluates ‘what-if’ scenarios such as evaluating the performance of alternative collaborative filtering models or, adapting the algorithm based on user-click feedbacks to maximize reward, using approaches like the multi-armed bandit setting [17, 18] or counterfactual learning systems [5].",
      "startOffset" : 263,
      "endOffset" : 271
    }, {
      "referenceID" : 17,
      "context" : "This line of research evaluates ‘what-if’ scenarios such as evaluating the performance of alternative collaborative filtering models or, adapting the algorithm based on user-click feedbacks to maximize reward, using approaches like the multi-armed bandit setting [17, 18] or counterfactual learning systems [5].",
      "startOffset" : 263,
      "endOffset" : 271
    }, {
      "referenceID" : 4,
      "context" : "This line of research evaluates ‘what-if’ scenarios such as evaluating the performance of alternative collaborative filtering models or, adapting the algorithm based on user-click feedbacks to maximize reward, using approaches like the multi-armed bandit setting [17, 18] or counterfactual learning systems [5].",
      "startOffset" : 307,
      "endOffset" : 310
    } ],
    "year" : 2016,
    "abstractText" : "Collaborative filtering is a popular technique to infer users’ preferences on new content based on the collective information of all users preferences. Recommender systems then use this information to make personalized suggestions to users. When users accept these recommendations it creates a feedback loop in the recommender system, and these loops iteratively influence the collaborative filtering algorithm’s predictions over time. We investigate whether it is possible to identify items affected by these feedback loops. We state sufficient assumptions to deconvolve the feedback loops while keeping the inverse solution tractable. We furthermore develop a metric to unravel the recommender system’s influence on the entire user-item rating matrix. We use this metric on synthetic and real-world datasets to (1) identify the extent to which the recommender system affects the final rating matrix, (2) rank frequently recommended items, and (3) distinguish whether a user’s rated item was recommended or an intrinsic preference. Our results indicate that it is possible to recover the ratings matrix of intrinsic user preferences using a single snapshot of the ratings matrix without any temporal information.",
    "creator" : null
  }
}