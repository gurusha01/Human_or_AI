{
  "name" : "6aca97005c68f1206823815f66102863.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Fast -free Inference of Simulation Models with Bayesian Conditional Density Estimation",
    "authors" : [ "George Papamakarios", "Iain Murray" ],
    "emails" : [ "g.papamakarios@ed.ac.uk", "i.murray@ed.ac.uk" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "A simulator-based model is a data-generating process described by a computer program, usually with some free parameters we need to learn from data. Simulator-based modelling lends itself naturally to scientific domains such as evolutionary biology [1], ecology [24], disease epidemics [10], economics [8] and cosmology [23], where observations are best understood as products of underlying physical processes. Inference in these models amounts to discovering plausible parameter settings that could have generated our observed data. The application domains mentioned can require properly calibrated distributions that express uncertainty over plausible parameters, rather than just point estimates, in order to reach scientific conclusions or make decisions.\nAs an analytical expression for the likelihood of parameters given observations is typically not available for simulator-based models, conventional likelihood-based Bayesian inference is not applicable. An alternative family of algorithms for likelihood-free inference has been developed, referred to as Approximate Bayesian Computation (ABC). These algorithms simulate the model repeatedly and only accept parameter settings which generate synthetic data similar to the observed data, typically gathered in a real-world experiment.\nRejection ABC [21], the most basic ABC algorithm, simulates the model for each setting of proposed parameters, and rejects parameters if the generated data is not within a certain distance from the observations. The accepted parameters form a set of independent samples from an approximate posterior. Markov Chain Monte Carlo ABC (MCMC-ABC) [13] is an improvement over rejection ABC which, instead of independently proposing parameters, explores the parameter space by perturbing the most recently accepted parameters. Sequential Monte Carlo ABC (SMC-ABC) [2, 5] uses importance sampling to simulate a sequence of slowly-changing distributions, the last of which is an approximation to the parameter posterior.\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nConventional ABC algorithms such as the above suffer from three drawbacks. First, they only represent the parameter posterior as a set of (possibly weighted or correlated) samples. A samplebased representation easily gives estimates and error bars of individual parameters, and model predictions. However these computations are noisy, and it is not obvious how to perform some other computations using samples, such as combining posteriors from two separate analyses. Second, the parameter samples do not come from the correct Bayesian posterior, but from an approximation based on assuming a pseudo-observation that the data is within an -ball centred on the data actually observed. Third, as the -tolerance is reduced, it can become impractical to simulate the model enough times to match the observed data even once. When simulations are expensive to perform, good quality inference becomes impractical.\nWe propose a parametric approach to likelihood-free inference, which unlike conventional ABC does not suffer from the above three issues. Instead of returning samples from an -approximation to the posterior, our approach learns a parametric approximation to the exact posterior, which can be made as accurate as required. Preliminary fits to the posterior are used to guide future simulations, which can reduce the number of simulations required to learn an accurate approximation by orders of magnitude. Our approach uses conditional density estimation with Bayesian neural networks, and draws upon advances in parametric density estimation, stochastic variational inference, and recognition networks, as discussed in the related work section."
    }, {
      "heading" : "2 Bayesian conditional density estimation for likelihood-free inference",
      "text" : ""
    }, {
      "heading" : "2.1 Simulator-based models and ABC",
      "text" : "Let θ be a vector of parameters controlling a simulator-based model, and let x be a data vector generated by the model. The model may be provided as a probabilistic program that can be easily simulated, and implicitly defines a likelihood p(x |θ), which we assume we cannot evaluate. Let p(θ) encode our prior beliefs about the parameters. Given an observation xo, we are interested in the parameter posterior p(θ |x = xo) ∝ p(x = xo |θ) p(θ). As the likelihood p(x = xo |θ) is unavailable, conventional Bayesian inference cannot be carried out. The principle behind ABC is to approximate p(x = xo |θ) by p(‖x− xo‖ < |θ) for a sufficiently small value of , and then estimate the latter—e.g. by Monte Carlo—using simulations from the model. Hence, ABC approximates the posterior by p(θ | ‖x− xo‖ < ), which is typically broader and more uncertain. ABC can trade off computation for accuracy by decreasing , which improves the approximation to the posterior but requires more simulations from the model. However, the approximation becomes exact only when → 0, in which case simulations never match the observations, p(‖x− xo‖ < |θ)→ 0, and existing methods break down. In this paper, we refer to p(θ |x = xo) as the exact posterior, as it corresponds to setting = 0 in p(θ | ‖x− xo‖ < ). In most practical applications of ABC, x is taken to be a fixed-length vector of summary statistics that is calculated from data generated by the simulator, rather than the raw data itself. Extracting statistics is often necessary in practice, to reduce the dimensionality of the data and maintain p(‖x− xo‖ < |θ) to practically acceptable levels. For the purposes of this paper, we will make no distinction between raw data and summary statistics, and we will regard the calculation of summary statistics as part of the data generating process."
    }, {
      "heading" : "2.2 Learning the posterior",
      "text" : "Rather than using simulations from the model in order to estimate an approximate likelihood, p(‖x− xo‖ < |θ), we will use the simulations to directly estimate p(θ |x = xo). We will run simulations for parameters drawn from a distribution, p̃(θ), which we shall refer to as the proposal prior. The proposition below indicates how we can then form a consistent estimate of the exact posterior, using a flexible family of conditional densities, qφ(θ |x), parameterized by a vector φ. Proposition 1. We assume that each of a set of N pairs (θn,xn) was independently generated by θn ∼ p̃(θ) and xn ∼ p(x |θn). (1) In the limit N →∞, the probability of the parameter vectors∏n qφ(θn |xn) is maximized w.r.t. φ if and only if\nqφ(θ |x) ∝ p̃(θ)\np(θ) p(θ |x), (2)\nprovided a setting of φ that makes qφ(θ |x) proportional to p̃(θ)p(θ) p(θ |x) exists.\nIntuition: if we simulated enough parameters from the prior, the density estimator qφ would learn a conditional of the joint prior model over parameters and data, which is the posterior p(θ |x). If we simulate parameters drawn from another distribution, we need to “importance reweight” the result. A more detailed proof can be found in Section A of the supplementary material.\nThe proposition above suggests the following procedure for learning the posterior: (a) propose a set of parameter vectors {θn} from the proposal prior; (b) for each θn run the simulator to obtain a corresponding data vector xn; (c) train qφ with maximum likelihood on {θn,xn}; and (d) estimate the posterior by\np̂(θ |x = xo) ∝ p(θ)\np̃(θ) qφ(θ |xo). (3)\nThis procedure is summarized in Algorithm 2."
    }, {
      "heading" : "2.3 Choice of conditional density estimator and proposal prior",
      "text" : "In choosing the types of density estimator qφ(θ |x) and proposal prior p̃(θ), we need to meet the following criteria: (a) qφ should be flexible enough to represent the posterior but easy to train with maximum likelihood; (b) p̃(θ) should be easy to evaluate and sample from; and (c) the right-hand side expression in Equation (3) should be easily evaluated and normalized.\nWe draw upon work on conditional neural density estimation and take qφ to be a Mixture Density Network (MDN) [3] with fully parameterized covariance matrices. That is, qφ takes the form of a mixture of K Gaussian components qφ(θ |x) = ∑ k αkN (θ |mk,Sk), whose mixing coefficients {αk}, means {mk} and covariance matrices {Sk} are computed by a feedforward neural network parameterized by φ, taking x as input. Such an architecture is capable of representing any conditional distribution arbitrarily accurately—provided the number of components K and number of hidden units in the neural network are sufficiently large—while remaining trainable by backpropagation. The parameterization of the MDN is detailed in Section B of the supplementary material.\nWe take the proposal prior to be a single Gaussian p̃(θ) = N (θ |m0,S0), with mean m0 and full covariance matrix S0. Assuming the prior p(θ) is a simple distribution (uniform or Gaussian, as is typically the case in practice), then this choice allows us to calculate p̂(θ |x = xo) in Equation (3) analytically. That is, p̂(θ |x = xo) will be a mixture of K Gaussians, whose parameters will be a function of {αk,mk,Sk} evaluated at xo (as detailed in Section C of the supplementary material)."
    }, {
      "heading" : "2.4 Learning the proposal prior",
      "text" : "Simple rejection ABC is inefficient because the posterior p(θ |x = xo) is typically much narrower than the prior p(θ). A parameter vector θ sampled from p(θ) will rarely be plausible under p(θ |x = xo) and will most likely be rejected. Practical ABC algorithms attempt to reduce the number of rejections by modifying the way they propose parameters; for instance, MCMC-ABC and SMC-ABC propose new parameters by perturbing parameters they already consider plausible, in the hope that nearby parameters remain plausible.\nIn our framework, the key to efficient use of simulations lies in the choice of proposal prior. If we take p̃(θ) to be the actual prior, then qφ(θ |x) will learn the posterior for all x, as can be seen from Equation (2). Such a strategy however is grossly inefficient if we are only interested in the posterior for x = xo. Conversely, if p̃(θ) closely matches p(θ |x = xo), then most simulations will produce samples that are highly informative in learning qφ(θ |x) for x = xo. In other words, if we already knew the true posterior, we could use it to construct an efficient proposal prior for learning it.\nWe exploit this idea to set up a fixed-point system. Our strategy becomes to learn an efficient proposal prior that closely approximates the posterior as follows: (a) initially take p̃(θ) to be the prior p(θ); (b) propose N samples {θn} from p̃(θ) and corresponding samples {xn} from the simulator, and train qφ(θ |x) on them; (c) approximate the posterior using Equation (3) and set p̃(θ) to it; (d) repeat until p̃(θ) has converged. This procedure is summarized in Algorithm 1.\nIn the procedure above, as long as qφ(θ |x) has only one Gaussian component (K = 1) then p̃(θ) remains a single Gaussian throughout. Moreover, in each iteration we initialize qφ with the density\nAlgorithm 1: Training of proposal prior initialize qφ(θ |x) with one component p̃(θ)← p(θ) repeat\nfor n = 1..N do sample θn ∼ p̃(θ) sample xn ∼ p(x |θn) end retrain qφ(θ |x) on {θn,xn} p̃(θ)← p(θ)p̃(θ) qφ(θ |xo)\nuntil p̃(θ) has converged;\nAlgorithm 2: Training of posterior initialize qφ(θ |x) with K components // if qφ available by Algorithm 1 // initialize by replicating its // one component K times for n = 1..N do\nsample θn ∼ p̃(θ) sample xn ∼ p(x |θn)\nend train qφ(θ |x) on {θn,xn} p̂(θ |x = xo)← p(θ)p̃(θ) qφ(θ |xo)\nestimator learnt in the iteration before, thus we keep training qφ throughout. This initialization allows us to use a small sample size N in each iteration, thus making efficient use of simulations.\nAs we shall demonstrate in Section 3, the procedure above learns Gaussian approximations to the true posterior fast: in our experiments typically 4–6 iterations of 200–500 samples each were sufficient. This Gaussian approximation can be used as a rough but cheap approximation to the true posterior, or it can serve as a good proposal prior in Algorithm 2 for efficiently fine-tuning a non-Gaussian multi-component posterior. If the second strategy is adopted, then we can reuse the single-component neural density estimator learnt in Algorithm 1 to initialize qφ in Algorithm 2. The weights in the final layer of the MDN are replicated K times, with small random perturbations to break symmetry."
    }, {
      "heading" : "2.5 Use of Bayesian neural density estimators",
      "text" : "To make Algorithm 1 as efficient as possible, the number of simulations per iteration N should be kept small, while at the same time it should provide a sufficient training signal for qφ. With a conventional MDN, if N is made too small, there is a danger of overfitting, especially in early iterations, leading to over-confident proposal priors and an unstable procedure. Early stopping could be used to avoid overfitting; however a significant fraction of the N samples would have to be used as a validation set, leading to inefficient use of simulations.\nAs a better alternative, we developed a Bayesian version of the MDN using Stochastic Variational Inference (SVI) for neural networks [12]. We shall refer to this Bayesian version of the MDN as MDN-SVI. An MDN-SVI has two sets of adjustable parameters of the same size, the means φm and the log variances φs. The means correspond to the parameters φ of a conventional MDN. During training, Gaussian noise of variance expφs is added to the means independently for each training example (θn,xn). The Bayesian interpretation of this procedure is that it optimizes a variational Gaussian posterior with a diagonal covariance matrix over parameters φ. At prediction time, the noise is switched off and the MDN-SVI behaves like a conventional MDN with φ = φm. Section D of the supplementary material details the implementation and training of MDN-SVI. We found that using an MDN-SVI instead of an MDN improves the robustness and efficiency of Algorithm 1 because (a) MDN-SVI is resistant to overfitting, allowing us to use a smaller number of simulations N ; (b) no validation set is needed, so all samples can be used for training; and (c) since overfitting is not an issue, no careful tuning of training time is necessary."
    }, {
      "heading" : "3 Experiments",
      "text" : "We showcase three versions of our approach: (a) learning the posterior with Algorithm 2 where qφ is a conventional MDN and the proposal prior p̃(θ) is taken to be the actual prior p(θ), which we refer to as MDN with prior; (b) training a proposal prior with Algorithm 1 where qφ is an MDN-SVI, which we refer to as proposal prior; and (c) learning the posterior with Algorithm 2 where qφ is an MDN-SVI and the proposal prior p̃(θ) is taken to be the one learnt in (b), which we refer to as MDN with proposal. All MDNs were trained using Adam [11] with its default parameters.\nWe compare to three ABC baselines: (a) rejection ABC [21], where parameters are proposed from the prior and are accepted if ‖x− xo‖ < ; (b) MCMC-ABC [13] with a spherical Gaussian proposal, whose variance we manually tuned separately in each case for best performance; and (c) SMC-\nABC [2], where the sequence of ’s was exponentially decayed, with a decay rate manually tuned separately in each case for best performance. MCMC-ABC was given the unrealistic advantage of being initialized with a sample from rejection ABC, removing the need for an otherwise necessary burn-in period. Code for reproducing the experiments is provided in the supplementary material and at https://github.com/gpapamak/epsilon_free_inference."
    }, {
      "heading" : "3.1 Mixture of two Gaussians",
      "text" : "The first experiment is a toy problem where the goal is to infer the common mean θ of a mixture of two 1D Gaussians, given a single datapoint xo. The setup is\np(θ) = U(θ | θα, θβ) and p(x | θ) = αN ( x | θ, σ21 ) + (1− α)N ( x | θ, σ22 ) , (4)\nwhere θα = −10, θβ = 10, α = 0.5, σ1 = 1, σ2 = 0.1 and xo = 0. The posterior can be calculated analytically, and is proportional to an equal mixture of two Gaussians centred at xo with variances σ21 and σ22 , restricted to [θα, θβ ]. This problem is often used in the SMC-ABC literature to illustrate the difficulty of MCMC-ABC in representing long tails. Here we use it to demonstrate the correctness of our approach and its ability to accurately represent non-Gaussian long-tailed posteriors.\nFigure 1 shows the results of neural density estimation using each strategy. All MDNs have one hidden layer with 20 tanh units and 2 Gaussian components, except for the proposal prior MDN which has a single component. Both MDN with prior and MDN with proposal learn good parametric approximations to the true posterior, and the proposal prior is a good Gaussian approximation to it. We used 10K simulations to train the MDN with prior, whereas the prior proposal took 4 iterations of 200 simulations each to train, and the MDN with proposal took 1000 simulations on top of the previous 800. The MDN with prior learns the posterior distributions for a large range of possible observations x (middle plot of Figure 1), whereas the MDN with proposal gives accurate posterior probabilities only near the value actually observed (right plot of Figure 1)."
    }, {
      "heading" : "3.2 Bayesian linear regression",
      "text" : "In Bayesian linear regression, the goal is to infer the parameters θ of a linear map from noisy observations of outputs at known inputs. The setup is\np(θ) = N (θ |m,S) and p(x |θ) =∏iN (xi |θTui, σ2), (5) where we took m = 0, S = I, σ = 0.1, randomly generated inputs {ui} from a standard Gaussian, and randomly generated observations xo from the model. In our setup, θ and x have 6 and 10 dimensions respectively. The posterior is analytically tractable, and is a single Gaussian.\nAll MDNs have one hidden layer of 50 tanh units and one Gaussian component. ABC methods were run for a sequence of decreasing ’s, up to their failing points. To measure the approximation quality to the posterior, we analytically calculated the KL divergence from the true posterior to the learnt posterior (which for ABC was taken to be a Gaussian fit to the set of returned posterior samples). The left of Figure 2 shows the approximation quality vs ; MDN methods are shown as horizontal\nlines. As is decreased, ABC methods sample from an increasingly better approximation to the true posterior, however they eventually reach their failing point, or take prohibitively long. The best approximations are achieved by MDN with proposal and a very long run of SMC-ABC.\nThe middle of Figure 2 shows the increase in number of simulations needed to improve approximation quality (as decreases). We quote the total number of simulations for MDN training, and the number of simulations per effective sample for ABC. Section E of the supplementary material describes how the number of effective samples is calculated. The number of simulations per effective sample should be multiplied by the number of effective samples needed in practice. Moreover, SMC-ABC will not work well with only one particle, so many times the quoted cost will always be needed. Here, MDNs make more efficient use of simulations than Monte Carlo ABC methods. Sequentially fitting a prior proposal was more than ten times cheaper than training with prior samples, and more accurate."
    }, {
      "heading" : "3.3 Lotka–Volterra predator-prey population model",
      "text" : "The Lotka–Volterra model is a stochastic Markov jump process that describes the continuous time evolution of a population of predators interacting with a population of prey. There are four possible reactions: (a) a predator being born, (b) a predator dying, (c) a prey being born, and (d) a prey being eaten by a predator. Positive parameters θ = (θ1, θ2, θ3, θ4) control the rate of each reaction. Given a set of statistics xo calculated from an observed population time series, the objective is to infer θ. We used a flat prior over log θ, and calculated a set of 9 statistics x. The full setup is detailed in Section F of the supplementary material. The Lotka–Volterra model is commonly used in the ABC literature as a realistic model which can be simulated, but whose likelihood is intractable. One of the properties of Lotka–Volterra is that typical nature-like observations only occur for very specific parameter settings, resulting in narrow, Gaussian-like posteriors that are hard to recover.\nThe MDN trained with prior has two hidden layers of 50 tanh units each, whereas the MDN-SVI used to train the proposal prior and the MDN-SVI trained with proposal have one hidden layer of 50 tanh units. All three have one Gaussian component. We found that using more than one components made no difference to the results; in all cases the MDNs chose to use only one component and switch the rest off, which is consistent with our observation about the near-Gaussianity of the posterior.\nWe measure how well each method retrieves the true parameter values that were used to generate xo by calculating their log probability under each learnt posterior; for ABC a Gaussian fit to the posterior samples was used. The left panel of Figure 3 shows how this log probability varies with , demonstrating the superiority of MDN methods over ABC. In the middle panel we can see that MDN training with proposal makes efficient use of simulations compared to training with prior and ABC; note that for ABC the number of simulations is only for one effective sample. In the right panel, we can see that the estimates returned by MDN methods are more confident around the true parameters compared to ABC, because the MDNs learn the exact posterior rather than an inflated version of it like ABC does (plots for the other three parameters look similar).\nWe found that when training an MDN with a well-tuned proposal that focuses on the plausible region, an MDN with fewer parameters is needed compared to training with the prior. This is because the\nMDN trained with proposal needs to learn only the local relationship between x and θ near xo, as opposed to in the entire domain of the prior. Hence, not only are savings achieved in number of simulations, but also training the MDN itself becomes more efficient."
    }, {
      "heading" : "3.4 M/G/1 queue model",
      "text" : "The M/G/1 queue model describes the processing of a queue of continuously arriving jobs by a single server. In this model, the time the server takes to process each job is independently and uniformly distributed in the interval [θ1, θ2]. The time interval between arrival of two consecutive jobs is independently and exponentially distributed with rate θ3. The server observes only the time intervals between departure of two consecutive jobs. Given a set of equally-spaced percentiles xo of inter-departure times, the task is to infer parameters θ = (θ1, θ2, θ3). This model is easy to simulate but its likelihood is intractable, and it has often been used as an ABC benchmark [4, 16]. Unlike Lotka–Volterra, data x is weakly informative about θ, and hence the posterior over θ tends to be broad and non-Gaussian. In our setup, we placed flat independent priors over θ1, θ2 − θ1 and θ3, and we took x to be 5 equally spaced percentiles, as detailed in Section G of the supplementary material.\nThe MDN trained with prior has two hidden layers of 50 tanh units each, whereas the MDN-SVI used to train the proposal prior and the one trained with proposal have one hidden layer of 50 tanh units. As observed in the Lotka–Volterra demo, less capacity is required when training with proposal, as the relationship to be learned is local and hence simpler, which saves compute time and gives a more accurate final posterior. All MDNs have 8 Gaussian components (except the MDN-SVI used to train the proposal prior, which always has one), which, after experimentation, we determined are enough for the MDNs to represent the non-Gaussian nature of the posterior.\nFigure 4 reports the log probability of the true parameters under each posterior learnt—for ABC, the log probability was calculated by fitting a mixture of 8 Gaussians to posterior samples using Expectation-Maximization—and the number of simulations needed to achieve it. As before, MDN methods are more confident compared to ABC around the true parameters, which is due to ABC computing a broader posterior than the true one. MDN methods make more efficient use of simulations, since they use all of them for training and, unlike ABC, do not throw a proportion of them away."
    }, {
      "heading" : "4 Related work",
      "text" : "Regression adjustment. An early parametric approach to ABC is regression adjustment, where a parametric regressor is trained on simulation data in order to learn a mapping from x to θ. The learnt mapping is then used to correct for using a large , by adjusting the location of posterior samples gathered by e.g. rejection ABC. Beaumont et al. [1] used linear regressors, and later Blum and François [4] used neural networks with one hidden layer that separately predicted the mean and variance of θ. Both can be viewed as rudimentary density estimators and as such they are a predecessor to our work. However, they were not flexible enough to accurately estimate the posterior, and they were only used within some other ABC method to allow for a larger . In our work, we make conditional density estimation flexible enough to approximate the posterior accurately.\nSynthetic likelihood. Another parametric approach is synthetic likelihood, where parametric models are used to estimate the likelihood p(x |θ). Wood [24] used a single Gaussian, and later Fan et al. [7] used a mixture Gaussian model. Both of them learnt a separate density model of x for each θ by repeatedly simulating the model for fixed θ. More recently, Meeds and Welling [14] used a Gaussian process model to interpolate Gaussian likelihood approximations between different θ’s. Compared to learning the posterior, synthetic likelihood has the advantage of not depending on the choice of proposal prior. Its main disadvantage is the need of further approximate inference on top of it in order to obtain the posterior. In our work we directly learn the posterior, eliminating the need for further inference, and we address the problem of correcting for the proposal prior.\nEfficient Monte Carlo ABC. Recent work on ABC has focused on reducing the simulation cost of sample-based ABC methods. Hamiltonian ABC [15] improves upon MCMC-ABC by using stochastically estimated gradients in order to explore the parameter space more efficiently. Optimization Monte Carlo ABC [16] explicitly optimizes the location of ABC samples, which greatly reduces rejection rate. Bayesian optimization ABC [10] models p(‖x− xo‖ |θ) as a Gaussian process and then uses Bayesian optimization to guide simulations towards the region of small distances ‖x− xo‖. In our work we show how a significant reduction in simulation cost can also be achieved with parametric methods, which target the posterior directly.\nRecognition networks. Our use of neural density estimators for learning posteriors is reminiscent of recognition networks in machine learning. A recognition network is a neural network that is trained to invert a generative model. The Helmholtz machine [6], the variational auto-encoder [12] and stochastic backpropagation [22] are examples where a recognition network is trained jointly with the generative network it is designed to invert. Feedforward neural networks have been used to invert black-box generative models [18] and binary-valued Bayesian networks [17], and convolutional neural networks have been used to invert a physics engine [25]. Our work illustrates the potential of recognition networks in the field of likelihood-free inference, where the generative model is fixed, and inference of its parameters is the goal.\nLearning proposals. Neural density estimators have been employed in learning proposal distributions for importance sampling [20] and Sequential Monte Carlo [9, 19]. Although not our focus here, our fit to the posterior could also be used within Monte Carlo inference methods. In this work we see how far we can get purely by fitting a series of conditional density estimators."
    }, {
      "heading" : "5 Conclusions",
      "text" : "Bayesian conditional density estimation improves likelihood-free inference in three main ways: (a) it represents the posterior parametrically, as opposed to as a set of samples, allowing for probabilistic evaluations later on in the pipeline; (b) it targets the exact posterior, rather than an -approximation of it; and (c) it makes efficient use of simulations by not rejecting samples, by interpolating between samples, and by gradually focusing on the plausible parameter region. Our belief is that neural density estimation is a tool with great potential in likelihood-free inference, and our hope is that this work helps in establishing its usefulness in the field."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank Amos Storkey for useful comments. George Papamakarios is supported by the Centre for Doctoral Training in Data Science, funded by EPSRC (grant EP/L016427/1) and the University of Edinburgh, and by Microsoft Research through its PhD Scholarship Programme."
    } ],
    "references" : [ {
      "title" : "Approximate Bayesian Computation in population genetics",
      "author" : [ "M.A. Beaumont", "W. Zhang", "D.J. Balding" ],
      "venue" : "Genetics,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2002
    }, {
      "title" : "Adaptive Approximate Bayesian Computation",
      "author" : [ "M.A. Beaumont", "J.-M. Cornuet", "J.-M. Marin", "C.P. Robert" ],
      "venue" : "Biometrika, 96(4):983–990",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Mixture density networks",
      "author" : [ "C.M. Bishop" ],
      "venue" : "Technical Report NCRG/94/004, Aston University",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "Non-linear regression models for Approximate Bayesian Computation",
      "author" : [ "M.G.B. Blum", "O. François" ],
      "venue" : "Statistics and Computing, 20(1):63–73",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Sequential Monte Carlo with adaptive weights for Approximate Bayesian Computation",
      "author" : [ "F.V. Bonassi", "M. West" ],
      "venue" : "Bayesian Analysis,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2015
    }, {
      "title" : "The Helmholtz machine",
      "author" : [ "P. Dayan", "G.E. Hinton", "R.M. Neal", "R.S. Zemel" ],
      "venue" : "Neural Computation, 7: 889–904",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Approximate Bayesian Computation via regression density estimation",
      "author" : [ "Y. Fan", "D.J. Nott", "S.A. Sisson" ],
      "venue" : "Stat, 2(1):34–48",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Indirect inference",
      "author" : [ "C. Gouriéroux", "A. Monfort", "E. Renault" ],
      "venue" : "Journal of Applied Econometrics, 8(S1): S85–S118",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Neural adaptive Sequential Monte Carlo",
      "author" : [ "S. Gu", "Z. Ghahramani", "R.E. Turner" ],
      "venue" : "Advances in Neural Information Processing Systems 28, pages 2629–2637",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Bayesian optimization for likelihood-free inference of simulator-based statistical models",
      "author" : [ "M.U. Gutmann", "J. Corander" ],
      "venue" : "arXiv e-prints, abs/1501.03291v3",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "D.P. Kingma", "J. Ba" ],
      "venue" : "Proceedings of the 3rd International Conference on Learning Representations",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Auto-encoding variational Bayes",
      "author" : [ "D.P. Kingma", "M. Welling" ],
      "venue" : "Proceedings of the 2nd International Conference on Learning Representations",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Markov chain Monte Carlo without likelihoods",
      "author" : [ "P. Marjoram", "J. Molitor", "V. Plagnol", "S. Tavaré" ],
      "venue" : "Proceedings of the National Academy of Sciences,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2003
    }, {
      "title" : "GPS-ABC: Gaussian Process Surrogate Approximate Bayesian Computation",
      "author" : [ "E. Meeds", "M. Welling" ],
      "venue" : "Proceedings of the 30th Conference on Uncertainty in Artificial Intelligence, 30",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Hamiltonian ABC",
      "author" : [ "E. Meeds", "R. Leenders", "M. Welling" ],
      "venue" : "Proceedings of the 31st Conference on Uncertainty in Artificial Intelligence, pages 582–591",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Optimization Monte Carlo: Efficient and embarrassingly parallel likelihood-free inference",
      "author" : [ "T. Meeds", "M. Welling" ],
      "venue" : "Advances in Neural Information Processing Systems 28, pages 2071–2079",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Recognition networks for approximate inference in BN20 networks",
      "author" : [ "Q. Morris" ],
      "venue" : "Proceedings of the 17th Conference on Uncertainty in Artificial Intelligence, pages 370–377",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Analysis-by-synthesis by learning to invert generative black boxes",
      "author" : [ "V. Nair", "J. Susskind", "G.E. Hinton" ],
      "venue" : "Proceedings of the 18th International Conference on Artificial Neural Networks, 5163:971–981",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Inference networks for Sequential Monte Carlo in graphical models",
      "author" : [ "B. Paige", "F. Wood" ],
      "venue" : "Proceedings of the 33rd International Conference on Machine Learning",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "Distilling intractable generative models",
      "author" : [ "G. Papamakarios", "I. Murray" ],
      "venue" : "Probabilistic Integration Workshop at Neural Information Processing Systems",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Population growth of human Y chromosomes: a study of Y chromosome microsatellites",
      "author" : [ "J.K. Pritchard", "M.T. Seielstad", "A. Perez-Lezaun", "M.W. Feldman" ],
      "venue" : "Molecular Biology and Evolution, 16(12): 1791–1798",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Stochastic backpropagation and approximate inference in deep generative models",
      "author" : [ "D.J. Rezende", "S. Mohamed", "D. Wierstra" ],
      "venue" : "Proceedings of the 31st International Conference on Machine Learning, pages 1278–1286",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Likelihood-free inference in cosmology: Potential for the estimation of luminosity functions",
      "author" : [ "C.M. Schafer", "P.E. Freeman" ],
      "venue" : "Statistical Challenges in Modern Astronomy V, pages 3–19",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Statistical inference for noisy nonlinear ecological dynamic systems",
      "author" : [ "S.N. Wood" ],
      "venue" : "Nature, 466(7310): 1102–1104",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Galileo: Perceiving physical object properties by integrating a physics engine with deep learning",
      "author" : [ "J. Wu", "I. Yildirim", "J.J. Lim", "B. Freeman", "J. Tenenbaum" ],
      "venue" : "Advances in Neural Information Processing Systems 28, pages 127–135",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Simulator-based modelling lends itself naturally to scientific domains such as evolutionary biology [1], ecology [24], disease epidemics [10], economics [8] and cosmology [23], where observations are best understood as products of underlying physical processes.",
      "startOffset" : 100,
      "endOffset" : 103
    }, {
      "referenceID" : 23,
      "context" : "Simulator-based modelling lends itself naturally to scientific domains such as evolutionary biology [1], ecology [24], disease epidemics [10], economics [8] and cosmology [23], where observations are best understood as products of underlying physical processes.",
      "startOffset" : 113,
      "endOffset" : 117
    }, {
      "referenceID" : 9,
      "context" : "Simulator-based modelling lends itself naturally to scientific domains such as evolutionary biology [1], ecology [24], disease epidemics [10], economics [8] and cosmology [23], where observations are best understood as products of underlying physical processes.",
      "startOffset" : 137,
      "endOffset" : 141
    }, {
      "referenceID" : 7,
      "context" : "Simulator-based modelling lends itself naturally to scientific domains such as evolutionary biology [1], ecology [24], disease epidemics [10], economics [8] and cosmology [23], where observations are best understood as products of underlying physical processes.",
      "startOffset" : 153,
      "endOffset" : 156
    }, {
      "referenceID" : 22,
      "context" : "Simulator-based modelling lends itself naturally to scientific domains such as evolutionary biology [1], ecology [24], disease epidemics [10], economics [8] and cosmology [23], where observations are best understood as products of underlying physical processes.",
      "startOffset" : 171,
      "endOffset" : 175
    }, {
      "referenceID" : 20,
      "context" : "Rejection ABC [21], the most basic ABC algorithm, simulates the model for each setting of proposed parameters, and rejects parameters if the generated data is not within a certain distance from the observations.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 12,
      "context" : "Markov Chain Monte Carlo ABC (MCMC-ABC) [13] is an improvement over rejection ABC which, instead of independently proposing parameters, explores the parameter space by perturbing the most recently accepted parameters.",
      "startOffset" : 40,
      "endOffset" : 44
    }, {
      "referenceID" : 1,
      "context" : "Sequential Monte Carlo ABC (SMC-ABC) [2, 5] uses importance sampling to simulate a sequence of slowly-changing distributions, the last of which is an approximation to the parameter posterior.",
      "startOffset" : 37,
      "endOffset" : 43
    }, {
      "referenceID" : 4,
      "context" : "Sequential Monte Carlo ABC (SMC-ABC) [2, 5] uses importance sampling to simulate a sequence of slowly-changing distributions, the last of which is an approximation to the parameter posterior.",
      "startOffset" : 37,
      "endOffset" : 43
    }, {
      "referenceID" : 2,
      "context" : "We draw upon work on conditional neural density estimation and take qφ to be a Mixture Density Network (MDN) [3] with fully parameterized covariance matrices.",
      "startOffset" : 109,
      "endOffset" : 112
    }, {
      "referenceID" : 11,
      "context" : "As a better alternative, we developed a Bayesian version of the MDN using Stochastic Variational Inference (SVI) for neural networks [12].",
      "startOffset" : 133,
      "endOffset" : 137
    }, {
      "referenceID" : 10,
      "context" : "All MDNs were trained using Adam [11] with its default parameters.",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 20,
      "context" : "We compare to three ABC baselines: (a) rejection ABC [21], where parameters are proposed from the prior and are accepted if ‖x− xo‖ < ; (b) MCMC-ABC [13] with a spherical Gaussian proposal, whose variance we manually tuned separately in each case for best performance; and (c) SMC-",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 12,
      "context" : "We compare to three ABC baselines: (a) rejection ABC [21], where parameters are proposed from the prior and are accepted if ‖x− xo‖ < ; (b) MCMC-ABC [13] with a spherical Gaussian proposal, whose variance we manually tuned separately in each case for best performance; and (c) SMC-",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 1,
      "context" : "ABC [2], where the sequence of ’s was exponentially decayed, with a decay rate manually tuned separately in each case for best performance.",
      "startOffset" : 4,
      "endOffset" : 7
    }, {
      "referenceID" : 3,
      "context" : "This model is easy to simulate but its likelihood is intractable, and it has often been used as an ABC benchmark [4, 16].",
      "startOffset" : 113,
      "endOffset" : 120
    }, {
      "referenceID" : 15,
      "context" : "This model is easy to simulate but its likelihood is intractable, and it has often been used as an ABC benchmark [4, 16].",
      "startOffset" : 113,
      "endOffset" : 120
    }, {
      "referenceID" : 0,
      "context" : "[1] used linear regressors, and later Blum and François [4] used neural networks with one hidden layer that separately predicted the mean and variance of θ.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[1] used linear regressors, and later Blum and François [4] used neural networks with one hidden layer that separately predicted the mean and variance of θ.",
      "startOffset" : 56,
      "endOffset" : 59
    }, {
      "referenceID" : 23,
      "context" : "Wood [24] used a single Gaussian, and later Fan et al.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 13,
      "context" : "More recently, Meeds and Welling [14] used a Gaussian process model to interpolate Gaussian likelihood approximations between different θ’s.",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 14,
      "context" : "Hamiltonian ABC [15] improves upon MCMC-ABC by using stochastically estimated gradients in order to explore the parameter space more efficiently.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 15,
      "context" : "Optimization Monte Carlo ABC [16] explicitly optimizes the location of ABC samples, which greatly reduces rejection rate.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 9,
      "context" : "Bayesian optimization ABC [10] models p(‖x− xo‖ |θ) as a Gaussian process and then uses Bayesian optimization to guide simulations towards the region of small distances ‖x− xo‖.",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 5,
      "context" : "The Helmholtz machine [6], the variational auto-encoder [12] and stochastic backpropagation [22] are examples where a recognition network is trained jointly with the generative network it is designed to invert.",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 11,
      "context" : "The Helmholtz machine [6], the variational auto-encoder [12] and stochastic backpropagation [22] are examples where a recognition network is trained jointly with the generative network it is designed to invert.",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 21,
      "context" : "The Helmholtz machine [6], the variational auto-encoder [12] and stochastic backpropagation [22] are examples where a recognition network is trained jointly with the generative network it is designed to invert.",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 17,
      "context" : "Feedforward neural networks have been used to invert black-box generative models [18] and binary-valued Bayesian networks [17], and convolutional neural networks have been used to invert a physics engine [25].",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 16,
      "context" : "Feedforward neural networks have been used to invert black-box generative models [18] and binary-valued Bayesian networks [17], and convolutional neural networks have been used to invert a physics engine [25].",
      "startOffset" : 122,
      "endOffset" : 126
    }, {
      "referenceID" : 24,
      "context" : "Feedforward neural networks have been used to invert black-box generative models [18] and binary-valued Bayesian networks [17], and convolutional neural networks have been used to invert a physics engine [25].",
      "startOffset" : 204,
      "endOffset" : 208
    }, {
      "referenceID" : 19,
      "context" : "Neural density estimators have been employed in learning proposal distributions for importance sampling [20] and Sequential Monte Carlo [9, 19].",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 8,
      "context" : "Neural density estimators have been employed in learning proposal distributions for importance sampling [20] and Sequential Monte Carlo [9, 19].",
      "startOffset" : 136,
      "endOffset" : 143
    }, {
      "referenceID" : 18,
      "context" : "Neural density estimators have been employed in learning proposal distributions for importance sampling [20] and Sequential Monte Carlo [9, 19].",
      "startOffset" : 136,
      "endOffset" : 143
    } ],
    "year" : 2016,
    "abstractText" : "Many statistical models can be simulated forwards but have intractable likelihoods. Approximate Bayesian Computation (ABC) methods are used to infer properties of these models from data. Traditionally these methods approximate the posterior over parameters by conditioning on data being inside an -ball around the observed data, which is only correct in the limit →0. Monte Carlo methods can then draw samples from the approximate posterior to approximate predictions or error bars on parameters. These algorithms critically slow down as →0, and in practice draw samples from a broader distribution than the posterior. We propose a new approach to likelihood-free inference based on Bayesian conditional density estimation. Preliminary inferences based on limited simulation data are used to guide later simulations. In some cases, learning an accurate parametric representation of the entire true posterior distribution requires fewer model simulations than Monte Carlo ABC methods need to produce a single sample from an approximate posterior.",
    "creator" : null
  }
}