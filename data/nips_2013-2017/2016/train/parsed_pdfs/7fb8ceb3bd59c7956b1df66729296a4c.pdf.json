{
  "name" : "7fb8ceb3bd59c7956b1df66729296a4c.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Matrix Completion has No Spurious Local Minimum",
    "authors" : [ "Rong Ge", "Jason D. Lee", "Tengyu Ma" ],
    "emails" : [ "rongge@cs.duke.edu.", "jasonlee@marshall.usc.edu.", "tengyu@cs.princeton.edu." ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Matrix completion is the problem of recovering a low rank matrix from partially observed entries. It has been widely used in collaborative filtering and recommender systems [Kor09, RS05], dimension reduction [CLMW11] and multi-class learning [AFSU07]. There has been extensive work on designing efficient algorithms for matrix completion with guarantees. One earlier line of results (see [Rec11, CT10, CR09] and the references therein) rely on convex relaxations. These algorithms achieve strong statistical guarantees, but are quite computationally expensive in practice.\nMore recently, there has been growing interest in analyzing non-convex algorithms for matrix completion [KMO10, JNS13, Har14, HW14, SL15, ZWL15, CW15]. Let M 2 Rd⇥d be the target matrix with rank r ⌧ d that we aim to recover, and let ⌦ = {(i, j) : Mi,j is observed} be the set of observed entries. These methods are instantiations of optimization algorithms applied to the objective1,\nf(X) = 1\n2\nX\n(i,j)2⌦\n⇥ Mi,j (XX>)i,j ⇤ 2 , (1.1)\nThese algorithms are much faster than the convex relaxation algorithms, which is crucial for their empirical success in large-scale collaborative filtering applications [Kor09].\n1In this paper, we focus on the symmetric case when the true M has a symmetric decomposition M = ZZT . Some of previous papers work on the asymmetric case when M = ZWT , which is harder than the symmetric case.\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nAll of the theoretical analysis for the nonconvex procedures require careful initialization schemes: the initial point should already be close to optimum. In fact, Sun and Luo [SL15] showed that after this initialization the problem is effectively strongly-convex, hence many different optimization procedures can be analyzed by standard techniques from convex optimization.\nHowever, in practice people typically use a random initialization, which still leads to robust and fast convergence. Why can these practical algorithms find the optimal solution in spite of the nonconvexity? In this work we investigate this question and show that the matrix completion objective has no spurious local minima. More precisely, we show that any local minimum X of objective function f(·) is also a global minimum with f(X) = 0, and recovers the correct low rank matrix M . Our characterization of the structure in the objective function implies that (stochastic) gradient descent from arbitrary starting point converge to a global minimum. This is because gradient descent converges to a local minimum [GHJY15, LSJR16], and every local minimum is also a global minimum."
    }, {
      "heading" : "1.1 Main results",
      "text" : "Assume the target matrix M is symmetric and each entry of M is observed with probability p independently 2. We assume M = ZZ> for some matrix Z 2 Rd⇥r. There are two known issues with matrix completion. First, the choice of Z is not unique since M = (ZR)(ZR)> for any orthonormal matrix Z. Our goal is to find one of these equivalent solutions.\nAnother issue is that matrix completion is impossible when M is “aligned” with standard basis. For example, when M is the identity matrix in its first r ⇥ r block, we will very likely be observing only 0 entries. To address this issue, we make the following standard assumption: Assumption 1. For any row Zi of Z, we have kZik 6 µ/ p d · kZkF . Moreover, Z has a bounded condition number max (Z)/ min (Z) = .\nThroughout this paper we think of µ and  as small constants, and the sample complexity depends polynomially on these two parameters. Also note that this assumption is independent of the choice of Z: all Z such that ZZT = M have the same row norms and Frobenius norm.\nThis assumption is similar to the “incoherence” assumption [CR09]. Our assumption is the same as the one used in analyzing non-convex algorithms [KMO10, SL15].\nWe enforce X to also satisfy this assumption by a regularizer\nf(X) = 1\n2\nX\n(i,j)2⌦\n⇥ Mi,j (XX>)i,j ⇤ 2 +R(X), (1.2)\nwhere R(X) is a function that penalizes X when one of its rows is too large. See Section 4 and Section A for the precise definition. Our main result shows that in this setting, the regularized objective function has no spurious local minimum: Theorem 1.1. [Informal] All local minimum of the regularized objective (1.1) satisfy XXT = ZZT = M when p > poly(, r, µ, log d)/d.\nCombined with the results in [GHJY15, LSJR16] (see more discussions in Section 1.2), we have, Theorem 1.2 (Informal). With high probability, stochastic gradient descent on the regularized objective (1.1) will converge to a solution X such that XXT = ZZT = M in polynomial time from any starting point. Gradient descent will converge to such a point with probability 1 from a random starting point.\nOur results are also robust to noise. Even if each entry is corrupted with Gaussian noise of standard deviation µ2kZk2F /d (comparable to the magnitude of the entry itself!), we can still guarantee that all the local minima satisfy kXXT ZZT kF 6 \" when p is large enough. See the discussion in Appendix B for results on noisy matrix completion.\n2The entries (i, j) and (j, i) are the same. With probability p we observe both entries and otherwise we observe neither.\nOur main technique is to show that every point that satisfies the first and second order necessary conditions for optimality must be a desired solution. To achieve this we use new ideas to analyze the effect of the regularizer and show how it is useful in modifying the first and second order conditions to exclude any spurious local minimum."
    }, {
      "heading" : "1.2 Related Work",
      "text" : "Matrix Completion. The earlier theoretical works on matrix completion analyzed the nuclear norm heuristic [Rec11, CT10, CR09]. This line of work has the cleanest and strongest theoretical guarantees; [CT10, Rec11] showed that if |⌦| & drµ2 log2 d the nuclear norm convex relaxation recovers the exact underlying low rank matrix. The solution can be computed via the solving a convex program in polynomial time. However the primary disadvantage of nuclear norm methods is their computational and memory requirements. The fastest known algorithms have running time O(d3) and require O(d2) memory, which are both prohibitive for moderate to large values of d. These concerns led to the development of the low-rank factorization paradigm of [BM03]; Burer and Monteiro proposed factorizing the optimization variable cM = XXT , and optimizing over X 2 Rd⇥r instead of cM 2 Rd⇥d . This approach only requires O(dr) memory, and a single gradient iteration takes time O(r|⌦|), so has much lower memory requirement and computational complexity than the nuclear norm relaxation. On the other hand, the factorization causes the optimization problem to be non-convex in X , which leads to theoretical difficulties in analyzing algorithms. Under incoherence and sufficient sample size assumptions, [KMO10] showed that well-initialized gradient descent recovers M . Similary, [HW14, Har14, JNS13] showed that well-initialized alternating least squares or block coordinate descent converges to M , and [CW15] showed that well-initialized gradient descent converges to M . [SL15, ZWL15] provided a more unified analysis by showing that with careful initialization many algorithms, including gradient descent and alternating least squres, succeed. [SL15] accomplished this by showing an analog of strong convexity in the neighborhood of the solution M .\nNon-convex Optimization. Recently, a line of work analyzes non-convex optimization by separating the problem into two aspects: the geometric aspect which shows the function has no spurious local minimum and the algorithmic aspect which designs efficient algorithms can converge to local minimum that satisfy first and (relaxed versions) of second order necessary conditions.\nOur result is the first that explains the geometry of the matrix completion objective. Similar geometric results are only known for a few problems: phase retrieval/synchronization, orthogonal tensor decomposition, dictionary learning [GHJY15, SQW15, BBV16]. The matrix completion objective requires different tools due to the sampling of the observed entries, as well as carefully managing the regularizer to restrict the geometry. Parallel to our work Bhojanapalli et al.[BNS16] showed similar results for matrix sensing, which is closely related to matrix completion. Loh and Wainwright [LW15] showed that for many statistical settings that involve missing/noisy data and non-convex regularizers, any stationary point of the non-convex objective is close to global optima; furthermore, there is a unique stationary point that is the global minimum under stronger assumptions [LW14].\nOn the algorithmic side, it is known that second order algorithms like cubic regularization [NP06] and trust-region [SQW15] algorithms converge to local minima that approximately satisfy first and second order conditions. Gradient descent is also known to converge to local minima [LSJR16] from a random starting point. Stochastic gradient descent can converge to a local minimum in polynomial time from any starting point [Pem90, GHJY15]. All of these results can be applied to our setting, implying various heuristics used in practice are guaranteed to solve matrix completion."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "Notations: For ⌦ ⇢ [d] ⇥ [d], let P ⌦ be the linear operator that maps a matrix A to P ⌦ (A), where P\n⌦ (A) has the same values as A on ⌦, and 0 outside of ⌦. We will use the following matrix norms: k · kF the frobenius norm, k · k spectral norm, |A|1 elementwise infinity norm, and |A|p!q = maxkxkp=1 kAkq. We use the shorthand kAk⌦ = kP⌦AkF . The trace inner product of two matrices is hA,Bi = tr(A>B), and\nmin (X), max (X) are the smallest and largest singular values of X . We also use Xi to denote the i-th row of a matrix X ."
    }, {
      "heading" : "2.1 Necessary conditions for Optimality",
      "text" : "Given an objective function f(x) : Rn ! R, we use rf(x) to denote the gradient of the function, and r2f(x) to denote the Hessian of the function (r2f(x) is an n⇥ n matrix where [r2f(x)]i,j =\n@2\n@xi@xj f(x)). It is well known that local minima of the function f(x) must satisfy some necessary conditions: Definition 2.1. A point x satisfies the first order necessary condition for optimality (later abbreviated as first order optimality condition) if rf(x) = 0. A point x satisfies the second order necessary condition for optimality (later abbreviated as second order optimality condition)if r2f(x) ⌫ 0.\nThese conditions are necessary for a local minimum because otherwise it is easy to find a direction where the function value decreases. We will also consider a relaxed second order necessary condition, where we only require the smallest eigenvalue of the Hessian r2f(x) to be not very negative: Definition 2.2. For ⌧ > 0, a point x satisfies the ⌧ -relaxed second order optimality condition, if r2f(x) ⌫ ⌧ · I .\nThis relaxation to the second order condition makes the conditions more robust, and allows for efficient algorithms. Theorem 2.3. [NP06, SQW15, GHJY15] If every point x that satisfies first order and ⌧ -relaxed second order necessary condition is a global minimum, then many optimization algorithms (cubic regularization, trust-region, stochastic gradient descent) can find the global minimum up to \" error in function value in time poly(1/\", 1/⌧, d)."
    }, {
      "heading" : "3 Proof Strategy: “simple” proofs are more generalizable",
      "text" : "In this section, we demonstrate the key ideas behind our analysis using the rank r = 1 case. In particular, we first give a “simple” proof for the fully observed case. Then we show this simple proof can be easily generalized to the random observation case. We believe that this proof strategy is applicable to other statistical problems involving partial/noisy observations. The proof sketches in this section are only meant to be illustrative and may not be fully rigorous in various places. We refer the readers to Section 4 and Section A for the complete proofs.\nIn the rank r = 1 case, we assume M = zz>, where kzk = 1, and kzk1 6 µpd . Let \" ⌧ 1 be the target accuracy that we aim to achieve in this section and let p = poly(µ, log d)/(d\").\nFor simplicity, we focus on the following domain B of incoherent vectors where the regularizer R(x) vanishes,\nB = ⇢ x : kxk1 < 2µp d . (3.1)\nInside this domain B, we can restrict our attention to the objective function without the regularizer, defined as,\ng̃(x) = 1\n2\n· kP ⌦ (M xx>)k2F . (3.2)\nThe global minima of g̃(·) are z and z with function value 0. Our goal of this section is to (informally) prove that all the local minima of g̃(·) are O( p \")-close to ±z. In later section we will formally prove that the only local minima are ±z. Lemma 3.1 (Partial observation case, informally stated). Under the setting of this section, in the domain B, all local mimina of the function g̃(·) are O( p \")-close to ±z.\nIt turns out to be insightful to consider the full observation case when ⌦ = [d]⇥[d]. The corresponding objective is\ng(x) = 1\n2\n· kM xx>k2F . (3.3)\nObserve that g̃(x) is a sampled version of the g(x), and therefore we expect that they share the same geometric properties. In particular, if g(x) does not have spurious local minima then neither does g̃(x).\nLemma 3.2 (Full observation case, informally stated). Under the setting of this section, in the domain B, the function g(·) has only two local minima {±z} .\nBefore introducing the “simple” proof, let us first look at a delicate proof that does not generalize well.\nDifficult to Generalize Proof of Lemma 3.2. We compute the gradient and Hessian of g(x), rg(x) = Mx kxk2x, r2g(x) = 2xx> M + kxk2 · I .Therefore, a critical point x satisfies rg(x) = Mx kxk2x = 0, and thus it must be an eigenvector of M and kxk2 is the corresponding eigenvalue. Next, we prove that the hessian is only positive definite at the top eigenvector . Let x be an eigenvector with eigenvalue = kxk2, and is strictly less than the top eigenvalue ⇤. Let z be the top eigenvector. We have that hz,r2g(x)zi = hz,Mzi+ kxk2 = ⇤ + < 0, which shows that x is not a local minimum. Thus only z can be a local minimizer, and it is easily verified that r2g(z) is indeed positive definite.\nThe difficulty of generalizing the proof above to the partial observation case is that it uses the properties of eigenvectors heavily. Suppose we want to imitate the proof above for the partial observation case, the first difficulty is how to solve the equation g̃(x) = P\n⌦ (M xx>)x = 0. Moreover, even if we could have a reasonable approximation for the critical points (the solution of rg̃(x) = 0), it would be difficult to examine the Hessian of these critical points without having the orthogonality of the eigenvectors.\n“Simple” and Generalizable proof. The lessons from the subsection above suggest us find an alternative proof for the full observation case which is generalizable. The alternative proof will be simple in the sense that it doesn’t use the notion of eigenvectors and eigenvalues. Concretely, the key observation behind most of the analysis in this paper is the following,\nProofs that consist of inequalities that are linear in 1 ⌦ are often easily generalizable to partial observation case.\nHere statements that are linear in 1 ⌦ mean the statements of the form P ij 1(i,j)2⌦Tij 6 a. We will call these kinds of proofs “simple” proofs in this section. Roughly speaking, the observation follows from the law of large numbers — Suppose Tij , (i, j) 2 [d]⇥ [d] is a sequence of bounded real numbers, then the sampled sum P\n(i,j)2⌦ Tij = P i,j 1(i,j)2⌦Tij is an accurate estimate of the sum p P\ni,j Tij , when the sampling probability p is relatively large. Then, the mathematical implications of p P Tij 6 a are expected to be similar to the implications of P\n(i,j)2⌦ Tij 6 a, up to some small error introduced by the approximation. To make this concrete, we give below informal proofs for Lemma 3.2 and Lemma 3.1 that only consists of statements that are linear in 1\n⌦ . Readers will see that due to the linearity, the proof for the partial observation case (shown on the right column) is a direct generalization of the proof for the full observation case (shown on the left column) via concentration inequalities (which will be discussed more at the end of the section)."
    }, {
      "heading" : "A “simple” proof for Lemma 3.2.",
      "text" : "Claim 1f. Suppose x 2 B satisfies rg(x) = 0, then hx, zi2 = kxk4.\nProof. We have,\nrg(x) = (zz> xx>)x = 0 ) hx,rg(x)i = hx, (zz> xx>)xi = 0\n(3.4)\n) hx, zi2 = kxk4\nIntuitively, this proof says that the norm of a critical point x is controlled by its correlation with z. Here at the lasa sampling version of the f the lasa sampling ver the f the lasa sampling vesio\nGeneralization to Lemma 3.1. Claim 1p. Suppose x 2 B satisfies rg̃(x) = 0, then hx, zi2 = kxk4 \".\nProof. Imitating the proof on the left, we have\nrg̃(x) = P⌦(zz> xx>)x = 0 ) hx,rg̃(x)i = hx, P⌦(zz> xx>)xi = 0\n(3.5)\n) hx, zi2 > kxk4 \" The last step uses the fact that equation (3.4) and (3.5) are approximately equal up to scaling factor p for any x 2 B, since (3.5) is a sampled version of (3.4).\nClaim 2f. If x 2 B has positive Hessian r2g(x) ⌫ 0, then kxk2 > 1/3. Proof. By the assumption on x, we have that hz,r2g(x)zi > 0. Calculating the quadratic form of the Hessian (see Proposition 4.1 for details),\nhz,r2g(x)zi = kzx> + xz>k2\n2z>(zz> xx>)z > 0aaaaaa (3.6) ) kxk2 + 2hz, xi2 > 1 ) kxk2 > 1/3 (since hz, xi2 6 kxk2)\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\nClaim 2p. If x 2 B has positive Hessian r2g̃(x) ⌫ 0, then kxk2 > 1/3 \". Proof. Imitating the proof on the left, calculating the quadratic form over the Hessian at z (see Proposition 4.1) , we have aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\nhz,r2g̃(x)zi = kP⌦(zx> + xz>)k2\n2z>P⌦(zz> xx>)z > 0 (3.7) ) · · · · · · (same step as the left) ) kxk2 > 1/3 \"\nHere we use the fact that hz,r2g̃(x)zi ⇡ phz,r2g(x)zi for any x 2 B.\nWith these two claims, we are ready to prove Lemma 3.2 and 3.1 by using another step that is linear in 1\n⌦\n.\nProof of Lemma 3.2. By Claim 1f and 2f, we have x satisfies hx, zi2 > kxk4 > 1/9. Moreover, we have that rg(x) = 0 implies\nhz,rg(x)i = hz, (zz> xx>)xi = 0 (3.8)\n) hx, zi(1 kxk2) = 0 ) kxk2 = 1 (by hx, zi2 > 1/9)\nThen by Claim 1f again we obtain hx, zi2 = 1, and therefore x = ±z. aaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\nProof of Lemma 3.1. By Claim 1p and 2p, we have x satisfies hx, zi2 > kxk4 > 1/9 O(\"). Moreover, we have that rg̃(x) = 0 implies\nhz,rg̃(x)i = hz, P ⌦ (zz> xx>)xi = 0 (3.9)\n) · · · · · · (same step as the left) ) kxk2 = 1±O(\") (same step as the left)\nSince (3.9) is the sampled version of equation (3.8), we expect they lead to the same conclusion up to some approximation. Then by Cl im 1p again we obt in hx, zi2 = 1±O(\"), and therefore x is O( p \")-close to either of ±z.\nSubtleties regarding uniform convergence. In the proof sketches above, our key idea is to use concentration inequalities to link the full observation objective g(x) with the partial observation counterpart. However, we require a uniform convergence result. For example, we need a statement like “w.h.p over the choice of ⌦, equation (3.4) and (3.5) are similar to each other up to scaling”. This type of statement is often only true for x inside the incoherent ball B. The fix to this is the regularizer. For non-incoherent x, we will use a different argument that uses the property of the regularizer. This is besides the main proof strategy of this section and will be discussed in subsequent sections."
    }, {
      "heading" : "4 Warm-up: Rank-1 Case",
      "text" : "In this section, using the general proof strategy described in previous section, we provide a formal proof for the rank-1 case. In subsection 4.1, we formally work out the proof sketches of Section 3 inside the incoherent ball. The rest of the proofs is deferred to supplementary material.\nIn the rank-1 case, the objective function simplifies to,\nf(x) = 1\n2\nkP ⌦ (M xx>)k2F + R(x) . (4.1)\nHere we use the the regularization R(x)\nR(x) = d X\ni=1\nh(xi), and h(t) = (|t| ↵)4 It>↵ .\nThe parameters and ↵ will be chosen later as in Theorem 4.2. We will choose ↵ > 10µ/ p d so that R(x) = 0 for incoherent x, and thus it only penalizes coherent x. Moreover, we note R(x) has Lipschitz second order derivative. 3\nWe first state the optimality conditions, whose proof is deferred to Appendix A. Proposition 4.1. The first order optimality condition of objective (4.1) is,\n2P ⌦\n(M xx>)x = rR(x) , (4.2)\nand the second order optimality condition requires:\n8v 2 Rd, kP ⌦ (vx> + xv>)k2F + v>r2R(x)v > 2v>P⌦(M xx>)v . (4.3) Moreover, The ⌧ -relaxed second order optimality condition requires\n8v 2 Rd, kP ⌦ (vx> + xv>)k2F + v>r2R(x)v > 2v>P⌦(M xx>)v ⌧kvk2 . (4.4)\nWe give the precise version of Theorem 1.1 for the rank-1 case.\nTheorem 4.2. For p > cµ6 log1.5 dd where c is a large enough absolute constant, set ↵ = 10µ p\n1/d and > µ2p/↵2.Then, with high probability over the randomness of ⌦, the only points in Rd that satisfy both first and second order optimality conditions (or ⌧ -relaxed optimality conditions with ⌧ < 0.1p) are z and z.\nIn the rest of this section, we will first prove that when x is constrained to be incoherent (and hence the regularizer is 0 and concentration is straightforward) and satisfies the optimality conditions, then x has to be z or z. Then we go on to explain how the regularizer helps us to change the geometry of those points that are far away from z so that we can rule out them from being local minimum. For simplicity, we will focus on the part that shows a local minimum x must be close enough to z. Lemma 4.3. In the setting of Theorem 4.2, suppose x satisfies the first-order and second-order optimality condition (4.2) and (4.3). Then when p is defined as in Theorem 4.2,\nxx> zz> 2 F 6 O(\") .\nwhere \" = µ3(pd) 1/2.\nThis turns out to be the main challenge. Once we proved x is close, we can apply the result of Sun and Luo [SL15] (see Lemma C.1), and obtain Theorem 4.2."
    }, {
      "heading" : "4.1 Handling incoherent x",
      "text" : "To demonstrate the key idea, in this section we restrict our attention to the subset of Rd which contains incoherent x with `\n2\nnorm bounded by 1, that is, we consider,\nB = ⇢ x : kxk1 6 2µp d , kxk 6 1 . (4.5)\nNote that the desired solution z is in B, and the regularization R(x) vanishes inside B. The following lemmas assume x satisfies the first and second order optimality conditions, and deduce a sequence of properties that x must satisfy. Lemma 4.4. Under the setting of Theorem 4.2 , with high probability over the choice of ⌦, for any x 2 B that satisfies second-order optimality condition (4.3) we have,\nkxk2 > 1/4. The same is true if x 2 B only satisfies ⌧ -relaxed second order optimality condition for ⌧ 6 0.1p.\nProof. We plug in v = z in the second-order optimality condition (4.3), and obtain that\nP ⌦\n(zx> + xz>) 2 F > 2z>P ⌦ (M xx>)z . (4.6) 3This is the main reason for us to choose 4-th power instead of 2-nd power.\nIntuitively, when restricted to ⌦, the squared Frobenius on the LHS and the quadratic form on the RHS should both be approximately a p fraction of the unrestricted case. In fact, both LHS and RHS can be written as the sum of terms of the form hP\n⌦ (uvT ), P ⌦ (stT )i, because\nP ⌦\n(zx> + xz>) 2\nF = 2hP ⌦ (zxT ), P ⌦ (zxT )i+ 2hP ⌦ (zxT ), P ⌦ (xzT )i 2z>P\n⌦ (M xx>)z = 2hP ⌦ (zzT ), P ⌦ (zzT )i 2hP ⌦ (xxT ), P ⌦ (zzT )i.\nTherefore we can use concentration inequalities (Theorem D.1), and simplify the equation\nLHS of (4.6) = p zx> + xz> 2\nF ±O(\np\npdkxk21kzk21kxk2kzk2) = 2pkxk2kzk2 + 2phx, zi2 ±O(p\") , (Since x, z 2 B)\nwhere \" = O(µ2 q\nlog d pd ). Similarly, by Theorem D.1 again, we have\nRHS of (4.6) = 2 hP ⌦ (zz>), P ⌦ (zz>)i hP ⌦ (xx>), P ⌦ (zz>)i\n(Since M = zz>)\n= 2pkzk4 2phx, zi2 ±O(p\") (by Theorem D.1 and x, z 2 B)\n(Note that even we use the ⌧ -relaxed second order optimality condition, the RHS only becomes 1.99pkzk4 2phx, zi2 ±O(p\") which does not effect the later proofs.) Therefore plugging in estimates above back into equation (4.6), we have that\n2pkxk2kzk2 + 2phx, zi2 ±O(p\") > 2kzk4 2hx, zi2 ±O(p\") ,\nwhich implies that 6pkxk2kzk2 > 2pkxk2kzk2 + 4phx, zi2 > 2pkzk4 O(p\"). Using kzk2 = 1, and \" being sufficiently small, we complete the proof.\nNext we use first order optimality condition to pin down another property of x – it has to be close to z after scaling. Note that this doesn’t mean directly that x has to be close to z since x = 0 also satisfies first order optimality condition (and therefore the conclusion (4.7) below).\nLemma 4.5. With high probability over the randomness of ⌦, for any x 2 B that satisfies first-order optimality condition (4.2), we have that x also satisfies\nhz, xiz kxk2x 6 O(\") . (4.7)\nwhere \" = ˜O(µ3(pd) 1/2).\nFinally we combine the two optimality conditions and show equation (4.7) implies xxT must be close to zzT .\nLemma 4.6. Suppose vector x satisfies that kxk2 > 1/4, and that hz, xiz kxk2x 6 . Then for 2 (0, 0.1),\nxx> zz> 2 F 6 O( ) ."
    }, {
      "heading" : "5 Conclusions",
      "text" : "Although the matrix completion objective is non-convex, we showed the objective function has very nice properties that ensures the local minima are also global. This property gives guarantees for many basic optimization algorithms. An important open problem is the robustness of this property under different model assumptions: Can we extend the result to handle asymmetric matrix completion? Is it possible to add weights to different entries (similar to the settings studied in [LLR16])? Can we replace the objective function with a different distance measure rather than Frobenius norm (which is related to works on 1-bit matrix sensing [DPvdBW14])? We hope this framework of analyzing the geometry of objective function can be applied to other problems."
    } ],
    "references" : [ {
      "title" : "Uncovering shared structures in multiclass classification",
      "author" : [ "Yonatan Amit", "Michael Fink", "Nathan Srebro", "Shimon Ullman" ],
      "venue" : "In Proceedings of the 24th international conference on Machine learning,",
      "citeRegEx" : "Amit et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Amit et al\\.",
      "year" : 2007
    }, {
      "title" : "On the low-rank approach for semidefinite programs arising in synchronization and community detection",
      "author" : [ "Afonso S Bandeira", "Nicolas Boumal", "Vladislav Voroninski" ],
      "venue" : "arXiv preprint arXiv:1602.04426,",
      "citeRegEx" : "Bandeira et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Bandeira et al\\.",
      "year" : 2016
    }, {
      "title" : "A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization",
      "author" : [ "Samuel Burer", "Renato DC Monteiro" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Burer and Monteiro.,? \\Q2003\\E",
      "shortCiteRegEx" : "Burer and Monteiro.",
      "year" : 2003
    }, {
      "title" : "Global Optimality of Local Search for Low Rank Matrix Recovery",
      "author" : [ "S. Bhojanapalli", "B. Neyshabur", "N. Srebro" ],
      "venue" : null,
      "citeRegEx" : "Bhojanapalli et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Bhojanapalli et al\\.",
      "year" : 2016
    }, {
      "title" : "Robust principal component analysis",
      "author" : [ "Emmanuel J Candès", "Xiaodong Li", "Yi Ma", "John Wright" ],
      "venue" : "Journal of the ACM (JACM),",
      "citeRegEx" : "Candès et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Candès et al\\.",
      "year" : 2011
    }, {
      "title" : "Exact matrix completion via convex optimization",
      "author" : [ "Emmanuel J Candès", "Benjamin Recht" ],
      "venue" : "Foundations of Computational mathematics,",
      "citeRegEx" : "Candès and Recht.,? \\Q2009\\E",
      "shortCiteRegEx" : "Candès and Recht.",
      "year" : 2009
    }, {
      "title" : "The power of convex relaxation: Near-optimal matrix completion",
      "author" : [ "Emmanuel J Candès", "Terence Tao" ],
      "venue" : "Information Theory, IEEE Transactions on,",
      "citeRegEx" : "Candès and Tao.,? \\Q2010\\E",
      "shortCiteRegEx" : "Candès and Tao.",
      "year" : 2010
    }, {
      "title" : "Fast low-rank estimation by projected gradient descent: General statistical and algorithmic guarantees",
      "author" : [ "Yudong Chen", "Martin J Wainwright" ],
      "venue" : "arXiv preprint arXiv:1509.03025,",
      "citeRegEx" : "Chen and Wainwright.,? \\Q2015\\E",
      "shortCiteRegEx" : "Chen and Wainwright.",
      "year" : 2015
    }, {
      "title" : "1-bit matrix completion",
      "author" : [ "Mark A Davenport", "Yaniv Plan", "Ewout van den Berg", "Mary Wootters" ],
      "venue" : "Information and Inference,",
      "citeRegEx" : "Davenport et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Davenport et al\\.",
      "year" : 2014
    }, {
      "title" : "Escaping from saddle points—online stochastic gradient for tensor decomposition",
      "author" : [ "Rong Ge", "Furong Huang", "Chi Jin", "Yang Yuan" ],
      "venue" : null,
      "citeRegEx" : "Ge et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Ge et al\\.",
      "year" : 2015
    }, {
      "title" : "Understanding alternating minimization for matrix completion",
      "author" : [ "Moritz Hardt" ],
      "venue" : "In FOCS 2014. IEEE,",
      "citeRegEx" : "Hardt.,? \\Q2014\\E",
      "shortCiteRegEx" : "Hardt.",
      "year" : 2014
    }, {
      "title" : "A tail inequality for quadratic forms of subgaussian random vectors",
      "author" : [ "Daniel Hsu", "Sham M Kakade", "Tong Zhang" ],
      "venue" : "Electron. Commun. Probab,",
      "citeRegEx" : "Hsu et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Hsu et al\\.",
      "year" : 2012
    }, {
      "title" : "Fast matrix completion without the condition number",
      "author" : [ "Moritz Hardt", "Mary Wootters" ],
      "venue" : "COLT",
      "citeRegEx" : "Hardt and Wootters.,? \\Q2014\\E",
      "shortCiteRegEx" : "Hardt and Wootters.",
      "year" : 2014
    }, {
      "title" : "Sums of random Hermitian matrices and an inequality by Rudelson",
      "author" : [ "R. Imbuzeiro Oliveira" ],
      "venue" : "ArXiv e-prints,",
      "citeRegEx" : "Oliveira.,? \\Q2010\\E",
      "shortCiteRegEx" : "Oliveira.",
      "year" : 2010
    }, {
      "title" : "Low-rank matrix completion using alternating minimization",
      "author" : [ "Prateek Jain", "Praneeth Netrapalli", "Sujay Sanghavi" ],
      "venue" : "In Proceedings of the forty-fifth annual ACM symposium on Theory of computing,",
      "citeRegEx" : "Jain et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Jain et al\\.",
      "year" : 2013
    }, {
      "title" : "Matrix completion from a few entries",
      "author" : [ "Raghunandan H Keshavan", "Andrea Montanari", "Sewoong Oh" ],
      "venue" : "Information Theory, IEEE Transactions on,",
      "citeRegEx" : "Keshavan et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Keshavan et al\\.",
      "year" : 2010
    }, {
      "title" : "The bellkor solution to the netflix grand prize",
      "author" : [ "Yehuda Koren" ],
      "venue" : "Netflix prize documentation,",
      "citeRegEx" : "Koren.,? \\Q2009\\E",
      "shortCiteRegEx" : "Koren.",
      "year" : 2009
    }, {
      "title" : "Recovery guarantee of weighted low-rank approximation via alternating minimization",
      "author" : [ "Yuanzhi Li", "Yingyu Liang", "Andrej Risteski" ],
      "venue" : "arXiv preprint arXiv:1602.02262,",
      "citeRegEx" : "Li et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Gradient descent converges to minimizers",
      "author" : [ "Jason D Lee", "Max Simchowitz", "Michael I Jordan", "Benjamin Recht" ],
      "venue" : "University of California, Berkeley,",
      "citeRegEx" : "Lee et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2016
    }, {
      "title" : "Support recovery without incoherence: A case for nonconvex regularization",
      "author" : [ "Po-Ling Loh", "Martin J Wainwright" ],
      "venue" : "arXiv preprint arXiv:1412.5632,",
      "citeRegEx" : "Loh and Wainwright.,? \\Q2014\\E",
      "shortCiteRegEx" : "Loh and Wainwright.",
      "year" : 2014
    }, {
      "title" : "Regularized m-estimators with nonconvexity: statistical and algorithmic theory for local optima",
      "author" : [ "Po-Ling Loh", "Martin J. Wainwright" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Loh and Wainwright.,? \\Q2015\\E",
      "shortCiteRegEx" : "Loh and Wainwright.",
      "year" : 2015
    }, {
      "title" : "Cubic regularization of Newton method and its global performance",
      "author" : [ "Yurii Nesterov", "Boris T Polyak" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "Nesterov and Polyak.,? \\Q2006\\E",
      "shortCiteRegEx" : "Nesterov and Polyak.",
      "year" : 2006
    }, {
      "title" : "Nonconvergence to unstable points in urn models and stochastic approximations",
      "author" : [ "Robin Pemantle" ],
      "venue" : "The Annals of Probability,",
      "citeRegEx" : "Pemantle.,? \\Q1990\\E",
      "shortCiteRegEx" : "Pemantle.",
      "year" : 1990
    }, {
      "title" : "A simpler approach to matrix completion",
      "author" : [ "Benjamin Recht" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Recht.,? \\Q2011\\E",
      "shortCiteRegEx" : "Recht.",
      "year" : 2011
    }, {
      "title" : "Fast maximum margin matrix factorization for collaborative prediction",
      "author" : [ "Jasson DM Rennie", "Nathan Srebro" ],
      "venue" : "In Proceedings of the 22nd international conference on Machine learning,",
      "citeRegEx" : "Rennie and Srebro.,? \\Q2005\\E",
      "shortCiteRegEx" : "Rennie and Srebro.",
      "year" : 2005
    }, {
      "title" : "Guaranteed matrix completion via nonconvex factorization",
      "author" : [ "Ruoyu Sun", "Zhi-Quan Luo" ],
      "venue" : "In Foundations of Computer Science (FOCS),",
      "citeRegEx" : "Sun and Luo.,? \\Q2015\\E",
      "shortCiteRegEx" : "Sun and Luo.",
      "year" : 2015
    }, {
      "title" : "When are nonconvex problems not scary",
      "author" : [ "Ju Sun", "Qing Qu", "John Wright" ],
      "venue" : "arXiv preprint arXiv:1510.06096,",
      "citeRegEx" : "Sun et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2015
    }, {
      "title" : "A nonconvex optimization framework for low rank matrix estimation",
      "author" : [ "Tuo Zhao", "Zhaoran Wang", "Han Liu" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Zhao et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "Matrix completion is a basic machine learning problem that has wide applications, especially in collaborative filtering and recommender systems. Simple non-convex optimization algorithms are popular and effective in practice. Despite recent progress in proving various non-convex algorithms converge from a good initial point, it remains unclear why random or arbitrary initialization suffices in practice. We prove that the commonly used non-convex objective function for positive semidefinite matrix completion has no spurious local minima – all local minima must also be global. Therefore, many popular optimization algorithms such as (stochastic) gradient descent can provably solve positive semidefinite matrix completion with arbitrary initialization in polynomial time. The result can be generalized to the setting when the observed entries contain noise. We believe that our main proof strategy can be useful for understanding geometric properties of other statistical problems involving partial or noisy observations.",
    "creator" : null
  }
}