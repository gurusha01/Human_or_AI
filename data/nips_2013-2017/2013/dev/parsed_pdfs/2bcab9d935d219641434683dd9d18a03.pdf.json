{
  "name" : "2bcab9d935d219641434683dd9d18a03.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Demixing odors — fast inference in olfaction",
    "authors" : [ "Agnieszka Grabska-Barwińska", "Peter E. Latham" ],
    "emails" : [ "agnieszka@gatsby.ucl.ac.uk", "jeff@gatsby.ucl.ac.uk", "Alexandre.Pouget@unige.ch", "pel@gatsby.ucl.ac.uk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "The olfactory system faces a difficult inference problem: it has to determine what odors are present based on the distributed activation of its receptor neurons. Here we derive neural implementations of two approximate inference algorithms that could be used by the brain. One is a variational algorithm (which builds on the work of Beck. et al., 2012), the other is based on sampling. Importantly, we use a more realistic prior distribution over odors than has been used in the past: we use a “spike and slab” prior, for which most odors have zero concentration. After mapping the two algorithms onto neural dynamics, we find that both can infer correct odors in less than 100 ms. Thus, at the behavioral level, the two algorithms make very similar predictions. However, they make different assumptions about connectivity and neural computations, and make different predictions about neural activity. Thus, they should be distinguishable experimentally. If so, that would provide insight into the mechanisms employed by the olfactory system, and, because the two algorithms use very different coding strategies, that would also provide insight into how networks represent probabilities."
    }, {
      "heading" : "1 Introduction",
      "text" : "The problem faced by the sensory system is to infer the underlying causes of a set of input spike trains. For the olfactory system, the input spikes come from a few hundred different types of olfactory receptor neurons, and the problem is to infer which odors caused them. As there are more than 10,000 possible odors, and more than one can be present at a time, the search space for mixtures of odors is combinatorially large. Nevertheless, olfactory processing is fast: organisms can typically determine what odors are present in a few hundred ms.\nHere we ask how organisms could do this. Since our focus is on inference, not learning: we assume that the olfactory system has learned both the statistics of odors in the world and the mapping from those odors to olfactory receptor neuron activity. We then choose a particular model for both, and compute, via Bayes rule, the full posterior distribution. This distribution is, however, highly complex: it tells us, for example, the probability of coffee at a concentration of 14 parts per million (ppm), and no bacon, and a rose at 27 ppm, and acetone at 3 ppm, and no apples and so on, where the “so on” is a list of thousands more odors. It is unlikely that such detailed information is useful to an organism. It is far more likely that organisms are interested in marginal probabilities, such as whether or not coffee is present independent of all the other odors. Unfortunately, even though we can write down the full posterior, calculation of marginal probabilities is intractable due to the\nsum over all possible combinations of odors: the number of terms in the sum is exponential in the number of odors.\nWe must, therefore, consider approximate algorithms. Here we consider two: a variational approximation, which naturally generates approximate posterior marginals, and sampling from the posterior, which directly gives us the marginals. Our main goal is to determine which, if either, is capable of performing inference on ecologically relevant timescales using biologically plausible circuits. We begin by introducing a generative model for spikes in a population of olfactory receptor neurons. We then describe the variational and sampling inference schemes. Both descriptions lead very naturally to network equations. We simulate those equations, and find that both the variational and sampling approaches work well, and require less than 100 ms to converge to a reasonable solution. Therefore, from the point of view of speed and accuracy – things that can be measured from behavioral experiments – it is not possible to rule out either of them. However, they do make different predictions about activity, and so it should be possible to tell them apart from electrophysiological experiments. They also make different predictions about the neural representation of probability distributions. If one or the other could be corroborated experimentally, that would provide valuable insight into how the brain (or at least one part of the brain) codes for probabilities [1]."
    }, {
      "heading" : "2 The generative model for olfaction",
      "text" : "The generative model consists of a probabilistic mapping from odors (which for us are a high level percepts, such as coffee or bacon, each of which consists of a mixture of many different chemicals) to odorant receptor neurons, and a prior over the presence or absence of odors and their concentrations. It is known that each odor, by itself, activates a different subset of the olfactory receptor neurons; typically on the order of 10%-30% [2]. Here we assume, for simplicity, that activation is linear, for which the activity of odorant receptor neuron i, denoted ri is linearly related to the concentrations, cj of the various odors which are present in a given olfactory scene, plus some background rate, r0. Assuming Poisson noise, the response distribution has the form\nP (r|c) = ∏ i\n( r0 + ∑ j wijcj )ri ri! e− ( r0+ ∑ j wijcj ) . (2.1)\nIn a nutshell, ri is Poisson with mean r0 + ∑ j wijcj .\nIn contrast to previous work [3], which used a smooth prior on the concentrations, here we use a spike and slab prior. With this prior, there is a finite probability that the concentration of any particular odor is zero. This prior is much more realistic than a smooth one, as it allows only a small number of odors (out of ∼10,000) to be present in any given olfactory scene. It is modeled by introducing a binary variable, sj , which is 1 if odor j is present and 0 otherwise. For simplicity we assume that odors are independent and statistically homogeneous,\nP (c|s) = ∏ j (1− sj)δ(cj) + sjΓ(cj |α1, β1) (2.2a)\nP (s) = ∏ j πsj (1− π)1−sj (2.2b)\nwhere δ(c) is the Dirac delta function and Γ(c|α, β) is the Gamma distribution: Γ(c|α, β) = βαcα−1e−βc/Γ(α) with Γ(α) the ordinary Gamma function, Γ(α) = ∫∞ 0 dxxα−1e−x."
    }, {
      "heading" : "3 Inference",
      "text" : ""
    }, {
      "heading" : "3.1 Variational inference",
      "text" : "Because of the delta-function in the prior, performing efficient variational inference in our model is difficult. Therefore, we smooth the delta-function, and replace it with a Gamma distribution. With this manipulation, the approximate (with respect to the true model, Eq. (2.2a)) prior on c is\nPvar(c|s) = ∏ j (1− sj)Γ(cj |α0, β0) + sjΓ(cj |α1, β1) . (3.1)\nThe approximate prior allows absent odors to have nonzero concentration. We can partially compensate for that by setting the background firing rate, r0 to zero, and choosing α0 and β0 such that the effective background firing rate (due to the small concentration when sj = 0) is equal to r0; see Sec. 4.\nAs is typical in variational inference, we use a factorized approximate distribution. This distribution, denoted Q(c, s|r),was set to Q(c|s, r)Q(s|r) where\nQ(c|s, r) = ∏ j (1− sj)Γ(cj |α0j , β0j) + sjΓ(cj |α1j , β1j) (3.2a)\nQ(s|r) = ∏ j λ sj j (1− λj) 1−sj . (3.2b)\nIntroducing auxiliary variables, as described in Supplementary Material, and minimizing the Kullback-Leibler distance between Q and the true posterior augmented by the auxiliary variables leads to a set of nonlinear equations for the parameters of Q. To simplify those equations, we set α1 to α0 + 1, resulting in\nα0j = α0 + ∑ i riwijFj(λj , α0j)∑ k=1 wikFk(λk, α0k)\n(3.3a)\nLj ≡ log λj\n1− λj = L0j + log(α0j/α0) + α0j log(β0j/β1j) (3.3b)\nwhere\nL0j ≡ log π\n1− π − α0 log (β0/β1) + log(β1/β1j) (3.3c)\nFj(λ, α) ≡ exp [(1− λ)(Ψ(α)− log β0j) + λ(Ψ(α+ 1)− log β1j)] (3.3d)\nand Ψ(α) ≡ d log Γ(α)/dα is the digamma function. The remaining two parameters, β0j and β1j , are fixed by our choice of weights and priors: β0j = β0 + ∑ i wij and β1j = β1 + ∑ i wij .\nTo solve Eqs. (3.3a-b) in a way that mimics the kinds of operations that could be performed by neuronal circuitry, we write down a set of differential equations that have fixed points satisfying Eq. (3.3),\nτρ dρi dt = ri − ρi ∑ j wijFj(λj , α0j) (3.4a)\nτα dα0j dt = α0 + Fj(λj , α0j) ∑ i ρiwij − α0j (3.4b)\nτλ dLj dt = L0j + log(α0j/α0) + α0j log(β0j/β1j)− Lj (3.4c)\nNote that we have introduced an additional variable, ρi. This variable is proportional to ri, but modulated by divisive inhibition: the fixed point of Eq. (3.4a) is\nρi = ri∑\nk wikFk(λk, α0k) . (3.5)\nClose scrutiny of Eqs. (3.4) and (3.3d) might raise some concerns: (i) ρ and α are reciprocally and symmetrically connected; (ii) there are multiplicative interactions between F (λj , α0j) and ρ; and (iii) the neurons need to compute nontrivial nonlinearities, such as logarithm, exponent and a mixture of digamma functions. However: (i) reciprocal and symmetric connectivity exists in the early olfactory processing system [4, 5, 6]; (ii) although multiplicative interactions are in general not easy for neurons, the divisive normalization (Eq. (3.5)) has been observed in the olfactory bulb [7], and (iii) the nonlinearities in our algorithms are not extreme (the logarithm is defined only on the positive range (α0j > α0, Eq. (3.3a)), and Fj(λ, α) function is a soft-thresholded linear function; see Fig. S1). Nevertheless, a realistic model would have to approximate Eqs. (3.4a-c), and thus degrade slightly the quality of the inference."
    }, {
      "heading" : "3.2 Sampling",
      "text" : "The second approximate algorithm we consider is sampling. To sample efficiently from our model, we introduce a new set of variables, c̃j ,\ncj = c̃jsj . (3.6)\nWhen written in terms of c̃j rather than cj , the likelihood becomes\nP (r|c̃, s) = ∏ i\n(r0 + ∑ j wij c̃jsj) ri ri! e− ( r0+ ∑ j wij c̃jsj ) . (3.7)\nBecause the value of c̃j is unconstrained when sj = 0, we have complete freedom in choosing P (c̃j |sj = 0), the piece of the prior corresponding to the absence of odor j. It is convenient to set it to the same prior we use when sj = 1, which is Γ(c̃j |α1, β1). With this choice, c̃ is independent of s, and the prior over c̃ is simply\nP (c̃) = ∏ j Γ(c̃j |α1, β1) . (3.8)\nThe prior over s, Eq. (2.2b), remains the same. Note that this set of manipulations does not change the model: the likelihood doesn’t change, since by definition c̃jsj = cj ; when sj = 1, c̃j is drawn from the correct prior; and when sj = 0, c̃j does not appear in the likelihood.\nTo sample from this distribution we use Langevin sampling on c and Gibbs sampling on s. The former is standard,\nτc dc̃j dt = ∂ logP (c̃, s|r) ∂c̃j + ξ(t) = α1 − 1 c̃j − β1 + sj ∑ i wij ( ri r0 + ∑ k wik c̃ksk − 1 ) + ξ(t)\n(3.9)\nwhere ξ(t) is delta-correlated white noise with variance 2τ : 〈ξj(t)ξj′(t′)〉 = 2τδ(t− t′)δjj′ . Because the ultimate goal is to implement this algorithm in networks of neurons, we need a Gibbs sampler that runs asynchronously and in real time. This can be done by discretizing time into steps of length dt, and computing the update probability for each odor on each time step. This is a valid Gibbs sampler only in the limit dt→ 0, where no more than one odor can be updated per time step that’s the limit of interest here. The update rule is\nT (s′j |c̃, s, r) = ν0dtP (s′j |c̃, s, r) + (1− ν0dt) ∆(s′j − sj) (3.10)\nwhere s′j ≡ sj(t + dt), s and c̃ should be evaluated at time t, and ∆(s) is the Kronecker delta: ∆(s) = 1 if s = 0 and 0 otherwise. As is straightforward to show, this update rule has the correct equilibrium distribution in the limit dt→ 0 (see Supplementary Material). Computing P (s′j = 1|c̃, s, r) is straightforward, and we find that\nP (s′j = 1|c̃, s, r) = 1\n1 + exp[−Φj ]\nΦj = log π 1− π + ∑ i\n[ ri log r0 + ∑ k 6=j wik c̃ksk + wij c̃j\nr0 + ∑ k 6=j wik c̃ksk\n− c̃jwij ] . (3.11)\nEquations (3.9) and (3.11) raise almost exactly the same concerns that we saw for the variational approach: (i) c and s are reciprocally and symmetrically connected; (ii) there are multiplicative interactions between c̃ and s; and (iii) the neurons need to compute nontrivial nonlinearities, such as logarithm and divisive normalization. Additionally, the noise in the Langevin sampler (ξ in Eq. 3.9) has to be white and have exactly the right variance. Thus, as with the variational approach, we expect a biophysical model to introduce approximations, and, therefore — as with the variational algorithm — degrade slightly the quality of the inference."
    }, {
      "heading" : "4 Simulations",
      "text" : "To determine how fast and accurate these two algorithms are, we performed a set of simulations using either Eq. (3.4) (variational inference) or Eqs. (3.9 - 3.11) (sampling). For both algorithms, the odors were generated from the true prior, Eq. (2.2). We modeled a small olfactory system, with 40 olfactory receptor types (compared to approximately 350 in humans and 1000 in mice [8]). To keep the ratio of identifiable odors to receptor types similar to the one in humans [8], we assumed 400 possible odors, with 3 odors expected to be present in the scene (π = 3/400). If an odor was present, its concentration was drawn from a Gamma distribution with α1 = 1.5 and β1 = 1/40. The background spike count, r0, was set to 1. The connectivity matrix was binary and random, with a connection probability, pc (the probability that any particular element is 1), set to 0.1 [2]. All network time constants (τρ, τα, τλ, τc and 1/ν0, from Eqs (3.4), (3.9) and (3.10)) were set to 10 ms. The differential equations were solved using the Euler method with a time step of 0.01 ms. Because we used α1 = α0 + 1, the choice α1 = 1.5 forced α0 to be 0.5. Our remaining parameter, β0, was set to ensure that, for the variational algorithm, the absent odors (those with sj = 0) contributed a background firing rate of r0 on average. This average background rate is given by ∑ j〈wij〉〈cj〉 = pcNodorsα0/β0. Setting this to r0 yields β0 = pcNodorsα0/r0 = 0.1× 400× 0.5/1 = 20. The true (Eq. (2.2)) and approximate (Eq. (3.1)) prior distributions over concentration are shown in Fig. 1.\nFigure 2 shows how the inference process evolves over time for a typical set of odors and concentrations. The top panel shows concentration, with variational inference on the left (where we plot the mean of the posterior distribution over concentration, (1−λj)α0j(t)/β0j(t)+λjα1j(t)/β1j(t); see Eq. (3.2)) and sampling on the right (where we plot c̃j , the output of our Langevin sampler; see Eq. (3.9)) for a case with three odors present. The three colored lines correspond to the odors that\nwere presented, with solid lines for the inferred concentrations and dashed lines for the true ones. Black lines are the odors that were not present. At least in this example, both algorithms converge rapidly to the true concentration.\nIn the bottom left panel of Fig. 2 we plot the log-probability that each of the odors is present, λj(t). The present odors quickly approach probabilities of 1; the absent odors all have probabilities below 10−4 within about 200 ms. The bottom right panel shows samples from sj for all the odors, with dots denoting present odors (sj(t) = 1) and blanks absent odors (sj(t) = 0). Beyond about 500 ms, the true odors (the colored lines at the bottom) are on continuously, and for the odors that were not present, sj is still occasionally 1, but relatively rarely.\nIn Fig. 3 we show the time course of the probability of odors when between 1 and 5 odors were presented. We show only the first 100 ms, to emphasize the initial time course. Again, variational inference is on the left and sampling is on the right. The black lines are the average values of the probability of the correct odors; the gray regions mark 25%–75% percentiles. Ideally, we would like to compare these numbers to those expected from a true posterior. However, due to its intractability, we must seek different means of comparison. Therefore, we plot the probability of the most likely non-presented odor (red); the average probability of the non-presented odors (green), and the probability of guessing the correct odors via simple template matching (dashed; see Fig. 3 legend for details).\nAlthough odors are inferred relatively rapidly (they exceed template matching within 20 ms), there were almost always false positives. Even with just one odor present, both algorithms consistently report the existence of another odor (red). This problem diminishes with time if fewer odors are presented than the expected three, but it persists for more complex mixtures. The false positives are in fact consistent with human behavior: humans have difficulty correctly identify more than one odor in a mixture, with the most common problem being false positives [9].\nFinally, because the two algorithms encode probabilities differently (see Discussion below), we also look into the time courses of the neural activity. In Fig. 4, we show the log-probability, L (left), and probability, λ (right), averaged across 400 scenes containing 3 odors (see Supplementary Fig. 2 for the other odor mixtures). The probability of absent odors drops from log(3/400) ≈ e−5 (the prior) to e−12 (the final inferred probability). For the variational approach, this represents a drop in activity of 7 log units, comparable to the increase of about 5 log units for the present odors (whose probability is inferred to be near 1). For the sampling based approach, on the other hand, this represents a very small drop in activity. Thus, for the variational algorithm the average activity associated with the absent odors exhibits a large drop, whereas for the sampling based approach the average activity associated with the absent odors starts small and stays small."
    }, {
      "heading" : "5 Discussion",
      "text" : "We introduced two algorithms for inferring odors from the activity of the odorant receptor neurons. One was a variational method; the other sampling based. We mapped both algorithms onto dynamical systems, and, assuming time constants of 10 ms (plausible for biophysically realistic networks), tested the time course of the inference.\nThe two algorithms performed with striking similarity: they both inferred odors within about 100 ms and they both had about the same accuracy. However, since the two methods encode probabilities differently (linear vs logarithmic encoding), they can be differentiated at the level of neural activity. As can be seen by examining Eqs. (3.4a) and (3.4c), for variational inference the log probability of concentration and presence/absence are related to the dynamical variables via\nlogQ(cj) ∼ α1j log cj − β1jcj (5.1a) logQ(sj) ∼ Ljsj (5.1b)\nwhere ∼ indicates equality within a constant. If we interpret α0j and Lj as firing rates, then these equations correspond to a linear probabilistic population code [10]: the log probability inferred by the approximate algorithm is linear in firing rate, with a parameter-dependent offset (the term−β1jcj in Eq. (5.1a)). For the sampling-based algorithm, on the other hand, activity generates samples from the posterior; an average of those samples codes for the probability of an odor being present. Thus, if the olfactory system uses variational inference, activity should code for log probability, whereas if it uses sampling, activity should code for probability.\nwith odor j; that is, it chooses j’s that maximize\n∑\ni riwij/\n(∑\ni r 2 i\n∑\ni w 2 ij\n)1/2\n. The number of odors chosen by template matching was set to the number of odors presented.) For more complex mixtures, sampling is slightly more efficient at inferring the presented odors. See Supplementary Material for the time course out to 1 second and for mixtures of up to 10 odors.\nThere are two ways to determine which. One is to note that for the variational algorithm there is a large drop in the average activity of the neurons coding for the non-present odors (Fig. 4 and Supplementary Figure 2). This drop could be detected with electrophysiology. The other focuses on the present odors, and requires a comparison between the posterior probability inferred by an animal and neural activity. The inferred probability can be measured by so-called “opt-out” experiments [11]; the latter by sticking an electrode into an animal’s head, which is by now standard.\nThe two algorithms also make different predictions about the activity coding for concentration. For the variational approach, activity, α0j , codes for the parameters of a probability distribution. Importantly, in the variational scheme the mean and variance of the distribution are tied – both are proportional to activity. Sampling, on the other hand, can represent arbitrary concentration distributions. These two schemes could, therefore, be distinguished by separately manipulating average concentration and uncertainty – by, for example, showing either very similar or very different odors.\nUnfortunately, it is not clear where exactly one needs to stick the electrode to record the trace of the olfactory inference. A good place to start would be the olfactory bulb, where odor representations have been studied extensively [12, 13, 14]. For example, the dendro-dendritic connections observed in this structure [4] are particularly well suited to meet the symmetry requirements on wij . We note in passing that these connections have been the subject of many theoretical studies. Most, however, considered single odors [15, 6, 16], for which one does not need a complicated inference process An early notable exception to the two-odor standard was Zhaoping [17], who proposed a model for serial analysis of complex mixtures, whereby higher cortical structures would actively adapt the already recognized components and send a feedback signal to the lower structures. Exactly how her network relates to our inference algorithms remains unclear. We should also point out that although the olfactory bulb is a likely location for at least part of our two inference algorithms, both are sufficiently complicated that they may need to be performed by higher cortical structures, such as the anterior piriform cortex, [18, 19].\nFuture directions. We have made several unrealistic assumptions in this analysis. For instance, the generative model was very simple: we assumed that concentrations added linearly, that weights were binary (so that each odor activated a subset of the olfactory receptor neurons at a finite value, and did not activate the rest at all), and that noise was Poisson. None of these are likely to be exactly true. And we considered priors such that all odors were independent. This too is unlikely to be true – for instance, the set of odors one expects in a restaurant are very different than the ones one expects in a toxic waste dump, consistent with the fact that responses in the olfactory bulb are modulated by task-relevant behavior [20]. Taking these effects into account will require a more complicated, almost certainly hierarchical, model. We have also focused solely on inference: we assumed that the network knew perfectly both the mapping from odors to odorant receptor neurons and the priors. In fact, both have to be learned. Finally, the neurons in our network had to implement relatively complicated nonlinearities: logs, exponents, and digamma and quadratic functions, and neurons had to be reciprocally connected. Building a network that can both exhibit the proper nonlinearities (at least approximately) and learn the reciprocal weights is challenging. While these issues are nontrivial, they do not appear to be insurmountable. We expect, therefore, that a more realistic model will retain many of the features of the simple model we presented here."
    } ],
    "references" : [ {
      "title" : "Statistically optimal perception and learning: from behavior to neural representations",
      "author" : [ "J. Fiser", "P. Berkes", "G. Orban", "M. Lengyel" ],
      "venue" : "Trends Cogn. Sci. (Regul. Ed.),",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2010
    }, {
      "title" : "Dense representation of natural odorants in the mouse olfactory bulb",
      "author" : [ "R. Vincis", "O. Gschwend", "K. Bhaukaurally", "J. Beroud", "A. Carleton" ],
      "venue" : "Nat. Neurosci.,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2012
    }, {
      "title" : "Complex inference in neural circuits with probabilistic population codes and topic models",
      "author" : [ "Jeff Beck", "Katherine Heller", "Alexandre Pouget" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2012
    }, {
      "title" : "Theoretical reconstruction of field potentials and dendrodendritic synaptic interactions in olfactory bulb",
      "author" : [ "W. Rall", "G.M. Shepherd" ],
      "venue" : "J. Neurophysiol.,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1968
    }, {
      "title" : "The synaptic organization of the brain, volume 4, chapter Olfactory bulb, pages 165–216",
      "author" : [ "GM Shepherd", "WR Chen", "CA. Greer" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2004
    }, {
      "title" : "Sparse incomplete representations: a potential role of olfactory granule cells",
      "author" : [ "A.A. Koulakov", "D. Rinberg" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2011
    }, {
      "title" : "Divisive normalization in olfactory population",
      "author" : [ "Shawn Olsen", "Vikas Bhandawat", "Rachel Wilson" ],
      "venue" : "codes. Neuron,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2010
    }, {
      "title" : "Genes and ligands for odorant, vomeronasal and taste receptors",
      "author" : [ "P. Mombaerts" ],
      "venue" : "Nat. Rev. Neurosci.,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2004
    }, {
      "title" : "The capacity of humans to identify odors in mixtures",
      "author" : [ "D.G. Laing", "G.W. Francis" ],
      "venue" : "Physiol. Behav.,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1989
    }, {
      "title" : "Bayesian inference with probabilistic population",
      "author" : [ "W.J. Ma", "J.M. Beck", "P.E. Latham", "A. Pouget" ],
      "venue" : "codes. Nat. Neurosci.,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2006
    }, {
      "title" : "Representation of confidence associated with a decision by neurons in the parietal cortex",
      "author" : [ "R. Kiani", "M.N. Shadlen" ],
      "venue" : "Science,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2009
    }, {
      "title" : "Odor encoding as an active, dynamical process: experiments, computation, and theory",
      "author" : [ "G. Laurent", "M. Stopfer", "R.W. Friedrich", "M.I. Rabinovich", "A. Volkovskii", "H.D. Abarbanel" ],
      "venue" : "Annu. Rev. Neurosci.,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2001
    }, {
      "title" : "Spatio-temporal dynamics of odor representations in the mammalian olfactory",
      "author" : [ "H. Spors", "A. Grinvald" ],
      "venue" : "bulb. Neuron,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2002
    }, {
      "title" : "Robust odor coding via inhalation-coupled transient activity in the mammalian olfactory",
      "author" : [ "Kevin Cury", "Naoshige Uchida" ],
      "venue" : "bulb. Neuron,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2010
    }, {
      "title" : "Modeling the olfactory bulb and its neural oscillatory processings",
      "author" : [ "Z. Li", "J.J. Hopfield" ],
      "venue" : "Biol Cybern,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1989
    }, {
      "title" : "Sparse distributed representation of odors in a large-scale olfactory bulb circuit",
      "author" : [ "Y. Yu", "T.S. McTavish", "M.L. Hines", "G.M. Shepherd", "C. Valenti", "M. Migliore" ],
      "venue" : "PLoS Comput. Biol.,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2013
    }, {
      "title" : "A model of olfactory adaptation and sensitivity enhancement in the olfactory bulb",
      "author" : [ "Z. Li" ],
      "venue" : "Biol Cybern,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1990
    }, {
      "title" : "Bidirectional plasticity of cortical pattern recognition and behavioral sensory acuity",
      "author" : [ "Julie Chapuis", "Donald Wilson" ],
      "venue" : "Nature neuroscience,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2012
    }, {
      "title" : "Odor representations in olfactory cortex: distributed rate coding and decorrelated population activity",
      "author" : [ "Keiji Miura", "Zachary Mainen", "Naoshige Uchida" ],
      "venue" : null,
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2012
    }, {
      "title" : "Neuronal activity of mitraltufted cells in awake rats during passive and active odorant stimulation",
      "author" : [ "R.A. Fuentes", "M.I. Aguilar", "M.L. Aylwin", "P.E. Maldonado" ],
      "venue" : "J. Neurophysiol.,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "If one or the other could be corroborated experimentally, that would provide valuable insight into how the brain (or at least one part of the brain) codes for probabilities [1].",
      "startOffset" : 173,
      "endOffset" : 176
    }, {
      "referenceID" : 1,
      "context" : "It is known that each odor, by itself, activates a different subset of the olfactory receptor neurons; typically on the order of 10%-30% [2].",
      "startOffset" : 137,
      "endOffset" : 140
    }, {
      "referenceID" : 2,
      "context" : "In contrast to previous work [3], which used a smooth prior on the concentrations, here we use a spike and slab prior.",
      "startOffset" : 29,
      "endOffset" : 32
    }, {
      "referenceID" : 3,
      "context" : "However: (i) reciprocal and symmetric connectivity exists in the early olfactory processing system [4, 5, 6]; (ii) although multiplicative interactions are in general not easy for neurons, the divisive normalization (Eq.",
      "startOffset" : 99,
      "endOffset" : 108
    }, {
      "referenceID" : 4,
      "context" : "However: (i) reciprocal and symmetric connectivity exists in the early olfactory processing system [4, 5, 6]; (ii) although multiplicative interactions are in general not easy for neurons, the divisive normalization (Eq.",
      "startOffset" : 99,
      "endOffset" : 108
    }, {
      "referenceID" : 5,
      "context" : "However: (i) reciprocal and symmetric connectivity exists in the early olfactory processing system [4, 5, 6]; (ii) although multiplicative interactions are in general not easy for neurons, the divisive normalization (Eq.",
      "startOffset" : 99,
      "endOffset" : 108
    }, {
      "referenceID" : 6,
      "context" : "5)) has been observed in the olfactory bulb [7], and (iii) the nonlinearities in our algorithms are not extreme (the logarithm is defined only on the positive range (α0j > α0, Eq.",
      "startOffset" : 44,
      "endOffset" : 47
    }, {
      "referenceID" : 7,
      "context" : "We modeled a small olfactory system, with 40 olfactory receptor types (compared to approximately 350 in humans and 1000 in mice [8]).",
      "startOffset" : 128,
      "endOffset" : 131
    }, {
      "referenceID" : 7,
      "context" : "To keep the ratio of identifiable odors to receptor types similar to the one in humans [8], we assumed 400 possible odors, with 3 odors expected to be present in the scene (π = 3/400).",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 8,
      "context" : "The false positives are in fact consistent with human behavior: humans have difficulty correctly identify more than one odor in a mixture, with the most common problem being false positives [9].",
      "startOffset" : 190,
      "endOffset" : 193
    }, {
      "referenceID" : 9,
      "context" : "If we interpret α0j and Lj as firing rates, then these equations correspond to a linear probabilistic population code [10]: the log probability inferred by the approximate algorithm is linear in firing rate, with a parameter-dependent offset (the term−β1jcj in Eq.",
      "startOffset" : 118,
      "endOffset" : 122
    }, {
      "referenceID" : 10,
      "context" : "The inferred probability can be measured by so-called “opt-out” experiments [11]; the latter by sticking an electrode into an animal’s head, which is by now standard.",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 11,
      "context" : "A good place to start would be the olfactory bulb, where odor representations have been studied extensively [12, 13, 14].",
      "startOffset" : 108,
      "endOffset" : 120
    }, {
      "referenceID" : 12,
      "context" : "A good place to start would be the olfactory bulb, where odor representations have been studied extensively [12, 13, 14].",
      "startOffset" : 108,
      "endOffset" : 120
    }, {
      "referenceID" : 13,
      "context" : "A good place to start would be the olfactory bulb, where odor representations have been studied extensively [12, 13, 14].",
      "startOffset" : 108,
      "endOffset" : 120
    }, {
      "referenceID" : 3,
      "context" : "For example, the dendro-dendritic connections observed in this structure [4] are particularly well suited to meet the symmetry requirements on wij .",
      "startOffset" : 73,
      "endOffset" : 76
    }, {
      "referenceID" : 14,
      "context" : "Most, however, considered single odors [15, 6, 16], for which one does not need a complicated inference process An early notable exception to the two-odor standard was Zhaoping [17], who proposed a model for serial analysis of complex mixtures, whereby higher cortical structures would actively adapt the already recognized components and send a feedback signal to the lower structures.",
      "startOffset" : 39,
      "endOffset" : 50
    }, {
      "referenceID" : 5,
      "context" : "Most, however, considered single odors [15, 6, 16], for which one does not need a complicated inference process An early notable exception to the two-odor standard was Zhaoping [17], who proposed a model for serial analysis of complex mixtures, whereby higher cortical structures would actively adapt the already recognized components and send a feedback signal to the lower structures.",
      "startOffset" : 39,
      "endOffset" : 50
    }, {
      "referenceID" : 15,
      "context" : "Most, however, considered single odors [15, 6, 16], for which one does not need a complicated inference process An early notable exception to the two-odor standard was Zhaoping [17], who proposed a model for serial analysis of complex mixtures, whereby higher cortical structures would actively adapt the already recognized components and send a feedback signal to the lower structures.",
      "startOffset" : 39,
      "endOffset" : 50
    }, {
      "referenceID" : 16,
      "context" : "Most, however, considered single odors [15, 6, 16], for which one does not need a complicated inference process An early notable exception to the two-odor standard was Zhaoping [17], who proposed a model for serial analysis of complex mixtures, whereby higher cortical structures would actively adapt the already recognized components and send a feedback signal to the lower structures.",
      "startOffset" : 177,
      "endOffset" : 181
    }, {
      "referenceID" : 17,
      "context" : "We should also point out that although the olfactory bulb is a likely location for at least part of our two inference algorithms, both are sufficiently complicated that they may need to be performed by higher cortical structures, such as the anterior piriform cortex, [18, 19].",
      "startOffset" : 268,
      "endOffset" : 276
    }, {
      "referenceID" : 18,
      "context" : "We should also point out that although the olfactory bulb is a likely location for at least part of our two inference algorithms, both are sufficiently complicated that they may need to be performed by higher cortical structures, such as the anterior piriform cortex, [18, 19].",
      "startOffset" : 268,
      "endOffset" : 276
    }, {
      "referenceID" : 19,
      "context" : "This too is unlikely to be true – for instance, the set of odors one expects in a restaurant are very different than the ones one expects in a toxic waste dump, consistent with the fact that responses in the olfactory bulb are modulated by task-relevant behavior [20].",
      "startOffset" : 263,
      "endOffset" : 267
    } ],
    "year" : 2013,
    "abstractText" : "The olfactory system faces a difficult inference problem: it has to determine what odors are present based on the distributed activation of its receptor neurons. Here we derive neural implementations of two approximate inference algorithms that could be used by the brain. One is a variational algorithm (which builds on the work of Beck. et al., 2012), the other is based on sampling. Importantly, we use a more realistic prior distribution over odors than has been used in the past: we use a “spike and slab” prior, for which most odors have zero concentration. After mapping the two algorithms onto neural dynamics, we find that both can infer correct odors in less than 100 ms. Thus, at the behavioral level, the two algorithms make very similar predictions. However, they make different assumptions about connectivity and neural computations, and make different predictions about neural activity. Thus, they should be distinguishable experimentally. If so, that would provide insight into the mechanisms employed by the olfactory system, and, because the two algorithms use very different coding strategies, that would also provide insight into how networks represent probabilities.",
    "creator" : null
  }
}