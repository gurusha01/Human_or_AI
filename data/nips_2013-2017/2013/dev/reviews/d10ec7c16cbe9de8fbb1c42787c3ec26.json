{"title": "Bayesian inference as iterated random functions with  applications to sequential inference in graphical models", "abstract": "We propose a general formalism of iterated random functions with semigroup property, under which exact and approximate Bayesian posterior updates can be viewed as specific instances. A convergence theory for iterated random functions is presented. As an application of the general theory we analyze convergence behaviors of exact and approximate message-passing algorithms that arise in a sequential change point detection problem formulated via a latent variable directed graphical model. The sequential inference algorithm and its supporting theory are  illustrated by simulated examples.", "id": "d10ec7c16cbe9de8fbb1c42787c3ec26", "authors": ["Arash Amini", "XuanLong Nguyen"], "conference": "NIPS2013", "accepted": true, "reviews": [{"comments": "This paper gives a new perspective on the Bayesian posterior updates (BPU) as\na system of iterated random functions (IRF) [4].\nBy proving a general convergence theorem of IRF with semigroup property,\nthe convergence of algorithms for change point detection problems [17] are analyzed.\nThe major contributions are\n- to establish a general convergence theory for IRF with semigroup property (Theorem 1),\n- to cast existing (exact) algorithms for the classical change point problem (CCPP) \nand the multiple change point problem (MCPP) in the IRF framework, and prove their \nconvergence, based on Theorem 1.\n- to propose a fast approximate algorithm for MCPP and prove its convergence,\nbased on Theorem 1.\n\nI think this is a nice paper with a significant impact.\nBPU is clearly a Markov chain, and so it might be natural that \nit is analyzed in the IRF framework.\nHowever, the previous convergence results on IRF are not directly applicable to BPU,\nbecause the Lipschitz condition is not satisfied in BPU.\nInstead, the authors use semigroup property of BPU,\nand establish another type of convergence theory.\nI expect that the established theory would have wide range of applications.\n\nPros:\n- A new perspective on BPU as a special case of IRF with semigroup property (3) is given.\n- A general convergence theory (Theorem 1) for IRF with semigroup property \nis established, which might have wide range of potential applications.\n- A fast algorithm (Section 4.1) for MCPP is proposed with its convergence \nguarantees (Theorem 2).\n\nCons:\n- The relation between the theory (Theorem 2) and the experiment (Figure 1) is not \nclear (see the first one in 'Other comments' below).\n- No practical application of the multiple change point detection is introduced \n(see the second one in 'Other comments' below).\n\nQuality:\nThe paper is technically sound, and the claims are supported by theory.\n\nClarity:\nThe paper is clearly written, and well-organized.\n\nOriginality:\nThe perspective on BPU as IRF with semigroup property, \nand the obtained convergence theorem (Theorem 1) are novel.\n\nSignificance:\nThe found relation between BPU and IRF with semigroup property, \nand the established convergence theory could be used by other theoreticians \nto analyze algorithms for other problems.\n\nOther comments:\n- It would be nice if Eqs.(19) and (20) are somehow expressed in the posterior path\ngraphs in Figure 1. This would make it clear that the simulation supports Theorem 2.\nIn Section 4.3, it is said that 'in some cases, they might deviate for a while, \nbut quickly snap back together once the change points have occurred.'\nReaders cannot see this because the change points are not indicated.\n- It would be nice if any practical example of MCCP is introduced\n(I could not find any also in [17]).\nEspecially, I wonder in what applications the rule\nlambda_e = min(lambda_s1, lambda_s2) is appropriate.\nTo me, it seems more natural to assume that the distribution of X_e\nchanges both at lambda_s1 and at lambda_s2.\nMoreover, if I understand correctly, Theorem 2 guarantees the convergence \nafter all the sensors are broken.\nI suppose people are more interested in the convergence after any of the sensors \nis broken, or the sensor on which a user focuses is broken.\n- Perhaps, some thetas in and around Eq.(4) should not be bold-faced.\n- In Line 225, 'probabilities 10 by message-passing' looks corrupted.\nIs 10 a citation?\n- In the last line in Section 5, parentheses for Eq.(29) are missing.\n\n\n A nice paper that gives a new perspective on the Bayesian posterior updatesas a system of iterated random functions with semigroup property,and establishes a general convergence theory for the system.The used techniques and obtained theorems might have wide rangeof potential applications.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper presents an interesting interpretation of Bayesian inference \nas as a system of iterated random functions, with a particular focus on \nBayesian changepoint detection. This interpretation allows for \nconvergence analysis of message passing algorithms which is of wide \ninterest. The general approach for convergence analysis is presented \nwith focus on providing details of the proof technique. \n\nI found the interpretation of Bayesian inference as iterated random \nfunctions interesting and think others will as well. It was interesting \nto see that we can derive algorithms that we can show to have geometric \nconvergence. Overall I think the paper would be improved if there was \nmore of a discussion and focus on the implications of this theory and \nthe insights it gives us into obtaining efficient algorithms. Here there \nwas a specific focus on changepoint detection: was this special for some \nreason. What other model classes can we extend this to and for which it is reasonable \nto assume the conditions will hold. The simulation section can be improved \nto be more clear on the setup, indicating where the changepoints are \nand connecting the observed with theoretical convergence over n. \n An interesting interpretation of the paper showing convergence analysis for message passing algorithms. Can be improved by looking into accessibility for many not familiar with the tools used here and the settings in which such tools should be used.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper presents iterated random functions and discusses the theory of its convergence. This theory is then used to analyze the convergence of message passing algorithms for Bayesian inference. \n\nQuality: Excellent. \n\nClarity: Good. \n\nThis paper is original and makes significant contributions. \n\nI should admit that I haven't gone through the proofs in complete details, but at the first pass it looks ok to me. I will surely be spending next few days checking things more carefully. \n\nSome questions: \n1) What are typical value of -I+epsilon? Is it always negative? If not, under what condition will it be. \n\n2) Can these results be used to explain the convergence for other graphical models where convergence is known, for example, BP on a tree? To my knowledge, there is very little work done on the analysis of message-passing algorithm, and hence any such attempts are very useful. This paper uses iterated random functions to analyze the convergence of message passing, which is very interesting. I hope that the presented approach can be generalized to other graphical models, to better understand the convergence of message passing algorithms.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
