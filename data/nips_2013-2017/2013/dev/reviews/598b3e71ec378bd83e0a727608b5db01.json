{"title": "Distributed Exploration in Multi-Armed Bandits", "abstract": "", "id": "598b3e71ec378bd83e0a727608b5db01", "authors": ["Eshcar Hillel", "Zohar S. Karnin", "Tomer Koren", "Ronny Lempel", "Oren Somekh"], "conference": "NIPS2013", "accepted": true, "reviews": [{"comments": "The paper considers the possibility of parallelizing the best arm identification problem. In specific, they ask how and what speed-up can by achieved by running k instances of an algorithm in parallel if they are allowed to share some information with each other. The information sharing is done by each of the instances broadcasting some information for the rest of the algorithms (typically at the end of the run), but with the restriction that the number of broadcasted bits is limited (typically of size \\tilde{O}(n) for each instance). \n\nThe authors compare their algorithms to the full-communication method, the no-communication method, and the method that takes the majority vote (MV) of the individuals recommendations. The first one generates too much network data, the second one obviously achieves no speed-up, and, as they claim, the MV method achieves no speed-up either. In contrast, the algorithm they propose achieves a speed-up of \\sqrt{k}. They also show that this is optimal if only one round of communication is allowed. \n\nFinally, they show that if more communication rounds are allowed, then there is a trade-off between the possible speed-up (up to k) and the amount of information exchanged. \n\n\n\nEVALUATIION \n\nThe writing style is clear (mostly---but more about that below), the proposed solutions are simple but clever, and the problem is both non-trivial and reasonable (their motivating example is the distributed computation model of MapReduce). \n\nHowever, there are two issues which should be clarified. \n\nFirst of all, please define precisely what you mean by ``speed-up'', and state your goals formally! It is quite natural to think that if some algorithm A achieves confidence 1-\\delta in time T, whereas a distributed version achieves confidence 1-\\delta' during the same time for some \\delta' much less than \\delta, then this is a kind of speed-up. (Indeed, for a stand-alone version of A to achieve the same 1-\\delta' confidence could take much longer than T.) And, in this sense, MV would clearly achieve a speed-up: if time T is enough for A to output the best arm with probability 2/3, then increasing k to infinity, and simply taking the majority vote of the k instances of A (each run for time T) would return the best arm with a probability getting arbitrarily close to 1. \n\nAlso, the performance of the MV method should be treated with more care. In order to achieve that (in expectation) at least half of the players return the best arm, the individual algorithms indeed have to output the best arm with probability at least 1/2. However, for the MV method to work this is not at all required. In fact, it is enough to have that the individual algorithms output the best arm with higher probability as any other suboptimal arm. \n\n\nFinally, two less significant questions: \n1. In the second line of the proof of Lemma 3.3 why do you have the multiplicator 6 in front of H/\\sqrt{k}? \n2. In the second line of the proof of Lemma 3.4 shouldn't 12n be devided by \\Delta^\\star in the logarithm? The problem is both non-trivial and reasonable, the proposed solutions are simplebut clever, and the writing style is mostly clear. Some issues are raised though(regarding how they define their ``speed-up'' and why they claim that the majorityvote does not work) that require clarifications.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "Paper summary: \n-------------- \nThe paper presents algorithms and their analysis for several settings of distributed best-arm identification in multiarmed bandits (MAB) problem. The authors consider best-arm and epsilon-best arm identification by k \"workers\" with one and with R communication rounds. For one round of communication the authors demonstrate \\sqrt{k} speed-up and for R rounds of communication the authors demonstrate \\epsilon^{2/R} k speed-up. In particular, for R = O(log(1/\\epsilon)) the algorithm achieves the best-possible speed-up factor of k. The result for one communication round is accompanied by a matching lower bound. \n\nQuality, clarity, originality, and significance: \n------------------------------------------------ \nThe paper is of good quality, clearly written, significant, and original. (I did not check the supplementary material, except for the proof of the lower bound, but other results sound plausible). I think this is a good paper that would be interesting to the NIPS community. My comments are all minor and can be easily corrected by the authors.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper considers the problem of minimizing the simple regret in multi-armed bandit problems, that is, it is concerned with the sample complexity of identifying the arm with highest payoff. The authors aim to find out whether it is possible to speed up previously known algorithms by parallel processing on k processors. They propose an algorithm that attains a sqrt(k) speedup by letting the nodes communicate only once, and they show that no greater speedup can be achieved when restricting communication to a single round. Furthermore, it is shown that it is possible to attain the optimal speedup of k by allowing O(log 1/epsilon) communication rounds, where epsilon is the desired precision. \n\nI have greatly enjoyed reading the paper; it is very well-written. Even though it seemed to me that every interesting problem has already been solved concerning the problem of best-arm selection, the authors manage to come up with a novel, practically relevant framework, and prove elegant results concerning the complexity of the resulting learning problem. The results are quite original, even though proving them did not need any spectacular new techniques. Nevertheless, the technical content seems sound. Overall, I have only very minor complaints/additional questions concerning the paper. \n\n\nDetailed comments \n------------------------- \n182 The results concerning using Alg 3 for selecting the best arm are not communicated appropriately. You only state your results for epsilon > 0, these should be also stated in terms of Delta_* for completeness. \n194 In the last row, r -> R to stay consistent with Corollary 4.2 \n211 Wouldn\u2019t it be more straightforward to require that an algorithm successfully returns the best arm with probability at least 1-delta? Kalyanakrishnan et al. (2012) and Gabillon et al. (2012) provide such algorithms for the more general problem of selecting the m best arms. Any comment on how your results generalize to that setting? \n263 The wording of Lemma 3.3 is somewhat confusing: as can be deducted from the proof of Lemma 3.4, it should say that the probability that a fixed player identifies the best arm with such and such probability. Currently, the statement can be misunderstood as if it was saying that *all* players identify the correct arm with said probability. \n307 Even though I understand that you did not try to optimize the constants, can you give any insights as to how much these factors can be possibly improved? These factors of 400 and 50 seem to come out of nowhere, is it possible to significantly reduce them? \n398 Delta_* \n467 H. D. III -> H. Daume III, or, even better, H. Daum\u00e9 III \n The paper provides an elegant solution to a well-motivated new learning problem. The writing style and the technical quality is excellent.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
