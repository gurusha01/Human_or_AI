{
  "name" : "41ae36ecb9b3eee609d05b90c14222fb.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "On the Linear Convergence of the Proximal Gradient Method for Trace Norm Regularization",
    "authors" : [ "Ke Hou", "Zirui Zhou", "Anthony Man–Cho" ],
    "emails" : [ "khou@se.cuhk.edu.hk", "zrzhou@se.cuhk.edu.hk", "manchoso@se.cuhk.edu.hk", "luozq@ece.umn.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The problem of finding a low–rank matrix that (approximately) satisfies a given set of conditions has recently generated a lot of interest in many communities. Indeed, such a problem arises in a wide variety of applications, including approximation algorithms [17], automatic control [5], matrix classification [20], matrix completion [6], multi–label classification [1], multi–task learning [2], network localization [7], subspace learning [24], and trace regression [9], just to name a few. Due to the combinatorial nature of the rank function, the task of recovering a matrix with the desired rank and properties is generally intractable. To circumvent this, a popular approach is to use the trace norm1 (also known as the nuclear norm) as a surrogate for the rank function. Such an approach is quite natural, as the trace norm is the tightest convex lower bound of the rank function over the set of matrices with spectral norm at most one [13]. In the context of machine learning, the trace norm is typically used as a regularizer in the minimization of certain convex loss function. This gives rise to convex optimization problems of the form\nmin X∈Rm×n {F (X) = f(X) + τ‖X‖∗} , (1)\nwhere f : Rm×n → R is the convex loss function, ‖X‖∗ denotes the trace norm of X , and τ > 0 is a regularization parameter. By standard results in convex optimization [4], the above formulation is tractable (i.e., polynomial–time solvable) for many choices of the loss function f . In practice,\n1Recall that the trace norm of a matrix is defined as the sum of its singular values.\nhowever, one is often interested in settings where the decision variable X is of high dimension. Thus, there has been much research effort in developing fast algorithms for solving (1) lately.\nCurrently, a popular method for solving (1) is the proximal gradient method (PGM), which exploits the composite nature of the objective function F and certain smoothness properties of the loss function f [8, 19, 11]. The attractiveness of PGM lies not only in its excellent numerical performance, but also in its strong theoretical convergence rate guarantees. Indeed, for the trace norm–regularized problem (1) with f being convex and continuously differentiable and ∇f being Lipschitz continuous, the standard PGM will achieve an additive error of O(1/k) in the optimal value after k iterations. Moreover, this error can be reduced to O(1/k2) using acceleration techniques; see, e.g., [19]. The sublinear O(1/k2) convergence rate is known to be optimal if f is simply given by a first–order oracle [12]. On the other hand, if f is strongly convex, then the convergence rate can be improved to O(ck) for some c ∈ (0, 1) (i.e., a linear convergence rate) [16]. However, in machine learning, the loss functions of interest are often highly structured and hence not just given by an oracle, but they are not necessarily strongly convex either. For instance, in matrix completion, a commonly used loss function is the square loss f(·) = ‖A(·)− b‖22/2, where A : R\nm×n → Rp is a linear measurement operator and b ∈ Rp is a given set of observations. Clearly, f is not strongly convex when A has a non–trivial nullspace (or equivalently, when A is not injective). In view of this, it is natural to ask whether linear convergence of the PGM can be established for a larger class of loss functions.\nIn this paper, we take a first step towards answering this question. Specifically, we show that when the loss function f takes the form f(X) = h(A(X)), where A : Rm×n → Rp is an arbitrary linear operator and h : Rp → R is strictly convex with certain smoothness and curvature properties, the PGM for solving (1) has an asymptotic linear rate of convergence. Note that f need not be strictly convex even if h is, as A is arbitrary. Our result covers a wide range of loss functions used in the literature, such as square loss and logistic loss. Moreover, to the best of our knowledge, it is the first linear convergence result concerning the application of a first–order method to the trace norm–regularized problem (1) that does not require the strong convexity of f .\nThe key to our convergence analysis is a new Lipschitzian error bound for problem (1). Roughly, it says that the distance between a point X ∈ Rm×n and the optimal solution set of (1) is on the order of the residual norm ‖proxτ (X − ∇f(X)) − X‖F , where proxτ is the proximity operator associated with the regularization term τ‖X‖∗. Once we have such a bound, a routine application of the powerful analysis framework developed by Luo and Tseng [10] will yield the desired linear convergence result. Prior to this work, Lipschitzian error bounds for composite function minimization are available for cases where the non–smooth part either has a polyhedral epigraph (such as the ℓ1–norm) [23] or is the (sparse) group LASSO regularization [22, 25]. However, the question of whether a similar bound holds for trace norm regularization has remained open, despite its apparent similarity to ℓ1–norm regularization. Indeed, unlike the ℓ1–norm, the trace norm has a non– polyhedral epigraph; see, e.g., [18]. Moreover, the existing approach for establishing error bounds for ℓ1–norm or (sparse) group LASSO regularization is based on splitting the decision variables into groups, where variables from different groups do not interfere with one another, so that each group can be analyzed separately. However, the trace norm of a matrix is determined by its singular values, and each of them depends on every single entry of the matrix. Thus, we cannot use the same splitting approach to analyze the entries of the matrix. To overcome the above difficulties, we make the crucial observation that if X̄ is an optimal solution to (1), then both X̄ and −∇f(X̄) have the same set of left and right singular vectors; see Proposition 4.2. As a result, we can use matrix perturbation theory to get hold of the spectral structure of the points that are close to the optimal solution set. This in turn allows us to establish a Lipschitzian error bound for the trace norm–regularized problem (1), thereby resolving the aforementioned open question in the affirmative."
    }, {
      "heading" : "2 Preliminaries",
      "text" : ""
    }, {
      "heading" : "2.1 Basic Setup",
      "text" : "We consider the trace norm–regularized optimization problem (1), in which the loss function f : R\nm×n → R takes the form f(X) = h(A(X)), (2)\nwhere A : Rm×n → Rp is a linear operator and h : Rp → R is a function satisfying the following assumptions:\nAssumption 2.1\n(a) The effective domain of h, denoted by dom(h), is open and non–empty.\n(b) The function h is continuously differentiable with Lipschitz–continuous gradient on dom(h) and is strongly convex on any convex compact subset of dom(h).\nNote that Assumption 2.1(b) implies the strict convexity of h on dom(h) and the Lipschitz continuity of ∇f . Now, let X denote the set of optimal solutions to problem (1). We make the following assumption concerning X :\nAssumption 2.2 The optimal solution set X is non–empty.\nThe above assumptions can be justified in various applications. For instance, in matrix completion, the square loss f(·) = ‖A(·) − b‖22/2 induced by the linear measurement operator A and the set of observations b ∈ Rp is of the form (2), with h(·) = ‖(·) − b‖22/2. Moreover, it is clear that such an h satisfies Assumptions 2.1 and 2.2. In multi–task learning, the loss function takes the form f(·) = ∑T\nt=1 ℓ(At(·), yt), where T is the number of learning tasks, At : R m×n → Rp is the linear\noperator defined by the input data for the t–th task, yt ∈ R p is the output data for the t–th task, and ℓ : Rp × Rp → R measures the learning error. Note that f can be put into the form (2), where A : Rm×n → RTp is given by A(X) = (A1(X),A2(X), . . . ,AT (X)), and h : R Tp → R is given by h(z) = ∑T\nt=1 ℓ(zt, yt) with zt ∈ R p for t = 1, . . . , T and z = (z1, . . . , zT ). Moreover,\nin the case where ℓ is, say, the square loss (i.e., ℓ(zt, yt) = ‖zt − yt‖ 2 2/2) or the logistic loss (i.e., ℓ(zt, yt) = ∑p i=1 log(1 + exp(−ztiyti))), it can be verified that Assumptions 2.1 and 2.2 hold."
    }, {
      "heading" : "2.2 Some Facts about the Optimal Solution Set",
      "text" : "Since f(·) = h(A(·)) by (2) and h(·) is strictly convex on dom(h) by Assumption 2.1(b), it is easy to verify that the map X 7→ A(X) is invariant over the optimal solution set X . In other words, there exists a z̄ ∈ dom(h) such that for any X∗ ∈ X , we have A(X∗) = z̄. Thus, we can express X as\nX = { X ∈ Rm×n : τ‖X‖∗ = v ∗ − h(z̄), A(X) = z̄ } ,\nwhere v∗ > −∞ is the optimal value of (1). In particular, X is a non–empty convex compact set. This implies that every X ∈ Rm×n has a unique projection X̄ ∈ X onto X , which is given by the solution to the following optimization problem:\ndist(X,X ) = min Y ∈X ‖X − Y ‖F .\nIn addition, since X is bounded and F is convex, it follows from [14, Corollary 8.7.1] that the level set {X ∈ Rm×n : F (X) ≤ ζ} is bounded for any ζ ∈ R."
    }, {
      "heading" : "2.3 Proximal Gradient Method and the Residual Map",
      "text" : "To motivate the PGM for solving (1), we recall an alternative characterization of the optimal solution set X . Consider the proximity operator proxτ : R m×n → Rm×n, which is defined as\nproxτ (X) = arg min Z∈Rm×n\n{\nτ‖Z‖∗ + 1\n2 ‖X − Z‖2F\n}\n. (3)\nBy comparing the optimality conditions for (1) and (3), it is immediate that a solution X∗ ∈ Rm×n is optimal for (1) if and only if it satisfies the following fixed–point equation:\nX∗ = proxτ (X ∗ −∇f(X∗)). (4)\nThis naturally lead to the following PGM for solving (1): {\nY k+1 = Xk − αk∇f(X k), Xk+1 = proxταk(Y k+1),\n(5)\nwhere αk > 0 is the step size in the k–th iteration, for k = 0, 1, . . .; see, e.g., [8, 19, 11]. As is well–known, the proximity operator defined above can be expressed in terms of the so–called matrix\nshrinkage operator. To describe this result, we introduce some definitions. Let µ > 0 be given. The non–negative vector shrinkage operator sµ : R p + → R p + is defined as (sµ(z))i = max{0, zi − µ}, where i = 1, . . . , p. The matrix shrinkage operator Sµ : R m×n → Rm×n is defined as Sµ(X) = UΣµV T , where X = UΣV T is the singular value decomposition of X with Σ = Diag(σ(X)) and σ(X) being the vector of singular values of X , and Σµ = Diag(sµ(σ(X))). Then, it can be shown that\nproxτ (X) = Sτ (X); (6)\nsee, e.g., [11, Theorem 3].\nOur goal in this paper is to study the convergence rate of the PGM (5). Towards that end, we need a measure to quantify its progress towards optimality. One natural candidate would be dist(·,X ), the distance to the optimal solution set X . Despite its intuitive appeal, such a measure is hard to compute or analyze. In view of (4) and (6), a reasonable alternative would be the norm of the residual map R : Rm×n → Rm×n, which is defined as\nR(X) = Sτ (X −∇f(X))−X. (7)\nIntuitively, the residual map measures how much a solution X ∈ Rm×n violates the optimality condition (4). In particular, X is an optimal solution to (1) if and only if R(X) = 0. However, since ‖R(·)‖F is only a surrogate of dist(·,X ), we need to establish a relationship between them. This motivates the development of a so–called error bound for problem (1)."
    }, {
      "heading" : "3 Main Results",
      "text" : "Key to our convergence analysis of the PGM (5) is the following error bound for problem (1), which constitutes the main contribution of this paper:\nTheorem 3.1 (Error Bound for Trace Norm Regularization) Suppose that in problem (1), f is of the form (2), and Assumptions 2.1 and 2.2 are satisfied. Then, for any ζ ≥ v∗, there exist constants η > 0 and ǫ > 0 such that\ndist(X,X ) ≤ η‖R(X)‖F whenever F (X) ≤ ζ, ‖R(X)‖F ≤ ǫ. (8)\nArmed with Theorem 3.1 and some standard properties of the PGM (5), we can apply the convergence analysis framework developed by Luo and Tseng [10] to establish the linear convergence of (5). Recall that a sequence of vectors {wk}k≥0 is said to converge Q–linearly (resp. R– linearly) to a vector w∞ if there exist an index K ≥ 0 and a constant ρ ∈ (0, 1) such that ‖wk+1−w∞‖2/‖w\nk−w∞‖2 ≤ ρ for all k ≥ K (resp. if there exist constants γ > 0 and ρ ∈ (0, 1) such that ‖wk − w∞‖2 ≤ γ · ρ k for all k ≥ 0).\nTheorem 3.2 (Linear Convergence of the Proximal Gradient Method) Suppose that in problem (1), f is of the form (2), and Assumptions 2.1 and 2.2 are satisfied. Moreover, suppose that the step size αk in the PGM (5) satisfies 0 < α < αk < ᾱ < 1/Lf for k = 0, 1, 2, . . ., where Lf is the Lipschitz constant of ∇f , and α, ᾱ are given constants. Then, the sequence of solutions {Xk}k≥0 generated by the PGM (5) converges R–linearly to an element in the optimal solution set X , and the associated sequence of objective values {F (Xk)}k≥0 converges Q–linearly to the optimal value v ∗.\nProof. Under the given setting, it can be shown that there exist scalars κ1, κ2, κ3 > 0, which depend on α, ᾱ, and Lf , such that\nF (Xk)− F (Xk+1) ≥ κ1‖X k −Xk+1‖2F , (9)\nF (Xk+1)− v∗ ≤ κ2 [ (dist(Xk,X ))2 + ‖Xk+1 −Xk‖2F ] , (10)\n‖R(Xk)‖F ≤ κ3‖X k −Xk+1‖F ; (11)\nsee the supplementary material. Since {F (Xk)}k≥0 is a monotonically decreasing sequence by (9) and F (Xk) ≥ v∗ for all k ≥ 0, we conclude, again by (9), that Xk − Xk+1 → 0. This, together with (11), implies that R(Xk) → 0. Thus, by (9), (10) and Theorem 3.1, there exist an index K ≥ 0 and a constant κ4 > 0 such that for all k ≥ K ,\nF (Xk+1)− v∗ ≤ κ4‖X k −Xk+1‖2F ≤ κ4 κ1 (F (Xk)− F (Xk+1)).\nIt follows that\nF (Xk+1)− v∗ ≤ κ4\nκ1 + κ4 (F (Xk)− v∗), (12)\nwhich establishes the Q–linear convergence of {F (Xk)}k≥0 to v ∗. Using (9) and (12), we can show that {‖Xk+1 −Xk‖2F }k≥0 converges R–linearly to 0, which, together with (11), implies that {Xk}k≥0 converges R–linearly to a point in X ; see the supplementary material."
    }, {
      "heading" : "4 Proof of the Error Bound",
      "text" : "The structure of our proof of Theorem 3.1 largely follows that laid out in [22, Section 6]. However, as explained in Section 1, some new ingredients are needed in order to analyze the spectral properties of a point that is close to the optimal solution set X . Before we proceed, let us set up the notation that will be used in the proof. Let L > 0 denote the Lipschitz constant of ∇h and ∂‖ · ‖∗ denote the subdifferential of ‖ · ‖∗. Given a sequence {X k}k≥0 ∈ R m×n\\X , define\nRk = R(Xk), X̄k = argminY ∈X ‖X k − Y ‖F , δk = ‖X k − X̄k‖F ,\nzk = A(Xk), Gk = ∇f(Xk) = A∗(∇h(zk)), Ḡ = A∗(∇h(z̄)), (13)\nwhere A∗ is the adjoint operator of A. The crux of the proof of Theorem 3.1 is the following lemma:\nLemma 4.1 Under the setting of Theorem 3.1, suppose that there exists a convergent sequence {Xk}k≥0 ∈ R m×n\\X satisfying\nF (Xk) ≤ ζ for all k ≥ 0, Rk → 0, Rk\nδk → 0. (14)\nThen, the following hold:\n(a) (Asymptotic Optimality) The limit point X̄ of {Xk}k≥0 belongs to X .\n(b) (Bounded Iterates) There exists a convex compact subset Z of dom(h) such that zk, z̄ ∈ Z for all k ≥ 0. Consequently, there exists a constant σ ∈ (0, L] such that for all k ≥ 0,\n(∇h(zk)−∇h(z̄))T (zk − z̄) ≥ σ‖zk − z̄‖22. (15)\n(c) (Restricted Invertibility) There exists a constant κ > 0 such that\n‖Xk − X̄k‖F ≤ κ‖z k − z̄‖2 = κ‖A(X k − X̄k)‖2 for all k ≥ 0. (16)"
    }, {
      "heading" : "It is clear that ‖A(Xk − X̄k)‖2 ≤ ‖A‖ · ‖X",
      "text" : "k − X̄k‖F , where ‖A‖ = sup‖Y ‖F=1 ‖A(Y )‖2 is the spectral norm of A. Thus, the key element in Lemma 4.1 is the restricted invertibility property (16). For the sake of continuity, let us proceed to prove Theorem 3.1 by assuming the validity of Lemma 4.1.\nProof. [Theorem 3.1] We argue by contradiction. Suppose that there exists ζ ≥ v∗ such that (8) fails to hold for all η > 0 and ǫ > 0. Then, there exists a sequence {Xk}k≥0 ∈ R\nm×n\\X satisfying (14). Since {X ∈ Rm×n : F (X) ≤ ζ} is bounded (see Section 2.2), by passing to a subsequence if necessary, we may assume that {Xk}k≥0 converges to some X̄ . Hence, the premises of Lemma 4.1 are satisfied. Now, by Fermat’s rule [15, Theorem 10.1], for each k ≥ 0,\nRk ∈ argmin D\n{ 〈Gk +Rk, D〉+ τ‖Xk +D‖∗ } . (17)\nHence, we have\n〈Gk +Rk, Rk〉+ τ‖Xk +Rk‖∗ ≤ 〈G k +Rk, X̄k −Xk〉+ τ‖X̄k‖∗.\nSince X̄k ∈ X and ∇f(X̄k) = Ḡ, we also have −Ḡ ∈ τ∂‖X̄k‖∗, which implies that\nτ‖X̄k‖∗ ≤ 〈Ḡ,X k +Rk − X̄k〉+ τ‖Xk +Rk‖∗.\nAdding the two inequalities above and simplifying yield\n〈Gk − Ḡ,Xk − X̄k〉+ ‖Rk‖2F ≤ 〈Ḡ−G k, Rk〉+ 〈Rk, X̄k −Xk〉. (18)\nSince zk = A(Xk) and z̄ = A(X̄k), by Lemma 4.1(b,c),\n〈Gk − Ḡ,Xk − X̄k〉 = (∇h(zk)−∇h(z̄))T (zk − z̄) ≥ σ‖zk − z̄‖22 ≥ σ\nκ2 ‖Xk − X̄k‖2F . (19)\nHence, it follows from (15), (18), (19) and the Lipschitz continuity of ∇h that σ\nκ2 ‖Xk − X̄k‖2F + ‖R k‖2F ≤ (∇h(z̄)−∇h(z k))TA(Rk) + 〈Rk, X̄k −Xk〉\n≤ L‖A‖2‖Xk − X̄k‖F‖R k‖F + ‖X k − X̄k‖F ‖R k‖F .\nIn particular, this implies that σ\nκ2 ‖Xk − X̄k‖2F ≤ (L‖A‖ 2 + 1)‖Xk − X̄k‖F ‖R k‖F\nfor all k ≥ 0, which, upon dividing both sides by ‖Xk − X̄k‖F , yields a contradiction to (14)."
    }, {
      "heading" : "4.1 Proof of Lemma 4.1",
      "text" : "We now return to the proof of Lemma 4.1. Since Rk → 0 by (14) and R is continuous, we have R(X̄) = 0, which implies that X̄ ∈ X . This establishes (a). To prove (b), observe that due to (a), the sequence {Xk}k≥0 is bounded. Hence, the sequence {A(X\nk)}k≥0 is also bounded, which implies that the points zk = A(Xk) and z̄ = A(X̄) lie in a convex compact subset Z of dom(h) for all k ≥ 0. The inequality (15) then follows from Assumption 2.1(b). Note that we have σ ≤ L, as ∇h is Lipschitz continuous with parameter L.\nTo prove (c), we argue by contradiction. Suppose that (16) is false. Then, by further passing to a subsequence if necessary, we may assume that\n‖A(Xk)− z̄‖2 / ‖Xk − X̄k‖F → 0. (20)\nIn the sequel, we will also assume without loss of generality that m ≤ n. The following proposition establishes a property of the optimal solution set X that will play a crucial role in our proof.\nProposition 4.2 Consider a fixed X̄ ∈ X . Let X̄ − Ḡ = Ū [Diag(σ̄) 0] V̄ T be the singular value decomposition of X̄ − Ḡ, where Ū ∈ Rm×m, V̄ ∈ Rn×n are orthogonal matrices and σ̄ is the vector of singular values of X̄ − Ḡ. Then, the matrices X̄ and −Ḡ can be simultaneously singular–value–decomposed by Ū and V̄ . Moreover, the set Xc ⊂ X , which is defined as\nXc = { X ∈ X : X = Ū [Diag(σ(X)) 0] V̄ T } ,\nis a non–empty convex compact set.\nBy Proposition 4.2, for every k ≥ 0, the point Xk has a unique projection X̃k ∈ Xc onto Xc. Let\nγk = ‖X k − X̃k‖F = min Y ∈Xc ‖Xk − Y ‖F . (21)\nSince Xc ⊂ X , we have γk = ‖X k − X̃k‖F ≥ ‖X k − X̄k‖F = δk. It follows from (20) that ‖A(Xk)− z̄‖2 / ‖Xk − X̃k‖F → 0. This is equivalent to A(Q k) → 0, where\nQk = Xk − X̃k\nγk for all k ≥ 0. (22)\nIn particular, we have ‖Qk‖F = 1 for all k ≥ 0. By further passing to a subsequence if necessary, we will assume that {Qk}k≥0 converges to some Q̄. Clearly, we have A(Q̄) = 0 and ‖Q̄‖F = 1."
    }, {
      "heading" : "4.1.1 Decomposing Q̄",
      "text" : "Our goal now is to show that for k sufficiently large and ǫ > 0 sufficiently small, the point X̂ = X̃k + ǫQ̄ belongs to Xc and is closer to X\nk than X̃k is to Xk. This would then contradict the fact that X̃k is the projection of Xk onto Xc. To begin, let σ\nk be the vector of singular values of Xk −Gk. Since Xk −Gk → X̄ − Ḡ, the sequence {σk}k≥0 is bounded. Hence, for i = 1, . . . ,m, by passing to a subsequence if necessary, we can classify the sequence {σki }k≥0 into one of the following three cases: (A) σki ≤ τ for all k ≥ 0; (B) σ k i > τ and σi(X̃ k) > 0 for all k ≥ 0; (C) σki > τ and σi(X̃ k) = 0 for all k ≥ 0. The following proposition gives the key structural properties of Q̄ that will lead to the desired contradiction:\nProposition 4.3 The matrix Q̄ admits the decomposition Q̄ = Ū [Diag(λ) 0] V̄ T , where\nλi\n\n  \n   \n= − lim k→∞\nσi(X̃ k)\nγk ≤ 0 in Case (A),\n∈ R in Case (B),\n> 0 in Case (C),\nfor i = 1, . . . ,m.\nIt should be noted that the decomposition given in Proposition 4.3 is not necessarily the singular value decomposition of Q̄, as λ could have negative components. A proof of Proposition 4.3 can be found in the supplementary material."
    }, {
      "heading" : "4.1.2 Completing the Proof",
      "text" : "Armed with Proposition 4.3, we are now ready to complete the proof of Lemma 4.1(c). Since Qk 6= 0 for all k ≥ 0, it follows from (22) that 〈Xk − X̃k, Q̄〉 > 0 for all k sufficiently large. Fix any such k and let X̂ = X̃k + ǫQ̄, where ǫ > 0 is a parameter to be determined. Since A(Q̄) = 0, it follows from (13) that ∇f(X̂) = ∇f(X̃k) = Ḡ. Moreover, since X̃k ∈ Xc, by the optimality condition (4) and Proposition 4.2, we have\nmax { 0, σi(X̃ k) + σi(−Ḡ)− τ } = σi(X̃ k) for i = 1, . . . ,m. (23)\nNow, we claim that for ǫ > 0 sufficiently small, X̂ satisfies\nSτ (X̂ − Ḡ)v̄i = X̂v̄i for i = 1, . . . , n, (24)\nūTi Sτ (X̂ − Ḡ) = ū T i X̂ for i = 1, . . . ,m,\nwhere ūi (resp. v̄i) is the i–th column of Ū (resp. V̄ ). This would then imply that X̂ ∈ Xc. To prove the claim, observe that for i = m + 1, . . . , n, both sides of (24) are equal to 0. Moreover, since X̃k ∈ Xc, Propositions 4.2 and 4.3 give\nX̂ − Ḡ = Ū [ Diag(σ(X̃k) + ǫλ+ σ(−Ḡ)) 0 ] V̄ T .\nThus, it suffices to show that for ǫ > 0 sufficiently small,\nσi(X̃ k) + ǫλi + σi(−Ḡ) ≥ 0 for i = 1, . . . ,m, (25)\nsτ (σi(X̃ k) + ǫλi + σi(−Ḡ)) = σi(X̃ k) + ǫλi for i = 1, . . . ,m. (26)\nTowards that end, fix an index i = 1, . . . ,m and consider the three cases defined in Section 4.1.1:\nCase (A). If σi(X̃ k) = 0 for all k sufficiently large, then Proposition 4.3 gives λi = 0. Moreover, we have σi(−Ḡ) ≤ τ by (23). This implies that both (25) and (26) are satisfied for any choice of ǫ > 0. On the other hand, if σi(X̃ k) > 0 for all k sufficiently large, then Proposition 4.3 gives λi < 0. Moreover, we have σi(−Ḡ) = τ by (23). By choosing ǫ > 0 so that σi(X̃ k) + ǫλi ≥ 0, we can guarantee that both (25) and (26) are satisfied.\nCase (B). Since σi(X̃ k) > 0 for all k ≥ 0, we have σi(−Ḡ) = τ by (23). Hence, both (25) and (26) can be satisfied by choosing ǫ > 0 so that σi(X̃ k) + ǫλi ≥ 0.\nCase (C). By Proposition 4.2, we have X̄ ∈ Xc. Since X k → X̄ and γk = ‖X k − X̃k‖F ≤ ‖Xk − X̄‖F , we have X̃ k → X̄ as well. It follows that σi(X̄) = 0, as σi(X̃\nk) = 0 for all k ≥ 0 by assumption. Now, since Xk −Gk → X̄ − Ḡ and σki > τ , we have σ̄i ≥ τ . Thus, Proposition 4.2 implies that τ ≤ σ̄i = σi(X̄ − Ḡ) = σi(X̄) + σi(−Ḡ) = σi(−Ḡ). This, together with (23), yields σi(−Ḡ) = τ . Since λi > 0 by Proposition 4.3, we conclude that both (25) and (26) can be satisfied by any choice of ǫ > 0.\nThus, in all three cases, the claim is established. In particular, we have X̂ ∈ Xc. This, together with 〈Xk − X̃k, Q̄〉 > 0 and ‖Q̄‖F = 1, yields\n‖Xk − X̂‖2F = ‖X k − X̃k − ǫQ̄‖2F = ‖X k − X̃k‖2F − 2ǫ〈X k − X̃k, Q̄〉+ ǫ2 < ‖Xk − X̃k‖2F\nfor ǫ > 0 sufficiently small, which contradicts the fact that X̃k is the projection of Xk onto Xc. This completes the proof of Lemma 4.1(c)."
    }, {
      "heading" : "5 Numerical Experiments",
      "text" : "In this section, we complement our theoretical results by testing the numerical performance of the PGM (5) on two problems: matrix completion and matrix classification.\nMatrix Completion: We randomly generate an n × n matrix M with a prescribed rank r. Then, we fix a sampling ratio θ ∈ (0, 1] and sample p = ⌊θn2⌋ entries of M uniformly at random. This induces a sampling operatorP : Rm×n → Rp and an observation vector b ∈ Rp. In our experiments, we fix the rank r = 3 and use the square loss f(·) = ‖P(·) − b‖22/2 with regularization parameter µ = 1 in problem (1). We then solve the resulting problem for different values of n and θ using the PGM (5) with a fixed step size α = 1. We stop the algorithm when F (Xk) − F (Xk+1) < 10−8. Figure 1 shows the semi–log plots of the error in objective value and the error in solution against the number of iterations. It can be seen that as long as the iterates are close enough to the optimal set, both the objective values and the solutions converge linearly.\n0 200 400 600 800 1000 1200\nIterations\nConvergence Performance of Objective Value\nθ=0.2 θ=0.5 θ=0.8\nn = 40\n0 200 400 600 800 1000 1200\nIterations\nConvergence Performance of Solution\nθ=0.2 θ=0.5 θ=0.8\nn = 40\nFigure 2: Matrix Classification\nMatrix Classification: We consider a matrix classification problem under the setting described in [21]. Specifically, we first randomly generate a low-rank matrix classifier X∗, which is an n× n symmetric matrix of rank r. Then, we specify a sampling ratio θ ∈ (0, 1] and sample p = ⌊θn2⌋/2 independent n × n symmetric matrices W1, . . . ,Wp from the standard Wishart distribution with n degrees of freedom. The label of Wi, denoted by yi, is given by sgn(〈X\n∗,Wi〉). In our experiments, we fix the rank r = 3, the dimension n = 40, and use the logistic loss f(·) =\n∑p i=1 log(1 +\nexp(−yi〈·,Wi〉)) with regularization parameter µ = 1 in problem (1). Since a good lower bound on the Lipschitz constant Lf of ∇f is not readily available in this case, a backtracking line search was adopted at each iteration to achieve an acceptable step size; see, e.g., [3]. We stop the algorithm when F (Xk) − F (Xk+1) < 10−6. Figure 2 shows the convergence performance of the PGM (5) as θ varies. Again, it can be seen that both the objective values and the solutions converge linearly."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper, we have established the linear convergence of the PGM for solving a class of trace norm–regularized problems. Our convergence result does not require the objective function to be strongly convex and is applicable to many settings in machine learning. The key technical tool in the proof is a Lipschitzian error bound for trace norm–regularized problems, which could be of independent interest. A future direction is to study error bounds for more general matrix norm– regularized problems and their implications on the convergence rates of first–order methods.\nAcknowledgments The authors would like to thank the anonymous reviewers for their careful reading of the manuscript and insightful comments. The research of A. M.–C. So is supported in part by a gift grant from Microsoft Research Asia."
    } ],
    "references" : [ {
      "title" : "Uncovering Shared Structures in Multiclass Classification",
      "author" : [ "Y. Amit", "M. Fink", "N. Srebro", "S. Ullman" ],
      "venue" : "Proc. 24th ICML, pages 17–24",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Convex Multi–Task Feature Learning",
      "author" : [ "A. Argyriou", "T. Evgeniou", "M. Pontil" ],
      "venue" : "Mach. Learn., 73(3):243– 272",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "A Fast Iterative Shrinkage–Thresholding Algorithm for Linear Inverse Problems",
      "author" : [ "A. Beck", "M. Teboulle" ],
      "venue" : "SIAM J. Imaging Sci., 2(1):183–202",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Lectures on Modern Convex Optimization: Analysis",
      "author" : [ "A. Ben-Tal", "A. Nemirovski" ],
      "venue" : "Algorithms, and Engineering Applications. MPS–SIAM Series on Optimization. Society for Industrial and Applied Mathematics, Philadelphia, Pennsylvania",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "A Rank Minimization Heuristic with Application to Minimum Order System Approximation",
      "author" : [ "M. Fazel", "H. Hindi", "S.P. Boyd" ],
      "venue" : "Proc. 2001 ACC, pages 4734–4739",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Recovering Low–Rank Matrices from Few Coefficients in Any Basis",
      "author" : [ "D. Gross" ],
      "venue" : "IEEE Trans. Inf. Theory, 57(3):1548–1566",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Beyond Convex Relaxation: A Polynomial–Time Non–Convex Optimization Approach to Network Localization",
      "author" : [ "S. Ji", "K.-F. Sze", "Z. Zhou", "A.M.-C. So", "Y. Ye" ],
      "venue" : "Proc. 32nd IEEE INFOCOM, pages 2499–2507",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "An Accelerated Gradient Method for Trace Norm Minimization",
      "author" : [ "S. Ji", "J. Ye" ],
      "venue" : "Proc. 26th ICML, pages 457–464",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Nuclear–Norm Penalization and Optimal Rates for Noisy Low–Rank Matrix Completion",
      "author" : [ "V. Koltchinskii", "K. Lounici", "A.B. Tsybakov" ],
      "venue" : "Ann. Stat., 39(5):2302–2329",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Error Bounds and Convergence Analysis of Feasible Descent Methods: A General Approach",
      "author" : [ "Z.-Q. Luo", "P. Tseng" ],
      "venue" : "Ann. Oper. Res., 46(1):157–178",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Fixed Point and Bregman Iterative Methods for Matrix Rank Minimization",
      "author" : [ "S. Ma", "D. Goldfarb", "L. Chen" ],
      "venue" : "Math. Program., 128(1–2):321–353",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Introductory Lectures on Convex Optimization: A Basic Course",
      "author" : [ "Yu. Nesterov" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2004
    }, {
      "title" : "Guaranteed Minimum–Rank Solutions of Linear Matrix Equations via Nuclear Norm Minimization",
      "author" : [ "B. Recht", "M. Fazel", "P.A. Parrilo" ],
      "venue" : "SIAM Rev., 52(3):471–501",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Convex Analysis",
      "author" : [ "R.T. Rockafellar" ],
      "venue" : "Princeton Landmarks in Mathematics and Physics. Princeton University Press, Princeton, New Jersey",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Variational Analysis",
      "author" : [ "R.T. Rockafellar", "R.J.-B. Wets" ],
      "venue" : "volume 317 of Grundlehren der mathematischen Wissenschaften. Springer–Verlag, Berlin Heidelberg, second edition",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Convergence Rates of Inexact Proximal–Gradient Methods for Convex Optimization",
      "author" : [ "M. Schmidt", "N. Le Roux", "F. Bach" ],
      "venue" : "Proc. NIPS 2011, pages 1458–1466",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "A Unified Theorem on SDP Rank Reduction",
      "author" : [ "A.M.-C. So", "Y. Ye", "J. Zhang" ],
      "venue" : "Math. Oper. Res., 33(4):910–920",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Facial Structures of Schatten p–Norms",
      "author" : [ "W. So" ],
      "venue" : "Linear and Multilinear Algebra, 27(3):207–212",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 1990
    }, {
      "title" : "An Accelerated Proximal Gradient Algorithm for Nuclear Norm Regularized Linear Least Squares Problems",
      "author" : [ "K.-C. Toh", "S. Yun" ],
      "venue" : "Pac. J. Optim., 6(3):615–640",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Classifying Matrices with a Spectral Regularization",
      "author" : [ "R. Tomioka", "K. Aihara" ],
      "venue" : "Proc. of the 24th ICML, pages 895–902",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "A Fast Augmented Lagrangian Algorithm for Learning Low–Rank Matrices",
      "author" : [ "R. Tomioka", "T. Suzuki", "M. Sugiyama", "H. Kashima" ],
      "venue" : "Proc. 27th ICML, pages 1087–1094",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Approximation Accuracy",
      "author" : [ "P. Tseng" ],
      "venue" : "Gradient Methods, and Error Bound for Structured Convex Optimization. Math. Program., 125(2):263–295",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A Coordinate Gradient Descent Method for Nonsmooth Separable Minimization",
      "author" : [ "P. Tseng", "S. Yun" ],
      "venue" : "Math. Program., 117(1–2):387–423",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Convex Multi–View Subspace Learning",
      "author" : [ "M. White", "Y. Yu", "X. Zhang", "D. Schuurmans" ],
      "venue" : "Proc. NIPS 2012, pages 1682–1690",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "On the Linear Convergence of a Proximal Gradient Method for a Class of Nonsmooth Convex Minimization Problems",
      "author" : [ "H. Zhang", "J. Jiang", "Z.-Q. Luo" ],
      "venue" : "J. Oper. Res. Soc. China, 1(2):163–186",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 16,
      "context" : "Indeed, such a problem arises in a wide variety of applications, including approximation algorithms [17], automatic control [5], matrix classification [20], matrix completion [6], multi–label classification [1], multi–task learning [2], network localization [7], subspace learning [24], and trace regression [9], just to name a few.",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 4,
      "context" : "Indeed, such a problem arises in a wide variety of applications, including approximation algorithms [17], automatic control [5], matrix classification [20], matrix completion [6], multi–label classification [1], multi–task learning [2], network localization [7], subspace learning [24], and trace regression [9], just to name a few.",
      "startOffset" : 124,
      "endOffset" : 127
    }, {
      "referenceID" : 19,
      "context" : "Indeed, such a problem arises in a wide variety of applications, including approximation algorithms [17], automatic control [5], matrix classification [20], matrix completion [6], multi–label classification [1], multi–task learning [2], network localization [7], subspace learning [24], and trace regression [9], just to name a few.",
      "startOffset" : 151,
      "endOffset" : 155
    }, {
      "referenceID" : 5,
      "context" : "Indeed, such a problem arises in a wide variety of applications, including approximation algorithms [17], automatic control [5], matrix classification [20], matrix completion [6], multi–label classification [1], multi–task learning [2], network localization [7], subspace learning [24], and trace regression [9], just to name a few.",
      "startOffset" : 175,
      "endOffset" : 178
    }, {
      "referenceID" : 0,
      "context" : "Indeed, such a problem arises in a wide variety of applications, including approximation algorithms [17], automatic control [5], matrix classification [20], matrix completion [6], multi–label classification [1], multi–task learning [2], network localization [7], subspace learning [24], and trace regression [9], just to name a few.",
      "startOffset" : 207,
      "endOffset" : 210
    }, {
      "referenceID" : 1,
      "context" : "Indeed, such a problem arises in a wide variety of applications, including approximation algorithms [17], automatic control [5], matrix classification [20], matrix completion [6], multi–label classification [1], multi–task learning [2], network localization [7], subspace learning [24], and trace regression [9], just to name a few.",
      "startOffset" : 232,
      "endOffset" : 235
    }, {
      "referenceID" : 6,
      "context" : "Indeed, such a problem arises in a wide variety of applications, including approximation algorithms [17], automatic control [5], matrix classification [20], matrix completion [6], multi–label classification [1], multi–task learning [2], network localization [7], subspace learning [24], and trace regression [9], just to name a few.",
      "startOffset" : 258,
      "endOffset" : 261
    }, {
      "referenceID" : 23,
      "context" : "Indeed, such a problem arises in a wide variety of applications, including approximation algorithms [17], automatic control [5], matrix classification [20], matrix completion [6], multi–label classification [1], multi–task learning [2], network localization [7], subspace learning [24], and trace regression [9], just to name a few.",
      "startOffset" : 281,
      "endOffset" : 285
    }, {
      "referenceID" : 8,
      "context" : "Indeed, such a problem arises in a wide variety of applications, including approximation algorithms [17], automatic control [5], matrix classification [20], matrix completion [6], multi–label classification [1], multi–task learning [2], network localization [7], subspace learning [24], and trace regression [9], just to name a few.",
      "startOffset" : 308,
      "endOffset" : 311
    }, {
      "referenceID" : 12,
      "context" : "Such an approach is quite natural, as the trace norm is the tightest convex lower bound of the rank function over the set of matrices with spectral norm at most one [13].",
      "startOffset" : 165,
      "endOffset" : 169
    }, {
      "referenceID" : 3,
      "context" : "By standard results in convex optimization [4], the above formulation is tractable (i.",
      "startOffset" : 43,
      "endOffset" : 46
    }, {
      "referenceID" : 7,
      "context" : "Currently, a popular method for solving (1) is the proximal gradient method (PGM), which exploits the composite nature of the objective function F and certain smoothness properties of the loss function f [8, 19, 11].",
      "startOffset" : 204,
      "endOffset" : 215
    }, {
      "referenceID" : 18,
      "context" : "Currently, a popular method for solving (1) is the proximal gradient method (PGM), which exploits the composite nature of the objective function F and certain smoothness properties of the loss function f [8, 19, 11].",
      "startOffset" : 204,
      "endOffset" : 215
    }, {
      "referenceID" : 10,
      "context" : "Currently, a popular method for solving (1) is the proximal gradient method (PGM), which exploits the composite nature of the objective function F and certain smoothness properties of the loss function f [8, 19, 11].",
      "startOffset" : 204,
      "endOffset" : 215
    }, {
      "referenceID" : 11,
      "context" : "The sublinear O(1/k(2)) convergence rate is known to be optimal if f is simply given by a first–order oracle [12].",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 9,
      "context" : "Once we have such a bound, a routine application of the powerful analysis framework developed by Luo and Tseng [10] will yield the desired linear convergence result.",
      "startOffset" : 111,
      "endOffset" : 115
    }, {
      "referenceID" : 22,
      "context" : "Prior to this work, Lipschitzian error bounds for composite function minimization are available for cases where the non–smooth part either has a polyhedral epigraph (such as the l1–norm) [23] or is the (sparse) group LASSO regularization [22, 25].",
      "startOffset" : 187,
      "endOffset" : 191
    }, {
      "referenceID" : 21,
      "context" : "Prior to this work, Lipschitzian error bounds for composite function minimization are available for cases where the non–smooth part either has a polyhedral epigraph (such as the l1–norm) [23] or is the (sparse) group LASSO regularization [22, 25].",
      "startOffset" : 238,
      "endOffset" : 246
    }, {
      "referenceID" : 24,
      "context" : "Prior to this work, Lipschitzian error bounds for composite function minimization are available for cases where the non–smooth part either has a polyhedral epigraph (such as the l1–norm) [23] or is the (sparse) group LASSO regularization [22, 25].",
      "startOffset" : 238,
      "endOffset" : 246
    }, {
      "referenceID" : 9,
      "context" : "1 and some standard properties of the PGM (5), we can apply the convergence analysis framework developed by Luo and Tseng [10] to establish the linear convergence of (5).",
      "startOffset" : 122,
      "endOffset" : 126
    }, {
      "referenceID" : 20,
      "context" : "Matrix Classification: We consider a matrix classification problem under the setting described in [21].",
      "startOffset" : 98,
      "endOffset" : 102
    } ],
    "year" : 2013,
    "abstractText" : "Motivated by various applications in machine learning, the problem of minimizing a convex smooth loss function with trace norm regularization has received much attention lately. Currently, a popular method for solving such problem is the proximal gradient method (PGM), which is known to have a sublinear rate of convergence. In this paper, we show that for a large class of loss functions, the convergence rate of the PGM is in fact linear. Our result is established without any strong convexity assumption on the loss function. A key ingredient in our proof is a new Lipschitzian error bound for the aforementioned trace norm–regularized problem, which may be of independent interest.",
    "creator" : null
  }
}