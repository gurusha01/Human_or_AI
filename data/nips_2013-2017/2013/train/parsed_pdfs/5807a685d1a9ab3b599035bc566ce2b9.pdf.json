{
  "name" : "5807a685d1a9ab3b599035bc566ce2b9.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Local Privacy and Minimax Bounds: Sharp Rates for Probability Estimation",
    "authors" : [ "John C. Duchi", "Michael I. Jordan", "Martin J. Wainwright" ],
    "emails" : [ "jduchi@eecs.berkeley.edu", "jordan@eecs.berkeley.edu", "wainwrig@eecs.berkeley.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The original motivation for providing privacy in statistical problems, first discussed by Warner [23], was that “for reasons of modesty, fear of being thought bigoted, or merely a reluctance to confide secrets to strangers,” respondents to surveys might prefer to be able to answer certain questions non-truthfully, or at least without the interviewer knowing their true response. With this motivation, Warner considered the problem of estimating the fractions of the population belonging to certain strata, which can be viewed as probability estimation within a multinomial model. In this paper, we revisit Warner’s probability estimation problem, doing so within a theoretical framework that allows us to characterize optimal estimation under constraints on privacy. We also apply our theoretical tools to a further probability estimation problem—that of nonparametric density estimation.\nIn the large body of research on privacy and statistical inference [e.g., 23, 14, 10, 15], a major focus has been on the problem of reducing disclosure risk: the probability that a member of a dataset can be identified given released statistics of the dataset. The literature has stopped short, however, of providing a formal treatment of disclosure risk that would permit decision-theoretic tools to be used in characterizing trade-offs between the utility of achieving privacy and the utility associated with an inferential goal. Recently, a formal treatment of disclosure risk known as “differential privacy” has been proposed and studied in the cryptography, database and theoretical computer science literatures [11, 1]. Differential privacy has strong semantic privacy guarantees that make it a good candidate for declaring a statistical procedure or data collection mechanism private, and it has been the focus of a growing body of recent work [13, 16, 24, 21, 6, 18, 8, 5, 9].\nIn this paper, we bring together the formal treatment of disclosure risk provided by differential privacy with the tools of minimax decision theory to provide a theoretical treatment of probability estimation under privacy constraints. Just as in classical minimax theory, we are able to provide lower bounds on the convergence rates of any estimator, in our case under a restriction to estimators that guarantee privacy. We complement these results with matching upper bounds that are achievable using computationally efficient algorithms. We thus bring classical notions of privacy, as introduced by Warner [23], into contact with differential privacy and statistical decision theory, obtaining quantitative trade-offs between privacy and statistical efficiency."
    }, {
      "heading" : "1.1 Setting and contributions",
      "text" : "Let us develop some basic formalism before describing our main results. We study procedures that receive private views Z1, . . . , Zn ∈ Z of an original set of observations, X1, . . . , Xn ∈ X , where X is the (known) sample space. In our setting, Zi is drawn conditional on Xi via the channel distribution Qi(Zi | Xi = x); typically we omit the dependence of Qi on i. We focus in this paper on the non-interactive setting (in information-theoretic terms, on memoryless channels), where Qi is chosen prior to seeing data; see Duchi et al. [9] for more discussion.\nWe assume each of these private views Zi is α-differentially private for the original dataXi. To give a precise definition for this type of privacy, known as “local privacy,” let σ(Z) be the σ-field on Z over which the channel Q is defined. Then Q provides α-local differential privacy if\nsup { Q(S | Xi = x) Q(S | Xi = x′) | S ∈ σ(Z), and x, x′ ∈ X } ≤ exp(α). (1)\nThis formulation of local privacy was first proposed by Evfimievski et al. [13]. The likelihood ratio bound (1) is attractive for many reasons. It means that any individual providing data guarantees his or her own privacy—no further processing or mistakes by a collection agency can compromise one’s data—and the individual has plausible deniability about taking a value x, since any outcome z is nearly as likely to have come from some other initial value x′. The likelihood ratio also controls the error rate in tests for the presence of points x in the data [24].\nIn the current paper, we study minimax convergence rates when the data provided satisfies the local privacy guarantee (1). Our two main results quantify the penalty that must be paid when local privacy at a level α is provided in multinomial estimation and density estimation problems. At a high level, our first result implies that for estimation of a d-dimensional multinomial probability mass function, the effective sample size of any statistical estimation procedure decreases from n to nα2/d whenever α is a sufficiently small constant. A consequence of our results is that Warner’s randomized response procedure [23] enjoys optimal sample complexity; it is interesting to note that even with the recent focus on privacy and statistical inference, the optimal privacy-preserving strategy for problems such as survey collection has been known for almost 50 years.\nOur second main result, on density estimation, exhibits an interesting departure from standard minimax estimation results. If the density being estimated has β continuous derivatives, then classical results on density estimation [e.g., 26, 25, 22] show that the minimax integrated squared error scales (in the sample size n) as n−2β/(2β+1). In the locally private case, we show that there is a difference in the polynomial rate of convergence: we obtain a scaling of (α2n)−2β/(2β+2). We give efficiently implementable algorithms that attain sharp upper bounds as companions to our lower bounds, which in some cases exhibit the necessity of non-trivial sampling strategies to guarantee privacy.\nNotation: Given distributions P and Q defined on a space X , each absolutely continuous with respect to a measure µ (with densities p and q), the KL-divergence between P and Q is\nDkl (P‖Q) := ∫\nX\ndP log dP\ndQ =\n∫\nX\np log p\nq dµ.\nLetting σ(X ) denote an appropriate σ-field on X , the total variation distance between P and Q is\n‖P −Q‖TV := sup S∈σ(X ) |P (S)−Q(S)| = 1 2\n∫\nX\n|p(x)− q(x)| dµ(x).\nLet X be distributed according to P and Y | X be distributed according to Q(· | X), and let M = ∫ Q(· | x)dP (x) denote the marginal of Y . The mutual information between X and Y is\nI(X;Y ) := EP [Dkl (Q(· | X)‖M(·))] = ∫ Dkl (Q(· | X = x)‖M(·)) dP (x).\nA random variable Y has Laplace(α) distribution if its density pY (y) = α 2 exp (−α|y|). We write an . bn to denote an = O(bn) and an ≍ bn to denote an = O(bn) and bn = O(an). For a convex set C ⊂ Rd, we let ΠC denote the orthogonal projection operator onto C."
    }, {
      "heading" : "2 Background and Problem Formulation",
      "text" : "In this section, we provide the necessary background on the minimax framework used throughout the paper, more details of which can be found in standard sources [e.g., 17, 25, 26, 22]. We also reference our work [9] paper on statistical inference under differential privacy constraints; we restate two theorems from the paper [9] to keep our presentation self-contained."
    }, {
      "heading" : "2.1 Minimax framework",
      "text" : "Let P denote a class of distributions on the sample space X , and let θ : P → Θ denote a function defined on P . The range Θ depends on the underlying statistical model; for example, for density estimation, Θ may consist of the set of probability densities defined on [0, 1]. We let ρ denote the semi-metric on the space Θ that we use to measure the error of an estimator for θ, and Φ : R+ → R+ be a non-decreasing function with Φ(0) = 0 (for example, Φ(t) = t2).\nRecalling that Z is the domain of the private variables Zi, let θ̂ : Zn → Θ denote an arbitrary estimator for θ. Let Qα denote the set of conditional (or channel) distributions guaranteeing α-local privacy (1). Looking uniformly over all channels Q ∈ Qα, we define the central object of interest for this paper, the α-private minimax rate for the family θ(P),\nMn(θ(P),Φ ◦ ρ, α) := inf θ̂,Q∈Qα sup P∈P EP,Q\n[ Φ ( ρ(θ̂(Z1, . . . , Zn), θ(P )) )] . (2)\nassociated with estimating θ based on (Z1, . . . , Zn). We remark here (see also the discussion in [9]) that the private minimax risk (2) is different from previous work on optimality in differential privacy (e.g. [2, 16, 8]): prior work focuses on accurate estimation of a sample quantity θ(x1:n) based on the sample x1:n, while we provide lower bounds on error of the population estimator θ(P ). Lower bounds on population estimation imply those on sample estimation, so our lower bounds are stronger than most of those in prior work.\nA standard route for lower bounding the minimax risk (2) is by reducing the estimation problem to the testing problem of identifying a point θ ∈ Θ from a collection of well-separated points [26, 25]. Given an index set V , the indexed family of distributions {Pν , ν ∈ V} ⊂ P is a 2δ-packing of Θ if ρ(θ(Pν), θ(Pν′)) ≥ 2δ for all ν 6= ν′ in V . The setup is that of a standard hypothesis testing problem: nature chooses V ∈ V uniformly at random, then data (X1, . . . , Xn) are drawn i.i.d. from Pnν , conditioning on V = ν. The problem is to identify the member ν of the packing set V . In this work we have the additional complication that all the statistician observes are the private samplesZ1, . . . , Zn. To that end, if we letQ\nn(· | x1:n) denote the conditional distribution ofZ1, . . . , Zn given that X1 = x1, . . . , Xn = xn, we define the marginal channel M n ν via the expression\nMnν (A) := ∫ Qn(A | x1, . . . , xn)dPν(x1, . . . , xn) for A ∈ σ(Zn). (3)\nLetting ψ : Zn → V denote an arbitrary testing procedure, we have the following minimax bound, whose two parts are known as Le Cam’s two-point method [26, 22] and Fano’s inequality [25, 7, 22].\nLemma 1 (Minimax risk bound). For the previously described estimation and testing problems,\nMn(θ(P),Φ ◦ ρ,Q) ≥ Φ(δ) inf ψ P(ψ(Z1, . . . , Zn) 6= V ), (4)\nwhere the infimum is taken over all testing procedures. For a binary test specified by V = {ν, ν′},\ninf ψ\nP (ψ(Z1, . . . , Zn) 6= V ) = 1 2 − 1 2 ‖Mnν −Mnν′‖TV , (5a)\nand more generally,\ninf ψ\nP(ψ(Z1, . . . , Zn) 6= V ) ≥ [ 1− I(Z1, . . . , Zn;V ) + log 2\nlog |V|\n] . (5b)"
    }, {
      "heading" : "2.2 Information bounds",
      "text" : "The main step in proving minimax lower bounds is to control the divergences involved in the lower bounds (5a) and (5b). We review two results from our work [9] that obtain such bounds as a function of the amount of privacy provided. The second of the results provides a variational upper bound on the mutual information I(Z1, . . . , Zn;V ), in that we optimize jointly over subset S ⊂ X . To state the proposition, we require a bit of notation: for each i ∈ {1, . . . , n}, let Pν,i be the distribution of Xi conditional on the random packing element V = ν, and let M n ν be the marginal distribution (3) induced by passing Xi through Q. Define the mixture distribution P i = 1 |V| ∑ ν∈V Pν,i, We can then state a proposition summarizing the results we require from Duchi et al. [9]: Proposition 1 (Information bounds). For any ν, ν′ ∈ V and α ≥ 0,\nDkl (M n ν ‖Mnν′) ≤ 4(eα − 1)2\nn∑\ni=1\n‖Pν,i − Pν′,i‖2TV . (6)\nAdditionally for V chosen uniformly at random from V , we have the variational bound\nI(Z1, . . . , Zn;V ) ≤ eα (eα − e−α)2\n|V|\nn∑\ni=1\nsup S∈σ(X )\n∑\nν∈V\n( Pν,i(S)− P (S) )2 . (7)\nBy combining Proposition 1 with Lemma 1, it is possible to derive sharp lower bounds on arbitrary estimation procedures under α-local privacy. In the remainder of the paper, we demonstrate this combination for probability estimation problems; we provide proofs of all results in [9]."
    }, {
      "heading" : "3 Multinomial Estimation under Local Privacy",
      "text" : "In this section we return to the classical problem of avoiding answer bias in surveys, the original motivation for studying local privacy [23]."
    }, {
      "heading" : "3.1 Minimax rates of convergence for multinomial estimation",
      "text" : "Let ∆d := { θ ∈ Rd | θ ≥ 0,∑dj=1 θj = 1 } denote the probability simplex in Rd. The multinomial estimation problem is defined as follows. Given a vector θ ∈ ∆d, samples X are drawn i.i.d. from a multinomial with parameters θ, where Pθ(X = j) = θj for j ∈ {1, . . . , d}, and the goal is to estimate θ. In one of the earliest evaluations of privacy, Warner [23] studied the Bernoulli variant of this problem and proposed randomized response: for a given survey question, respondents provide a truthful answer with probability p > 1/2 and lie with probability 1− p. In our setting, we assume the statistician sees α-locally private (1) random variables Zi for the corresponding samplesXi from the multinomial. In this case, we have the following result, which characterizes the minimax rate of estimation of a multinomial in both mean-squared error E[‖θ̂ − θ‖22] and absolute error E[‖θ̂ − θ‖1]; the latter may be more relevant for probability estimation problems. Theorem 1. There exist universal constants 0 < cℓ ≤ cu < 5 such that for all α ∈ [0, 1], the minimax rate for multinomial estimation satisfies the bounds\ncℓmin\n{ 1,\n1√ nα2 , d nα2\n} ≤ Mn ( ∆d, ‖·‖22 , α ) ≤ cumin { 1, d\nnα2\n} , (8)\nand\ncℓmin\n{ 1,\nd√ nα2\n} ≤ Mn (∆d, ‖·‖1 , α) ≤ cumin { 1,\nd√ nα2\n} . (9)\nTheorem 1 shows that providing local privacy can sometimes be quite detrimental to the quality of statistical estimators. Indeed, let us compare this rate to the classical rate in which there is no privacy. Then estimating θ via proportions (i.e., maximum likelihood), we have\nE [ ‖θ̂ − θ‖22 ] = d∑\nj=1\nE [ (θ̂j − θj)2 ] = 1\nn\nd∑\nj=1\nθj(1− θj) ≤ 1\nn\n( 1− 1\nd\n) < 1\nn .\nBy inequality (8), for suitably large sample sizes n, the effect of providing differential privacy at a level α causes a reduction in the effective sample size of n 7→ nα2/d."
    }, {
      "heading" : "3.2 Optimal mechanisms: attainability for multinomial estimation",
      "text" : "An interesting consequence of the lower bound in (8) is the following fact that we now demonstrate: Warner’s classical randomized response mechanism [23] (with minor modification) achieves the optimal convergence rate. There are also other relatively simple estimation strategies that achieve convergence rate d/nα2; the perturbation approach Dwork et al. [11] propose, where Laplace(α) noise is added to each coordinate of a multinomial sample, is one such strategy. Nonetheless, the ease of use and explainability of randomized response, coupled with our optimality results, provide support for randomized response as a preferred method for private estimation of population probabilities.\nWe now prove that randomized response attains the optimal rate of convergence. There is a bijection between multinomial samples x ∈ {1, . . . , d} and the d standard basis vectors e1, . . . , ed ∈ Rd, so we abuse notation and represent samples x as either when designing estimation strategies. In randomized response, we construct the private vector Z ∈ {0, 1}d from a multinomial observation x ∈ {e1, . . . , ed} by sampling d coordinates independently via the procedure\n[Z]j =\n{ xj with probability exp(α/2) 1+exp(α/2)\n1− xj with probability 11+exp(α/2) . (10)\nWe claim that this channel (10) is α-differentially private: indeed, note that for any x, x′ ∈ ∆d and any vector z ∈ {0, 1}d we have\nQ(Z = z | x) Q(Z = z | x′) = exp (α 2 (‖z − x‖1 − ‖z − x′‖1) ) ∈ [exp(−α), exp(α)] ,\nwhere we used the triangle inequality to assert that | ‖z − x‖1 − ‖z − x′‖1 | ≤ ‖x− x′‖1 ≤ 2. We can compute the expected value and variance of the random variables Z; indeed, by definition (10)\nE[Z | x] = e α/2\n1 + eα/2 x+\n1 1 + eα/2 (1− x) = e α/2 − 1 eα/2 + 1 x+ 1 1 + eα/2 1.\nSince the Z are Bernoulli, we obtain the variance bound E[‖Z − E[Z]‖22] < d/4+1 < d. Recalling the definition of the projection Π∆d onto the simplex, we arrive at the natural estimator\nθ̂part := 1\nn\nn∑\ni=1\n( Zi − 1/(1 + eα/2) ) eα/2 + 1 eα/2 − 1 and θ̂ := Π∆d ( θ̂part ) . (11)\nThe projection of θ̂part onto the probability simplex can be done in time linear in the dimension d of the problem [3], so the estimator (11) is efficiently computable. Since projections only decrease distance, vectors in the simplex are at most distance √ 2 apart, and Eθ[θ̂part] = θ, we find\nE [ ‖θ̂ − θ‖22 ] ≤ min { 2,E [ ‖θ̂part − θ‖22 ]} ≤ min { 2, d\nn\n( eα/2 + 1\neα/2 − 1\n)2 } . min { 1, d\nnα2\n} .\nA similar argument shows that randomized response is minimax optimal for the ℓ1-loss as well."
    }, {
      "heading" : "4 Density Estimation under Local Privacy",
      "text" : "In this section, we turn to studying a nonparametric statistical problem in which the effects of local differential privacy turn out to be somewhat more severe. We show that for the problem of density estimation, instead of just multiplicative loss in the effective sample size as in the previous section, imposing local differential privacy leads to a different convergence rate. In more detail, we consider estimation of probability densities f : R → R+, ∫ f(x)dx = 1 and f ≥ 0, defined on the real line, focusing on a standard family of densities of varying smoothness [e.g. 22]. Throughout this section, we let β ∈ N denote a fixed positive integer. Roughly, we consider densities that have bounded βth derivative, and we study density estimation using the squared L2norm ‖f‖22 := ∫ f2(x)dx as our metric; in formal terms, we impose these constraints in terms of Sobolev classes (e.g. [22, 12]). Let the countable collection of functions {ϕj}∞j=1 be an orthonormal basis for L2([0, 1]). Then any function f ∈ L2([0, 1]) can be expanded as a sum ∑∞ j=1 θjϕj in\nterms of the basis coefficients θj := ∫ f(x)ϕj(x)dx, where {θj}∞j=1 ∈ ℓ2(N). The Sobolev space Fβ [C] is obtained by enforcing a particular decay rate on the coefficients θ:\nDefinition 1 (Elliptical Sobolev space). For a given orthonormal basis {ϕj} of L2([0, 1]), smoothness parameter β > 1/2 and radius C, the function class Fβ [C] is given by\nFβ [C] := { f ∈ L2([0, 1]) | f = ∞∑\nj=1\nθjϕj such that\n∞∑\nj=1\nj2βϕ2j ≤ C2 } .\nIf we choose the trigonometric basis as our orthonormal basis, then membership in the class Fβ [C] corresponds to certain smoothness constraints on the derivatives of f . More precisely, for j ∈ N, consider the orthonormal basis for L2([0, 1]) of trigonometric functions:\nϕ0(t) = 1, ϕ2j(t) = √ 2 cos(2πjt), ϕ2j+1(t) = √ 2 sin(2πjt). (12)\nNow consider a β-times almost everywhere differentiable function f for which |f (β)(x)| ≤ C for almost every x ∈ [0, 1] satisfying f (k)(0) = f (k)(1) for k ≤ β − 1. Uniformly for such f , there is a universal constant c such that that f ∈ Fβ [cC] [22, Lemma A.3]. Thus, Definition 1 (essentially) captures densities that have Lipschitz-continuous (β − 1)th derivative. In the sequel, we write Fβ when the bound C in Fβ [C] is O(1). It is well known [26, 25, 22] that the minimax risk for nonprivate estimation of densities in the class Fβ scales as\nMn ( Fβ , ‖·‖22 ,∞ ) ≍ n− 2β 2β+1 . (13)\nOur main result is to demonstrate that the classical rate (13) is no longer attainable when we require α-local differential privacy. In Sections 4.2 and 4.3, we show how to achieve the (new) optimal rate using histogram and orthogonal series estimators."
    }, {
      "heading" : "4.1 Lower bounds on density estimation",
      "text" : "We begin by giving our main lower bound on the minimax rate of estimation of densities when are kept differentially private, providing the proof in the longer paper [9].\nTheorem 2. Consider the class of densities Fβ defined using the trigonometric basis (12). For some α ∈ [0, 1], suppose Zi are α-locally private (1) for the samples Xi ∈ [0, 1]. There exists a constant cβ > 0, dependent only on β, such that\nMn ( Fβ , ‖·‖22 , α ) ≥ cβ ( nα2 )− 2β 2β+2 . (14)\nIn comparison with the classical minimax rate (13), the lower bound (14) involves a different polynomial exponent: privacy reduces the exponent from 2β/(2β + 1) to 2β/(2β + 2). For example, for Lipschitz densities we have β = 1, and the rate degrades from n−2/3 to n−1/2.\nInterestingly, no estimator based on Laplace (or exponential) perturbation of the samples Xi themselves can attain the rate of convergence (14). In their study of the deconvolution problem, Carroll and Hall [4] show that if samples Xi are perturbed by additive noise W , where the characteristic function φW of the additive noise has tails behaving as |φW (t)| = O(|t|−a) for some a > 0, then no estimator can deconvolve the samples X +W and attain a rate of convergence better than n−2β/(2β+2a+1). Since the Laplace distribution’s characteristic function has tails decaying as t−2, no estimator based on perturbing the samples directly can attain a rate of convergence better than n−2β/(2β+5). If the lower bound (14) is attainable, we must then study privacy mechanisms that are not simply based on direct perturbation of the samples {Xi}ni=1."
    }, {
      "heading" : "4.2 Achievability by histogram estimators",
      "text" : "We now turn to the mean-squared errors achieved by specific practical schemes, beginning with the special case of Lipschitz density functions (β = 1), for which it suffices to consider a private version of a classical histogram estimate. For a fixed positive integer k ∈ N, let {Xj}kj=1 denote the partition of X = [0, 1] into the intervals\nXj = [(j − 1)/k, j/k) for j = 1, 2, . . . , k − 1, and Xk = [(k − 1)/k, 1].\nAny histogram estimate of the density based on these k bins can be specified by a vector θ ∈ k∆k, where we recall ∆k ⊂ Rk+ is the probability simplex. Any such vector defines a density estimate via the sum fθ := ∑k j=1 θj1Xj , where 1E denotes the characteristic (indicator) function of the set E.\nLet us now describe a mechanism that guarantees α-local differential privacy. Given a data set {X1, . . . , Xn} of samples from the distribution f , consider the vectors\nZi := ek(Xi) +Wi, for i = 1, 2, . . . , n, (15)\nwhere ek(Xi) ∈ ∆k is a k-vector with the jth entry equal to one if Xi ∈ Xj , and zeroes in all other entries, and Wi is a random vector with i.i.d. Laplace(α/2) entries. The variables {Zi}ni=1 so-defined are α-locally differentially private for {Xi}ni=1. Using these private variables, we then form the density estimate f̂ := fθ̂ = ∑k j=1 θ̂j1Xj based on\nθ̂ := Πk\n( k\nn\nn∑\ni=1\nZi\n) , (16)\nwhere Πk denotes the Euclidean projection operator onto the set k∆k. By construction, we have f̂ ≥ 0 and ∫ 1 0 f̂(x)dx = 1, so f̂ is a valid density estimate.\nProposition 2. Consider the estimate f̂ based on k = (nα2)1/4 bins in the histogram. For any 1-Lipschitz density f : [0, 1] → R+, we have\nEf [∥∥f̂ − f ∥∥2 2 ] ≤ 5(α2n)− 12 + √ αn−3/4. (17)\nFor any fixed α > 0, the first term in the bound (17) dominates, and the O((α2n)− 12 ) rate matches the minimax lower bound (14) in the case β = 1: the privatized histogram estimator is minimaxoptimal for Lipschitz densities. This result provides the private analog of the classical result that histogram estimators are minimax-optimal (in the non-private setting) for Lipschitz densities."
    }, {
      "heading" : "4.3 Achievability by orthogonal projection estimators",
      "text" : "For higher degrees of smoothness (β > 1), histogram estimators no longer achieve optimal rates in the classical setting [20]. Accordingly, we turn to estimators based on orthogonal series and show that even under local privacy, they achieve the lower bound (14) for all orders of smoothness β ≥ 1. Recall the elliptical Sobolev space (Definition 1), in which a function f is represented as f =∑∞ j=1 θjϕj , where θj = ∫ f(x)ϕj(x)dx. This representation underlies the classical method of orthonormal series estimation: given a data set, {X1, X2, . . . , Xn}, drawn i.i.d. according to a density f ∈ L2([0, 1]), we first compute the empirical basis coefficients\nθ̂j = 1\nn\nn∑\ni=1\nϕj(Xi) and then set f̂ = k∑\nj=1\nθ̂jϕj , (18)\nwhere the value k ∈ N is chosen either a priori based on known properties of the estimation problem or adaptively, for example, using cross-validation [12, 22].\nIn the setting of local privacy, we consider a mechanism that, instead of releasing the vector of coefficients ( ϕ1(Xi), . . . , ϕk(Xi) ) for each data point, employs a random vector Zi = (Zi,1, . . . , Zi,k) with the property that E[Zi,j | Xi] = ϕj(Xi) for each j = 1, 2, . . . , k. We assume the basis functions are uniformly bounded; i.e., there exists a constant B0 = supj supx |ϕj(x)| < ∞. For a fixed number B strictly larger than B0 (to be specified momentarily), consider the following scheme:\nSampling strategy Given a vector τ ∈ [−B0, B0]k, construct τ̃ ∈ {−B0, B0}k with coordinates τ̃j sampled independently from {−B0, B0} with probabilities 12 − τj 2B0 and 12 + τj 2B0 . Sample\nT from a Bernoulli(eα/(eα + 1)) distribution. Then choose Z ∈ {−B,B}k via\nZ ∼ { Uniform on { z ∈ {−B,B}k : 〈z, τ̃〉 > 0 } if T = 1\nUniform on { z ∈ {−B,B}k : 〈z, τ̃〉 ≤ 0 } if T = 0.\n(19)\nBy inspection, Z is α-differentially private for any initial vector in the box [−B0, B0]k, and moreover, the samples (19) are efficiently computable (for example by rejection sampling). Starting from the vector τ ∈ Rk, τj = ϕj(Xi), in the above sampling strategy we have\nE[[Z]j | X = x] = ck B\nB0 √ k\n( eα\neα + 1 − 1 eα + 1\n) ϕj(x) = ck B\nB0 √ k eα − 1 eα + 1 ϕj(x), (20)\nfor a constant ck that may depend on k but is O(1) and bounded away from 0. Consequently, to attain the unbiasedness condition E[[Zi]j | Xi] = ϕj(Xi), it suffices to take B = O(B0 √ k/α).\nThe full sampling and inferential scheme are as follows: (i) given a data point Xi, construct the vector τ = [ϕj(Xi)] k j=1; (ii) sample Zi according to strategy (19) using τ and the bound B =\nB0 √ k(eα + 1)/ck(e α − 1). (The constant ck is as in the expression (20).) Using the estimator\nf̂ := 1\nn\nn∑\ni=1\nk∑\nj=1\nZi,jϕj , (21)\nwe obtain the following proposition.\nProposition 3. Let {ϕj} be a B0-bounded orthonormal basis for L2([0, 1]). There exists a constant c (depending only on C and B0) such that the estimator (21) with k = (nα 2)1/(2β+2) satisfies\nsup f∈Fβ[C] Ef\n[ ‖f − f̂‖22 ] ≤ c ( nα2 )− 2β 2β+2 .\nPropositions 2 and 3 make clear that the minimax lower bound (14) is sharp, as claimed.\nBefore concluding our exposition, we make a few remarks on other potential density estimators. Our orthogonal-series estimator (21) (and sampling scheme (20)), while similar in spirit to that proposed by Wasserman and Zhou [24, Sec. 6], is different in that it is locally private and requires a different noise strategy to obtain both α-local privacy and optimal convergence rate. Lei [19] considers private M -estimators based on first performing a histogram density estimate, then using this to construct a second estimator; his estimator is not locally private, and the resulting M -estimators have sub-optimal convergence rates. Finally, we remark that density estimators that are based on orthogonal series and Laplace perturbation are sub-optimal: they can achieve (at best) rates of (nα2)− 2β\n2β+3 , which is polynomially worse than the sharp result provided by Proposition 3. It appears that appropriately chosen noise mechanisms are crucial for obtaining optimal results."
    }, {
      "heading" : "5 Discussion",
      "text" : "We have linked minimax analysis from statistical decision theory with differential privacy, bringing some of their respective foundational principles into close contact. In this paper particularly, we showed how to apply our divergence bounds to obtain sharp bounds on the convergence rate for certain nonparametric problems in addition to standard finite-dimensional settings. By providing sharp convergence rates for many standard statistical inference procedures under local differential privacy, we have developed and explored some tools that may be used to better understand privacy-preserving statistical inference and estimation procedures. We have identified a fundamental continuum along which privacy may be traded for utility in the form of accurate statistical estimates, providing a way to adjust statistical procedures to meet the privacy or utility needs of the statistician and the population being sampled. Formally identifying this trade-off in other statistical problems should allow us to better understand the costs and benefits of privacy; we believe we have laid some of the groundwork to do so."
    }, {
      "heading" : "Acknowledgments",
      "text" : "JCD was supported by a Facebook Graduate Fellowship and an NDSEG fellowship. Our work was supported in part by the U.S. Army Research Laboratory, U.S. Army Research Office under grant number W911NF-11-1-0391, and Office of Naval Research MURI grant N00014-11-1-0688."
    } ],
    "references" : [ {
      "title" : "Privacy, accuracy, and consistency too: A holistic solution to contingency table release",
      "author" : [ "B. Barak", "K. Chaudhuri", "C. Dwork", "S. Kale", "F. McSherry", "K. Talwar" ],
      "venue" : "Proceedings of the 26th ACM Symposium on Principles of Database Systems,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Distributed private data analysis: Simultaneously solving how and what",
      "author" : [ "A. Beimel", "K. Nissim", "E. Omri" ],
      "venue" : "Advances in Cryptology, volume 5157 of Lecture Notes in Computer Science, pages 451–468. Springer,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "An O(n) algorithm for quadratic knapsack problems",
      "author" : [ "P. Brucker" ],
      "venue" : "Operations Research Letters, 3(3): 163–166,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 1984
    }, {
      "title" : "Optimal rates of convergence for deconvolving a density",
      "author" : [ "R. Carroll", "P. Hall" ],
      "venue" : "Journal of the American Statistical Association, 83(404):1184–1186,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1988
    }, {
      "title" : "Convergence rates for differentially private statistical estimation",
      "author" : [ "K. Chaudhuri", "D. Hsu" ],
      "venue" : "Proceedings of the 29th International Conference on Machine Learning,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Differentially private empirical risk minimization",
      "author" : [ "K. Chaudhuri", "C. Monteleoni", "A.D. Sarwate" ],
      "venue" : "Journal of Machine Learning Research, 12:1069–1109,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Elements of Information Theory, Second Edition",
      "author" : [ "T.M. Cover", "J.A. Thomas" ],
      "venue" : "Wiley,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Lower bounds in differential privacy",
      "author" : [ "A. De" ],
      "venue" : "Proceedings of the Ninth Theory of Cryptography Conference,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Local privacy and statistical minimax rates",
      "author" : [ "J.C. Duchi", "M.I. Jordan", "M.J. Wainwright" ],
      "venue" : "arXiv:1302.3203 [math.ST],",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Disclosure-limited data dissemination",
      "author" : [ "G.T. Duncan", "D. Lambert" ],
      "venue" : "Journal of the American Statistical Association, 81(393):10–18,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1986
    }, {
      "title" : "Calibrating noise to sensitivity in private data analysis",
      "author" : [ "C. Dwork", "F. McSherry", "K. Nissim", "A. Smith" ],
      "venue" : "Proceedings of the 3rd Theory of Cryptography Conference, pages 265–284,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Nonparametric Curve Estimation: Methods, Theory, and Applications",
      "author" : [ "S. Efromovich" ],
      "venue" : "Springer-Verlag,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Limiting privacy breaches in privacy preserving data mining",
      "author" : [ "A.V. Evfimievski", "J. Gehrke", "R. Srikant" ],
      "venue" : "Proceedings of the Twenty-Second Symposium on Principles of Database Systems, pages 211–222,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "On the question of statistical confidentiality",
      "author" : [ "I.P. Fellegi" ],
      "venue" : "Journal of the American Statistical Association, 67(337):7–18,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 1972
    }, {
      "title" : "Disclosure limitation using perturbation and related methods for categorical data",
      "author" : [ "S.E. Fienberg", "U.E. Makov", "R.J. Steele" ],
      "venue" : "Journal of Official Statistics, 14(4):485–502,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "On the geometry of differential privacy",
      "author" : [ "M. Hardt", "K. Talwar" ],
      "venue" : "Proceedings of the Fourty- Second Annual ACM Symposium on the Theory of Computing, pages 705–714,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "What can we learn privately",
      "author" : [ "S.P. Kasiviswanathan", "H.K. Lee", "K. Nissim", "S. Raskhodnikova", "A. Smith" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2011
    }, {
      "title" : "Differentially private M-estimators",
      "author" : [ "J. Lei" ],
      "venue" : "Advances in Neural Information Processing Systems 25,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "On optimal and data-based histograms",
      "author" : [ "D. Scott" ],
      "venue" : "Biometrika, 66(3):605–610,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 1979
    }, {
      "title" : "Privacy-preserving statistical estimation with optimal convergence rates",
      "author" : [ "A. Smith" ],
      "venue" : "Proceedings of the Fourty-Third Annual ACM Symposium on the Theory of Computing,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Introduction to Nonparametric Estimation",
      "author" : [ "A.B. Tsybakov" ],
      "venue" : "Springer,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Randomized response: a survey technique for eliminating evasive answer bias",
      "author" : [ "S. Warner" ],
      "venue" : "Journal of the American Statistical Association, 60(309):63–69,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 1965
    }, {
      "title" : "A statistical framework for differential privacy",
      "author" : [ "L. Wasserman", "S. Zhou" ],
      "venue" : "Journal of the American Statistical Association, 105(489):375–389,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Information-theoretic determination of minimax rates of convergence",
      "author" : [ "Y. Yang", "A. Barron" ],
      "venue" : "Annals of Statistics, 27(5):1564–1599,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Assouad, Fano, and Le Cam",
      "author" : [ "B. Yu" ],
      "venue" : "Festschrift for Lucien Le Cam, pages 423–435. Springer-Verlag,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 1997
    } ],
    "referenceMentions" : [ {
      "referenceID" : 21,
      "context" : "The original motivation for providing privacy in statistical problems, first discussed by Warner [23], was that “for reasons of modesty, fear of being thought bigoted, or merely a reluctance to confide secrets to strangers,” respondents to surveys might prefer to be able to answer certain questions non-truthfully, or at least without the interviewer knowing their true response.",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 10,
      "context" : "Recently, a formal treatment of disclosure risk known as “differential privacy” has been proposed and studied in the cryptography, database and theoretical computer science literatures [11, 1].",
      "startOffset" : 185,
      "endOffset" : 192
    }, {
      "referenceID" : 0,
      "context" : "Recently, a formal treatment of disclosure risk known as “differential privacy” has been proposed and studied in the cryptography, database and theoretical computer science literatures [11, 1].",
      "startOffset" : 185,
      "endOffset" : 192
    }, {
      "referenceID" : 12,
      "context" : "Differential privacy has strong semantic privacy guarantees that make it a good candidate for declaring a statistical procedure or data collection mechanism private, and it has been the focus of a growing body of recent work [13, 16, 24, 21, 6, 18, 8, 5, 9].",
      "startOffset" : 225,
      "endOffset" : 257
    }, {
      "referenceID" : 15,
      "context" : "Differential privacy has strong semantic privacy guarantees that make it a good candidate for declaring a statistical procedure or data collection mechanism private, and it has been the focus of a growing body of recent work [13, 16, 24, 21, 6, 18, 8, 5, 9].",
      "startOffset" : 225,
      "endOffset" : 257
    }, {
      "referenceID" : 22,
      "context" : "Differential privacy has strong semantic privacy guarantees that make it a good candidate for declaring a statistical procedure or data collection mechanism private, and it has been the focus of a growing body of recent work [13, 16, 24, 21, 6, 18, 8, 5, 9].",
      "startOffset" : 225,
      "endOffset" : 257
    }, {
      "referenceID" : 19,
      "context" : "Differential privacy has strong semantic privacy guarantees that make it a good candidate for declaring a statistical procedure or data collection mechanism private, and it has been the focus of a growing body of recent work [13, 16, 24, 21, 6, 18, 8, 5, 9].",
      "startOffset" : 225,
      "endOffset" : 257
    }, {
      "referenceID" : 5,
      "context" : "Differential privacy has strong semantic privacy guarantees that make it a good candidate for declaring a statistical procedure or data collection mechanism private, and it has been the focus of a growing body of recent work [13, 16, 24, 21, 6, 18, 8, 5, 9].",
      "startOffset" : 225,
      "endOffset" : 257
    }, {
      "referenceID" : 16,
      "context" : "Differential privacy has strong semantic privacy guarantees that make it a good candidate for declaring a statistical procedure or data collection mechanism private, and it has been the focus of a growing body of recent work [13, 16, 24, 21, 6, 18, 8, 5, 9].",
      "startOffset" : 225,
      "endOffset" : 257
    }, {
      "referenceID" : 7,
      "context" : "Differential privacy has strong semantic privacy guarantees that make it a good candidate for declaring a statistical procedure or data collection mechanism private, and it has been the focus of a growing body of recent work [13, 16, 24, 21, 6, 18, 8, 5, 9].",
      "startOffset" : 225,
      "endOffset" : 257
    }, {
      "referenceID" : 4,
      "context" : "Differential privacy has strong semantic privacy guarantees that make it a good candidate for declaring a statistical procedure or data collection mechanism private, and it has been the focus of a growing body of recent work [13, 16, 24, 21, 6, 18, 8, 5, 9].",
      "startOffset" : 225,
      "endOffset" : 257
    }, {
      "referenceID" : 8,
      "context" : "Differential privacy has strong semantic privacy guarantees that make it a good candidate for declaring a statistical procedure or data collection mechanism private, and it has been the focus of a growing body of recent work [13, 16, 24, 21, 6, 18, 8, 5, 9].",
      "startOffset" : 225,
      "endOffset" : 257
    }, {
      "referenceID" : 21,
      "context" : "We thus bring classical notions of privacy, as introduced by Warner [23], into contact with differential privacy and statistical decision theory, obtaining quantitative trade-offs between privacy and statistical efficiency.",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 22,
      "context" : "The likelihood ratio also controls the error rate in tests for the presence of points x in the data [24].",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 21,
      "context" : "A consequence of our results is that Warner’s randomized response procedure [23] enjoys optimal sample complexity; it is interesting to note that even with the recent focus on privacy and statistical inference, the optimal privacy-preserving strategy for problems such as survey collection has been known for almost 50 years.",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 8,
      "context" : "We also reference our work [9] paper on statistical inference under differential privacy constraints; we restate two theorems from the paper [9] to keep our presentation self-contained.",
      "startOffset" : 27,
      "endOffset" : 30
    }, {
      "referenceID" : 8,
      "context" : "We also reference our work [9] paper on statistical inference under differential privacy constraints; we restate two theorems from the paper [9] to keep our presentation self-contained.",
      "startOffset" : 141,
      "endOffset" : 144
    }, {
      "referenceID" : 8,
      "context" : "We remark here (see also the discussion in [9]) that the private minimax risk (2) is different from previous work on optimality in differential privacy (e.",
      "startOffset" : 43,
      "endOffset" : 46
    }, {
      "referenceID" : 1,
      "context" : "[2, 16, 8]): prior work focuses on accurate estimation of a sample quantity θ(x1:n) based on the sample x1:n, while we provide lower bounds on error of the population estimator θ(P ).",
      "startOffset" : 0,
      "endOffset" : 10
    }, {
      "referenceID" : 15,
      "context" : "[2, 16, 8]): prior work focuses on accurate estimation of a sample quantity θ(x1:n) based on the sample x1:n, while we provide lower bounds on error of the population estimator θ(P ).",
      "startOffset" : 0,
      "endOffset" : 10
    }, {
      "referenceID" : 7,
      "context" : "[2, 16, 8]): prior work focuses on accurate estimation of a sample quantity θ(x1:n) based on the sample x1:n, while we provide lower bounds on error of the population estimator θ(P ).",
      "startOffset" : 0,
      "endOffset" : 10
    }, {
      "referenceID" : 24,
      "context" : "A standard route for lower bounding the minimax risk (2) is by reducing the estimation problem to the testing problem of identifying a point θ ∈ Θ from a collection of well-separated points [26, 25].",
      "startOffset" : 190,
      "endOffset" : 198
    }, {
      "referenceID" : 23,
      "context" : "A standard route for lower bounding the minimax risk (2) is by reducing the estimation problem to the testing problem of identifying a point θ ∈ Θ from a collection of well-separated points [26, 25].",
      "startOffset" : 190,
      "endOffset" : 198
    }, {
      "referenceID" : 24,
      "context" : "Letting ψ : Zn → V denote an arbitrary testing procedure, we have the following minimax bound, whose two parts are known as Le Cam’s two-point method [26, 22] and Fano’s inequality [25, 7, 22].",
      "startOffset" : 150,
      "endOffset" : 158
    }, {
      "referenceID" : 20,
      "context" : "Letting ψ : Zn → V denote an arbitrary testing procedure, we have the following minimax bound, whose two parts are known as Le Cam’s two-point method [26, 22] and Fano’s inequality [25, 7, 22].",
      "startOffset" : 150,
      "endOffset" : 158
    }, {
      "referenceID" : 23,
      "context" : "Letting ψ : Zn → V denote an arbitrary testing procedure, we have the following minimax bound, whose two parts are known as Le Cam’s two-point method [26, 22] and Fano’s inequality [25, 7, 22].",
      "startOffset" : 181,
      "endOffset" : 192
    }, {
      "referenceID" : 6,
      "context" : "Letting ψ : Zn → V denote an arbitrary testing procedure, we have the following minimax bound, whose two parts are known as Le Cam’s two-point method [26, 22] and Fano’s inequality [25, 7, 22].",
      "startOffset" : 181,
      "endOffset" : 192
    }, {
      "referenceID" : 20,
      "context" : "Letting ψ : Zn → V denote an arbitrary testing procedure, we have the following minimax bound, whose two parts are known as Le Cam’s two-point method [26, 22] and Fano’s inequality [25, 7, 22].",
      "startOffset" : 181,
      "endOffset" : 192
    }, {
      "referenceID" : 8,
      "context" : "We review two results from our work [9] that obtain such bounds as a function of the amount of privacy provided.",
      "startOffset" : 36,
      "endOffset" : 39
    }, {
      "referenceID" : 8,
      "context" : "[9]: Proposition 1 (Information bounds).",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "In the remainder of the paper, we demonstrate this combination for probability estimation problems; we provide proofs of all results in [9].",
      "startOffset" : 136,
      "endOffset" : 139
    }, {
      "referenceID" : 21,
      "context" : "In this section we return to the classical problem of avoiding answer bias in surveys, the original motivation for studying local privacy [23].",
      "startOffset" : 138,
      "endOffset" : 142
    }, {
      "referenceID" : 21,
      "context" : "In one of the earliest evaluations of privacy, Warner [23] studied the Bernoulli variant of this problem and proposed randomized response: for a given survey question, respondents provide a truthful answer with probability p > 1/2 and lie with probability 1− p.",
      "startOffset" : 54,
      "endOffset" : 58
    }, {
      "referenceID" : 21,
      "context" : "An interesting consequence of the lower bound in (8) is the following fact that we now demonstrate: Warner’s classical randomized response mechanism [23] (with minor modification) achieves the optimal convergence rate.",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 10,
      "context" : "[11] propose, where Laplace(α) noise is added to each coordinate of a multinomial sample, is one such strategy.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 2,
      "context" : "The projection of θ̂part onto the probability simplex can be done in time linear in the dimension d of the problem [3], so the estimator (11) is efficiently computable.",
      "startOffset" : 115,
      "endOffset" : 118
    }, {
      "referenceID" : 24,
      "context" : "It is well known [26, 25, 22] that the minimax risk for nonprivate estimation of densities in the class Fβ scales as",
      "startOffset" : 17,
      "endOffset" : 29
    }, {
      "referenceID" : 23,
      "context" : "It is well known [26, 25, 22] that the minimax risk for nonprivate estimation of densities in the class Fβ scales as",
      "startOffset" : 17,
      "endOffset" : 29
    }, {
      "referenceID" : 20,
      "context" : "It is well known [26, 25, 22] that the minimax risk for nonprivate estimation of densities in the class Fβ scales as",
      "startOffset" : 17,
      "endOffset" : 29
    }, {
      "referenceID" : 8,
      "context" : "We begin by giving our main lower bound on the minimax rate of estimation of densities when are kept differentially private, providing the proof in the longer paper [9].",
      "startOffset" : 165,
      "endOffset" : 168
    }, {
      "referenceID" : 3,
      "context" : "In their study of the deconvolution problem, Carroll and Hall [4] show that if samples Xi are perturbed by additive noise W , where the characteristic function φW of the additive noise has tails behaving as |φW (t)| = O(|t|−a) for some a > 0, then no estimator can deconvolve the samples X +W and attain a rate of convergence better than n.",
      "startOffset" : 62,
      "endOffset" : 65
    }, {
      "referenceID" : 18,
      "context" : "For higher degrees of smoothness (β > 1), histogram estimators no longer achieve optimal rates in the classical setting [20].",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 11,
      "context" : "where the value k ∈ N is chosen either a priori based on known properties of the estimation problem or adaptively, for example, using cross-validation [12, 22].",
      "startOffset" : 151,
      "endOffset" : 159
    }, {
      "referenceID" : 20,
      "context" : "where the value k ∈ N is chosen either a priori based on known properties of the estimation problem or adaptively, for example, using cross-validation [12, 22].",
      "startOffset" : 151,
      "endOffset" : 159
    }, {
      "referenceID" : 17,
      "context" : "Lei [19] considers private M -estimators based on first performing a histogram density estimate, then using this to construct a second estimator; his estimator is not locally private, and the resulting M -estimators have sub-optimal convergence rates.",
      "startOffset" : 4,
      "endOffset" : 8
    } ],
    "year" : 2013,
    "abstractText" : "We provide a detailed study of the estimation of probability distributions— discrete and continuous—in a stringent setting in which data is kept private even from the statistician. We give sharp minimax rates of convergence for estimation in these locally private settings, exhibiting fundamental trade-offs between privacy and convergence rate, as well as providing tools to allow movement along the privacy-statistical efficiency continuum. One of the consequences of our results is that Warner’s classical work on randomized response is an optimal way to perform survey sampling while maintaining privacy of the respondents.",
    "creator" : null
  }
}