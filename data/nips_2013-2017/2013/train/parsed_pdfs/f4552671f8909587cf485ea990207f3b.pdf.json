{
  "name" : "f4552671f8909587cf485ea990207f3b.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Noise-Enhanced Associative Memories",
    "authors" : [ "Amin Karbasi", "Amir Hesam Salavati" ],
    "emails" : [ "amin.karbasi@inf.ethz.ch", "hesam.salavati@epfl.ch", "amin.shokrollahi@epfl.ch", "varshney@alum.mit.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Hippocampus, olfactory cortex, and other brain regions are thought to operate as associative memories [1,2], having the ability to learn patterns from presented inputs, store a large number of patterns, and retrieve them reliably in the face of noisy or corrupted queries [3–5]. Associative memory models are designed to have these properties.\nAlthough such information storage and recall seemingly falls into the information-theoretic framework, where an exponential number of messages can be communicated reliably with a linear number of symbols, classical associative memory models could only store a linear number of patterns [4]. A primary reason is classical models require memorizing a randomly chosen set of patterns. By enforcing structure and redundancy in the possible set of memorizable patterns—like natural stimuli [6], internal neural representations [7], and error-control codewords—advances in associative memory design allow storage of an exponential number of patterns [8,9], just like in communication systems.\nInformation-theoretic and associative memory models of storage have been used to predict experimentally measurable properties of synapses in the mammalian brain [10,11]. But contrary to the fact that noise is present in computational operations of the brain [12, 13], associative memory models with exponential capacities have assumed no internal noise in the computational nodes. The purpose here is to model internal noise and study whether such associative memories still operate reliably. Surprisingly, we find internal noise actually enhances recall performance, suggesting a functional role for variability in the brain.\nIn particular we consider a multi-level, graph code-based, associative memory model [9] and find that even if all components are noisy, the final error probability in recall can be made exceedingly small. We characterize a threshold phenomenon and show how to optimize algorithm parameters when knowing statistical properties of internal noise. Rather counterintuitively the performance\nof the memory model improves in the presence of internal neural noise, as observed previously as stochastic resonance [13, 14]. There are mathematical connections to perturbed simplex algorithms for linear programing [15], where internal noise pushes the algorithm out of local minima.\nThe benefit of internal noise has been noted previously in associative memory models with stochastic update rules, cf. [16]. However, our framework differs from previous approaches in three key aspects. First, our memory model is different, which makes extension of previous analysis nontrivial. Second, and perhaps most importantly, pattern retrieval capacity in previous approaches decreases with internal noise, cf. [16, Fig. 6.1], in that increasing internal noise helps correct more external errors, but also reduces the number of memorizable patterns. In our framework, internal noise does not affect pattern retrieval capacity (up to a threshold) but improves recall performance. Finally, our noise model has bounded rather than Gaussian noise, and so a suitable network may achieve perfect recall despite internal noise.\nReliably storing information in memory systems constructed completely from unreliable components is a classical problem in fault-tolerant computing [17–19], where models have used random access architectures with sequential correcting networks. Although direct comparison is difficult since notions of circuit complexity are different, our work also demonstrates that associative memory architectures constructed from unreliable components can store information reliably.\nBuilding on the idea of structured pattern sets [20], our associative memory model [9] relies on the fact that all patterns to be learned lie in a low-dimensional subspace. Learning features of a lowdimensional space is very similar to autoencoders [21] and has structural similarities to Deep Belief Networks (DBNs), particularly Convolutional Neural Networks [22]."
    }, {
      "heading" : "2 Associative Memory Model",
      "text" : "Notation and basic structure: In our model, a neuron can assume an integer-valued state from the set S = {0, . . . , S − 1}, interpreted as the short term firing rate of neurons. A neuron updates its state based on the states of its neighbor {si}ni=1 as follows. It first computes a weighted sum h = ∑n i=1 wisi + ζ, where wi is the weight of the link from si and ζ is the internal noise, and then applies nonlinear function f : R→ S to h. An associative memory is represented by a weighted bipartite graph, G, with pattern neurons and constraint neurons. Each pattern x = (x1, . . . , xn) is a vector of length n, where xi ∈ S, i = 1, . . . , n. Following [9], the focus is on recalling patterns with strong local correlation among entries. Hence, we divide entries of each pattern x into L overlapping sub-patterns of lengths n1, . . . , nL. Due to overlaps, a pattern neuron can be a member of multiple subpatterns, as in Fig. 1a. The ith subpattern is denoted x(i) = (x(i)1 , . . . , x (i) ni ), and local correlations are assumed to be in the form of subspaces, i.e. the subpatterns x(i) form a subspace of dimension ki < ni.\nWe capture the local correlations by learning a set of linear constraints over each subspace corresponding to the dual vectors orthogonal to that subspace. More specifically, let {w(i)1 , . . . , w (i) mi} be a set of dual vectors orthogonal to all subpatterns x(i) of cluster i. Then:\ny (i) j = (w (i) j ) T · x(i) = 0, for all j ∈ {1, . . . ,mi} and for all i ∈ {1, . . . , L}. (1)\nEq. (1) can be rewritten as W (i) ·x(i) = 0 where W (i) = [w(i)1 |w (i) 2 | . . . |w (i) mi ] T is the matrix of dual vectors. Now we use a bipartite graph with connectivity matrix determined by W (i) to represent the subspace constraints learned from subpattern x(i); this graph is called cluster i. We developed an efficient way of learning W (i) in [9], also used here. Briefly, in each iteration of learning:\n1. Pick a pattern x at random from the dataset;\n2. Adjust weight vectorsw(i)j for j = {1, . . . ,mi} and i = {1, . . . , L} such that the projection of x onto w(i)j is reduced. Apply a sparsity penalty to favor sparse solutions.\nThis process repeats until all weights are orthogonal to the patterns in the dataset or the maximum iteration limit is reached. The learning rule allows us to assume the weight matricesW (i) are known and satisfy W (i) · x(i) = 0 for all patterns x in the dataset X , in this paper.\nFor the forthcoming asymptotic analysis, we need to define a contracted graph G̃whose connectivity matrix is denoted W̃ and has size L×n. This is a bipartite graph in which constraints in each cluster are represented by a single neuron. Thus, if pattern neuron xj is connected to cluster i, W̃ij = 1; otherwise W̃ij = 0. We also define the degree distribution from an edge perspective over G̃, using λ̃(z) = ∑ j λ̃jz j and ρ̃(z) = ∑ j ρ̃jz\nj−1 where λ̃j (resp., ρ̃j) equals the fraction of edges that connect to pattern (resp., cluster) nodes of degree j.\nNoise model: There are two types of noise in our model: external errors and internal noise. As mentioned earlier, a neural network should be able to retrieve memorized pattern x̂ from its corrupted version x due to external errors. We assume the external error is an additive vector of size n, denoted by z satisfying x = x̂ + z, whose entries assume values independently from {−1, 0,+1}1 with corresponding probabilities p−1 = p+1 = /2 and p0 = 1− . The realization of the external error on subpattern x(i) is denoted z(i). Note that the subspace assumption implies W · y = W · z and W (i) · y(i) = W (i) · z(i) for all i. Neurons also suffer from internal noise. We consider a bounded noise model, i.e. a random number uniformly distributed in the intervals [−υ, υ] and [−ν, ν] for the pattern and constraint neurons, respectively (υ, ν < 1).\nThe goal of recall is to filter the external error z to obtain the desired pattern x as the correct states of the pattern neurons. When neurons compute noiselessly, this task may be achieved by exploiting the fact the set of patterns x ∈ X to satisfy the set of constraints W (i) · x(i) = 0. However, it is not clear how to accomplish this objective when the neural computations are noisy. Rather surprisingly, we show that eliminating external errors is not only possible in the presence of internal noise, but that neural networks with moderate internal noise demonstrate better external noise resilience.\nRecall algorithms: To efficiently deal with external errors, we use a combination of Alg. 1 and Alg. 2. The role of Alg. 1 is to correct at least a single external error in each cluster. Without overlaps between clusters, the error resilience of the network is limited. Alg. 2 exploits the overlaps: it helps clusters with external errors recover their correct states by using the reliable information from clusters that do not have external errors. The error resilience of the resulting combination thereby drastically improves. Now we describe the details of Alg. 1 and Alg. 2 more precisely.\nAlg. 1 performs a series of forward and backward iterations in each cluster G(l) to remove (at least) one external error from its input domain. At each iteration, the pattern neurons locally decide whether to update their current state: if the amount of feedback received by a pattern neuron exceeds a threshold, the neuron updates its state, and otherwise remains as is. With abuse of notation, let us denote messages transmitted by pattern node i and constraint node j at round t by xi(t) and yj(t), respectively. In round 0, pattern nodes are initialized by a pattern x̂, sampled from dataset X , perturbed by external errors z, i.e., x(0) = x̂+ z. Thus, for cluster ` we have x(`)(0) = x̂(`) + z(`), where z(`) is the realization of errors on subpattern x(`).\nIn round t, the pattern and constraint neurons update their states using feedback from neighbors. However since neural computations are faulty, decisions made by neurons may not be reliable. To minimize effects of internal noise, we use the following update rule for pattern node i in cluster `:\nx (`) i (t+ 1) =\n{ x (`) i (t)− sign(g (`) i (t)), if |g (`) i (t)| ≥ ϕ\nx (`) i (t), otherwise,\n(2)\n1Note that the proposed algorithms also work with larger noise values, i.e. from a set {−a, . . . , a} for some a ∈ N, see [23]; the ±1 noise model is presented here for simplicity.\nAlgorithm 1 Intra-Module Error Correction Input: Training set X , thresholds ϕ,ψ, iteration tmax Output: x(`)1 , x (`) 2 , . . . , x (`) n`\n1: for t = 1→ tmax do 2: Forward iteration: Calculate the input h(`)i =∑n`\nj=1W (`) ij x (`) j + vi, for each neuron y (`) i and\nset y(`)i = f(h (`) i , ψ).\n3: Backward iteration: Each neuron x(`)j computes\ng (`) j = ∑m` i=1 sign(W (`)ij )y(`)i∑m` i=1 sign(|W (`)ij |) + ui.\n4: Update state of each pattern neuron j according to x(`)j = x (`) j − sign(g (`) j ) only if |g (`) j | > ϕ. 5: end for\nAlgorithm 2 Sequential Peeling Algorithm Input: G̃,G(1), G(2), . . . , G(L). Output: x1, x2, . . . , xn\n1: while there is an unsatisfied v(`) do 2: for ` = 1→ L do 3: If v(`) is unsatisfied, apply Alg. 1 to cluster G(l). 4: If v(`) remained unsatisfied, revert\nstate of pattern neurons connected to v(`) to their initial state. Otherwise, keep their current states.\n5: end for 6: end while 7: Declare x1, x2, . . . , xn if all v(`)’s are\nsatisfied. Otherwise, declare failure.\nwhere ϕ is the update threshold and g(`)i (t) = ( (sign(W (`))> · y(`)(t) ) i /d (`) i + ui. 2 Here, d(`)i is the degree of pattern node i in cluster `, y(`)(t) = [y(`)1 (t), . . . , y (`) m`(t)] is the vector of messages transmitted by the constraint neurons in cluster `, and ui is the random noise affecting pattern node i. Basically, the term g(`)i (t) reflects the (average) belief of constraint nodes connected to pattern neuron i about its correct value. If g(`)i (t) is larger than a specified threshold ϕ it means most of the connected constraints suggest the current state x(`)i (t) is not correct, hence, a change should be made. Note this average belief is diluted by the internal noise of neuron i. As mentioned earlier, ui is uniformly distributed in the interval [−υ, υ], for some υ < 1. On the constraint side, the update rule is:\ny (`) i (t) = f(h (`) i (t), ψ) =  +1, if h(`)i (t) ≥ ψ 0, if − ψ ≤ h(`)i (t) ≤ ψ −1, otherwise,\n(3)\nwhere ψ is the update threshold and h(`)i (t) = ( W (`) · x(`)(t) ) i + vi. Here, x(`)(t) = [x (`) 1 (t), . . . , x (`) n` (t)] is the vector of messages transmitted by the pattern neurons and vi is the random noise affecting node i. As before, we consider a bounded noise model for vi, i.e., it is uniformly distributed in the interval [−ν, ν] for some ν < 1.3\nThe error correction ability of Alg. 1 is fairly limited, as determined analytically and through simulations [23]. In essence, Alg. 1 can correct one external error with high probability, but degrades terribly against two or more external errors. Working independently, clusters cannot correct more than a few external errors, but their combined performance is much better. As clusters overlap, they help each other in resolving external errors: a cluster whose pattern neurons are in their correct states can always provide truthful information to neighboring clusters. This property is exploited in Alg. 2 by applying Alg. 1 in a round-robin fashion to each cluster. Clusters either eliminate their internal noise in which case they keep their new states and can now help other clusters, or revert back to their original states. Note that by such a scheduling scheme, neurons can only change their states towards correct values. This scheduling technique is similar in spirit to the peeling algorithm [24]."
    }, {
      "heading" : "3 Recall Performance Analysis",
      "text" : "Now let us analyze recall error performance. The following lemma shows that if ϕ and ψ are chosen properly, then in the absence of external errors the constraints remain satisfied and internal noise cannot result in violations. This is a crucial property for Alg. 2, as it allows one to determine whether\n2Note that x(`)i (t+1) is further mapped to the interval [0, S−1] by saturating the values below 0 and above S − 1 to 0 and S − 1 respectively. The corresponding equations are omitted for brevity.\n3Note that although the values of y(`)i (t) can be shifted to 0, 1, 2, instead of−1, 0, 1 to match our assumption that neural states are non-negative, we leave them as such to simplify later analysis.\na cluster has successfully eliminated external errors (Step 4 of algorithm) by merely checking the satisfaction of all constraint nodes.\nLemma 1. In the absence of external errors, the probability that a constraint neuron (resp. pattern neuron) in cluster ` makes a wrong decision due to its internal noise is given by π(`)0 =\nmax (\n0, ν−ψν ) (resp. P (`)0 = max ( 0, υ−ϕυ ) ).\nProof is given in [23]. In the sequel, we assume ϕ > υ and ψ > ν so that π(`)0 = 0 and P (`) 0 = 0. However, an external error combined with internal noise may still push neurons to an incorrect state.\nGiven the above lemma and our neural architecture, we can prove the following surprising result: in the asymptotic regime of increasing number of iterations of Alg. 2, a neural network with internal noise outperforms one without. Let us define the fraction of errors corrected by the noiseless and noisy neural network (parametrized by υ and ν) after T iterations of Alg. 2 by Λ(T ) and Λυ,ν(T ), respectively. Note that both Λ(T ) ≤ 1 and Λυ,ν(T ) ≤ 1 are non-decreasing sequences of T . Hence, their limiting values are well defined: limT→∞ Λ(T ) = Λ∗ and limT→∞ Λυ,ν(T ) = Λ∗υ,ν .\nTheorem 2. Let us choose ϕ and ψ so that π(`)0 = 0 and P (`) 0 = 0 for all ` ∈ {1, . . . , L}. For the same realization of external errors, we have Λ∗υ,ν ≥ Λ∗.\nProof is given in [23]. The high level idea why a noisy network outperforms a noiseless one comes from understanding stopping sets. These are realizations of external errors where the iterative Alg. 2 cannot correct all of them. We show that the stopping set shrinks as we add internal noise. In other words, we show that in the limit of T →∞ the noisy network can correct any error pattern that can be corrected by the noiseless version and it can also get out of stopping sets that cause the noiseless network to fail. Thus, the supposedly harmful internal noise will help Alg. 2 to avoid stopping sets.\nThm. 2 suggests the only possible downside with using a noisy network is its possible running time in eliminating external errors: the noisy neural network may need more iterations to achieve the same error correction performance. Interestingly, our empirical experiments show that in certain scenarios, even the running time improves when using a noisy network.\nThm. 2 indicates that noisy neural networks (under our model) outperform noiseless ones, but does not specify the level of errors that such networks can correct. Now we derive a theoretical upper bound on error correction performance. To this end, let Pci be the average probability that a cluster can correct i external errors in its domain. The following theorem gives a simple condition under which Alg. 2 can correct a linear fraction of external errors (in terms of n) with high probability. The condition involves λ̃ and ρ̃, the degree distributions of the contracted graph G̃.\nTheorem 3. Under the assumptions that graph G̃ grows large and it is chosen randomly with degree distributions given by λ̃ and ρ̃, Alg. 2 is successful if\nλ̃ 1−∑ i≥1 Pci zi−1 i! · d i−1ρ̃(1− z) dzi−1  < z, for z ∈ [0, ]. (4) Proof is given in [23] and is based on the density evolution technique [25]. Thm. 3 states that for any fraction of errors Λυ,ν ≤ Λ∗υ,ν that satisfies the above recursive formula, Alg. 2 will be successful with probability close to one. Note that the first fixed point of the above recursive equation dictates the maximum fraction of errors Λ∗υ,ν that our model can correct. For the special case of Pc1 = 1 and Pci = 0,∀i > 1, we obtain λ̃1− ρ̃(1− z)) < z, the same condition given in [9]. Thm. 3 takes into account the contribution of all Pci terms and as we will see, their values change as we incorporate the effect of internal noise υ and ν. Our results show that the maximum value of Pci does not occur when the internal noise is equal to zero, i.e. υ = ν = 0, but instead when the neurons are contaminated with internal noise! As an example, Fig. 2 illustrates how Pci behaves as a function of υ in the network considered (note that maximum values are not at υ = 0). This finding suggests that even individual clusters are able to correct more errors in the presence of internal noise."
    }, {
      "heading" : "3.1 Simulations",
      "text" : "Now we consider simulation results for a finite system. To learn the subspace constraints (1) for each cluster G(`) we use the learning algorithm in [9]. Henceforth, we assume that the weight matrix W is known and given. In our setup, we consider a network of size n = 400 with L = 50 clusters. We have 40 pattern nodes and 20 constraint nodes in each cluster, on average. External error is modeled by randomly generated vectors z with entries ±1 with probability and 0 otherwise. Vector z is added to the correct patterns, which satisfy (1). For recall, Alg. 2 is used and results are reported in terms of Symbol Error Rate (SER) as the level of external error ( ) or internal noise (υ, ν) is changed; this involves counting positions where the output of Alg. 2 differs from the correct pattern."
    }, {
      "heading" : "3.1.1 Symbol Error Rate as a function of Internal Noise",
      "text" : "Fig. 3 illustrates the final SER of our algorithm for different values of υ and ν. Recall that υ and ν quantify the level of noise in pattern and constraint neurons, respectively. Dashed lines in Fig. 3 are simulation results whereas solid lines are theoretical upper bounds provided in this paper. As evident, there is a threshold phenomenon such that SER is negligible for ≤ ∗ and grows beyond this threshold. As expected, simulation results are better than the theoretical bounds. In particular, the gap is relatively large as υ moves towards one.\nA more interesting trend in Fig. 3 is the fact that internal noise helps in achieving better performance, as predicted by theoretical analysis (Thm. 2). Notice how ∗ moves towards one as ν increases.\nThis phenomenon is examined more closely in Figs. 4a and 4b where is fixed to 0.125 while υ and ν vary. As we see, a moderate amount of internal noise at both pattern and constraint neurons improves performance. There is an optimum point (υ∗, ν∗) for which the SER reaches its minimum. Fig. 4b indicates for instance that ν∗ ≈ 0.25, beyond which SER deteriorates."
    }, {
      "heading" : "3.2 Recall Time as a function of Internal Noise",
      "text" : "Fig. 5 illustrates the number of iterations performed by Alg. 2 for correcting the external errors when is fixed to 0.075. We stop whenever the algorithm corrects all external errors or declare a recall error if all errors were not corrected in 40 iterations. Thus, the corresponding areas in the figure where the number of iterations reaches 40 indicates decoding failure. Figs. 6a and 6b are projected versions of Fig. 5 and show the average number of iterations as a function of υ and ν, respectively.\nThe amount of internal noise drastically affects the speed of Alg. 2. First, from Fig. 5 and 6b observe that running time is more sensitive to noise at constraint neurons than pattern neurons and that the algorithms become slower as noise at constraint neurons is increased. In contrast, note that internal noise at the pattern neurons may improve the running time, as seen in Fig. 6a.\nNote that the results presented here are for the case where the noiseless decoder succeeds as well and its average number of iterations is pretty close to the optimal value (see Fig. 5). In [23], we provide additional results corresponding to = 0.125, where the noiseless decoder encounters stopping sets while the noisy decoder is still capable of correcting external errors; there we see that the optimal running time occurs when the neurons have a fair amount of internal noise.\nIn [23] we also provide results of a study for a slightly modified scenario where there is only internal noise and no external errors. Furthermore, ϕ < υ. Thus, the internal noise can now cause neurons to make wrong decisions, even in the absence of external errors. There, we witness the more familiar phenomenon where increasing the amount of internal noise results in a worse performance. This finding emphasizes the importance of choosing update threshold ϕ and ψ according to Lem. 1."
    }, {
      "heading" : "4 Pattern Retrieval Capacity",
      "text" : "For completeness, we review pattern retrieval capacity results from [9] to show that the proposed model is capable of memorizing an exponentially large number of patterns. First, note that since the patterns form a subspace, the number of patterns C does not have any effect on the learning or recall algorithms (except for its obvious influence on the learning time). Thus, in order to show that the pattern retrieval capacity is exponential in n, all we need to demonstrate is that there exists a training set X with C patterns of length n for which C ∝ arn, for some a > 1 and 0 < r.\nTheorem 4 ( [9]). Let X be a C × n matrix, formed by C vectors of length n with entries from the set S. Furthermore, let k = rn for some 0 < r < 1. Then, there exists a set of vectors for which C = arn, with a > 1, and rank(X ) = k < n.\nThe proof is constructive: we create a dataset X such that it can be memorized by the proposed neural network and satisfies the required properties, i.e. the subpatterns form a subspace and pattern entries are integer values from the set S = {0, . . . , S − 1}. The complete proof can be found in [9]."
    }, {
      "heading" : "5 Discussion",
      "text" : "We have demonstrated that associative memories with exponential capacity still work reliably even when built from unreliable hardware, addressing a major problem in fault-tolerant computing and further arguing for the viability of associative memory models for the (noisy) mammalian brain. After all, brain regions modeled as associative memories, such as the hippocampus and the olfactory cortex, certainly do display internal noise [12, 13, 26]. The linear-nonlinear computations of Alg. 1 are certainly biologically plausible, but implementing the state reversion computation of Alg. 2 in a biologically plausible way remains an open question.\nWe found a threshold phenomenon for reliable operation, which manifests the tradeoff between the amount of internal noise and the amount of external noise that the system can handle. In fact, we showed that internal noise actually improves the performance of the network in dealing with external errors, up to some optimal value. This is a manifestation of the stochastic facilitation [13] or noise enhancement [14] phenomenon that has been observed in other neuronal and signal processing systems, providing a functional benefit to variability in the operation of neural systems.\nThe associative memory design developed herein uses thresholding operations in the messagepassing algorithm for recall; as part of our investigation, we optimized these neural firing thresholds based on the statistics of the internal noise. As noted by Sarpeshkar in describing the properties of analog and digital computing circuits, “In a cascade of analog stages, noise starts to accumulate. Thus, complex systems with many stages are difficult to build. [In digital systems] Round-off error does not accumulate significantly for many computations. Thus, complex systems with many stages are easy to build” [27]. One key to our result is capturing this benefit of digital processing (thresholding to prevent the build up of errors due to internal noise) as well as a modular architecture which allows us to correct a linear number of external errors (in terms of the pattern length).\nThis paper focused on recall, however learning is the other critical stage of associative memory operation. Indeed, information storage in nervous systems is said to be subject to storage (or learning) noise, in situ noise, and retrieval (or recall) noise [11, Fig. 1]. It should be noted, however, there is no essential loss by combining learning noise and in situ noise into what we have called external error herein, cf. [19, Fn. 1 and Prop. 1]. Thus our basic qualitative result extends to the setting where the learning and stored phases are also performed with noisy hardware.\nGoing forward, it is of interest to investigate other neural information processing models that explicitly incorporate internal noise and see whether they provide insight into observed empirical phenomena. As an example, we might be able to understand the threshold phenomenon observed in the SER of human telegraph operators under heat stress [28, Fig. 2], by invoking a thermal internal noise explanation."
    } ],
    "references" : [ {
      "title" : "Computational analysis of the role of the hippocampus in memory",
      "author" : [ "A. Treves", "E.T. Rolls" ],
      "venue" : "Hippocampus, vol. 4, pp. 374–391, Jun. 1994.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "Cortical processing of odor objects",
      "author" : [ "D.A. Wilson", "R.M. Sullivan" ],
      "venue" : "Neuron, vol. 72, pp. 506–519, Nov. 2011.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Neural networks and physical systems with emergent collective computational abilities",
      "author" : [ "J.J. Hopfield" ],
      "venue" : "Proc. Natl. Acad. Sci. U.S.A., vol. 79, pp. 2554–2558, Apr. 1982.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 1982
    }, {
      "title" : "The capacity of the Hopfield associative memory",
      "author" : [ "R.J. McEliece", "E.C. Posner", "E.R. Rodemich", "S.S. Venkatesh" ],
      "venue" : "IEEE Trans. Inf. Theory, vol. IT-33, pp. 461–482, 1987.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1987
    }, {
      "title" : "Learning in neural networks with material synapses",
      "author" : [ "D.J. Amit", "S. Fusi" ],
      "venue" : "Neural Comput., vol. 6, pp. 957–982, Sep. 1994.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "Sparse coding of sensory inputs",
      "author" : [ "B.A. Olshausen", "D.J. Field" ],
      "venue" : "Curr. Opin. Neurobiol., vol. 14, pp. 481–487, Aug. 2004.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Sparse incomplete representations: A potential role of olfactory granule cells",
      "author" : [ "A.A. Koulakov", "D. Rinberg" ],
      "venue" : "Neuron, vol. 72, pp. 124–136, Oct. 2011.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Multi-level error-resilient neural networks",
      "author" : [ "A.H. Salavati", "A. Karbasi" ],
      "venue" : "Proc. 2012 IEEE Int. Symp. Inf. Theory, Jul. 2012, pp. 1064–1068.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Iterative learning and denoising in convolutional neural associative memories",
      "author" : [ "A. Karbasi", "A.H. Salavati", "A. Shokrollahi" ],
      "venue" : "Proc. 30th Int. Conf. Mach. Learn. (ICML 2013), Jun. 2013, pp. 445–453.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Optimal information storage and the distribution of synaptic weights: Perceptron versus Purkinje cell",
      "author" : [ "N. Brunel", "V. Hakim", "P. Isope", "J.-P. Nadal", "B. Barbour" ],
      "venue" : "Neuron, vol. 43, pp. 745–757, 2004.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Optimal information storage in noisy synapses under resource constraints",
      "author" : [ "L.R. Varshney", "P.J. Sjöström", "D.B. Chklovskii" ],
      "venue" : "Neuron, vol. 52, pp. 409–423, Nov. 2006.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Biophysics of Computation",
      "author" : [ "C. Koch" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1999
    }, {
      "title" : "The benefits of noise in neural systems: bridging theory and experiment",
      "author" : [ "M.D. McDonnell", "L.M. Ward" ],
      "venue" : "Nat. Rev. Neurosci., vol. 12, pp. 415–426, Jul. 2011.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Theory of the stochastic resonance effect in signal detection: Part I–fixed detectors",
      "author" : [ "H. Chen", "P.K. Varshney", "S.M. Kay", "J.H. Michels" ],
      "venue" : "IEEE Trans. Signal Process., vol. 55, pp. 3172–3184, Jul. 2007.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Smoothed analysis of algorithms: Why the simplex algorithm usually takes polynomial time",
      "author" : [ "D.A. Spielman", "S.-H. Teng" ],
      "venue" : "J. ACM, vol. 51, pp. 385–463, May 2004.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Modeling Brain Function",
      "author" : [ "D.J. Amit" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1992
    }, {
      "title" : "Reliable information storage in memories designed from unreliable components",
      "author" : [ "M.G. Taylor" ],
      "venue" : "Bell Syst. Tech. J., vol. 47, pp. 2299–2337, Dec. 1968.",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 1968
    }, {
      "title" : "Information storage in a memory assembled from unreliable components",
      "author" : [ "A.V. Kuznetsov" ],
      "venue" : "Probl. Inf. Transm., vol. 9, pp. 100–114, July-Sept. 1973.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 1973
    }, {
      "title" : "Performance of LDPC codes under faulty iterative decoding",
      "author" : [ "L.R. Varshney" ],
      "venue" : "IEEE Trans. Inf. Theory, vol. 57, pp. 4427–4444, Jul. 2011.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Sparse neural networks with large learning diversity",
      "author" : [ "V. Gripon", "C. Berrou" ],
      "venue" : "IEEE Trans. Neural Netw., vol. 22, pp. 1087–1096, Jul. 2011.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Extracting and composing robust features with denoising autoencoders",
      "author" : [ "P. Vincent", "H. Larochelle", "Y. Bengio", "P.-A. Manzagol" ],
      "venue" : "Proc. 25th Int. Conf. Mach. Learn. (ICML 2008), Jul. 2008, pp. 1096–1103.",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Tiled convolutional neural networks",
      "author" : [ "Q.V. Le", "J. Ngiam", "Z. Chen", "D. Chia", "P.W. Koh", "A.Y. Ng" ],
      "venue" : "Advances in Neural Information Processing Systems 23, J. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R. S. Zemel, and A. Culotta, Eds. Cambridge, MA: MIT Press, 2010, pp. 1279–1287.",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Noise-enhanced associative memories",
      "author" : [ "A. Karbasi", "A.H. Salavati", "A. Shokrollahi", "L.R. Varshney" ],
      "venue" : "arXiv, 2013.",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Efficient erasure correcting codes",
      "author" : [ "M.G. Luby", "M. Mitzenmacher", "M.A. Shokrollahi", "D.A. Spielman" ],
      "venue" : "IEEE Trans. Inf. Theory, vol. 47, pp. 569–584, Feb. 2001.",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Modern Coding Theory",
      "author" : [ "T. Richardson", "R. Urbanke" ],
      "venue" : null,
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2008
    }, {
      "title" : "Stochastic resonance in the hippocampal CA3–CA1 model: a possible memory recall mechanism",
      "author" : [ "M. Yoshida", "H. Hayashi", "K. Tateno", "S. Ishizuka" ],
      "venue" : "Neural Netw., vol. 15, pp. 1171–1183, Dec. 2002.",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Analog versus digital: Extrapolating from electronics to neurobiology",
      "author" : [ "R. Sarpeshkar" ],
      "venue" : "Neural Comput., vol. 10, pp. 1601–1638, Oct. 1998.",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Effects of heat on wireless telegraphy operators hearing and recording Morse messages",
      "author" : [ "N.H. Mackworth" ],
      "venue" : "Br. J. Ind. Med., vol. 3, pp. 143–158, Jul. 1946. 9",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 1946
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Hippocampus, olfactory cortex, and other brain regions are thought to operate as associative memories [1,2], having the ability to learn patterns from presented inputs, store a large number of patterns, and retrieve them reliably in the face of noisy or corrupted queries [3–5].",
      "startOffset" : 102,
      "endOffset" : 107
    }, {
      "referenceID" : 1,
      "context" : "Hippocampus, olfactory cortex, and other brain regions are thought to operate as associative memories [1,2], having the ability to learn patterns from presented inputs, store a large number of patterns, and retrieve them reliably in the face of noisy or corrupted queries [3–5].",
      "startOffset" : 102,
      "endOffset" : 107
    }, {
      "referenceID" : 3,
      "context" : "Although such information storage and recall seemingly falls into the information-theoretic framework, where an exponential number of messages can be communicated reliably with a linear number of symbols, classical associative memory models could only store a linear number of patterns [4].",
      "startOffset" : 286,
      "endOffset" : 289
    }, {
      "referenceID" : 5,
      "context" : "By enforcing structure and redundancy in the possible set of memorizable patterns—like natural stimuli [6], internal neural representations [7], and error-control codewords—advances in associative memory design allow storage of an exponential number of patterns [8,9], just like in communication systems.",
      "startOffset" : 103,
      "endOffset" : 106
    }, {
      "referenceID" : 6,
      "context" : "By enforcing structure and redundancy in the possible set of memorizable patterns—like natural stimuli [6], internal neural representations [7], and error-control codewords—advances in associative memory design allow storage of an exponential number of patterns [8,9], just like in communication systems.",
      "startOffset" : 140,
      "endOffset" : 143
    }, {
      "referenceID" : 7,
      "context" : "By enforcing structure and redundancy in the possible set of memorizable patterns—like natural stimuli [6], internal neural representations [7], and error-control codewords—advances in associative memory design allow storage of an exponential number of patterns [8,9], just like in communication systems.",
      "startOffset" : 262,
      "endOffset" : 267
    }, {
      "referenceID" : 8,
      "context" : "By enforcing structure and redundancy in the possible set of memorizable patterns—like natural stimuli [6], internal neural representations [7], and error-control codewords—advances in associative memory design allow storage of an exponential number of patterns [8,9], just like in communication systems.",
      "startOffset" : 262,
      "endOffset" : 267
    }, {
      "referenceID" : 9,
      "context" : "Information-theoretic and associative memory models of storage have been used to predict experimentally measurable properties of synapses in the mammalian brain [10,11].",
      "startOffset" : 161,
      "endOffset" : 168
    }, {
      "referenceID" : 10,
      "context" : "Information-theoretic and associative memory models of storage have been used to predict experimentally measurable properties of synapses in the mammalian brain [10,11].",
      "startOffset" : 161,
      "endOffset" : 168
    }, {
      "referenceID" : 11,
      "context" : "But contrary to the fact that noise is present in computational operations of the brain [12, 13], associative memory models with exponential capacities have assumed no internal noise in the computational nodes.",
      "startOffset" : 88,
      "endOffset" : 96
    }, {
      "referenceID" : 12,
      "context" : "But contrary to the fact that noise is present in computational operations of the brain [12, 13], associative memory models with exponential capacities have assumed no internal noise in the computational nodes.",
      "startOffset" : 88,
      "endOffset" : 96
    }, {
      "referenceID" : 8,
      "context" : "In particular we consider a multi-level, graph code-based, associative memory model [9] and find that even if all components are noisy, the final error probability in recall can be made exceedingly small.",
      "startOffset" : 84,
      "endOffset" : 87
    }, {
      "referenceID" : 12,
      "context" : "of the memory model improves in the presence of internal neural noise, as observed previously as stochastic resonance [13, 14].",
      "startOffset" : 118,
      "endOffset" : 126
    }, {
      "referenceID" : 13,
      "context" : "of the memory model improves in the presence of internal neural noise, as observed previously as stochastic resonance [13, 14].",
      "startOffset" : 118,
      "endOffset" : 126
    }, {
      "referenceID" : 14,
      "context" : "There are mathematical connections to perturbed simplex algorithms for linear programing [15], where internal noise pushes the algorithm out of local minima.",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 19,
      "context" : "Building on the idea of structured pattern sets [20], our associative memory model [9] relies on the fact that all patterns to be learned lie in a low-dimensional subspace.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 8,
      "context" : "Building on the idea of structured pattern sets [20], our associative memory model [9] relies on the fact that all patterns to be learned lie in a low-dimensional subspace.",
      "startOffset" : 83,
      "endOffset" : 86
    }, {
      "referenceID" : 20,
      "context" : "Learning features of a lowdimensional space is very similar to autoencoders [21] and has structural similarities to Deep Belief Networks (DBNs), particularly Convolutional Neural Networks [22].",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 21,
      "context" : "Learning features of a lowdimensional space is very similar to autoencoders [21] and has structural similarities to Deep Belief Networks (DBNs), particularly Convolutional Neural Networks [22].",
      "startOffset" : 188,
      "endOffset" : 192
    }, {
      "referenceID" : 8,
      "context" : "Following [9], the focus is on recalling patterns with strong local correlation among entries.",
      "startOffset" : 10,
      "endOffset" : 13
    }, {
      "referenceID" : 8,
      "context" : "We developed an efficient way of learning W (i) in [9], also used here.",
      "startOffset" : 51,
      "endOffset" : 54
    }, {
      "referenceID" : 22,
      "context" : ", a} for some a ∈ N, see [23]; the ±1 noise model is presented here for simplicity.",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 22,
      "context" : "1 is fairly limited, as determined analytically and through simulations [23].",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 23,
      "context" : "This scheduling technique is similar in spirit to the peeling algorithm [24].",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 22,
      "context" : "Proof is given in [23] and is based on the density evolution technique [25].",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 24,
      "context" : "Proof is given in [23] and is based on the density evolution technique [25].",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 8,
      "context" : "For the special case of Pc1 = 1 and Pci = 0,∀i > 1, we obtain λ̃1− ρ̃(1− z)) < z, the same condition given in [9].",
      "startOffset" : 110,
      "endOffset" : 113
    }, {
      "referenceID" : 8,
      "context" : "To learn the subspace constraints (1) for each cluster G we use the learning algorithm in [9].",
      "startOffset" : 90,
      "endOffset" : 93
    }, {
      "referenceID" : 22,
      "context" : "In [23], we provide additional results corresponding to = 0.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 22,
      "context" : "In [23] we also provide results of a study for a slightly modified scenario where there is only internal noise and no external errors.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 8,
      "context" : "For completeness, we review pattern retrieval capacity results from [9] to show that the proposed model is capable of memorizing an exponentially large number of patterns.",
      "startOffset" : 68,
      "endOffset" : 71
    }, {
      "referenceID" : 8,
      "context" : "The complete proof can be found in [9].",
      "startOffset" : 35,
      "endOffset" : 38
    }, {
      "referenceID" : 11,
      "context" : "After all, brain regions modeled as associative memories, such as the hippocampus and the olfactory cortex, certainly do display internal noise [12, 13, 26].",
      "startOffset" : 144,
      "endOffset" : 156
    }, {
      "referenceID" : 12,
      "context" : "After all, brain regions modeled as associative memories, such as the hippocampus and the olfactory cortex, certainly do display internal noise [12, 13, 26].",
      "startOffset" : 144,
      "endOffset" : 156
    }, {
      "referenceID" : 25,
      "context" : "After all, brain regions modeled as associative memories, such as the hippocampus and the olfactory cortex, certainly do display internal noise [12, 13, 26].",
      "startOffset" : 144,
      "endOffset" : 156
    }, {
      "referenceID" : 12,
      "context" : "This is a manifestation of the stochastic facilitation [13] or noise enhancement [14] phenomenon that has been observed in other neuronal and signal processing systems, providing a functional benefit to variability in the operation of neural systems.",
      "startOffset" : 55,
      "endOffset" : 59
    }, {
      "referenceID" : 13,
      "context" : "This is a manifestation of the stochastic facilitation [13] or noise enhancement [14] phenomenon that has been observed in other neuronal and signal processing systems, providing a functional benefit to variability in the operation of neural systems.",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 26,
      "context" : "Thus, complex systems with many stages are easy to build” [27].",
      "startOffset" : 58,
      "endOffset" : 62
    } ],
    "year" : 2013,
    "abstractText" : "Recent advances in associative memory design through structured pattern sets and graph-based inference algorithms allow reliable learning and recall of exponential numbers of patterns. Though these designs correct external errors in recall, they assume neurons compute noiselessly, in contrast to highly variable neurons in hippocampus and olfactory cortex. Here we consider associative memories with noisy internal computations and analytically characterize performance. As long as internal noise is less than a specified threshold, error probability in the recall phase can be made exceedingly small. More surprisingly, we show internal noise actually improves performance of the recall phase. Computational experiments lend additional support to our theoretical analysis. This work suggests a functional benefit to noisy neurons in biological neuronal networks.",
    "creator" : null
  }
}