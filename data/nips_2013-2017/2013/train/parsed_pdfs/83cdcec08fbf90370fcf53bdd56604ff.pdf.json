{
  "name" : "83cdcec08fbf90370fcf53bdd56604ff.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Adaptive Anonymity via b-Matching",
    "authors" : [ "Krzysztof Choromanski", "Tony Jebara", "Kui Tang" ],
    "emails" : [ "kmc2178@columbia.edu", "tj2008@columbia.edu", "kt2384@columbia.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "In many situations, individuals wish to share their personal data for machine learning applications and other exploration purposes. If the data contains sensitive information, it is necessary to protect it with privacy guarantees while maintaining some notion of data utility [18, 2, 24]. There are various definitions of privacy. These include k-anonymity [19], l-diversity [16], t-closeness [14] and differential1 privacy [3, 22]. All these privacy guarantees fundamentally treat each contributed datum about an individual equally. However, the acceptable anonymity and comfort-level of each individual in a population can vary widely. This article explores the adaptive anonymity setting and shows how to generalize the k-anonymity framework to handle it. Other related approaches have been previously explored [20, 21, 15, 5, 6, 23] yet herein we contribute novel efficient algorithms and formalize precise privacy guarantees. Note also that there are various definitions of utility. This article focuses on the use of suppression since it is well-formalized. Therein, we hide certain values in the data-set by replacing them with a ∗ symbol (fewer ∗ symbols indicate higher utility). The overall goal is to maximize utility while preserving each individual’s level of desired privacy.\nThis article is organized as follows. § 2 formalizes the adaptive anonymity problem and shows how k-anonymity does not handle it. This leads to a relaxation of k-anonymity into symmetric and asymmetric bipartite regular compatibility graphs. § 3 provides algorithms for maximizing utility under these relaxed privacy criteria. § 4 provides theorems to ensure the privacy of these relaxed criteria for uniform anonymity as well as for adaptive anonymity. § 5 shows experiments on benchmark and social data-sets. Detailed proofs are provided in the Supplement."
    }, {
      "heading" : "2 Adaptive anonymity and necessary relaxations to k-anonymity",
      "text" : "The adaptive anonymity problem considers a data-setX ∈ Zn×d consisting of n ∈ N observations {x1, . . . ,xn} each of which is a d-dimensional discrete vector, in other words, xi ∈ Zd. Each user i contributes an observation vector xi which contains discrete attributes pertaining to that user2. Furthermore, each user i provides an adaptive anonymity parameter δi ∈ N they desire to keep when the database is released. Given such a data-set and anonymity parameters, we wish to output an obfuscated data-set denoted byY ∈ {Z ∪ ∗}n×d which consists of vectors {y1, . . . ,yn} where\n1Differential privacy often requires specifying the data application (e.g. logistic regression) in advance [4]. 2For instance, a vector can contain a user’s gender, race, height, weight, age, income bracket and so on.\nyi(k) ∈ {xi(k), ∗}. The star symbol ∗ indicates that the k’th attribute has been masked in the i’th user-record. We say that vector xi is compatible with vector yj if xi(k) = yj(k) for all elements of yj(k) $= ∗. The goal of this article is to create aY which contains a minimal number of ∗ symbols such that each entry yi ofY is compatible with at least δi entries ofX and vice-versa.\nThe most pervasive method for anonymity in the released data is the k-anonymity method [19, 1]. However, it is actually more constraining than the above desiderata. If all users have the same value δi = k, then k-anonymity suppresses data in the database such that, for each user’s data vector in the released (or anonymized) database, there are at least k − 1 identical copies in the released database. The existence of copies is used by k-anonymity to justify some protection to attack.\nWe will show that the idea of k − 1 copies can be understood as forming a compatibility graph between the original database and the released database which is composed of several fully-connected k-cliques. However, rather than guaranteeing copies or cliques, the anonymity problem can be relaxed into a k-regular compatibility to achieve nearly identical resilience to attack. More interestingly, this relaxation will naturally allow users to select different δi anonymity values or degrees in the compatibility graph and allow them to achieve their desired personal protection level.\nWhy can’t k-anonymity handle heterogeneous anonymity levels δi? Consider the case where the population contains many liberal users with very low anonymity levels yet one single paranoid user (user i) wants to have a maximal anonymity with δi = n. In the k-anonymity framework, that user will require n − 1 identical copies of his data in the released database. Thus, a single paranoid user will destroy all the information of the database which will merely contain completely redundant vectors. We will propose a b-matching relaxation to k-anonymity which prevents this degeneracy since it does not merely handle compatibility queries by creating copies in the released data.\nWhile k-anonymity is not the only criterion for privacy, there are situations in which it is sufficient as illustrated by the following scenario. First assume the data-set X is associated with a set of identities (or usernames) andY is associated with a set of keys. A key may be the user’s password or some secret information (such as their DNA sequence). Represent the usernames and keys using integers x1, . . . , xn and y1, . . . , yn, respectively. Username xi ∈ Z is associated with entry xi and key yj ∈ Z is associated with entry yj . Furthermore, assume that these usernames and keys are diverse, unique and independent of their corresponding attributes. These x and y values are known as the sensitive attributes and the entries ofX andY are the non-sensitive attributes [16]. We aim to release an obfuscated databaseY and its keys with the possibility that an adversary may have access to all or a subset ofX and the identities.\nThe goal is to ensure that the success of an attack (using a username-key pair) is low. In other words, the attack succeeds with probability no larger than 1/δi for a user which specified δi ∈ N. Thus, the attack we seek to protect against is the use of the data to match usernames to keys (rather than attacks in which additional non-sensitive attributes about a user are discovered). In the uniform δi setting, k-anonymity guarantees that a single one-time attack using a single username-key pair succeeds with probability at most 1/k. In the extreme case, it is easy to see that replacing all ofY with ∗ symbols will result in an attack success probability of 1/n if the adversary attempts a single random attack-pair (username and key). Meanwhile, releasing a database Y = X with keys could allow the adversary to succeed with an initial attack with probability 1.\nWe first assume that all degrees δi are constant and set to δ and discuss how the proposed b-matching privacy output subtly differs from standard k-anonymity [19]. First, define quasi-identifiers as sets of attributes like gender and age that can be linked with external data to uniquely identify an individual in the population. The k-anonymity criterion says that a data-set such as Y is protected against linking attacks that exploit quasi-identifiers if every element is indistinguishable from at least k − 1 other elements with respect to every set of quasi-identifier attributes. We will instead use a compatibility graphG to more precisely characterize how elements are indistinguishable in the data-sets and which entries of Y are compatible with entries in the original data-set X. The graph places edges between entries ofX which are compatible with entries ofY. Clearly, G is an undirected bipartite graph containing two equal-sized partitions (or color-classes) of nodes A and B each of cardinality n whereA = {a1, . . . , an} andB = {b1, . . . , bn}. Each element ofA is associated with an entry of X and each element of B is associated with an entry ofY. An edge e = (i, j) ∈ G that is adjacent to a node in A and a node in B indicates that the entries xi and yj are compatible. The absence of an edge means nothing: entries are either compatible or not compatible.\nFor δi = δ, b-matching produces δ-regular bipartite graphsGwhile k-anonymity produces δ-regular clique-bipartite graphs3 defined as follows.\nDefinition 2.1 Let G(A, B) be a bipartite graph with color classes: A, B where A = {a1, ..., an}, B = {b1, ..., bn}. We call a k-regular bipartite graph G(A, B) a clique-bipartite graph if it is a union of pairwise disjoint and nonadjacent complete k-regular bipartite graphs.\nDenote by Gn,δb the family of δ-regular bipartite graphs with n nodes. Similarly, denote by G n,δ k the family of δ-regular graphs clique-bipartite graphs. We will also denote by Gn,δs the family of symmetric b-regular graphs using the following definition of symmetry.\nDefinition 2.2 Let G(A, B) be a bipartite graph with color classes: A, B where A = {a1, ..., an}, B = {b1, ..., bn}. We say thatG(A, B) is symmetric if the existence of an edge (ai, bj) in G(A, B) implies the existence of an edge (aj , bi), where 1 ≤ i, j ≤ n.\nFor values of n that are not trivially small, it is easy to see that the graph families satisfy Gn,δk ⊆ Gn,δs ⊆ G n,δ b . This holds since symmetric δ-regular graphs are δ-regular with the additional symmetry constraint. Clique-bipartite graphs are δ-regular graphs constrained to be clique-bipartite and the latter property automatically yields symmetry.\nThis article introduces graph families Gn,δb and Gn,δs to enforce privacy since these are relaxations of the family Gn,bk as previously explored in k-anonymity research. These relaxations will achieve better utility in the released database. Furthermore, they will allow us to permit adaptive anonymity levels across the users in the database. We will drop the superscripts n and δ whenever the meaning is clear from the context. Additional properties of these graph families will be formalized in § 4 but we first informally illustrate how they are useful in achieving data privacy.\nIn figure 1, we see an example of k-anonymity with a graph from Gk . Here each entry of the anonymized data-set Y appears k = 2 times (or δ = 2). The compatibility graph shows 3 fully connected cliques since each of the k copies in Y has identical entries. By brute force exploration\n3 Traditional k-anonymity releases an obfuscated database of n rows where there are k copies of each row. So, each copy has the same neighborhood. Similarly, the entries of the original database all have to be connected to the same k copies in the obfuscated database. This induces a so-called bipartite clique-connectivity.\nwe find that the minimum number of stars to achieve this type of anonymity is #(∗) = 10. Moreover, since this problem is NP-hard [17], efficient algorithms rarely achieve this best-possible utility (minimal number of stars).\nNext, consider figure 2 where we have achieved superior utility by only introducing#(∗) = 8 stars to form Y. The compatibility graph is at least δ = 2-regular. It was possible to find a smaller number of stars since δ-regular bipartite graphs are a relaxation of k-clique graphs as shown in figure 1. Another possibility (not shown in the figures) is a symmetric version of figure 2 where nodes on the left hand side and nodes on the right hand side have a symmetric connectivity. Such an intermediate solution (since Gk ⊂ Gs ⊂ Gb) should potentially achieve#(∗) between 8 and 10.\nIt is easy to see why all graphs have to have a minimum degree of δ at least (i.e. must contain a δ-regular graph). If one of the nodes has a degree of 1, then the adversary will know the key (or the username) for that node with certainty. If each node has degree δ or larger, then the adversary will have probability at most 1/δ of choosing the correct key (or username) for any random victim.\nWe next describe algorithms which accept X and integers δ1, . . . , δn and output Y such that each entry i inY is compatible with at least δi entries inX and vice-versa. These algorithms operate by finding a graph in Gb or Gs and achieve similar protection as k-anonymity (which finds a graph in the most restrictive family Gk and therefore requires more stars). We provide a theoretical analysis of the topology of G in these two new families to show resilience to single and sustained attacks from an all-powerful adversary."
    }, {
      "heading" : "3 Approximation algorithms",
      "text" : "While the k-anonymity suppression problem is known to be NP-hard, a polynomial time method with an approximation guarantee is the forest algorithm [1] which has an approximation ratio of 3k− 3. In practice, though, the forest algorithm is slow and achieves poor utility compared to clustering methods [10]. We provide an algorithm for the b-matching anonymity problem with approximation ratio of δ and runtime of O(δm √ n) where n is the number of users in the data, δ is the largest anonymity level in {δ1, . . . , δn} and m is the number of edges to explore (in the worst case with no prior knowledge, we have m = O(n2) edges between all possible users). One algorithm solves for minimum weight bipartite b-matchings which is easy to implement using linear programming, max-flow methods or belief propagation in the bipartite case [9, 11]. The other algorithm uses a general non-bipartite solver which involves Blossom structures and requiresO(δmn log(n)) time[8, 9, 13]. Fortunately, minimum weight general matching has recently been shown to require only O(m\"−1 log \"−1) time to achieve a (1 − \") approximation [7].\nFirst, we define two quantities of interest. Given a graphG with adjacency matrixG ∈ Bn×n and a data-setX, the Hamming error is defined as h(G) = ∑\ni\n∑ j Gij ∑ k(Xik $= Xjk). The number of stars to achieveG is s(G) = nd − ∑\ni\n∑\nk\n∏\nj (1 − Gij(Xik $= Xjk)) .\nRecall Gb is the family of regular bipartite graphs. Let minG∈Gb s(G) be the minimum number of stars (or suppressions) that one can place in Y while keeping the entries in Y compatible with at least δ entries in X and vice-versa. We propose the following polynomial time algorithm which, in its first iteration, minimizes h(G) over the family Gb and then iteratively minimizes a variational upper bound [12] on s(G) using a weighted version of the Hamming distance.\nAlgorithm 1 variational bipartite b-matching InputX ∈ Zn×d, δi ∈ N for i ∈ {1, . . . , n}, ε > 0 and initializeW ∈ Rn×d to the all 1s matrix While not converged { Set Ĝ = arg minG∈Bn×n ∑ ij Gij ∑ k Wik(Xik $= Xjk) s.t. ∑ j Gij = ∑\nj Gji ≥ δi For all i and k setWik = exp ( ∑ j Ĝij(Xik $= Xjk) ln ε 1+ε )\n} For all i and k setYik = ∗ if Ĝij = 1 andXjk $= Xik for any j Choose random permutationM as matrixM ∈ Bn×n and outputYpublic = MY\nWe can further restrict the b-matching solver such that the graphG is symmetric with respect to both the original data X and the obfuscated data Y. To do so, we require thatG is a symmetric matrix. This will produce a graph G ∈ Gs. In such a situation, the value of Ĝ is recovered by a general\nunipartite b-matching algorithm rather than a bipartite b-matching program. Thus, the set of possible output solutions is strictly smaller (the bipartite formulation relaxes the symmetric one).\nAlgorithm 2 variational symmetric b-matching InputX ∈ Zn×d, δi ∈ N for i ∈ {1, . . . , n}, ε > 0 and initializeW ∈ Rn×d to the all 1s matrix While not converged { Set Ĝ = arg minG∈Bn×n ∑ ij Gij ∑ k Wik(Xik $= Xjk) s.t. ∑\nj Gij ≥ δi, Gij = Gji For all i and k setWik = exp ( ∑ j Ĝij(Xik $= Xjk) ln ε 1+ε )\n} For all i and k setYik = ∗ if Ĝij = 1 andXjk $= Xik for any j Choose random permutationM as matrixM ∈ Bn×n and outputYpublic = MY\nTheorem 1 For δi ≤ δ, iteration #1 of algorithm 1 finds Ĝ such that s(Ĝ) ≤ δ minG∈Gb s(G).\nTheorem 2 Each iteration of algorithm 1 monotonically decreases s(Ĝ).\nTheorem 1 and 2 apply to both algorithms. Both algorithms4 manipulate a bipartite regular graph G(A, B) containing the true matching {(a1, b1), . . . , (an, bn)}. However, they ultimately release the data-set Ypublic after randomly shuffling Y according to some matching or permutation M which hides the true matching. The random permutation or matching M can be represented as a matrix M ∈ Bn×n or as a function σ : {1, . . . , n} → {1, . . . , n}. We now discuss how an adversary can attack privacy by recovering this matching or parts of it."
    }, {
      "heading" : "4 Privacy guarantees",
      "text" : "We now characterize the anonymity provided by a compatibility graph G ∈ Gb (or G ∈ Gs) under several attack models. The goal of the adversary is to correctly match people to as many records as possible. In other words, the adversary wishes to find the randommatchingM used in the algorithms (or parts of M ) to connect the entries of X to the entries of Ypublic (assuming the adversary has stolenX andYpublic or portions of them). More precisely, we have a bipartite graphG(A, B) with color classes A, B, each of size n. Class A corresponds to n usernames and class B to n keys. Each username in A is matched to its key in B through some unknown matchingM .\nWe consider the model where the graphG(A, B) is δ-regular, where δ ∈ N is a parameter chosen by the publisher. The latter is especially important if we are interested in guaranteeing different levels of privacy for different users and allowing δ to vary with the user’s index i.\nSometimes it is the case that the adversary has some additional information and at the very beginning knows some complete records that belong to some people. In graph-theoretic terms, the adversary thus knows parts of the hidden matching M in advance. Alternatively, the adversary may have come across such additional information through sustained attack where previous attempts revealed the presence or absence of an edge. We are interested in analyzing how this extra knowledge can help him further reveal other edges of the matching. We aim to show that, for some range of the parameters of the bipartite graphs, this additional knowledge does not help him much. We will compare the resilience to attack relative to the resilience of k-anonymity. We say that a person v is k-anonymous if his or her real data record can be confused with at least k− 1 records from different people. We first discuss the case of single attacks and then discuss sustained attacks."
    }, {
      "heading" : "4.1 One-Time Attack Guarantees",
      "text" : "Assume first that the adversary has no extra information about the matching and performs a one-time attack. Then, lemma 4.1 holds which is a direct implication of lemma 4.2.\nLemma 4.1 IfG(A, B) is an arbitrary δ-regular graph and the adversary does not know any edges of the matching he is looking for then every person is δ-anonymous.\n4It is straightforward to put a different weight on certain suppressions over others if the utility of the data is not uniform for each entry or bit. This done by using an n × d weight matrix in the optimization. It is also straightforward to handle missing data by allowing initial stars inX before anonymizing.\nLemma 4.2 Let G(A, B) be a δ-regular bipartite graph. Then for every edge e of G(A, B) there exists a perfect matching in G(A, B) that uses e.\nThe result does not assume any structure in the graph beyond its δ-regularity. Thus, for a single attack, b-matching anonymity (symmetric or asymmetric) is equivalent to k-anonymity when b = k.\nCorollary 4.1 Assume the bipartite graph G(A, B) is either δ-regular, symmetric δ-regular or clique-bipartite and δ-regular. An adversary attackingG once succeeds with probability≤ 1/δ.\n4.2 Sustained Attack on k-Cliques\nNow consider the situation of sustained attacks or attacks with prior information. Here, the adversary may know c ∈ N edges in M a priori by whatever means (previous attacks or through side information). We begin by analyzing the resilience of k-anonymity where G is a cliques-structured graph. In the clique-bipartite graph, even if the adversary knows some edges of the matching (but not too many) then there still is hope of good anonymity for all people. The anonymity of every person decreases from δ to at least (δ − c). So, for example, if the adversary knows in advance δ2 edges of the matching then we get the same type of anonymity for every person as for the model with two times smaller degree in which the adversary has no extra knowledge. So we will be able to show the following:\nLemma 4.3 If G(A, B) is clique-bipartite δ-regular graph and the adversary knows in advance c edges of the matching then every person is (δ − c)-anonymous.\nThe above is simply a consequence of the following lemma.\nLemma 4.4 Assume that G(A, B) is clique-bipartite δ-regular graph. Denote by M some perfect matching in G(A, B). Let C be some subset of the edges of M and let c = |C|. Fix some vertex v ∈ A not matched in C. Then there are at least (δ − c) edges adjacent to v such that, for each of these edges e, there exists some perfect matchingM e in G(A, B) that uses both e and C.\nCorollary 4.2 Assume graph G(A, B) is a clique-bipartite and δ-regular. Assume that the adversary knows in advance c edges of the matching. The adversary selects uniformly at random a vertex the privacy of which he wants to break from the set of vertices he does not know in advance. Then he succeeds with probability at most 1\nδ−c .\nWe next show that b-matchings achieve comparable resilience under sustained attack.\n4.3 Sustained attack on asymmetric bipartite b-matching\nWe now consider the case where we do not have a graphG(A, B) which is clique-bipartite but rather is only δ-regular and potentially asymmetric (as returned by algorithm 1).\nTheorem 4.1 Let G(A,B) be a δ-regular bipartite graph with color classes: A and B. Assume that |A| = |B| = n. Denote by M some perfect matching M in G(A, B). Let C be some subset of the edges of M and let c = |C|. Take some ξ ≥ c. Denote n′ = n − c. Fix any function φ : N → R satisfying ∀δ(ξ √ 2δ + 14 < φ(δ) < δ). Then for all but at most\nη = 2cδ2n′ξ(1+\nφ(δ)+ √\nφ2(δ)−2ξ2δ 2ξδ )\nφ3(δ)(1+\nr\n1− 2ξ 2δ\nφ2(δ) )( 1ξ− c φ(δ) +\nδ(1− c ξ ) φ(δ) ) + cδ φ(δ) vertices v ∈ A not matched in C the following\nholds: The size of the set of edges e adjacent to v and having the additional property that there exists some perfect matchingMv inG(A, B) that uses e and edges from C is: at least (δ− c− φ(δ)).\nEssentially, theorem 4.1 says that all but at most a small number η of people are (δ − c − φ(δ))anonymous for every φ satisfying: c √\n2δ + 14 < φ(δ) < δ if the adversary knows in advance c edges of the matching. For example, take φ(δ) := θδ for θ ∈ (0, 1). Fix ξ = c and assume that the adversary knows in advance at most δ 14 edges of the matching. Then, using the formula from\ntheorem 4.1, we obtain that (for n large enough) all but at most 4n ′\nδ 1 4 θ3\n+ δ 1 4\nθ people from those that\nthe adversary does not know in advance are ((1 − θ)δ − δ 14 )-anonymous. So if δ is large enough then all but approximately a small fraction 4\nδ 1 4 θ3 of all people not known in advance are almost (1 − θ)δ-anonymous.\nAgain take φ(δ) := θδ where θ ∈ (0, 1). Take ξ = 2c. Next assume that 1 ≤ c ≤ min( δ4 , δ(1 − θ − θ2)). Assume that the adversary selects uniformly at random a person to attack. Our goal is to find an upper bound on the probability he succeeds. Then, using theorem 4.1, we can conclude that all but at most Fn′ people whose records are not known in advance are ((1 − θ)δ − c)-anonymous for F = 33c 2\nθ2δ . The probability of success is at most: F + (1 − F ) 1 (1−θ)δ−c . Using the expression on F that we have and our assumptions, we can conclude that the probability we are looking for is at most 34c 2\nθ2δ . Therefore we have:\nTheorem 4.2 Assume graph G(A, B) is δ-regular and the adversary knows in advance c edges of the matching, where c satisfies: 1 ≤ c ≤ min( δ4 , δ(1− θ− θ\n2)). The adversary selects uniformly at random a vertex the privacy of which he wants to break from those that he does not know in advance. Then he succeeds with probability at most 34c 2\nθ2δ .\n4.4 Sustained attack on symmetric b-matching with adaptive anonymity\nWe now consider the case where the graph is not only δ-regular but also symmetric as defined in definition 2.2 and as recovered by algorithm 2. Furthermore, we consider the case where we have varying values of δi for each node since some users want higher privacy than others. It turns out that if the corresponding bipartite graph is symmetric (we define this term below) we can conclude that each user is (δi − c)-anonymous, where δi is the degree of a vertex associated with the user of the bipartite matching graph. So we get results completely analogous to those for the much simpler models described before. We will use a slightly more elaborate definition of symmetric5, however, since this graph has one if its partitions permuted by a random matching (the last step in both algorithms before releasing the data).\nDefinition 4.1 Let G(A, B) be a bipartite graph with color classes: A, B and matching M = {(a1, b1), ...(an, bn)}, whereA = {a1, ..., an}, B = {b1, ..., bn}. We say thatG(A, B) is symmetric with respect to M if the existence of an edge (ai, bj) in G(A, B) implies the existence of an edge (aj , bi), where 1 ≤ i, j ≤ n.\nFrom now on, the matchingM with respect to whichG(A, B) is symmetric is a canonical matching of G(A, B). Assume that G(A, B) is symmetric with respect to its canonical matchingM (it does not need to be a clique-bipartite graph). In such a case, we will prove that, if the adversary knows in advance c edges of the matching, then every person from the class A of degree δi is (δi − c)anonymous. So we obtain the same type of anonymity as in a clique-bipartite graph (see: lemma 4.3).\nLemma 4.5 Assume that G(A, B) is a bipartite graph, symmetric with respect to its canonical matching M . Assume furthermore that the adversary knows in advance c edges of the matching. Then every person that he does not know in advance is (δi − c)-anonymous, where δi is a degree of the related vertex of the bipartite graph.\nAs a corollary, we obtain the same privacy guarantees in the symmetric case as the k-cliques case.\nCorollary 4.3 Assume bipartite graph G(A, B) is symmetric with respect to its canonical matchingsM . Assume that the adversary knows in advance c edges of the matching. The adversary selects uniformly at random a vertex the privacy of which he wants to break from the set of vertices he does not know in advance. Then he succeeds with probability at most 1δi−c , where δi is a degree of a vertex of the matching graph associated with the user.\n5A symmetric graph G(A, B) may not remain symmetric according to definition 2.2 if nodes in B are shuffled by a permutationM . However, it will still be symmetric with respect toM according to definition 4.1.\nIn summary, the symmetric case is as resilient to sustained attack as the cliques-bipartite case, the usual one underlying k-anonymity if we set δi = δ = k everywhere. The adversary succeeds with probability at most 1/(δi−c). However, the asymmetric case is potentially weaker and the adversary can succeed with probability at most 34c 2\nθ2δ . Interestingly, in the symmetric case with variable δi\ndegrees, however, we can provide guarantees that are just as good without forcing all individuals to agree on a common level of anonymity."
    }, {
      "heading" : "5 Experiments",
      "text" : "We compared algorithms 1 and 2 against an agglomerative clustering competitor (optimized to minimize stars) which is known to outperform the forest method [10]. Agglomerative clustering starts with singleton clusters and keeps unifying the two closest clusters with smallest increase in stars until clusters grow to a size at least k. Both algorithms release data with suppressions to achieve a desired constant anonymity level δ. For our algorithms, we swept values of ε in {2−1, 2−2, . . . , 2−10} from largest to smallest and chose the solution that produced the least number of stars. Furthermore, we warm-started the symmetric algorithm with the star-pattern solution of the asymmetric algorithm to make it converge more quickly. We first explored six standard data-sets from UCI http://archive.ics.uci.edu/ml/ in the uniform anonymity setting. Figure 3(a) summarizes the results where utility is plotted against δ. Fewer stars imply greater utility and larger δ implies higher anonymity. We discretized each numerical dimension in a data-set into a binary attribute by finding all elements above and below the median and mapped categorical values in the data-sets into a binary code (potentially increasing the dimensionality). Algorithms 1 achieved significantly better utility for any given fixed constant anonymity level δ while algorithm 2 achieved a slight improvement. We next explored Facebook social data experiments where each user has a different level of desired anonymity and has 7 discrete profile attributes which were binarized into d = 101 dimensions. We used the number of friends fi a user has to compute their desired anonymity level (which decreases as the number of friends increases). We set F = maxi=1,...n -log fi. and, for each value of δ in the plot, we set user i’s privacy level to δi = δ − (F − -log fi.). Figure 3(b) summarizes the results where utility is plotted against δ. Since the k-anonymity agglomerative clustering method requires a constant δ for all users, we set k = maxi δi in order to have a privacy guarantee. Algorithms 1 and 2 consistently achieved significantly better utility in the adaptive anonymity setting while also achieving the desired level of privacy protection."
    }, {
      "heading" : "6 Discussion",
      "text" : "We described the adaptive anonymity problem where data is obfuscated to respect each individual user’s privacy settings. We proposed a relaxation of k-anonymity which is straightforward to implement algorithmically. It yields similar privacy protection while offering greater utility and the ability to handle heterogeneous anonymity levels for each user."
    } ],
    "references" : [ {
      "title" : "Approximation algorithms for k-anonymity",
      "author" : [ "G. Aggarwal", "T. Feder", "K. Kenthapadi", "R. Motwani", "R. Panigrahy", "D. Thomas", "A. Zhu" ],
      "venue" : "Journal of Privacy Technology,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2005
    }, {
      "title" : "Issues and etiquette concerning use of shared measurement data",
      "author" : [ "M. Allman", "V. Paxson" ],
      "venue" : "In Proceedings of the 7th ACM SIGCOMM conference on Internet measurement,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2007
    }, {
      "title" : "Lecture Notes in Computer Science - Automata, Languages and Programming, chapter Differential Privacy",
      "author" : [ "M. Bugliesi", "B. Preneel", "V. Sassone", "I Wegener", "C. Dwork" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2006
    }, {
      "title" : "Differentially private empirical risk minimization",
      "author" : [ "K. Chaudhuri", "C. Monteleone", "A.D. Sarwate" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2011
    }, {
      "title" : "Class-based graph anonymization for social network data",
      "author" : [ "G. Cormode", "D. Srivastava", "S. Bhagat", "B. Krishnamurthy" ],
      "venue" : "In PVLDB,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2009
    }, {
      "title" : "Anonymizing bipartite graph data using safe groupings",
      "author" : [ "G. Cormode", "D. Srivastava", "T. Yu", "Q. Zhang" ],
      "venue" : "VLDB J.,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2010
    }, {
      "title" : "Approximating maximum weight matching in near-linear time",
      "author" : [ "R. Duan", "S. Pettie" ],
      "venue" : "In Proceedings 51st Symposium on Foundations of Computer Science,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2010
    }, {
      "title" : "Paths, trees and flowers",
      "author" : [ "J. Edmonds" ],
      "venue" : "Canadian Journal of Mathematics,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1965
    }, {
      "title" : "An efficient reduction technique for degree-constrained subgraph and bidirected network flow problems",
      "author" : [ "H.N. Gabow" ],
      "venue" : "In Proceedings of the fifteenth annual ACM symposium on Theory of computing,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1983
    }, {
      "title" : "k-anonymization revisited",
      "author" : [ "A. Gionis", "A. Mazza", "T. Tassa" ],
      "venue" : "In ICDE,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2008
    }, {
      "title" : "Fast b-matching via sufficient selection belief propagation",
      "author" : [ "B. Huang", "T. Jebara" ],
      "venue" : "In Artificial Intelligence and Statistics,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2011
    }, {
      "title" : "An introduction to variational methods for graphical models",
      "author" : [ "M.I. Jordan", "Z. Ghahramani", "T. Jaakkola", "L.K. Saul" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1999
    }, {
      "title" : "Blossom V: A new implementation of a minimum cost perfect matching algorithm",
      "author" : [ "V.N. Kolmogorov" ],
      "venue" : "Mathematical Programming Computation,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2009
    }, {
      "title" : "t-closeness: Privacy beyond k-anonymity and ldiversity",
      "author" : [ "N. Li", "T. Li", "S. Venkatasubramanian" ],
      "venue" : "In ICDE,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2007
    }, {
      "title" : "Probabilistic anonymity",
      "author" : [ "S. Lodha", "D. Thomas" ],
      "venue" : "In PinKDD,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2007
    }, {
      "title" : "L-diversity: Privacy beyond k-anonymity.ACMTransactions on Knowledge Discovery",
      "author" : [ "A. Machanavajjhala", "D. Kifer", "J. Gehrke", "M. Venkitasubramaniam" ],
      "venue" : "fromData (TKDD),",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2007
    }, {
      "title" : "On the complexity of optimal k-anonymity",
      "author" : [ "A. Meyerson", "R. Williams" ],
      "venue" : "In PODS,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2004
    }, {
      "title" : "Generalizing data to provide anonymity when disclosing information",
      "author" : [ "P. Samarati", "L. Sweeney" ],
      "venue" : "In PODS,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1998
    }, {
      "title" : "Achieving k-anonymity privacy protection using generalization and suppression",
      "author" : [ "L. Sweeney" ],
      "venue" : "International Journal on Uncertainty, Fuzziness and Knowledge-based Systems,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2002
    }, {
      "title" : "Personalized privacy preservation",
      "author" : [ "Y. Tao", "X. Xiao" ],
      "venue" : "In SIGMOD Conference,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2006
    }, {
      "title" : "Personalized privacy preservation",
      "author" : [ "Y. Tao", "X. Xiao" ],
      "venue" : "In Privacy-Preserving Data Mining,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2008
    }, {
      "title" : "Probabilistic inference and differential privacy",
      "author" : [ "O. Williams", "F. McSherry" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2010
    }, {
      "title" : "Anonymizing set-valued data by nonreciprocal recoding",
      "author" : [ "M. Xue", "P. Karras", "C. Rassi", "J. Vaidya", "K.-L. Tan" ],
      "venue" : "In KDD,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2012
    }, {
      "title" : "Preserving the privacy of sensitive relationships in graph data",
      "author" : [ "E. Zheleva", "L. Getoor" ],
      "venue" : "In KDD,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "If the data contains sensitive information, it is necessary to protect it with privacy guarantees while maintaining some notion of data utility [18, 2, 24].",
      "startOffset" : 144,
      "endOffset" : 155
    }, {
      "referenceID" : 1,
      "context" : "If the data contains sensitive information, it is necessary to protect it with privacy guarantees while maintaining some notion of data utility [18, 2, 24].",
      "startOffset" : 144,
      "endOffset" : 155
    }, {
      "referenceID" : 23,
      "context" : "If the data contains sensitive information, it is necessary to protect it with privacy guarantees while maintaining some notion of data utility [18, 2, 24].",
      "startOffset" : 144,
      "endOffset" : 155
    }, {
      "referenceID" : 18,
      "context" : "These include k-anonymity [19], l-diversity [16], t-closeness [14] and differential1 privacy [3, 22].",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 15,
      "context" : "These include k-anonymity [19], l-diversity [16], t-closeness [14] and differential1 privacy [3, 22].",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 13,
      "context" : "These include k-anonymity [19], l-diversity [16], t-closeness [14] and differential1 privacy [3, 22].",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 2,
      "context" : "These include k-anonymity [19], l-diversity [16], t-closeness [14] and differential1 privacy [3, 22].",
      "startOffset" : 93,
      "endOffset" : 100
    }, {
      "referenceID" : 21,
      "context" : "These include k-anonymity [19], l-diversity [16], t-closeness [14] and differential1 privacy [3, 22].",
      "startOffset" : 93,
      "endOffset" : 100
    }, {
      "referenceID" : 19,
      "context" : "Other related approaches have been previously explored [20, 21, 15, 5, 6, 23] yet herein we contribute novel efficient algorithms and formalize precise privacy guarantees.",
      "startOffset" : 55,
      "endOffset" : 77
    }, {
      "referenceID" : 20,
      "context" : "Other related approaches have been previously explored [20, 21, 15, 5, 6, 23] yet herein we contribute novel efficient algorithms and formalize precise privacy guarantees.",
      "startOffset" : 55,
      "endOffset" : 77
    }, {
      "referenceID" : 14,
      "context" : "Other related approaches have been previously explored [20, 21, 15, 5, 6, 23] yet herein we contribute novel efficient algorithms and formalize precise privacy guarantees.",
      "startOffset" : 55,
      "endOffset" : 77
    }, {
      "referenceID" : 4,
      "context" : "Other related approaches have been previously explored [20, 21, 15, 5, 6, 23] yet herein we contribute novel efficient algorithms and formalize precise privacy guarantees.",
      "startOffset" : 55,
      "endOffset" : 77
    }, {
      "referenceID" : 5,
      "context" : "Other related approaches have been previously explored [20, 21, 15, 5, 6, 23] yet herein we contribute novel efficient algorithms and formalize precise privacy guarantees.",
      "startOffset" : 55,
      "endOffset" : 77
    }, {
      "referenceID" : 22,
      "context" : "Other related approaches have been previously explored [20, 21, 15, 5, 6, 23] yet herein we contribute novel efficient algorithms and formalize precise privacy guarantees.",
      "startOffset" : 55,
      "endOffset" : 77
    }, {
      "referenceID" : 18,
      "context" : "The most pervasive method for anonymity in the released data is the k-anonymity method [19, 1].",
      "startOffset" : 87,
      "endOffset" : 94
    }, {
      "referenceID" : 0,
      "context" : "The most pervasive method for anonymity in the released data is the k-anonymity method [19, 1].",
      "startOffset" : 87,
      "endOffset" : 94
    }, {
      "referenceID" : 15,
      "context" : "These x and y values are known as the sensitive attributes and the entries ofX andY are the non-sensitive attributes [16].",
      "startOffset" : 117,
      "endOffset" : 121
    }, {
      "referenceID" : 18,
      "context" : "We first assume that all degrees δi are constant and set to δ and discuss how the proposed b-matching privacy output subtly differs from standard k-anonymity [19].",
      "startOffset" : 158,
      "endOffset" : 162
    }, {
      "referenceID" : 16,
      "context" : "Moreover, since this problem is NP-hard [17], efficient algorithms rarely achieve this best-possible utility (minimal number of stars).",
      "startOffset" : 40,
      "endOffset" : 44
    }, {
      "referenceID" : 0,
      "context" : "While the k-anonymity suppression problem is known to be NP-hard, a polynomial time method with an approximation guarantee is the forest algorithm [1] which has an approximation ratio of 3k− 3.",
      "startOffset" : 147,
      "endOffset" : 150
    }, {
      "referenceID" : 9,
      "context" : "In practice, though, the forest algorithm is slow and achieves poor utility compared to clustering methods [10].",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 8,
      "context" : "One algorithm solves for minimum weight bipartite b-matchings which is easy to implement using linear programming, max-flow methods or belief propagation in the bipartite case [9, 11].",
      "startOffset" : 176,
      "endOffset" : 183
    }, {
      "referenceID" : 10,
      "context" : "One algorithm solves for minimum weight bipartite b-matchings which is easy to implement using linear programming, max-flow methods or belief propagation in the bipartite case [9, 11].",
      "startOffset" : 176,
      "endOffset" : 183
    }, {
      "referenceID" : 7,
      "context" : "The other algorithm uses a general non-bipartite solver which involves Blossom structures and requiresO(δmn log(n)) time[8, 9, 13].",
      "startOffset" : 120,
      "endOffset" : 130
    }, {
      "referenceID" : 8,
      "context" : "The other algorithm uses a general non-bipartite solver which involves Blossom structures and requiresO(δmn log(n)) time[8, 9, 13].",
      "startOffset" : 120,
      "endOffset" : 130
    }, {
      "referenceID" : 12,
      "context" : "The other algorithm uses a general non-bipartite solver which involves Blossom structures and requiresO(δmn log(n)) time[8, 9, 13].",
      "startOffset" : 120,
      "endOffset" : 130
    }, {
      "referenceID" : 6,
      "context" : "Fortunately, minimum weight general matching has recently been shown to require only O(m\"−1 log \"−1) time to achieve a (1 − \") approximation [7].",
      "startOffset" : 141,
      "endOffset" : 144
    }, {
      "referenceID" : 11,
      "context" : "We propose the following polynomial time algorithm which, in its first iteration, minimizes h(G) over the family Gb and then iteratively minimizes a variational upper bound [12] on s(G) using a weighted version of the Hamming distance.",
      "startOffset" : 173,
      "endOffset" : 177
    }, {
      "referenceID" : 9,
      "context" : "We compared algorithms 1 and 2 against an agglomerative clustering competitor (optimized to minimize stars) which is known to outperform the forest method [10].",
      "startOffset" : 155,
      "endOffset" : 159
    } ],
    "year" : 2013,
    "abstractText" : "The adaptive anonymity problem is formalized where each individual shares their data along with an integer value to indicate their personal level of desired privacy. This problem leads to a generalization of k-anonymity to the b-matching setting. Novel algorithms and theory are provided to implement this type of anonymity. The relaxation achieves better utility, admits theoretical privacy guarantees that are as strong, and, most importantly, accommodates a variable level of anonymity for each individual. Empirical results confirm improved utility on benchmark and social data-sets.",
    "creator" : null
  }
}