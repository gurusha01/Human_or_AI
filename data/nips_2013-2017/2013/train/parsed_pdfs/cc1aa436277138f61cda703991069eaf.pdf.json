{
  "name" : "cc1aa436277138f61cda703991069eaf.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Scoring Workers in Crowdsourcing: How Many Control Questions are Enough?",
    "authors" : [ "Qiang Liu", "Mark Steyvers" ],
    "emails" : [ "qliu1@uci.edu", "mark.steyvers@uci.edu", "ihler@ics.uci.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The recent rise of crowdsourcing has provided a fast and inexpensive way to collect human knowledge and intelligence, as illustrated by human intelligence marketplaces such as Amazon Mechanical Turk, games with purpose like ESP, reCAPTCHA, and crowd-based forecasting for politics and sports. One of the philosophies behind these successes is the wisdom of crowds phenomenon: properly combining a group of untrained people can be better than the average performance of the individuals, and even as good as the experts in many application domains (e.g., Surowiecki, 2005, Sheng et al., 2008). Unfortunately, it is not always obvious how best to combine the crowd, because the (often anonymous) workers have unknown and diverse levels of expertise, and potentially systematic biases across the crowd. Naı̈ve consensus methods which simply take uniform averages or the majority answer of the workers have been known to perform poorly. This raises the problem of scoring the workers, that is, estimating their expertise, bias and any other associated parameters, in order to combine their answers more effectively.\nOne direct way to address this problem is to score workers using their past performance on similar problems. However, this is not always practical, since historical records are hard to maintain for anonymous workers, and their past tasks may be very different from the current one. An alternative is the idea behind reCAPTCHA: “seed” some control items with known answers into the assigned tasks (without telling workers which are control items), score the workers using these control items, and weight their answers accordingly on the unknown target items. Similar ideas have been widely used in existing crowdsourcing systems. CrowdFlower, for example, provides interfaces and tools to allow requesters to explicitly specify and analyze a set of control items (sometimes called “gold data”). The reCAPTCHA example is a particularly simple case, where workers answer exactly one control and one target item. However, in general crowdsourcing, the workers may answer hundreds of questions, raising the question of how many control items should be used. There is a clear tradeoff: having workers answer more control items gives better estimates of their performance and any\npotential systematic bias, but leaves fewer resources for the target items that are of direct interest. However, using few control items gives poor estimates of workers’ performance and their biases, also leading to bad results. A deep understanding of the value of control items may provide useful guidance for crowdsourcing practitioners.\nOn the other hand, a line of research has studied more advanced consensus methods that are able to simultaneously estimate the workers’ performance and items’ answers without any ground truth on the items, by building joint statistical models of the workers and labels (e.g., Dawid and Skene, 1979, Whitehill et al., 2009, Karger et al., 2011, Liu et al., 2012, Zhou et al., 2012). The basic idea is to score the workers by their agreement with other workers, assuming that the majority of workers are correct. Perhaps surprisingly, the worker reliabilities estimated by these “unsupervised” consensus methods can be almost as good as those estimated when the true labels of all the items are known, and are much better than self-evaluated worker reliability (Romney et al., 1987, Lee et al., 2012). Control items can also be incorporated into these methods: but how much can we expect them to improve results, or does an “unsupervised” method suffice?\nThe goal of this paper is to study the value of control items, and provide practical guidance on how many control items are enough under different scenarios. We give both theoretical and empirical results for this problem, and provide some rules of thumbs that that are easy to use in practice. We develop our theory on a class of Gaussian models for estimating continuous quantities, such as forecasting probabilities and point spreads in sports games, and show how it extends to more general models. As a byproduct, we also provide analytic results of the accuracy of different consensus algorithms. Important practical issues such as the impact of model misspecification, systematic biases and heteroscedasticity are also highlighted on real datasets."
    }, {
      "heading" : "2 Background",
      "text" : "Assume there is a set T of target items, associated with a set of labels µT ∶= {µi∶ i ∈ T } whose true values µ∗T we want to estimate. In addition, we have a set C of control (or training) items whose true labels µ∗C ∶= {µ ∗ i ∶ i ∈ C} are known. We denote the set of workers byW; each worker j is associated with a parameter ν∗j that characterizes their expertise, bias, any other relevant features. We denote the complete vector of worker parameters by ν ∶= {ν∗j ∶ j ∈ W}. Both µ and ν are assumed to be continuous variables in this paper. Denote by nt the number of target items and m the workers.\nLet ∂i be the set of workers assigned to item i, and ∂tj (and ∂ c j ) the set of target (and control) items labeled by worker j. The assignment relationship between the workers and the target items can be represented by a bipartite graph Gt = (T ,W,Et), where there is an edge (ij) ∈ Et iff item i is assigned to worker j. Let ri be the number of workers assigned to the i-th target item, and let `tj (and `cj) be the number of target (and control) items assigned to the j-th worker. Note that {ri} and {`tj} are the two degree sequences of the bipartite graph Gt.\nDenote by xij the label we collect from worker j for item i. In general, we can assume that xij is a random variable drawn from a probabilistic distribution p(xij ∣µ∗i , ν ∗ j ). The computational question is then to construct an estimator µ̂T of the true labels µ∗T based on the crowdsourced labels {xij}, such that the expected mean square error (MSE) on the target items, E[∣∣µ̂T − µ∗T ∣∣2], is minimized.\nGaussian Model. We focus on a class of simple Gaussian models on the labels xij :\nxij = µ ∗ i + b ∗ j + ξij , ξij ∼ N (0, σ ∗2 ), (1)\nwhere µ∗i is the quantity of interest of item i, b ∗ j is the bias of worker j, and σ ∗2 is the variance. For some quantities, like probabilities and prices, proper transforms should be applied before using such Gaussian models. Model (1) is equivalent to the two-way fixed effects model in statistics (e.g., Chamberlain, 1982). It captures heterogeneous biases across workers that are commonly observed in practice, for example in workers’ judgments on probabilities and prices, and which can have significant effects on the estimate accuracy. This model also has nice theoretical properties and will play an important role in our theoretical analysis. Note that the biases are not identifiable solely from the crowdsourced labels {xij}, making it is necessary to add some control items or other information when decoding the answers.\nAn extension of model (1) is to introduce heteroscedasticity, allowing different workers to have different level of Gaussian noise: that is, xij = µ∗i + b ∗ j + σ ∗ j ξij , where ξij ∼ N (0,1) and σ ∗2 j is a variance parameter of worker j. We will refer to this extension as the bias-variance model, and Model (1) as the bias-only model. We will also consider another special case, xij = µ∗j + σ ∗ j ξij , which assumes the workers all have zero bias but different variances (the variance-only model). Theoretical analysis of the bias-variance and variance-only models are significantly more difficult due to the presence of the variance parameters, but is still possible under asymptotic assumption."
    }, {
      "heading" : "2.1 Consensus Algorithms With Partial Ground Truth",
      "text" : "Control items with known true labels can be used to estimate workers’ parameters, and hence improve the estimation accuracy. In this section, we introduce two types of consensus methods that incorporate the control items in different ways: one simply scores the workers based on their performance on the control items, while the other uses a joint maximum likelihood estimator that scores the worker based on their answers on both control items and target items. We present both methods in terms of a general model p(xij ∣µi, νj) here; the updates for the Gaussian models can be easily derived, but are omitted for space.\nTwo-stage Estimator: the workers’ parameters are first estimated using the control items, and are then used to predict the target items. That is,\nScoring workers: ν̂j = arg max νj ∑ i∈∂cj\nlog p(xij ∣µ ∗ i , νj), for all j ∈W , (2)\nPredicting target items: µ̂i = arg max µi ∑ j∈∂i log p(xij ∣µi, ν̂j), for all i ∈ T , (3)\nwhere we use the maximum likelihood estimator as a general procedure for estimating parameters.\nJoint Estimator: we directly maximize the joint likelihood of the crowdsourced labels {xij} of both target and control items, with µC of the control items clamped to the true values µ∗C . That is,\n[µ̂T , ν̂] = arg max [µT ,ν] {∑ i∈C ∑ j∈∂i\nlog p(xij ∣µ ∗ i , νj) +∑\ni∈T ∑ j∈∂i\nlog p(xij ∣µi, νj)}, (4)\nwhich can be solved by block coordinate descent, alternatively optimizing µT and ν. Compared to the two-stage estimator, the joint estimator estimates the workers’ parameters based on both the control items and the target items, even though their true labels are unknown. This is because the labels xij provide information on µ∗i through the model assumption p(xij ∣µ ∗ i , ν ∗ j ). Therefore, the joint estimator may be much more efficient than the two-stage estimator when the model assumptions are satisfied, but may perform poorly if the model is misspecified."
    }, {
      "heading" : "3 How many control items are enough?",
      "text" : "We now consider the central question: assuming each worker answers ` items (we refer ` as the budget), including k control items and `−k target items, what is the optimal choice of k to minimize the expected MSE? To be concrete, here we assume all the workers (items) are assigned to the same number of randomly selected items (workers), and hence the assignment graph Gt is a random semi-regular bipartite graph, which can be generated by the configuration model (e.g., Karger et al., 2011). We assume r is the number of labels received by each target item, so that r =m(` − k)/nt.\nObviously, the optimal number of control items should depend on their usage in the subsequent consensus method. We will show that the two-stage and joint estimators exploit control items in fundamentally different ways, and yield very different optimal values of k. Roughly speaking, the optimal k should scale as O( √ `) when using a two-stage estimator, compared to O(`/ √ nt) when using joint estimators. We now discuss these two methods separately."
    }, {
      "heading" : "3.1 Optimal k for Two-stage Estimator",
      "text" : "We first address the problem on the bias-only model, which has a particularly simple analytic solution. We then extend our results to more general models.\nTheorem 3.1. (i). For the bias-only model with xij = µ∗i + b∗j + ξij , where ξij are i.i.d. noise drawn from N (0, σ∗2), the expected mean square error (MSE) of the two-stage estimator in (2)-(3) is\nE[∑ i∈T\n∣∣µ̂i − µ ∗ i ∣∣ 2 /nt] =\nσ∗2\nr (1 +\n1 k ). (5)\n(ii). Note that r = m(` − k)/nt, and the optimal k that minimizes the expected MSE in (5) is k∗ = ⌈ √ ` + 5/4 − 3/2⌉ ≈ √ `, where ⌈z⌉ denotes the smallest integer no less than z.\nProof. The solution of two-stage estimator has a simple linear form under the bias-only model,\nµ̂i = 1\nr ∑ j∈∂i\n(xij − b̂j), b̂j = 1\nk ∑ i∈∂cj\n(xij − µ ∗ i ), for ∀i ∈ T , ∀j ∈W .\nSince the xij are Gaussian, the µ̂i are also Gaussian. Calculating the mean and variance of µ̂i, we have that Eµ̂i = µ∗i , and Var(µ̂i) as in (5). The remaining steps are straightforward.\nRemarks. (i). Eq. (5) shows that the MSE is inversely proportional to the number r of workers per target item, while the number k of control items per workers only refines the multiplicative constant. Therefore, the resources assigned to the control items are much less “useful” than those assigned directly to the target items, suggesting the optimal k should be much less than the budget `.\n(ii). On the other hand, if k is too small, the multiplicative constant becomes large, which also degrades the MSE. In the extreme, if k = 0 then the bias is unidentifiable, and the MSE grows to infinity. In addition, if the budget ` grows to infinity, the optimal k should also grow to infinity, otherwise the multiplicative constant is strictly larger than one, which is suboptimal. One can readily see that k = O( √ `) achieves the desired balance of trade-offs.\nGeneral Models. The bias-only model is simple enough to give closed form solutions. It turns out that we can obtain similar results for more general models such as the bias-variance and the variance-only model, but only in the asymptotic regime.\nTo set up, assume {µi} and {νj} are drawn from prior distributions Qµ and Qν , respectively. Assume log p(xij ∣µi, νj) is twice differentiable w.r.t. µi and νj for all xij . Define the Fisher information matrix Hµµ = −Ex[∇2µµ log p(x∣µ, ν)], and similarly for Hµν and Hνν . Note that Hµµ is a random variable dependent on µ and ν, and denote by Eµν[Hµµ] its expectation w.r.t. Qµ and Qν .\nTheorem 3.2. (i). Assume the crowdsourced labels {xij} are drawn from p(xij ∣µ∗i , ν∗j ), where {µ∗i } and {ν ∗ j } are drawn from priors Qµ and Qν , respectively. The asymptotic expected MSE of the two-stage estimator defined in (2)-(3), as both r and k grow to infinity, is\nE[∑ i∈T\n∣∣µ̂i − µ ∗ i ∣∣ 2 /nt] =\nσ̃2\nr (1 +\na k ), (6)\nwhere σ̃2 = Eµν[tr(H−1µµ)], Jµµ = Ex,ν[∇ 2 µν log p(x∣µ, ν)H −1 νν∇ 2 µν log p(x∣µ, ν)\nT ], and a = Eµν[tr(H−1µµJµµH −1 µµ)]/Eµν[tr(H −1 µµ)],\n(ii). Note that r = m(` − k)/nt, and the optimal k that minimizes the asymptotic MSE in (6) is k∗ = ⌈ √ a` + a2 + 1/4 − a − 1/2⌉ ≈ √ a`, where ⌈k⌉ denotes the smallest integer no less than k.\nProof. Similar to Theorem 3.1, except asymptotic normality of M-estimators (e.g., Van der Vaart, 2000) should be used.\nRemarks. (i). The result in Theorem 3.2 is parallel to that in Theorem 3.1 for bias-only models, except that the contribution from uncertainty on the workers’ parameters is scaled by a modeldependent factor a, and correspondingly, the optimal k is scaled by √ a. Calculation yields a = 2 for the variance-only model, and a = 3 for the bias-variance model for any choice of prior Qµ and Qν . (ii). Letting k take continuous values, the optimal k to minimize (6) is k∗ = √ a` + a2 − a, which achieves a minimum MSE of nt m ⋅ σ̃2/(`−2k∗). For comparison, the MSE would be nt m ⋅ σ̃2/(`−k∗) if the worker parameters were known exactly. So, the uncertainty in the workers’ parameters creates an effective extra loss of k∗ labels for each target item. Note that this rule is universal, in that it remains true for any a (and hence any model)."
    }, {
      "heading" : "3.2 Optimal k for Joint Estimator",
      "text" : "The two-stage estimator is easy to analyze in that its accuracy is independent of the structure of the bipartite assignment graph beyond the degree r and k. This is not true for the joint estimator, whose accuracy depends on the topological structure of the assignment graph in a non-trivial way. In this section we study the properties of the joint estimator, again starting with the simple bias-only model, then discussing its extension to more general cases.\nWe first introduce some matrix notation. Let At be the adjacency matrix of Gt. Let Rt ∶= diag({ri ∶ i ∈ T }) be the diagonal matrix formed by the degree sequence of the target items, and similarly define Lt = diag({`tj ∶ j ∈W}) and Lc = diag({` c j ∶ j ∈W}).\nTheorem 3.3. (i). For the bias-only model with xij = µ∗i + b∗j + ξij , where ξij are i.i.d. noise drawn from N (0, σ∗2), the expected MSE of the joint estimator defined in (4) is\nE[∑ i∈T\n∣∣µ̂i − µ ∗ i ∣∣ 2 /nt] = σ ∗2tr((Rt −At(Lt +Lc)−1ATt ) −1 )/nt, (7)\nIf At is regular, with Rt = rI and Lt = (` − k)I , this simplifies:\nE[∑ i∈T\n∣∣µ̂i − µ ∗ i ∣∣ 2 /nt] = σ ∗2 1 r tr((I − ` − k ` W )−1)/nt, where W = R−1t AtL −1 t A T t . (8)\nProof. Assume B ∶= I −R−1t At(Lt + Lc) −1ATt is invertible. The solution of the joint estimator on the bias-only model is µ̂T = µ∗T +B −1zT , where zi = 1\nri ∑ j∈∂i\n(ξij − ξ̄j), and ξ̄j = 1\n`cj + ` t j ∑ i′∈∂cj∪∂tj\nξij\nand ξij = xij − µ∗i − b ∗ j for ∀i ∈ T . We obtain (7) by calculating Var(µ̂T ).\nRemarks. (ii). Equation (8) establishes an explicit connection between MSE and the spectral structure of the bipartite graph Gt. Consider the eigenvalues 1 = λ1 ≥ λ2 ≥ ⋯ ≥ 0 of W ∶= R−1t AtL −1 t A T t , where the second largest eigenvalue λ2 famously characterizes the connectivity of the graph Gt. Roughly speaking, Gt has better connectivity if λ2 is small, and verse versa. Observe that\ntr((I − ` − k ` W )−1) =\nnt\n∑ i=1\n(1 − ` − k\n` λi)\n−1 ≤\n` k + nt − 1\n1 − `−k ` λ2 . (9)\nTherefore, the joint estimator performs better when λ2 is small, i.e., when the graph is strongly connected. Intuitively, better connectivity “couples” the items and workers more tightly together, making it easier not to make mistakes during inference.\nBesides hoping for small error, one may also want the assignment graph to be sparse, i.e., use fewer labels. Graphs that are both sparse and strongly connected are known as expander graphs, and have been found universally important in areas like robust computer networks, error correcting codes, and communication networks; see Hoory et al. (2006) for a review. It is well known that large sparse random regular graphs are good expanders (e.g., Friedman et al., 1989), and hence a near-optimal allocation strategy for crowdsourcing (Karger et al., 2011). On such graphs, we can also estimate the optimal k in a simple form.\nTheorem 3.4. Assume At is a random regular bipartite graph, and nt =m. We have that\nE[∑ i∈T\n∣∣µ̂i − µ ∗ i ∣∣ 2 /nt] =\nσ∗2\n` − k [ nt − 1 nt (1 +O( 1 ` )) + ` ntk ], (10)\nwith probability one as nt → ∞. If in addition ` → ∞, the optimal k that minimizes (10) is k∗ = ⌈ √ `2/nt + `2/nt2 + 1/4 − `/nt − 1/2⌉ ≈ `/ √ nt.\nProof. Use (9) and the bound in Puder (2012) for λ2 of large random regular bipartite graphs.\nRemarks. (i). Perhaps surprisingly, the optimal k of the joint estimator scales linearly w.r.t. budget `, in contrast to the square-root rule of two-stage estimators. However, since usually ` ≤ nt, we have `/ √ nt ≤ √ `, that is, the joint estimator requires fewer control items than the two-stage estimator.\n(ii). In addition, the optimal k for the joint estimator also decreases as the total number nt of target items increases. Because nt is usually quite large in practice, the number of control items is usually very small. In particular, as nt → ∞, we have k∗ = 1, that is, there is no need for control items beyond fixing the unidentifiability issue of the biases.\nGeneral Models. The joint estimator on general models is more involved to analyze, but it is still possible to give an rough estimate by analyzing the Fisher information matrix of the likelihood. For notation, let Hµµ = Rt⊗Eµν(Hµµ), and Hνν = (Lt +Lc)⊗Eµν(Hνν), where ⊗ is the Kronecker product, and Hµν = [Hµiνj ]ij is a block matrix, where block Hµiνj for (ij) ∈ Et is a random copy of −∇2µν log p(x∣µ, ν) with random x, µ and ν, and Hµiνj = 0 for (ij) ∉ Et. Assuming the joint maximum likelihood estimator in (4) is asymptotically consistent (in terms of large ` and r), we can estimate its asymptotic MSE by the inverse of the Fisher information matrix,\nE[∑ i∈T\n∣∣µ̂i − µ ∗ i ∣∣ 2 /nt] ≈ E[tr((Hµµ −HµνHνν−1HµνT )−1)]/nt,\nwhere the expectation on the right side is w.r.t. the randomness of Hµν . This parallels (7) in Theorem 3.3, except the adjacency matrices are replaced by corresponding Hessian matrices. Unfortunately, it is more challenging to give a simple estimate of the optimal k as in Theorem 3.4, even when At is a random bipartite graph, because the spectral properties of the random matrix are complicated by blockwise structure, and may depend on the prior distribution Q(ν). However, experimentally the optimal k follows the trend ` √ a/nt, where the constant a depends on both the model assumption and the choice of Q(ν), and can be numerically estimated by simulation."
    }, {
      "heading" : "4 Experiments",
      "text" : "We show that our theoretical predictions match closely to the results on simulated data and two real datasets for estimating prices and point spreads. The experiments also highlight important practical issues such as the impact of model misspecification, biases, and heteroskedasticity.\nDatasets and Setup. The simulated data are generated by the Gaussian models definited in Section 2, where µi and bj are i.i.d. drawn from N (1,1); and σj from a χ2-distribution with degree 4 for the heteroskedastic versions. The price dataset consists of 80 household items collected from stores like Amazon and Costco, whose prices are estimated by 155 undergraduate students at UC Irvine. A log transform is performed on the prices before using the Gaussian models. The National Football League (NFL) forecasting data was collected by Massey et al. (2011), where 386 participants were asked to predict the point difference of 245 NFL games. We use the point spreads determined by professional bookmakers as the truth values in our experiments.\nFor all the experiments, we first construct the set of target items and control items by randomly partitioning items, and then randomly assign each worker with k control items and `−k target items, for varying values of ` and k. The MSE is estimated by averaging over 500 random trials. The optimal k is estimated by minimizing the averaged MSE over 300 randomly subsampled trials, and then taking average over 20 random subsamples.\nOptimal Number of Control Items. See Figure 1 for the results of the bias-only model when the data are simulated from the correct model. Figure 1(a) shows the empirical MSE of the two-stage estimator when varying the number k of control items. A clear trade-off appears: MSE is large both when k is too small to estimate workers’ parameters accurately, and when k is too large to leave a sufficient number of labels for the target items. The MSE of the joint estimator in Figure 1(b) follows a similar trend, but the gain by using control items is less significant (the left parts of the curves are flatter). This is because the joint estimator leverages the labels on the target items (whose true values are unknown), and relies less on the control items. In particular, as the number nt of target items increases, the optimal value of k for the joint estimator decreases with a rate of 1/ √ nt (see Figure 1(d)), but that of the two-stage estimator stays the same. Overall, the empirical optimal k of the two-stage and joint estimator aligns closely with our theoretical prediction (Figure 1(c)-(d)).\nWe show in Figure 2(a) the result of the bias-variance model when data are simulated from the correct model. The optimal k of the two-stage estimator aligns closely to √ a` with a = 3, matching the asymptotic result in Theorem 3.2, while that of the joint estimator scales like the line ` √ a/nt with a ≈ 3, matching our hypothesis in Section 3.2.\nModel misspecification. Real datasets are not expected to match the model assumptions perfectly. It is important, but difficult, to understand how the theory should be modified to compensate for the violation of assumptions. We provide some insights on this by constructing model misspecification artificially. Figure 2(b)-(c) shows the results when the data are simulated from a bias-variance model with non-zero biases, but we use the variance-only model (with zero bias) in the consensus algorithm. We see in Figure 2(b) that the optimal k of the two-stage estimator still aligns closely to our theoretical prediction, but that of the joint estimator is much larger than one would expect (almost half of the budget `). In addition, the MSE of the joint estimator in this case is significantly worse than that of the two-stage estimator (see Figure 2(c)), which is not expected if the model assumption holds. Therefore, the joint estimator seems to be more sensitive to model misspecification than the two-stage estimator, suggesting that caution should be taken when it is applied in practice.\nReal Datasets. Figure 3 shows the results of the bias-only model on the two real datasets; our prediction of the optimal k matches the empirical results surprisingly well on the NFL dataset (Figure 3(d)-(f)), while our theoretically optimal values of k on the price dataset tend to be smaller than the actual values (Figure 3(a)-(c)), perhaps caused by some unknown model misspecification. However, our bias on the estimated k does not cause a significant increase in MSE, because the scale in Figure 3(a)-(b) is relatively small compared to that in Figure 4(a).\nInterestingly, the two real datasets have opposite properties in terms of the importance of bias and heteroskedasticity (see Figure 4): In the price dataset, all the workers tend to underestimate the prices of the products, i.e., bj are negative for all workers, and the bias-only model performs much better than the zero-bias variance-only model. In contrast, the participants in the NFL dataset exhibit no systematic bias but seem to have different individual variances, and the variance-only model works better than the bias-only model. In both cases, the full bias-variance model works best if budget ` is large, but is not necessarily best if the budget is small and over-fitting is an issue."
    }, {
      "heading" : "5 Conclusion",
      "text" : "The problem of how many control questions to use is unlikely to yield a definitive answer, since real data are always likely to be more complicated than any model. However, our results highlight several issues and provide insights and rules of thumb that can help crowdsourcing practitioners make their own decisions. In particular, we show that the optimal number of control items should beO( √ `) for the two-stage estimator andO(`/ √ nt) for the joint estimator. Because the number nt of target items is usually large in practice, it is reasonable to recommend using a minimal number of control items, just enough to fix potential unidentifiability issues, assuming the model assumptions hold well. However, the joint estimator may require significantly more control items if model misspecification exists; in this case one might better switch to the more robust two-stage estimator, or search for better models. The control items can also be used to do model selection, an issue which deserves further discussion in the future.\nAcknowledgements. Work supported in part by NSF IIS-1065618 and IIS-1254071 and a Microsoft Research Fellowship. Thanks to Tobias Johnson for discussion on random matrix theory."
    } ],
    "references" : [ {
      "title" : "Get another label? Improving data quality and data mining using multiple, noisy labelers",
      "author" : [ "Victor S Sheng", "Foster Provost", "Panagiotis G Ipeirotis" ],
      "venue" : "In Proc. SIGKDD Int’l Conf. on Knowledge Discovery and Data Mining,",
      "citeRegEx" : "Sheng et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Sheng et al\\.",
      "year" : 2008
    }, {
      "title" : "Maximum likelihood estimation of observer error-rates using the EM algorithm",
      "author" : [ "A.P. Dawid", "A.M. Skene" ],
      "venue" : "Applied Statistics,",
      "citeRegEx" : "Dawid and Skene.,? \\Q1979\\E",
      "shortCiteRegEx" : "Dawid and Skene.",
      "year" : 1979
    }, {
      "title" : "Whose vote should count more: Optimal integration of labels from labelers of unknown expertise",
      "author" : [ "Jacob Whitehill", "Paul Ruvolo", "Tingfan Wu", "Jacob Bergsma", "Javier Movellan" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Whitehill et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Whitehill et al\\.",
      "year" : 2009
    }, {
      "title" : "Iterative learning for reliable crowdsourcing systems",
      "author" : [ "D.R. Karger", "S. Oh", "D. Shah" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Karger et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Karger et al\\.",
      "year" : 2011
    }, {
      "title" : "Variational inference for crowdsourcing",
      "author" : [ "Qiang Liu", "Jian Peng", "Alexander Ihler" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Liu et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2012
    }, {
      "title" : "Learning from the wisdom of crowds by minimax entropy",
      "author" : [ "Dengyong Zhou", "John Platt", "Sumit Basu", "Yi Mao" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "Zhou et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2012
    }, {
      "title" : "Recent applications of cultural consensus theory",
      "author" : [ "A Kimball Romney", "William H Batchelder", "Susan C Weller" ],
      "venue" : "American Behavioral Scientist,",
      "citeRegEx" : "Romney et al\\.,? \\Q1987\\E",
      "shortCiteRegEx" : "Romney et al\\.",
      "year" : 1987
    }, {
      "title" : "Inferring expertise in knowledge and prediction ranking tasks",
      "author" : [ "Michael D Lee", "Mark Steyvers", "Mindy de Young", "Brent Miller" ],
      "venue" : "Topics in cognitive science,",
      "citeRegEx" : "Lee et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2012
    }, {
      "title" : "Multivariate regression models for panel data",
      "author" : [ "Gary Chamberlain" ],
      "venue" : "Journal of Econometrics,",
      "citeRegEx" : "Chamberlain.,? \\Q1982\\E",
      "shortCiteRegEx" : "Chamberlain.",
      "year" : 1982
    }, {
      "title" : "Asymptotic statistics, volume 3",
      "author" : [ "Aad W Van der Vaart" ],
      "venue" : "Cambridge university press,",
      "citeRegEx" : "Vaart.,? \\Q2000\\E",
      "shortCiteRegEx" : "Vaart.",
      "year" : 2000
    }, {
      "title" : "Expander graphs and their applications",
      "author" : [ "Shlomo Hoory", "Nathan Linial", "Avi Wigderson" ],
      "venue" : "Bulletin of the American Mathematical Society,",
      "citeRegEx" : "Hoory et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Hoory et al\\.",
      "year" : 2006
    }, {
      "title" : "On the second eigenvalue of random regular graphs",
      "author" : [ "Joel Friedman", "Jeff Kahn", "Endre Szemeredi" ],
      "venue" : "In Proc. ACM Symp. on Theory of Computing,",
      "citeRegEx" : "Friedman et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Friedman et al\\.",
      "year" : 1989
    }, {
      "title" : "Expansion of random graphs: New proofs, new results",
      "author" : [ "Doron Puder" ],
      "venue" : "arXiv preprint arXiv:1212.5216,",
      "citeRegEx" : "Puder.,? \\Q2012\\E",
      "shortCiteRegEx" : "Puder.",
      "year" : 2012
    }, {
      "title" : "Hope over experience: Desirability and the persistence of optimism",
      "author" : [ "Cade Massey", "Joseph P Simmons", "David A Armor" ],
      "venue" : "Psychological Science,",
      "citeRegEx" : "Massey et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Massey et al\\.",
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : ", 1989), and hence a near-optimal allocation strategy for crowdsourcing (Karger et al., 2011).",
      "startOffset" : 72,
      "endOffset" : 93
    }, {
      "referenceID" : 9,
      "context" : "Graphs that are both sparse and strongly connected are known as expander graphs, and have been found universally important in areas like robust computer networks, error correcting codes, and communication networks; see Hoory et al. (2006) for a review.",
      "startOffset" : 219,
      "endOffset" : 239
    }, {
      "referenceID" : 12,
      "context" : "Use (9) and the bound in Puder (2012) for λ2 of large random regular bipartite graphs.",
      "startOffset" : 25,
      "endOffset" : 38
    }, {
      "referenceID" : 13,
      "context" : "The National Football League (NFL) forecasting data was collected by Massey et al. (2011), where 386 participants were asked to predict the point difference of 245 NFL games.",
      "startOffset" : 69,
      "endOffset" : 90
    } ],
    "year" : 2013,
    "abstractText" : "We study the problem of estimating continuous quantities, such as prices, probabilities, and point spreads, using a crowdsourcing approach. A challenging aspect of combining the crowd’s answers is that workers’ reliabilities and biases are usually unknown and highly diverse. Control items with known answers can be used to evaluate workers’ performance, and hence improve the combined results on the target items with unknown answers. This raises the problem of how many control items to use when the total number of items each workers can answer is limited: more control items evaluates the workers better, but leaves fewer resources for the target items that are of direct interest, and vice versa. We give theoretical results for this problem under different scenarios, and provide a simple rule of thumb for crowdsourcing practitioners. As a byproduct, we also provide theoretical analysis of the accuracy of different consensus methods.",
    "creator" : null
  }
}