{
  "name" : "cb70ab375662576bd1ac5aaf16b3fca4.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Learning Hidden Markov Models from Non-sequence Data via Tensor Decomposition",
    "authors" : [ "Tzu-Kuo Huang" ],
    "emails" : [ "tzukuoh@cs.cmu.edu", "schneide@cs.cmu.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Learning dynamic models from observed data has been a central issue in many fields of study, scientific or engineering tasks. The usual setting is that data are collected sequentially from trajectories of some dynamical system operation, and the goal is to recover parameters of the underlying dynamic model. Although many research and engineering efforts have been devoted to that setting, it turns out that in quite a few modern scientific modeling problems, another situation is more frequently encountered: observed data are out-of-order (or partially-ordered) snapshots rather than full sequential samples of the system operation. As pointed out in [7, 8], this situation may appear in the modeling of celestial objects such as galaxies or chronic diseases such as Alzheimer’s, because observations are usually taken from different trajectories (galaxies or patients) at unknown, arbitrary times. Or it may also appear in the study of biological processes, such as cell metabolism under external stimuli, where most measurement techniques are destructive, making it very difficult to repetitively collect observations from the same individual living organisms as they change over time. However, it is much easier to take single snapshots of multiple organisms undergoing the same biological process in a fully asynchronous fashion, hence the lack of timing information. Rabbat et al. [9] noted that in certain network inference problems, the only available data are sets of nodes co-occurring in random walks on the network without the order in which they were visited, and the goal is to reconstruct the network structure from such co-occurrence data. This problem is essentially about learning a first-order Markov chain from data lacking sequence information.\nAs one can imagine, dynamic model learning in a non-sequential setting is much more difficult than in the sequential setting and has not been thoroughly studied. One issue is that the notion of non-sequence data is vague because there can be many different generative processes resulting in non-sequence data. Without any restrictions, one can easily find a case where no meaningful dynamic model can be learnt. It is therefore important to figure out what assumptions on the data and the model would lead to successful learning. However, existing methods for non-sequential settings, e.g., [9, 11, 6, 8], do not shed much light on this issue because they are mostly based on Expectation-Maximization (EM), which require non-convex optimization. Regardless of the assumptions we make, as long as the resulting optimization problem remains non-convex, formal analysis of learning guarantees is still formidable.\nWe thus propose to take a different approach, based on another long-standing estimation principle: the method of moments (MoM). The basic idea of MoM is to find model parameters such that the resulting moments match or resemble the empirical moments. For some estimation problems, this approach is able to give unique and consistent estimates while the maximum-likelihood method gets entangled in multiple and potentially undesirable local maxima. Taking advantage of this property, an emerging area of research in machine learning has recently developed MoM-based learning algorithms with formal guarantees for some widely used latent variable models, such as Gaussian mixture models[5], Hidden Markov models [3], Latent Dirichlet Allocation [1, 4], etc. Although many learning algorithms for these models exist, some having been very successful in practice, barely any formal learning guarantee was given until the MoM-based methods were proposed. Such breakthroughs seem surprising, but it turns out that they are mostly based on one crucial property: for quite a few latent variable models, the model parameters can be uniquely determined from spectral decompositions of certain low-order moments of observable quantities.\nIn this work we demonstrate that under the MoM and spectral learning framework, there are reasonable assumptions on the generative process of non-sequence data, under which the tensor decomposition method [2], a recent advancement in spectral learning, can provably recover the parameters of first-order Markov models and hidden Markov models. To the best of our knowledge, ours is the first work that provides formal guarantees for learning from non-sequence data. Interestingly, these assumptions bear much similarity to the usual idea behind topic modeling: with the bag-of-words representation which is invariant to word orderings, the task of inferring topics is almost impossible given one single document (no matter how long it is!), but becomes easier as more documents touching upon various topics become available. For learning dynamic models, what we need in the non-sequence data are multiple sets of observations, where each set contains independent samples generated from its own initial distribution, and the many different initial distributions together cover the entire (hidden) state space. In some of the aforementioned scientific applications, such as biological studies, this type of assumptions might be realized by running multiple experiments with different initial configurations or amounts of stimuli.\nThe main body of the paper consists of four sections. Section 2 briefly reviews the essentials of the tensor decomposition framework [2]; Section 3 details our assumptions on non-sequence data, tensor-decomposition based learning algorithms, and theoretical guarantees; Section 4 reports some simulation results confirming our theoretical findings, followed by conclusions in Section 5. Proofs of theoretical results are given in the appendices in the supplementary material."
    }, {
      "heading" : "2 Tensor Decomposition",
      "text" : "We mainly follow the exposition in [2], starting with some preliminaries and notations. A real p-th order tensor A is a member of the tensor product space ⊗p i=1 R\nmi of p Euclidean spaces. For a vector x ∈ Rm, we denote by x⊗p := x⊗x⊗· · ·⊗x ∈ ⊗pi=1 Rm its p-th tensor power. A convenient way to represent A ∈ ⊗pi=1 Rm is through a p-way array of real numbers [Ai1i2···ip ]1≤i1,i2,...,ip≤m, where Ai1i2···ip denotes the (i1, i2, . . . , ip)-th coordinate of A with respect to a canonical basis. With this representation, we can view A as a multi-linear map that, given a set of p matrices {Xi ∈ Rm×mi}pi=1, produces another p-th order tensor A(X1,X2, · · · ,Xp) ∈ ⊗p i=1 R\nmi with the following p-way array representation:\nA(X1,X2, · · · ,Xp)i1i2···ip := ∑\n1≤j1,j2,...,jp≤m\nAj1j2···jp(X1)j1i1(V2)j2i2 · · · (Xp)jpip . (1)\nIn this work we consider tensors that are up to the third-order (p ≤ 3) and, for most of the time, also symmetric, meaning that their p-way array representations are invariant under permutations of array indices. More specifically, we focus on second and third-order symmetric tensors in or slightly perturbed from the following form:\nM2 :=\nk∑\ni=1\nωiµi ⊗ µi, M3 := k∑\ni=1\nωiµi ⊗ µi ⊗ µi, (2)\nsatisfying the following non-degeneracy conditions:\nCondition 1. ωi ≥ 0 ∀ 1 ≤ i ≤ k, {µi ∈ Rm}ki=1 are linearly independent, and k ≤ m.\nAs described in later sections, the core of our learning task involves estimating {ωi}ki=1 and {µi}ki=1 from perturbed or noisy versions of M2 and M3. We solve this estimation problem with the tensor decomposition method recently proposed by Anandkumar et al. [2]. The algorithm and its theoretical guarantee are summarized in Appendix A. The key component of this method is a novel tensor power iteration procedure for factorizing a symmetric orthogonal tensor, which is robust against input perturbation."
    }, {
      "heading" : "3 Learning from Non-sequence Data",
      "text" : "We first describe a generative process of non-sequence data for first-order Markov models and demonstrate how to apply tensor decomposition methods to perform consistent learning. Then we extend these ideas to hidden Markov models and provide theoretical guarantees on the sample complexity of the proposed learning algorithm. For notational conveniences we define the following vector-matrix cross product ⊗d∈{1,2,3} : (v ⊗1 M)ijk := vi(M)jk, (v ⊗2 M)ijk = vj(M)ik, (v ⊗3 M)ijk = vk(M)ij . For a matrix M we denote by Mi its i-th column."
    }, {
      "heading" : "3.1 First-order Markov Models",
      "text" : "Let P ∈ [0, 1]m×m be the transition probability matrix of a discrete, first-order, ergodic Markov chain with m states and a unique stationary distribution π. Let P be of full rank and 1⊤P = 1⊤. To give a high-level idea of what makes it possible to learn P from non-sequence data, we use the simple Markov chain with three states shown in Figure 1 as our running example, demonstrating step by step how to extend from a very restrictive generative setting of the data to a reasonably general setting, along with the assumptions made to allow consistent parameter estimation. In the usual setting where we have sequences of observations, say {x(1),x(2), . . .} with parenthesized superscripts denoting time, it is straightforward to consistently estimate P . We simply calculate the empirical frequency of consecutive pairs of states:\nP̂ij :=\n∑ t (x\n(t+1) = i,x(t) = j)∑ t (x (t) = j) .\nAlternatively, suppose for each state j, we have an i.i.d. sample of its immediate next state Dj := {x(1)1 ,x (1) 2 , . . . | x(0) = j}, where subscripts are data indices. Consistent estimation in this case is also easy: the empirical distribution of Dj consistently estimates Pj , the j-th column of P . For\nexample, the Markov chain in Figure 1 may produce the following three samples, whose empirical distributions estimate the three columns of P respectively:\nD1 = {2, 1, 2, 2, 2, 2, 2, 2, 2, 2} ⇒ P̂1 = [0.1 0.9 0.0]⊤, D2 = {3, 3, 2, 3, 2, 3, 3, 2, 3, 3} ⇒ P̂2 = [0.0 0.3 0.7]⊤, D3 = {1, 1, 3, 1, 3, 3, 1, 3, 3, 1} ⇒ P̂3 = [0.5 0.0 0.5]⊤.\nA nice property of these estimates is that, unlike in the sequential setting, they do not depend on any particular ordering of the observations in each set. Nevertheless, such data are not quite nonsequenced because all observations are made at exactly the next time step. We thus consider the following generalization: for each state j, we have Dj := {x(t1)1 ,x (t2) 2 , . . . | x(0) = j}, i.e., independent samples of states drawn at unknown future times {t1, t2, . . .}. For example, our data in this setting might be\nD1 = {2, 1, 2, 3, 2, 3, 3, 2, 2, 3}, D2 = {3, 3, 2, 3, 2, 1, 3, 2, 3, 1}, D3 = {1, 1, 3, 1, 2, 3, 2, 3, 3, 2}.\n(3)\nObviously it is hard to extract information about P from such data. However, if we assume that the unknown times {ti} are i.i.d. random variables following some distribution independent of the initial state j, it can then be easily shown that Dj’s empirical distribution consistently estimates Tj , the j-th column of the the expected transition probability matrix T := Et[P t]:\nD1 = {2, 1, 2, 3, 2, 3, 3, 2, 2, 3} ⇒ T̂1 = [0.1 0.5 0.4]⊤, D2 = {3, 3, 2, 3, 2, 1, 3, 2, 3, 1} ⇒ T̂2 = [0.2 0.3 0.5]⊤, D3 = {1, 1, 3, 1, 2, 3, 2, 3, 3, 2} ⇒ T̂3 = [0.3 0.3 0.4]⊤.\nIn general there exist many P ’s that result in the same T . Therefore, as detailed later, we make a specific distributional assumption on {ti} to enable unique recovery of the transition matrix P from T (Assumption A.1). Next we consider a further generalization, where the unknowns are not only the time stamps of the observations, but also the initial state j. In other words, we only know each set was generated from the same initial state, but do not know the actual initial state. In this case, the empirical distributions of the sets consistently estimate the columns of T in some unknown permutation Π:\nDΠ(3) = {1, 1, 3, 1, 2, 3, 2, 3, 3, 2} ⇒ T̂Π(3) = [0.3 0.3 0.4]⊤. DΠ(2) = {3, 3, 2, 3, 2, 1, 3, 2, 3, 1} ⇒ T̂Π(2) = [0.2 0.3 0.5]⊤, DΠ(1) = {2, 1, 2, 3, 2, 3, 3, 2, 2, 3} ⇒ T̂Π(1) = [0.1 0.5 0.4]⊤.\nIn order to be able to identify Π, we will again resort to randomness and assume the unknown initial states are random variables following a certain distribution (Assumption A.2) so that the data carry information about Π. Finally, we generalize from a single unknown initial state to an unknown initial state distribution, where each set of observations D := {x(t1)1 ,x (t2) 2 , . . . | π(0)} consists of independent samples of states drawn at random times from some unknown initial state distribution π (0). For example, the data may look like:\nD π\n(0) 1 = {1, 3, 3, 1, 2, 3, 2, 3, 3, 2}, D\nπ (0) 2 = {3, 1, 2, 3, 2, 1, 3, 2, 3, 1}, D\nπ (0) 3 = {2, 1, 2, 3, 3, 3, 3, 1, 2, 3}, ...\nWith this final generalization, most would agree that the generated data are non-sequenced and that the generative process is flexible enough to model the real-world situations described in Section 1. However, simple estimation with empirical distributions no longer works because each set may now contain observations from multiple initial states. This is where we take advantage of the tensor\ndecomposition framework outlined in Section 2, which requires proper assumptions on the initial state distribution π(0) (Assumption A.3).\nNow we are ready to give the definition of our entire generative process. Assume we have N sets of non-sequence data each containing n observations, and each set of observations {xi}ni=1 were independently generated by the following:\n• Draw an initial distribution π\n(0) ∼ Dirichlet(α), (Assumption A.3) E[π(0)] = α/( ∑m i=1 αi) = π, πi 6= πj ∀ i 6= j. (Assumption A.2) • For i = 1, . . . , n, – Draw a discrete time ti ∼ Geometric(r), ti ∈ {1, 2, 3, . . .}. (Assumption A.1) – Draw an initial state si ∼ Multinomial(π0), si ∈ {0, 1}m. – Draw an observation xi ∼ Multinomial(P tisi), xi ∈ {0, 1}m.\nThe above generative process has several properties. First, all the data points in the same set share the same initial state distribution but can have different initial states; the initial state distribution varies across different sets and yet centers at the stationary distribution of the Markov chain. As mentioned in Section 1, this may be achieved in biological studies by running multiple experiments with different input stimuli, so the data collected in the same experiment can be assumed to have the same initial state distribution. Second, each data point is drawn from an independent trajectory of the Markov chain, a similar situation in the modeling of galaxies or Alzheimer’s, and random time steps could be used to compensate for individual variations in speed: a small/large ti corresponds to a slowly/fast evolving individual object. Finally, the geometric distribution can be interpreted as an overall measure of the magnitude of speed variation: a large success probability r would result in many small ti’, meaning that most objects evolve at similar speeds, while a small r would lead to ti’s taking a wide range of values, indicating a large speed variation.\nTo use the tensor decomposition method in Appendix A, we need the tensor structure (2) in certain low-order moments of observed quantities. The following theorem identifies such quantities:\nTheorem 1. Define the expected transition probability matrix T := Et[P t] = rP (I − (1− r)P )−1 and let α0 := ∑ i αi, C2 := E[x1x ⊤ 2 ] and C3 := E[x1 ⊗ x2 ⊗ x3]. Then the following holds:\nE[x1] = π, C2 = 1 α0+1 Tdiag(π)T⊤ + α0 α0+1 ππ ⊤, (4)\nC3 = 2\n(α0+2)(α0+1)\n∑ i πiT ⊗3 i + α0 α0+2 ∑3 d=1 π ⊗d C2 − 2α20 (α0+2)(α0+1) π ⊗3, (5)\nM2 := (α0 + 1)C2 − α0ππ⊤ = Tdiag(π)T⊤, (6) M3 := (α0+2)(α0+1) 2 C3 − (α0+1)α0 2 ∑3 d=1 π ⊗d C2 + α20π⊗3 = ∑ i πiT ⊗3 i . (7)\nThe proof is in Appendix B.1, which relies on the special structure in the moments of the Dirichlet distribution (Assumption A.3). It is clear that M2 and M3 have the desired tensor structure. Assuming α0 is known, we can form estimates M̂2 and M̂3 by computing empirical moments from the data. Note that the xi’s are exchangeable, so we can use all pairs and triples of data points to compute the estimates. Interestingly, these low-order moments have a very similar structure to those in Latent Dirichlet Allocation [1]. Indeed, according to our generative process, we can view a set of non-sequence data points as a document generated by an LDA model with the expected transition matrix T as the topic matrix, the stationary distribution π as the topic proportions, and most importantly, the states as both the words and the topics. The last property is what distinguishes our generative process from a general LDA model: because both the words and the topics correspond to the states, the topic matrix is no longer invariant to column permutations. Since the tensor decomposition method may return T̂ under any column permutation, we need to recover the correct matching between its rows and columns. Note that the π̂ returned by the tensor decomposition method undergoes the same permutation as T̂ ’s columns. Because all πi’s have different values by Assumption A.2, we may recover the correct matching by sorting both the returned π̂ and the mean π̄ of all data.\nA final issue is estimating P and r from T̂ . This is in general difficult even when the exact T is available because multiple choices of P and r may result in the same T . However, if the true transition matrix P has at least one zero entry, then unique recovery is possible:\nTheorem 2. Let P ∗, r∗, T ∗ and π∗ denote the true values of the transition probability matrix, the success probability, the expected transition matrix, and the stationary distribution, respectively. Assume that P ∗ is ergodic and of full rank, and P ∗ij = 0 for some i and j. Let S := {λ/(λ − 1) | λ is a real negative eigenvalue of T ∗} ∪ {0}. Then the following holds:\n• 0 ≤ max(S) < r∗ ≤ 1.\n• For all r ∈ (0, 1] \\ S, P (r) := (rI + (1 − r)T ∗)−1T ∗ is well-defined and\n1 ⊤P (r) = 1⊤, P (r)π∗ = π∗, P ∗ = P (r∗),\nP (r)ij ≥ 0 ∀ i, j ⇐⇒ r ≥ r∗.\nThat is, P (r) is a stochastic matrix if and only if r ≥ r∗.\nThe proof is in Appendix C. This theorem indicates that we can determine r∗ from T ∗ by doing bi-section on (0, 1]. But this approach fails when we replace T ∗ by an estimate T̂ because even P̂ (r∗) might contain negative values. A more practical estimation procedure is the following: for each value of r in a decreasing sequence starting from 1, project P̂ (r) := (rI + (1− r)T̂ )−1T̂ onto the space of stochastic matrices and record the projection distance. Then search in the sequence of projection distances for the first sudden increase1 starting from 1, and take the corresponding value of r and projected P̂ (r) as our estimates.\nAssuming the true r and α0 are known, with the empirical moments being consistent estimators for the true moments and the tensor decomposition method guaranteed to return accurate estimates under small input perturbation, we can conclude that the estimates described above will converge (with high probability) to the true quantities as the sample size N increases. We give sample complexity bound on estimation error in the next section for hidden Markov models."
    }, {
      "heading" : "3.2 Hidden Markov Models",
      "text" : "Let P and π now be defined over the hidden discrete state space of size k and have the same properties as the first-order Markov model. The generative process here is almost identical to (and therefore share the same interpretation with) the one in Section 3.1, except for an extra mapping from the discrete hidden state to a continuous observation space:\n• Draw a state indicator vector hi ∼ Multinomial(P tisi),hi ∈ {0, 1}k. • Draw an observation: xi = Uhi + ǫi, where U ∈ Rm×k denotes a rank-k matrix of\nmean observation vectors for the k hidden states, and the random noise vectors ǫi’s are i.i.d satisfying E[ǫi] = 0 and Var[ǫi] = σ2I .\nNote that a spherical covariance2 is required for the tensor decomposition method to be applicable. The low-order moments that lead to the desired tensor structure are given in the following:\nTheorem 3. Define the expected hidden state transition matrix T := Et[P t] = rP (I−(1−r)P )−1 and let α0 := ∑ i αi, V1 := E[x1], V2 := E[x1x ⊤ 1 ], V3 := E[x ⊗3 1 ], C2 := E[x1x ⊤ 2 ] and C3 := E[x1 ⊗ x2 ⊗ x3]. Then the following holds:\nV1 = Uπ, V2 = Udiag(π)U⊤ + σ2I, V3 = ∑ i πiU ⊗3 i + ∑3 d=1 V1 ⊗d (σ2I),\nM2 := V2 − σ2I = Udiag(π)U⊤, M3 := V3 − ∑3 d=1 V1 ⊗d (σ2I) = ∑ i πiU ⊗3 i ,\nC2 = 1 α0+1 UTdiag(π)(UT )⊤ + α0 α0+1 V1V ⊤ 1 ,\nC3 = 2\n(α0+2)(α0+1)\n∑ i πi(UT ) ⊗3 i + α0 α0+2 ∑3 d=1 V1 ⊗d C2 − 2α20 (α0+2)(α0+1) V ⊗31\nM ′2 := (α0 + 1)C2 − α0V1V ⊤1 = UTdiag(π)(UT )⊤, M ′3 := (α0+2)(α0+1) 2 C3 − (α0+1)α0 2 ∑3 d=1 V1 ⊗d C2 + α20V ⊗31 = ∑ i πi(UT ) ⊗3 i .\n1Intuitively the jump should be easier to locate as P gets sparser, but we do not have a formal result. 2We may allow different covariances σ2j I for different hidden states. See Section 3.2 of [2] for details.\nAlgorithm 1 Tensor decomposition method for learning HMM from non-sequence data input N sets of non-sequence data points, the success probability r, the Dirichlet parameter α0, the\nnumber of hidden states k, and numbers of iterations L and N. output Estimates π̂, P̃ and Ũ possibly under permutation of state labels.\n1: Compute empirical averages V̂1, V̂2, V̂3, Ĉ2, Ĉ3, and σ̂2 := λmin(V̂2 − V̂1V̂1 ⊤ ). 2: Compute M̂2, M̂3, M̂ ′2, M̂ ′ 3 3: Run Algorithm A.1 (Appendix A) on M̂2 and M̂3 with the number of hidden states k to obtain a symmetric tensor T̂ ∈ Rk×k×k and a whitening transformation Ŵ ∈ Rm×k. 4: Run Algorithm A.2 (Appendix A) k times each with numbers of iterations L and N, the input tensor in the first run set to T̂ and in each subsequent run set to the deflated tensor returned by the previous run, resulting in k pairs of eigenvalue/eigenvector {(λ̂i, v̂i)}ki=1. 5: Repeat Steps 4 and 5 on M̂ ′2 and M̂ ′ 3 to obtain T̂ ′, Ŵ ′ and {(λ̂′i, v̂′i)}ki=1. 6: Match {(λ̂i, v̂i)}ki=1 with {(λ̂′i, v̂′i)}ki=1 by sorting {λ̂i}ki=1 and {λ̂′i}ki=1. 7: Obtain estimates of HMM parameters:\nÛT := (Ŵ ′)†V̂ ′Λ̂′, Û := (Ŵ⊤)†V̂ Λ̂,\nP̂ := (rÛ + (1 − r)ÛT )†ÛT , π̂ := [λ̂′1 −2 · · · λ̂′k −2 ]⊤,\nwhere V̂ := [v̂1 · · · v̂k], Λ̂ := diag([λ̂1 · · · λ̂k]⊤); V̂ ′ and Λ̂′ are defined in the same way. 8: (Optional) Project π̂ onto the simplex and P̂ onto the space of stochastic matrices.\nThe proof is in Appendix B.2. This theorem suggests that, unlike first-order Markov models, HMMs require two applications of the tensor decomposition methods, one on M2 and M3 for extracting the mean observation vectors U , and the other on M ′2 and M ′ 3 for extracting the matrix product UT . Another issue is that the estimates for M2 and M3 require an estimate for the noise variance σ2, which is not directly observable. Nevertheless, since M2 and M3 are in the form of low-order moments of spherical Gaussian mixtures, we may use the existing result (Theorem 3.2, [2]) to obtain an estimate σ̂2 = λmin(V̂2 − V̂1V̂ ⊤1 ). The situation regarding permutations of the estimates is also different here. First note that P = (rU+(1−r)UT )†UT, which implies that permuting the columns of U and the columns of UT in the same manner has the effect of permuting both the rows and the columns of P , essentially re-labeling the hidden states. Hence we can only expect to recover P up to some simultaneous row and column permutation. By the assumption that πi’s are all different, we can sort the two estimates π̂ and π̂′ to match the columns of Û and ÛT , and obtain P̂ if r is known. When r is unknown, a similar heuristics to the one for first-order Markov models can be used to estimate r, based on the fact that P = (rU + (1 − r)UT )†UT = (rI + (1 − r)T )−1T , suggesting that Theorem 2 remains true when expressing P by U and UT .\nAlgorithm 1 gives the complete procedure for learning HMM from non-sequence data. Combining the perturbation bounds of the tensor decomposition method (Appendix A), the whitening procedure (Appendix D.1) and the matrix pseudoinverse [10], and concentration bounds on empirical moments (Appendix D.3), we provide a sample complexity analysis:\nTheorem 4. Suppose the numbers of iterations N and L for Algorithm A.2 satisfy the conditions in Theorem A.1 (Appendix A), and the number of hidden states k, the success probability r, and the Dirichlet parameter α0 are all given. For any η ∈ (0, 1) and ǫ > 0, if the number of sets N satisfies\nN ≥ 12max(k 2,m)m3ν3(α0 + 2) 2(α0 + 1) 2\nη ·\nmax\n( 225000\nδ2min ,\n4600\nmin(σk(M ′2), σk(M2)) 2 ,\n42000c2σ1(UT ) 2 max(σ1(UT ), σ1(U), 1) 2 ǫ2σk(rU + (1 − r)UT )4 min(σk(UT ), σk(U), 1)4 ) ,\nwhere c is some constant, ν := max(σ2 + maxi,j(|Uik|2), 1), δmin := mini,j |1/√πj − 1/√πj |, and σi(·) denotes the i-th largest singular value, then the P̂ and Û returned by Algorithm 1 satisfy\nProb(‖P − P̂‖ ≤ ǫ) ≥ 1 − η and Prob ( ‖U − Û‖ ≤ ǫσk(rU + (1 − r)UT ) 2\n6σ1(UT )\n) ≥ 1 − η,\nwhere P and U may undergo label permutation.\nThe proof is in Appendix E. In this result, the sample size N exhibits a fairly high-order polynomial dependency on m, k, ǫ−1 and scales with 1/η linearly instead of logarithmically, as is common in sample complexity results on spectral learning. This is because we do not impose any constraints on the observation model and simply use the Markov inequality for bounding the deviation in the empirical moments. If we make stronger assumptions such as boundedness or sub-Gaussianity, it is possible to use stronger, exponential tail bounds to obtain better sample complexity. Also worth noting is that δ−2min acts as a threshold. As shown in our proof, as long as the operator norm of the tensor perturbation is sufficiently smaller than δmin, which measures the gaps between different πi’s, we can correctly match the two sets of estimated tensor eigenvalues. Lastly, the lower bound of N , as one would expect, depends on conditions of the matrices being estimated as reflected in the various ratios of singular values. An interesting quantity missing from the sample analysis is the size of each set n. To simplify the analysis we essentially assume n = 3, but understanding how n might affect the sample complexity may have a critical impact in practice: when collecting more data, should we collect more sets or larger sets? What is the trade-off between them? This is an interesting direction for future work."
    }, {
      "heading" : "4 Simulation",
      "text" : "Our HMM has m = 40 and k = 5 with Gaussian noise σ2 = 2. The mean vectors U were sampled from independent univariate standard normal and then normalized to lie on the unit sphere. The transition matrix P contains one zero entry. For the generative process, we set α0 = 1, r = 0.3, n = 1000, and N ∈ 1000{20, 21, . . . , 210}. The numbers of iterations for Algorithm A.2 were N = 200 and L = 1000. Figure 2(a) plots the relative matrix estimation error (in spectral norm) against the sample size N for P , U , and UT obtained by Algorithm 1 given the true r. It is clear that U is the easiest to learn, followed by UT , and P is the most difficult, and that all three errors converge to a very small value for sufficiently large N . Note that in Theorem 4 the bounds for P and U are different. With the model used here, the extra multiplicative factor in the bound for U is less than 0.007, suggesting that U is indeed easier to estimate than P . Figure 2(b) demonstrates the heuristics for determining r, showing projection distances (in logarithm) versus r. As N increases, the take-off point gets closer to the true r = 0.3. The large peak indicates a pole (the set S in Theorem 2)."
    }, {
      "heading" : "5 Conclusions",
      "text" : "We have demonstrated that under reasonable assumptions, tensor decomposition methods can provably learn first-order Markov models and hidden Markov models from non-sequence data. We believe this is the first formal guarantee on learning dynamic models in a non-sequential setting. There are several ways to extend our results. No matter what distribution generates the random time steps, tensor decomposition methods can always learn the expected transition probability matrix T . Depending on the application, it might be better to use some other distribution for the missing time. The proposed algorithm can be modified to learn discrete HMMs under a similar generative process. Finally, applying the proposed methods to real data should be the most interesting future direction."
    } ],
    "references" : [ {
      "title" : "A spectral algorithm for latent dirichlet allocation",
      "author" : [ "A. Anandkumar", "D.P. Foster", "D. Hsu", "S.M. Kakade", "Y.-K. Liu" ],
      "venue" : "arXiv preprint arXiv:1204.6703v4,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2013
    }, {
      "title" : "Tensor decompositions for learning latent variable models",
      "author" : [ "A. Anandkumar", "R. Ge", "D. Hsu", "S.M. Kakade", "M. Telgarsky" ],
      "venue" : "arXiv preprint arXiv:1210.7559v2,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2012
    }, {
      "title" : "A method of moments for mixture models and hidden Markov models",
      "author" : [ "A. Anandkumar", "D. Hsu", "S.M. Kakade" ],
      "venue" : "arXiv preprint arXiv:1203.0683,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2012
    }, {
      "title" : "A practical algorithm for topic modeling with provable guarantees",
      "author" : [ "S. Arora", "R. Ge", "Y. Halpern", "D. Mimno", "A. Moitra", "D. Sontag", "Y. Wu", "M. Zhu" ],
      "venue" : "arXiv preprint arXiv:1212.4777,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2012
    }, {
      "title" : "Learning mixtures of spherical gaussians: moment methods and spectral decompositions",
      "author" : [ "D. Hsu", "S.M. Kakade" ],
      "venue" : "In Proceedings of the 4th conference on Innovations in Theoretical Computer Science,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2013
    }, {
      "title" : "Learning linear dynamical systems without sequence information",
      "author" : [ "T.-K. Huang", "J. Schneider" ],
      "venue" : "In Proceedings of the 26th International Conference on Machine Learning,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2009
    }, {
      "title" : "Learning auto-regressive models from sequence and nonsequence data",
      "author" : [ "T.-K. Huang", "J. Schneider" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2011
    }, {
      "title" : "Learning nonlinear dynamic models from nonsequenced data",
      "author" : [ "T.-K. Huang", "L. Song", "J. Schneider" ],
      "venue" : "In Proceedings of the 13th International Conference on Artificial Intelligence and Statistics,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2010
    }, {
      "title" : "Network inference from co-occurrences",
      "author" : [ "M.G. Rabbat", "M.A. Figueiredo", "R.D. Nowak" ],
      "venue" : "Information Theory, IEEE Transactions on,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2008
    }, {
      "title" : "On the perturbation of pseudo-inverses, projections and linear least squares problems",
      "author" : [ "G. Stewart" ],
      "venue" : "SIAM review,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1977
    }, {
      "title" : "Learning bigrams from unigrams",
      "author" : [ "X. Zhu", "A.B. Goldberg", "M. Rabbat", "R. Nowak" ],
      "venue" : "In the Proceedings of 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technology,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Under that framework, we identify reasonable assumptions on the generative process of non-sequence data, and propose learning algorithms based on the tensor decomposition method [2] to provably recover firstorder Markov models and hidden Markov models.",
      "startOffset" : 178,
      "endOffset" : 181
    }, {
      "referenceID" : 6,
      "context" : "As pointed out in [7, 8], this situation may appear in the modeling of celestial objects such as galaxies or chronic diseases such as Alzheimer’s, because observations are usually taken from different trajectories (galaxies or patients) at unknown, arbitrary times.",
      "startOffset" : 18,
      "endOffset" : 24
    }, {
      "referenceID" : 7,
      "context" : "As pointed out in [7, 8], this situation may appear in the modeling of celestial objects such as galaxies or chronic diseases such as Alzheimer’s, because observations are usually taken from different trajectories (galaxies or patients) at unknown, arbitrary times.",
      "startOffset" : 18,
      "endOffset" : 24
    }, {
      "referenceID" : 8,
      "context" : "[9] noted that in certain network inference problems, the only available data are sets of nodes co-occurring in random walks on the network without the order in which they were visited, and the goal is to reconstruct the network structure from such co-occurrence data.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : ", [9, 11, 6, 8], do not shed much light on this issue because they are mostly based on Expectation-Maximization (EM), which require non-convex optimization.",
      "startOffset" : 2,
      "endOffset" : 15
    }, {
      "referenceID" : 10,
      "context" : ", [9, 11, 6, 8], do not shed much light on this issue because they are mostly based on Expectation-Maximization (EM), which require non-convex optimization.",
      "startOffset" : 2,
      "endOffset" : 15
    }, {
      "referenceID" : 5,
      "context" : ", [9, 11, 6, 8], do not shed much light on this issue because they are mostly based on Expectation-Maximization (EM), which require non-convex optimization.",
      "startOffset" : 2,
      "endOffset" : 15
    }, {
      "referenceID" : 7,
      "context" : ", [9, 11, 6, 8], do not shed much light on this issue because they are mostly based on Expectation-Maximization (EM), which require non-convex optimization.",
      "startOffset" : 2,
      "endOffset" : 15
    }, {
      "referenceID" : 4,
      "context" : "Taking advantage of this property, an emerging area of research in machine learning has recently developed MoM-based learning algorithms with formal guarantees for some widely used latent variable models, such as Gaussian mixture models[5], Hidden Markov models [3], Latent Dirichlet Allocation [1, 4], etc.",
      "startOffset" : 236,
      "endOffset" : 239
    }, {
      "referenceID" : 2,
      "context" : "Taking advantage of this property, an emerging area of research in machine learning has recently developed MoM-based learning algorithms with formal guarantees for some widely used latent variable models, such as Gaussian mixture models[5], Hidden Markov models [3], Latent Dirichlet Allocation [1, 4], etc.",
      "startOffset" : 262,
      "endOffset" : 265
    }, {
      "referenceID" : 0,
      "context" : "Taking advantage of this property, an emerging area of research in machine learning has recently developed MoM-based learning algorithms with formal guarantees for some widely used latent variable models, such as Gaussian mixture models[5], Hidden Markov models [3], Latent Dirichlet Allocation [1, 4], etc.",
      "startOffset" : 295,
      "endOffset" : 301
    }, {
      "referenceID" : 3,
      "context" : "Taking advantage of this property, an emerging area of research in machine learning has recently developed MoM-based learning algorithms with formal guarantees for some widely used latent variable models, such as Gaussian mixture models[5], Hidden Markov models [3], Latent Dirichlet Allocation [1, 4], etc.",
      "startOffset" : 295,
      "endOffset" : 301
    }, {
      "referenceID" : 1,
      "context" : "In this work we demonstrate that under the MoM and spectral learning framework, there are reasonable assumptions on the generative process of non-sequence data, under which the tensor decomposition method [2], a recent advancement in spectral learning, can provably recover the parameters of first-order Markov models and hidden Markov models.",
      "startOffset" : 205,
      "endOffset" : 208
    }, {
      "referenceID" : 1,
      "context" : "Section 2 briefly reviews the essentials of the tensor decomposition framework [2]; Section 3 details our assumptions on non-sequence data, tensor-decomposition based learning algorithms, and theoretical guarantees; Section 4 reports some simulation results confirming our theoretical findings, followed by conclusions in Section 5.",
      "startOffset" : 79,
      "endOffset" : 82
    }, {
      "referenceID" : 1,
      "context" : "We mainly follow the exposition in [2], starting with some preliminaries and notations.",
      "startOffset" : 35,
      "endOffset" : 38
    }, {
      "referenceID" : 0,
      "context" : "Interestingly, these low-order moments have a very similar structure to those in Latent Dirichlet Allocation [1].",
      "startOffset" : 109,
      "endOffset" : 112
    }, {
      "referenceID" : 1,
      "context" : "2, [2]) to obtain an estimate σ̂(2) = λmin(V̂2 − V̂1V̂ ⊤ 1 ).",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 9,
      "context" : "1) and the matrix pseudoinverse [10], and concentration bounds on empirical moments (Appendix D.",
      "startOffset" : 32,
      "endOffset" : 36
    } ],
    "year" : 2013,
    "abstractText" : "Learning dynamic models from observed data has been a central issue in many scientific studies or engineering tasks. The usual setting is that data are collected sequentially from trajectories of some dynamical system operation. In quite a few modern scientific modeling tasks, however, it turns out that reliable sequential data are rather difficult to gather, whereas out-of-order snapshots are much easier to obtain. Examples include the modeling of galaxies, chronic diseases such Alzheimer’s, or certain biological processes. Existing methods for learning dynamic model from non-sequence data are mostly based on Expectation-Maximization, which involves non-convex optimization and is thus hard to analyze. Inspired by recent advances in spectral learning methods, we propose to study this problem from a different perspective: moment matching and spectral decomposition. Under that framework, we identify reasonable assumptions on the generative process of non-sequence data, and propose learning algorithms based on the tensor decomposition method [2] to provably recover firstorder Markov models and hidden Markov models. To the best of our knowledge, this is the first formal guarantee on learning from non-sequence data. Preliminary simulation results confirm our theoretical findings.",
    "creator" : null
  }
}