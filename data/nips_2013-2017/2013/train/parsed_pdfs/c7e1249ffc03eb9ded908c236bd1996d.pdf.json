{
  "name" : "c7e1249ffc03eb9ded908c236bd1996d.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Generalized Random Utility Models with Multiple Types",
    "authors" : [ "Hossein Azari Soufiani", "Hansheng Diao", "Zhenyu Lai", "David C. Parkes" ],
    "emails" : [ "azari@fas.harvard.edu", "diao@fas.harvard.edu", "zlai@fas.harvard.edu", "parkes@eecs.harvard.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "We propose a model for demand estimation in multi-agent, differentiated product settings and present an estimation algorithm that uses reversible jump MCMC techniques to classify agents’ types. Our model extends the popular setup in Berry, Levinsohn and Pakes (1995) to allow for the data-driven classification of agents’ types using agent-level data. We focus on applications involving data on agents’ ranking over alternatives, and present theoretical conditions that establish the identifiability of the model and uni-modality of the likelihood/posterior. Results on both real and simulated data provide support for the scalability of our approach."
    }, {
      "heading" : "1 Introduction",
      "text" : "Random utility models (RUM), which presume agent utility to be composed of a deterministic component and a stochastic unobserved error component, are frequently used to model choices by individuals over alternatives. In this paper, we focus on applications where the data is rankings by individuals over alternatives. Examples from economics include the popular random coefficients logit model [7] where the data may involve a (partial) consumer ranking of products [9]. In a RUM, each agent receives an intrinsic utility that is common across all agents for a given choice of alternative, a pairwise-specific utility that varies with the interaction between agent characteristics and the characteristics of the agent’s chosen alternative, as well as an agent-specific taste shock (noise) for his chosen alternative. These ingredients are used to construct a posterior/likelihood function of specific data moments, such as the fraction of agents of each type that choose each alternative.\nTo estimate preferences across heterogenous agents, one approach as allowed by prior work [20, 24] is to assume a mixture of agents with a finite number of types. We build upon this work by developing an algorithm to endogenously learn the classification of agent types within this mixture. Empirical researchers are increasingly being presented with rich data on the choices made by individuals, and asked to classify these agents into different types [28, 29] and to estimate the preferences of each type [10, 23]. Examples of individual-level data used in economics include household purchases from supermarket-scanner data [1, 21], and patients’ hospital or treatment choices from healthcare data [22].\nThe partitioning of agents into latent, discrete sets (or “types”) allows for the study of the underlying distribution of preferences across a population of heterogeneous agents. For example, preferences may be correlated with an agent characteristic, such as income, and the true classification of each agent’s type, such as his income bracket, may be unobserved. By using a model of demand to estimate the elasticity in behavioral response of each type of agent and by aggregating these responses over the different types of agents, it is possible to simulate the impact of a social or public policy [8], or simulate the counterfactual outcome of changing the options available to agents [19]."
    }, {
      "heading" : "1.1 Our Contributions",
      "text" : "This paper focuses on estimating generalized random utility models (GRUM1) when the observed data is partial orders of agents’ rankings over alternatives and when latent types are present.\nWe build on recent work [3, 4] on estimating GRUMs by allowing for an interaction between agent characteristics and the characteristics of the agent’s chosen alternative.The interaction term helps us to avoid unrealistic substitution patterns due to the independence of irrelevant alternatives [26] by allowing agent utilities to be correlated across alternatives with similar characteristics. For example, this prevents a situation where removing the top choices of both a rich household and a poor household lead them to become equally likely to substitute to the same alternative choice. Our model also allows the marginal utilities associated with the characteristics of alternatives to vary across agent types.\nTo classify agents’ types and estimate the parameters associated with each type, we propose an algorithm involving a novel application of reversible jump Markov Chain Monte Carlo (RJMCMC) techniques. RJMCMC can be used for model selection and learning a posterior on the number of types in a mixture model [31]. Here, we use RJMCMC to cluster agents into different types, where each type exhibits demand for alternatives based on different preferences; i.e., different interaction terms between agent and alternative characteristics.\nWe apply the approach to a real-world dataset involving consumers’ preference rankings and also conduct experiments on synthetic data to perform coverage analysis of RJMCMC. The results show that our method is scalable, and that the clustering of types provides a better fit to real world data. The proposed learning algorithm is based on Bayesian methods to find posteriors on the parameters. This differentiates us from previous estimation approaches in econometrics rely on techniques based on the generalized method of moments.2\nThe main theoretical contribution establishes identifiability of mixture models over data consisting of partial orders. Previous theoretical results have established identifiability for data consisting of vectors of real numbers [2, 18], but not for data consisting of partial orders. We establish conditions under which the GRUM likelihood function is uni-modal for the case of observable types. We do not provide results on the log concavity of the general likelihood problem with unknown types and leave it for future studies."
    }, {
      "heading" : "1.2 Related work",
      "text" : "Prior work in econometrics has focused on developing models that use data aggregated across types of agents, such as at the level of a geographic market, and that allow heterogeneity by using random coefficients on either agents’ preference parameters [7, 9] or on a set of dummy variables that define types of agents [6, 27], or by imposing additional structure on the covariance matrix of idiosyncratic taste shocks [16]. In practice, this approach typically relies on restrictive functional assumptions about the distribution of consumer taste shocks that enter the RUM in order to reduce computational\n1Defined in [4] as a RUM with a generalized linear model for the regression of the mean parameters on the interaction of characteristics data as in Figure 1\n2There are alternative methods to RJMCMC, such as the saturation method [13]. However, the memory required to keep track of former sampled memberships in the saturation method quickly becomes infeasible given the combinatorial nature of our problem.\nburden. For example, the logit model [26] assumes i.i.d. draws from a Type I extreme value distribution. This may lead to biased estimates, in particular when the number of alternatives grow large [5].\nPrevious work on clustering ranking data for variations of the Placket-Luce (PL) model [28, 29] has been restricted to settings without agent and alternative characteristics. Morover, Gormley et al. [28] and Chu et al. [14] performed clustering for RUMs with normal distributions, but this was limited to pairwise comparisons. Inference of GRUMs for partial ranks involved the computational hardness addressed in [3]. In mixture models, assuming an arbitrary number of types can lead to biased results, and reduces the statistical efficiency of the estimators [15].\nTo the best of our knowledge, we are the first to study the identifiability and inference of GRUMs with multiple types. Inference for GRUMs has been generalized in [4], However, Azari et al. [4] do not consider existence of multiple types. Our method applies to data involving individual-level observations, and partial orders with more than two alternatives. The inference method establishes a posterior on the number of types, resolving the common issue of how the researcher should select the number of types."
    }, {
      "heading" : "2 Model",
      "text" : "Suppose we have N agents and M alternatives {c1, .., cM}, and there are S types (subgroups) of agents and s(n) is agent n’s type.\nAgent characteristics are observed and defined as anN×K matrixX , and alternative characteristics are observed and defined as an L × M matrix Z, where K and L are the number of agent and alternative characteristics respectively.\nLet unm be agent n’s perceived utility for alternative m, and let W s(n) be a K × L real matrix that models the linear relation between the attributes of alternatives and the attributes of agents. We have,\nunm = δm + ~xnW s(n)(~zm) T + nm, (1)\nwhere ~xn is the nth row of the matrix X and ~zm is the mth column of the matrix Z. In words, agent n’s utility for alternative m consists of the following three parts:\n1. δm:gs The intrinsic utility of alternative m, which is the same across all agents;\n2. ~xnW s(n)(~zm)T : The agent-specific utility, which is unique to all agents of type s(n), and where W s(n) has at least one nonzero element;\n3. nm: The random noise (agent-specific taste shock), which is generated independently across agents and alternatives.\nThe number of parameters for each type is P = KL+M .\nSee Figure 2 for an illustration of the model. In order to write the model as a linear regression, we define matrix A(n)M×P , such that A (n) KL+m,m = 1 for 1 ≤ m ≤M and A (n) KL+m,m′ = 0 for m 6= m′ and A(n)(k−1)L+l,m = ~xn(k)~zm(l) for 1 ≤ l ≤ L and 1 ≤ k ≤ K. We also need to shuffle the parameters for all types into a P × S matrix Ψ, such that ΨKL+m,s = δ and Ψ(k−1)L+l,s = W skl for 1 ≤ k ≤ K and 1 ≤ l ≤ L. We adopt B (n) S×1 to indicate the type of agent n, with B (n) s(n),1 = 1 and B (n) s,1 = 0 for all s 6= s(n). We also define an M ×1 matrix, U (n), as U (n) m,1 = unm. We can now rewrite (1) as:\nU (n) = A(n)ΨB(n) + (2)\nSuppose that an agent has type s with probability γs. Given this, the random utility model can be written as, Pr(U (n)|X(n), Z,Ψ,Γ) = ∑S s=1 γs Pr(U\n(n)|X(n), Z,Ψs), where Ψs is the sth column of the matrix Ψ. An agent ranks the alternatives according to her perceived utilities for the alternatives. Define rank order πn as a permutation (πn(1), . . . , πn(m)) of {1, . . . ,M}. πn represents the full ranking [cπi(1) i cπi(2) i · · · i cπi(m)] of the alternatives {c1, .., cM}. That is, for agent n, cm1 n cm2 if and only if unm1 > unm2 (In this model, situations with tied perceived utilities have zero probability measure).\nThe model for observed data π(n), can be written as: Pr(π(n)|X(n), Z,Γ,Ψ) = ∫ π(n)=order(U(n)) Pr(U (n)|X(n), Z,Ψ,Γ) = S∑ s=1 γs Pr(π (n)|X(n), Z,Ψs)\nNote that X(n) and Z are observed characteristics, while Γ and Ψ are unknown parameters. π = order(U) is the ranking implied by U, and π(i) is the ith largest utility in U . D = {π1, .., πN} denotes the collection of all data for different agents. We have that\nPr(D|X,Z,Ψ,Γ) = N∏ n=1 Pr(π(n)|X(n), Z,Ψ,Γ)"
    }, {
      "heading" : "3 Strict Log-concavity and Identifiability",
      "text" : "In this section, we establish conditions for identifiability of the types and parameters for the model. Identifiability is a necessary property in order for researchers to be able to infer economicallyrelevant parameters from an econometric model. Establishing identifiability in a model with multiple types and ranking data requires a different approach from classical identifiability results for mixture models [2, 18, e.g.].\nMoreover, we establish conditions for uni-modality of the likelihood for the parameters Γ and Ψ, when the types are observed. Although our main focus is on data with unobservable types, establishing the conditions for unimodality conditioned on known types remains an essential step because of the sampling and optimization aspects of RJMCMC. We sample from the parameters conditional on the algorithm’s specification of types.\nThe uni-modality result establishes that the sampling approach is exploring a uni-modal distribution conditional on its specified types. Despite adopting a Bayesian point of view in presenting the model, we adopt a uniform prior on the parameter set, and only impose nontrivial priors on the number of types in order to obtain some regularization. Given this, we present the theory with regards to the likelihood function from the data rather than the posterior on parameters."
    }, {
      "heading" : "3.1 Strict Log-concavity of the Likelihood Function",
      "text" : "For agent n, we define a set Gn of function gn’s whose positivity is equivalent to giving an order πn. More precisely, we define gnm(~ψ,~ ) = [µnπn(m) + nπn(m)] − [µnπn(m+1) + nπn(m+1)] for m = 1, ..,M − 1 where µnj = δj + ∑ k,l xn(k)W s(n) kl zj(l) for 1 ≤ j ≤ M . Here, ~ψ is a vector of KL + M variables consisting of all δj’s and Wkl’s. We have, L(~ψ, πn) = L(~ψ,Gn) = Pr(gn1 (\n~ψ,~ ) ≥ 0, ..., gnM−1(~ψ,~ ) ≥ 0). This is because gnm(~ψ,~ ) ≥ 0 is equivalent to saying alternative πn(m) is preferred to alternative πn(m+ 1) in the RUM sense.\nThen using the result in [3] and [30], L(~ψ) = L(~ψ, π) is logarithmic concave in the sense that L(λ~ψ + (1 − λ) ~ψ′) ≥ L(ψ)λL(ψ′)1−λ for any 0 < λ < 1 and any two vectors ~ψ, ~ψ′ ∈ RLK+M . The detailed statement and proof of this result are contained in the Appendix. Let’s consider all n agents together. We study the function, l(Ψ, D) = ∑N n=1 logPr(π\nn|~ψs(n)). By log-concavity of L(~ψ, π) and using the fact that sum of concave functions is concave, we know that l(Ψ, D) is concave in Ψ, viewed as a vector in RSKL+M . To show uni-modality, we need to prove that this\nconcave function has a unique maximum. Namely, we need to be able to establish the conditions for when the equality holds. If our data is subject to some mild condition, which implies boundedness of the parameter set that maximizes l(Ψ, D), Theorem 1 bellow tells us when the equality holds. This condition has been explained in [3] as condition (1).\nBefore stating the main result, we define the following auxiliary (M − 1)N ′ × (SKL + M − 1) matrix Ã = ÃN ′ (Here, let N ′ ≤ N be a positive number that we will specify later.) such that,\nÃ(M−1)(n−1)+m,(s−1)KL+(K−1)l+k is equal to xn(k)(zm(l) − zM (l))if s = s(n) and is equal to 0 if s 6= s(n), for all 1 ≤ n ≤ N ′, 1 ≤ m ≤ M − 1, 1 ≤ s ≤ S, 1 ≤ k ≤ K, and 1 ≤ l ≤ L. Also, Ã(M−1)(n−1)+m,SKL+m′ is equal to 1 if m = m′ and is equal to 0 if m 6= m′, for all 1 ≤ m,m′ ≤M − 1 and 1 ≤ n ≤ N ′. Theorem 1. Suppose there is an N ′ ≤ N such that rank ÃN ′ = SKL + M − 1. Then l(Ψ) = l(Ψ, D) is strictly concave up to δ-shift, in the sense that,\nl(λΨ + (1− λ)Ψ′) ≥ λl(Ψ) + (1− λ)l(Ψ′), (3)\nfor any 0 < λ < 1 and any Ψ,Ψ′ ∈ RSKL+M , and the equality holds if and only if there exists c ∈ R, such that: {\nδm = δ ′ m + c for all 1 ≤ m ≤M\nW skl = W ′s kl for all s, k, l\nThe proof of this theorem is in the appendix. Remark 1. We remark that the strictness “up to δ-shift” is natural. A δ-shift results in a shift in the intrinsic utilities of all the products, which does not change the utility difference between products. So such a shift does not affect our outcome. In practice, we may set one of the δ’s to be 0 and then our algorithm will converge to a single maximum. Remark 2. It’s easy to see that N ′ must be larger than or equal to 1 + SKLM−1 . The reason we introduce N ′ is to avoid cumbersome calculations involving N ."
    }, {
      "heading" : "3.2 Identifiability of the Model",
      "text" : "In this section, we show that, for the case of unobserved types, our model is identifiable for a certain class of cdfs for the noise in random utility models. Let’s first specify this class of “nice” cdfs: Definition 1. Let φ(x) be a smooth pdf defined on R or [0,∞), and let Φ(x) be the associated cdf. For each i ≥ 1, we write φ(i)(x) for the i-th derivative of φ(x). Let gi(x) = φ (i+1)(x) φ(i)(x)\n. The function Φ is called nice if it satisfies one of the following two mutually exclusive conditions:\n(a) φ(x) is defined on R. For any x1, x2 ∈ R, the sequence gi(x1)gi(x2) converges to some value in R (as i→∞) only if either x1 = x2; or x1 = −x2 and gi(x1)gi(x2) → −1 as i→∞.\n(b) φ(x) is defined on [0,∞). For any x1, x2 ≥ 0, the ratio φ (i)(x1) φ(i)(x2)\nis independent of i for i sufficiently large. Moreover, we require that φ(x1) = φ(x2) if and only if x1 = x2.\nThis class of nice functions contains normal distributions and exponential distributions. A proof of this fact is included in the appendix.\nIdentifiability is formalized as follows: Let C = {{γs}Ss=1 |S ∈ Z>0, γi ∈ R>0, ∑S s=1 γs = 1}. Suppose, for two sequences {γs}Ss=1 and {γ′s}S ′ s=1, we have:\nS∑ s=1 γs Pr(π|X(n), Z,Ψ) = S′∑ s=1 γ′s Pr(π|X(n), Z,Ψ′) (4)\nfor all possible orders π of M products, and for all agents n. Then, we must have S = S′ and (up to a permutation of indices {1, · · · , S}) γs = γ′s and Ψ = Ψ′ (up to δ-shift).\nFor now, let’s fix the number of agent characteristics, K. One observation is that the number xn(k), for any characteristic k, reflects certain characteristics of agent n. Varying the agent n, this amount xn(k) is in a bounded interval in R. Suppose the collection of data D is sufficiently large. Based on this, assuming that N can be be arbitrarily large, we can assume that the xn(k)’s form a dense subset in a closed interval Ik ⊂ R. Hence, (4) should hold for any X ∈ Ik, leading to the following theorem: Theorem 2. Define an (M−1)×L matrix Z̃ by setting Z̃m,l = zm(l)−zM (l). Suppose the matrix"
    }, {
      "heading" : "Z̃ has rank L, and suppose,",
      "text" : "S∑ s=1 γs Pr(π|X,Z,Ψ) = S′∑ s=1 γ′s Pr(π|X,Z,Ψ′), (5)\nfor all x(k) ∈ Ik and all possible orders π of M products. Here, the probability measure is associated with a nice cdf. Then we must have S = S′ and (up to a permutation of indices {1, · · · , S}), γs = γ ′ s and Ψ = Ψ ′ (up to δ-shift).\nThe proof of this theorem is provided in the appendix. Here, we illustrate the idea for the simple case, with two alternatives (m = 2) and no agent or alternative characteristics (K = L = 1). Equation (5) is merely a single identity. Unwrapping the definition, we obtain:\nS∑ s=1 γs Pr( 1− 2 > δ1−δ2+xW s(z1−z2)) = S′∑ s=1 γ′s Pr( 1− 2 > δ′1−δ′2+xW ′s(z1−z2)). (6)\nWithout loss of generality, we may assume z1 = 1, z2 = 0, and δ2 = 0. We may further assume that the interval I = I1 contains 0. (Otherwise, we just need to shift I and δ accordingly.) Given this, the problem reduces to the following lemma: Lemma 1. Let Φ(x) be a nice cdf. Suppose,\nS∑ s=1 γsΦ(δ + xW s) = S′∑ s=1 γ′sΦ(δ ′ + xW ′s), (7)\nfor all x in a closed interval I containing 0. Then we must have S = S′, δ = δ′ and (up to a permutation of {1, · · · , S}) γs = γs, W s = W ′s.\nThe proof of this lemma is in the appendix. By applying this to (6), we can show identifiablity for the simple case of m = 2 and K = L = 1.\nTheorem 2 guarantees identifiability in the limit case that we observe agents with characteristics that are dense in an interval. Beyond the theoretical guarantee, we would in practice expect (6) to have a unique solution with a enough agents with different characteristics. Lemma 1 itself is a new identifiability result for scalar observations from a set of truncated distributions."
    }, {
      "heading" : "4 RJMCMC for Parameter Estimation",
      "text" : "We are using a uniform prior for the parameter space and regularize the number of types with a geometric prior. We use a Gibbs sampler, as detailed in the appendix (supplementary material Algorithm (1)) to sample from the posterior. In each of T iterations, we sample utilities un for each agent, matrix ψs for each type, and set of assignments of agents to alternatives Sn. The utility of each agent for each alternative conditioned on the data and other parameters is sampled from a truncated Exponential Family (e.g. Normal) distribution. In order to sample agent i’s utility for alternative j (uij), we set thresholds for lower and upper truncation based on agent i’s former samples of utility for the two alternatives that are ranked one below and one above alternative j, respectively.\nWe use reversible-jump MCMC [17] for sampling from conditional distributions of the assignment function (see Algorithm 1). We consider three possible moves for sampling from the assignment function S(n):\n(1) Increasing the number of types by one, through moving a random agent to a new type of its own. The acceptance ratio for this move is: Prsplit = min{1, Pr(S+1)Pr(M (t+1)|D)\nPr(S) Pr(M(t)|D) . 1 S+1 1 S . p+1p−1 . 1 p(α) .J(t)→(t+1)}, where M (t) = {u, ψ,B, S, π}(t),\nand J(t)→(t+1) = 2P is the Jacobian of the transformation from the previous state to the proposed state and Pr(S) is the prior (regularizer) for the number of types.\n(2) Decrease the number of types by one, through merging two random types. The acceptance ratio for the merge move is: Prmerge = min{1, Pr(S−1) Pr(M (t+1)|D) Pr(S) Pr(M(t)|D) . 1 S−1 1 S .p−1p+1 .J(t)→(t+1)}.\n(3) We do not change the number of types, and consider moving one random agent from one type to another. This case reduces to a standard Metropolis-Hastings, where because of the normal symmetric proposal distribution, the proposal is accepted with probability: Prmh = min{1, Pr(M (t+1)|D) Pr(M(t)|D) }.\nAlgorithm 1 RJMCMC to update S(t+1)(n) from S(t)(n)\nSet p−1, p0, p+1, Find S: number of distinct types in S(t)(n) Propose move ν from {−1, 0,+1} with probabilities p−1, p0, p+1, respectively. case ν = +1:\nSelect random type Ms and agent n ∈ Ms uniformly and Assign n to module Ms1 and remainder to Ms2 and Draw vector α ∼ N (0, 1) and Propose ψs1 = ψs − α and ψs2 = ψs + α and Compute proposal {un, πn}(t+1) Accept S(t+1)(Ms1) = S + 1, S(t+1)(Ms2) = s with Prsplit from update S = S + 1 case ν = −1: Select two random types Ms1 and Ms2 and Merge into one type Ms and Propose ψs = (ψs1 + ψs1)/2 and Compute proposed {un, πn}(i+1) Accept S(t+1)(n) = s1 for ∀n s.t. S(t)(n) = s2 with Prmerge update S = S − 1 case ν = 0: Select two random types Ms1 and Ms2 and Move a random agent n from Ms1 to Ms2 and Compute proposed {u(n), π(n)}(t+1) Accept S(t+1)(n) = s2 with probability Prmh end switch"
    }, {
      "heading" : "5 Experimental Study",
      "text" : "We evaluate the performance of the algorithm on synthetic data, and for a real world data set in which we observe agents’ characteristics and their orderings on alternatives. For the synthetic data, we generate data with different numbers of types and perform RJMCMC in order to estimate the parameters and number of types. The algorithm is implemented in MATLAB and scales linearly in the number of samples and agents. It takes on average 60 ± 5 seconds to generate 50 samples for N = 200, M = 10, K = 4 and L = 3 on an i5 2.70GHz Intel(R).\nCoverage Analysis for the number of types S for Synthetic Data: In this experiment, the data is generated from a randomly chosen number of clusters S for N = 200, K = 3, L = 3 and M = 10 and the posterior on S is estimated using RJMCMC. The prior is chosen to be Pr(S) ∝ exp(−3SKL). We consider a noisy regime by generating data from noise level of σ = 1, where all the characteristics (X ,Z) are generated from N (0, 1). We repeat the experiment 100 times. Given this, we estimate 60%, 90% and 95% confidence intervals for the number of types from the posterior samples. We also estimate the coverage percentage, which is defined to be the percentage of samples which include the true number of types in the interval. The simulations show 61%, 73%, 88%, 93% for the intervals 60%, 75%, 90%, 95% respectively, which indicates that the method is providing reliable intervals for the number of types.\nPerformance for Synthetic Data: We generate data randomly from a model with between 1 and 4 types. N is set to 200, and M is set to 10 for K = 4 and L = 3. We draw 10, 000 samples from the stationary posterior distribution. The prior for S has chosen to be exp(−αSKL) where α is uniformly chosen in (0, 10). We repeat the experiment 5 times. Table 1 shows that the algorithm successfully provides larger log posterior when the number of types is the number of true types.\nClustering Performance for Real World Data: We have tested our algorithm on a sushi dataset, where 5, 000 users provide rankings on M = 10 different kinds of sushi [25]. We fit the multi-type\nGRUM for different number of types, on 100 randomly chosen subsets of the sushi data with size N = 200 , using the same prior we used in synthetic case and provide the performance on the Sushi data in Table 1. It can be seen that GRUM with 3 types has significantly better performance in terms of log posterior (with the prior that we chose, log posterior can be seen as log likelihood penalized for number of parameters) than GRUM with one, two or four types. We have taken non-categorical features as K = 4 feature for agents (age, time for filling the questionnaire, region ID, prefecture ID) and L = 3 features for sushi ( price,heaviness, sales volume).\n6 Conclusions\n0 2000 4000 6000 8000 10000 0\n2\n4\n6\n8\n10\n0\n2\n4\n6\n8\n10\nN um\nbe r o\nf S ub\ngr ou\nps (S\n)\nIterations\nFrequency\nFigure 3: Left Panel: 10000 samples for S in Synthetic data, where the true S is 5. Right Panel: Histogram of the samples for S with max at 5 and mean at 4.56.\nSynthetic True types Sushi Type One two Three Four sushi one type -2069 -2631 -2780 -2907 -2880 two types -2755 -2522 -2545 -2692 -2849\nthree types -2796 -2642 -2582 -2790 -2819 four types -2778 -2807 -2803 -2593 -2850\nTable 1: Performance of the method for different number of true types and number of types in algorithm in terms of log posterior. All the standard deviations are between 15 and 20. Bold numbers indicate the best performance in their column with statistical significance of 95%.\nIn this paper, we have proposed an extension of GRUMs in which we allow agents to adopt heterogeneous types. We develop a theory establishing the identifiability of the mixture model when we observe ranking data. Our theoretical results for identifiability show that the number of types and the parameters associated with them can be identified. Moreover, we prove uni-modality of the likelihood (or posterior) function when types are observable. We propose a scalable algorithm for inference, which can be parallelized for use on very large data sets. Our experimental results show that models with multiple types provide a significantly better fit, in real-world data. By clustering agents into multiple types, our estimation algorithm allows choices to be correlated across agents of the same type, without making any a priori assumptions on how types of agents are to be partitioned. This use of machine learning tech-\nniques complements various approaches in economics [11, 7, 8] by allowing the researcher to have additional flexibility in dealing with missing data or unobserved agent characteristics. We expect the development of these techniques to grow in importance as large, individual-level datasets become increasingly available. In future research we intend to pursue applications of this method to problems of economic interest."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work is supported in part by NSF Grants No. CCF- 0915016 and No. AF-1301976. We thank Elham Azizi for helping in the design and implementation of RJMCMC algorithm. We thank Simon Lunagomez for helpful discussion on RJMCMC. We thank Lirong Xia, Gregory Lewis, Edoardo Airoldi, Ryan Adams and Nikhil Agarwal for comments on the modeling and algorithmic aspects of this paper. We thank anonymous NIPS-13 reviewers, for helpful comments and suggestions."
    } ],
    "references" : [ {
      "title" : "Advertising, learning, and consumer choice in experience goods: An empirical examination",
      "author" : [ "Daniel A. Ackerberg" ],
      "venue" : "International Economic Review,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2003
    }, {
      "title" : "Muoz-Pichardo. A new condition for identifiability of finite mixture distributions. Metrika",
      "author" : [ "N. Atienza", "J. Garcia-Heras", "J.M" ],
      "venue" : null,
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2006
    }, {
      "title" : "Random utility theory for social choice",
      "author" : [ "Hossein Azari Soufiani", "David C. Parkes", "Lirong Xia" ],
      "venue" : "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2012
    }, {
      "title" : "Preference elicitation for generalized random utility models",
      "author" : [ "Hossein Azari Soufiani", "David C. Parkes", "Lirong Xia" ],
      "venue" : "In Proceedings of the Annual Conference on Uncertainty in Artificial Intelligence (UAI),",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2013
    }, {
      "title" : "Discrete choice models as structural models of demand: Some economic implications of common approaches",
      "author" : [ "Patrick Bajari", "C. Lanier Benkard" ],
      "venue" : "Technical report, Working Paper,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2003
    }, {
      "title" : "A nested logit model of automobile holdings for one vehicle households",
      "author" : [ "James Berkovec", "John Rust" ],
      "venue" : "Transportation Research Part B: Methodological,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1985
    }, {
      "title" : "Automobile prices in market",
      "author" : [ "Steven Berry", "James Levinsohn", "Ariel Pakes" ],
      "venue" : "equilibrium. Econometrica,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1995
    }, {
      "title" : "Voluntary export restraints on automobiles: evaluating a trade policy",
      "author" : [ "Steven Berry", "James Levinsohn", "Ariel Pakes" ],
      "venue" : "The American Economic Review,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1999
    }, {
      "title" : "Differentiated products demand systems from a combination of micro and macro data: The new car market",
      "author" : [ "Steven Berry", "James Levinsohn", "Ariel Pakes" ],
      "venue" : "Journal of Political Economy,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2004
    }, {
      "title" : "Some applications and limitations of recent advances in empirical industrial organization: Merger analysis",
      "author" : [ "Steven Berry", "Ariel Pakes" ],
      "venue" : "The American Economic Review,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1993
    }, {
      "title" : "Estimating discrete-choice models of product differentiation",
      "author" : [ "Steven Berry" ],
      "venue" : "The RAND Journal of Economics,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1994
    }, {
      "title" : "Gaussian process preference elicitation",
      "author" : [ "Edwin Bonilla", "Shengbo Guo", "Scott Sanner" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2010
    }, {
      "title" : "Efficient construction of reversible jump Markov chain Monte Carlo proposal distributions",
      "author" : [ "Stephen P Brooks", "Paulo Giudici", "Gareth O Roberts" ],
      "venue" : "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2003
    }, {
      "title" : "Gaussian processes for ordinal regression",
      "author" : [ "Wei Chu", "Zoubin Ghahramani" ],
      "venue" : "In Journal of Machine Learning Research,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2005
    }, {
      "title" : "How many clusters? which clustering method? answers via modelbased cluster analysis",
      "author" : [ "Chris Fraley", "Adrian E. Raftery" ],
      "venue" : "THE COMPUTER JOURNAL,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1998
    }, {
      "title" : "Alternative computational approaches to inference in the multinomial probit model",
      "author" : [ "John Geweke", "Michael Keane", "David Runkle" ],
      "venue" : "Review of Economics and Statistics,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1994
    }, {
      "title" : "Reversible jump Markov chain Monte Carlo computation and Bayesian model determination",
      "author" : [ "P.J. Green" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1995
    }, {
      "title" : "Identifiability of finite mixtures of multinomial logit models with varying and fixed effects",
      "author" : [ "Bettina Grn", "Friedrich Leisch" ],
      "venue" : "Journal of Classification,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2008
    }, {
      "title" : "Valuation of new goods under perfect and imperfect competition",
      "author" : [ "Jerry A. Hausman" ],
      "venue" : null,
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1996
    }, {
      "title" : "Econometric duration analysis",
      "author" : [ "James J. Heckman", "Burton Singer" ],
      "venue" : "Journal of Econometrics,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1984
    }, {
      "title" : "Measuring the implications of sales and consumer inventory",
      "author" : [ "Igal Hendel", "Aviv Nevo" ],
      "venue" : "behavior. Econometrica,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2006
    }, {
      "title" : "The welfare effects of restricted hospital choice in the us medical care market",
      "author" : [ "Katherine Ho" ],
      "venue" : "Journal of Applied Econometrics,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2006
    }, {
      "title" : "Collaborative gaussian processes for preference learning",
      "author" : [ "Neil Houlsby", "Jose Miguel Hernandez-Lobato", "Ferenc Huszar", "Zoubin Ghahramani" ],
      "venue" : "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2012
    }, {
      "title" : "Finite-mixture structural equation models for response-based segmentation and unobserved heterogeneity",
      "author" : [ "Kamel Jedidi", "Harsharanjeet S. Jagpal", "Wayne S. DeSarbo" ],
      "venue" : "Marketing Science,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 1997
    }, {
      "title" : "Nantonac collaborative filtering: Recommendation based on order responses",
      "author" : [ "Toshihiro Kamishima" ],
      "venue" : "In Proceedings of the Ninth International Conference on Knowledge Discovery and Data Mining (KDD),",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2003
    }, {
      "title" : "The measurement of urban travel demand",
      "author" : [ "Daniel McFadden" ],
      "venue" : "Journal of Public Economics,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1974
    }, {
      "title" : "Modelling the choice of residential location",
      "author" : [ "Daniel McFadden" ],
      "venue" : "Spatial Interaction Theory and Planing Models,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1978
    }, {
      "title" : "Clustering ordinal data via latent variable models",
      "author" : [ "Gormley-Claire McParland", "Damien" ],
      "venue" : "IFCS 2013 Conference of the International Federation of Classification",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2013
    }, {
      "title" : "Dirichlet process mixtures of generalized Mallows models",
      "author" : [ "Marina Meila", "Harr Chen" ],
      "venue" : "arXiv preprint arXiv:1203.3496,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2012
    }, {
      "title" : "Logarithmic concave measures and related topics. In Stochastic Programming, pages 63–82",
      "author" : [ "András Prékopa" ],
      "venue" : null,
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 1980
    }, {
      "title" : "Bayesian variable selection in clustering highdimensional data",
      "author" : [ "Mahlet G. Tadesse", "Naijun Sha", "Marina Vannucci" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2005
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "Examples from economics include the popular random coefficients logit model [7] where the data may involve a (partial) consumer ranking of products [9].",
      "startOffset" : 76,
      "endOffset" : 79
    }, {
      "referenceID" : 8,
      "context" : "Examples from economics include the popular random coefficients logit model [7] where the data may involve a (partial) consumer ranking of products [9].",
      "startOffset" : 148,
      "endOffset" : 151
    }, {
      "referenceID" : 19,
      "context" : "To estimate preferences across heterogenous agents, one approach as allowed by prior work [20, 24] is to assume a mixture of agents with a finite number of types.",
      "startOffset" : 90,
      "endOffset" : 98
    }, {
      "referenceID" : 23,
      "context" : "To estimate preferences across heterogenous agents, one approach as allowed by prior work [20, 24] is to assume a mixture of agents with a finite number of types.",
      "startOffset" : 90,
      "endOffset" : 98
    }, {
      "referenceID" : 27,
      "context" : "Empirical researchers are increasingly being presented with rich data on the choices made by individuals, and asked to classify these agents into different types [28, 29] and to estimate the preferences of each type [10, 23].",
      "startOffset" : 162,
      "endOffset" : 170
    }, {
      "referenceID" : 28,
      "context" : "Empirical researchers are increasingly being presented with rich data on the choices made by individuals, and asked to classify these agents into different types [28, 29] and to estimate the preferences of each type [10, 23].",
      "startOffset" : 162,
      "endOffset" : 170
    }, {
      "referenceID" : 9,
      "context" : "Empirical researchers are increasingly being presented with rich data on the choices made by individuals, and asked to classify these agents into different types [28, 29] and to estimate the preferences of each type [10, 23].",
      "startOffset" : 216,
      "endOffset" : 224
    }, {
      "referenceID" : 22,
      "context" : "Empirical researchers are increasingly being presented with rich data on the choices made by individuals, and asked to classify these agents into different types [28, 29] and to estimate the preferences of each type [10, 23].",
      "startOffset" : 216,
      "endOffset" : 224
    }, {
      "referenceID" : 0,
      "context" : "Examples of individual-level data used in economics include household purchases from supermarket-scanner data [1, 21], and patients’ hospital or treatment choices from healthcare data [22].",
      "startOffset" : 110,
      "endOffset" : 117
    }, {
      "referenceID" : 20,
      "context" : "Examples of individual-level data used in economics include household purchases from supermarket-scanner data [1, 21], and patients’ hospital or treatment choices from healthcare data [22].",
      "startOffset" : 110,
      "endOffset" : 117
    }, {
      "referenceID" : 21,
      "context" : "Examples of individual-level data used in economics include household purchases from supermarket-scanner data [1, 21], and patients’ hospital or treatment choices from healthcare data [22].",
      "startOffset" : 184,
      "endOffset" : 188
    }, {
      "referenceID" : 7,
      "context" : "By using a model of demand to estimate the elasticity in behavioral response of each type of agent and by aggregating these responses over the different types of agents, it is possible to simulate the impact of a social or public policy [8], or simulate the counterfactual outcome of changing the options available to agents [19].",
      "startOffset" : 237,
      "endOffset" : 240
    }, {
      "referenceID" : 18,
      "context" : "By using a model of demand to estimate the elasticity in behavioral response of each type of agent and by aggregating these responses over the different types of agents, it is possible to simulate the impact of a social or public policy [8], or simulate the counterfactual outcome of changing the options available to agents [19].",
      "startOffset" : 325,
      "endOffset" : 329
    }, {
      "referenceID" : 2,
      "context" : "We build on recent work [3, 4] on estimating GRUMs by allowing for an interaction between agent characteristics and the characteristics of the agent’s chosen alternative.",
      "startOffset" : 24,
      "endOffset" : 30
    }, {
      "referenceID" : 3,
      "context" : "We build on recent work [3, 4] on estimating GRUMs by allowing for an interaction between agent characteristics and the characteristics of the agent’s chosen alternative.",
      "startOffset" : 24,
      "endOffset" : 30
    }, {
      "referenceID" : 25,
      "context" : "The interaction term helps us to avoid unrealistic substitution patterns due to the independence of irrelevant alternatives [26] by allowing agent utilities to be correlated across alternatives with similar characteristics.",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 30,
      "context" : "RJMCMC can be used for model selection and learning a posterior on the number of types in a mixture model [31].",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 1,
      "context" : "Previous theoretical results have established identifiability for data consisting of vectors of real numbers [2, 18], but not for data consisting of partial orders.",
      "startOffset" : 109,
      "endOffset" : 116
    }, {
      "referenceID" : 17,
      "context" : "Previous theoretical results have established identifiability for data consisting of vectors of real numbers [2, 18], but not for data consisting of partial orders.",
      "startOffset" : 109,
      "endOffset" : 116
    }, {
      "referenceID" : 6,
      "context" : "Prior work in econometrics has focused on developing models that use data aggregated across types of agents, such as at the level of a geographic market, and that allow heterogeneity by using random coefficients on either agents’ preference parameters [7, 9] or on a set of dummy variables that define types of agents [6, 27], or by imposing additional structure on the covariance matrix of idiosyncratic taste shocks [16].",
      "startOffset" : 252,
      "endOffset" : 258
    }, {
      "referenceID" : 8,
      "context" : "Prior work in econometrics has focused on developing models that use data aggregated across types of agents, such as at the level of a geographic market, and that allow heterogeneity by using random coefficients on either agents’ preference parameters [7, 9] or on a set of dummy variables that define types of agents [6, 27], or by imposing additional structure on the covariance matrix of idiosyncratic taste shocks [16].",
      "startOffset" : 252,
      "endOffset" : 258
    }, {
      "referenceID" : 5,
      "context" : "Prior work in econometrics has focused on developing models that use data aggregated across types of agents, such as at the level of a geographic market, and that allow heterogeneity by using random coefficients on either agents’ preference parameters [7, 9] or on a set of dummy variables that define types of agents [6, 27], or by imposing additional structure on the covariance matrix of idiosyncratic taste shocks [16].",
      "startOffset" : 318,
      "endOffset" : 325
    }, {
      "referenceID" : 26,
      "context" : "Prior work in econometrics has focused on developing models that use data aggregated across types of agents, such as at the level of a geographic market, and that allow heterogeneity by using random coefficients on either agents’ preference parameters [7, 9] or on a set of dummy variables that define types of agents [6, 27], or by imposing additional structure on the covariance matrix of idiosyncratic taste shocks [16].",
      "startOffset" : 318,
      "endOffset" : 325
    }, {
      "referenceID" : 15,
      "context" : "Prior work in econometrics has focused on developing models that use data aggregated across types of agents, such as at the level of a geographic market, and that allow heterogeneity by using random coefficients on either agents’ preference parameters [7, 9] or on a set of dummy variables that define types of agents [6, 27], or by imposing additional structure on the covariance matrix of idiosyncratic taste shocks [16].",
      "startOffset" : 418,
      "endOffset" : 422
    }, {
      "referenceID" : 3,
      "context" : "Defined in [4] as a RUM with a generalized linear model for the regression of the mean parameters on the interaction of characteristics data as in Figure 1 (2)There are alternative methods to RJMCMC, such as the saturation method [13].",
      "startOffset" : 11,
      "endOffset" : 14
    }, {
      "referenceID" : 12,
      "context" : "Defined in [4] as a RUM with a generalized linear model for the regression of the mean parameters on the interaction of characteristics data as in Figure 1 (2)There are alternative methods to RJMCMC, such as the saturation method [13].",
      "startOffset" : 230,
      "endOffset" : 234
    }, {
      "referenceID" : 25,
      "context" : "For example, the logit model [26] assumes i.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 4,
      "context" : "This may lead to biased estimates, in particular when the number of alternatives grow large [5].",
      "startOffset" : 92,
      "endOffset" : 95
    }, {
      "referenceID" : 27,
      "context" : "Previous work on clustering ranking data for variations of the Placket-Luce (PL) model [28, 29] has been restricted to settings without agent and alternative characteristics.",
      "startOffset" : 87,
      "endOffset" : 95
    }, {
      "referenceID" : 28,
      "context" : "Previous work on clustering ranking data for variations of the Placket-Luce (PL) model [28, 29] has been restricted to settings without agent and alternative characteristics.",
      "startOffset" : 87,
      "endOffset" : 95
    }, {
      "referenceID" : 13,
      "context" : "[14] performed clustering for RUMs with normal distributions, but this was limited to pairwise comparisons.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 2,
      "context" : "Inference of GRUMs for partial ranks involved the computational hardness addressed in [3].",
      "startOffset" : 86,
      "endOffset" : 89
    }, {
      "referenceID" : 14,
      "context" : "In mixture models, assuming an arbitrary number of types can lead to biased results, and reduces the statistical efficiency of the estimators [15].",
      "startOffset" : 142,
      "endOffset" : 146
    }, {
      "referenceID" : 3,
      "context" : "Inference for GRUMs has been generalized in [4], However, Azari et al.",
      "startOffset" : 44,
      "endOffset" : 47
    }, {
      "referenceID" : 3,
      "context" : "[4] do not consider existence of multiple types.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "Then using the result in [3] and [30], L(~ ψ) = L(~ ψ, π) is logarithmic concave in the sense that L(λ~ ψ + (1 − λ) ~ ψ′) ≥ L(ψ)λL(ψ′)1−λ for any 0 < λ < 1 and any two vectors ~ ψ, ~ ψ′ ∈ R .",
      "startOffset" : 25,
      "endOffset" : 28
    }, {
      "referenceID" : 29,
      "context" : "Then using the result in [3] and [30], L(~ ψ) = L(~ ψ, π) is logarithmic concave in the sense that L(λ~ ψ + (1 − λ) ~ ψ′) ≥ L(ψ)λL(ψ′)1−λ for any 0 < λ < 1 and any two vectors ~ ψ, ~ ψ′ ∈ R .",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 2,
      "context" : "This condition has been explained in [3] as condition (1).",
      "startOffset" : 37,
      "endOffset" : 40
    }, {
      "referenceID" : 16,
      "context" : "We use reversible-jump MCMC [17] for sampling from conditional distributions of the assignment function (see Algorithm 1).",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 24,
      "context" : "Clustering Performance for Real World Data: We have tested our algorithm on a sushi dataset, where 5, 000 users provide rankings on M = 10 different kinds of sushi [25].",
      "startOffset" : 164,
      "endOffset" : 168
    }, {
      "referenceID" : 10,
      "context" : "This use of machine learning techniques complements various approaches in economics [11, 7, 8] by allowing the researcher to have additional flexibility in dealing with missing data or unobserved agent characteristics.",
      "startOffset" : 84,
      "endOffset" : 94
    }, {
      "referenceID" : 6,
      "context" : "This use of machine learning techniques complements various approaches in economics [11, 7, 8] by allowing the researcher to have additional flexibility in dealing with missing data or unobserved agent characteristics.",
      "startOffset" : 84,
      "endOffset" : 94
    }, {
      "referenceID" : 7,
      "context" : "This use of machine learning techniques complements various approaches in economics [11, 7, 8] by allowing the researcher to have additional flexibility in dealing with missing data or unobserved agent characteristics.",
      "startOffset" : 84,
      "endOffset" : 94
    } ],
    "year" : 2013,
    "abstractText" : "We propose a model for demand estimation in multi-agent, differentiated product settings and present an estimation algorithm that uses reversible jump MCMC techniques to classify agents’ types. Our model extends the popular setup in Berry, Levinsohn and Pakes (1995) to allow for the data-driven classification of agents’ types using agent-level data. We focus on applications involving data on agents’ ranking over alternatives, and present theoretical conditions that establish the identifiability of the model and uni-modality of the likelihood/posterior. Results on both real and simulated data provide support for the scalability of our approach.",
    "creator" : null
  }
}