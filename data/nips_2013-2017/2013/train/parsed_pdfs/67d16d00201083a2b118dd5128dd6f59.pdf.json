{
  "name" : "67d16d00201083a2b118dd5128dd6f59.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Gaussian Process Conditional Copulas with Applications to Financial Time Series",
    "authors" : [ "José Miguel Hernández-Lobato", "James Robert Lloyd" ],
    "emails" : [ "jmh233@cam.ac.uk", "jrl44@cam.ac.uk", "daniel.hernandez@uam.es" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Understanding dependencies within multivariate data is a central problem in the analysis of financial time series, underpinning common tasks such as portfolio construction and calculation of value-atrisk. Classical methods estimate these dependencies in terms of a covariance matrix (possibly time varying) which is induced from the data [4, 5, 7, 1]. However, a more general approach is to use copula functions to model dependencies [6]. Copulas have become popular since they separate the estimation of marginal distributions from the estimation of the dependence structure, which is completely determined by the copula.\nThe use of standard copula methods to estimate dependencies is likely to be inaccurate when the actual dependencies are strongly influenced by other covariates. For example, dependencies can vary with time or be affected by observations of other time series. Standard copula methods cannot handle such conditional dependencies. To address this limitation, we propose a probabilistic framework to estimate conditional copulas. Specifically we assume parametric copulas whose parameters are specified by unknown non-linear functions of arbitrary conditioning variables. These latent functions are approximated using Gaussian processes (GP) [17].\nGPs have previously been used to model conditional copulas in [12] but that work only applies to copulas specified by a single parameter. We extend this work to accommodate copulas with multiple parameters. This is an important improvement since it allows the use of a richer set of copulas including Student’s t and asymmetric copulas. We demonstrate our method by choosing the conditioning variables to be time and evaluating its ability to estimate time-varying dependencies\non several currency and equity time series. Our method achieves consistently superior predictive performance compared to static copula models and other dynamic copula methods. These include models that allow their parameters to change with time, e.g. regime switching models [11] and methods proposing GARCH-style updates to copula parameters [20, 11]."
    }, {
      "heading" : "2 Copulas and Conditional Copulas",
      "text" : "Copulas provide a powerful framework for the construction of multivariate probabilistic models by separating the modeling of univariate marginal distributions from the modeling of dependencies between variables [6]. We focus on bivariate copulas since higher dimensional copulas are typically constructed using bivariate copulas as building blocks [e.g 2, 12].\nSklar’s theorem [18] states that given two one-dimensional random variables, X and Y , with continuous marginal cumulative distribution functions (cdfs) FX(X) and FY (Y ), we can express their joint cdf FX,Y as FX,Y (x, y) = CX,Y [FX(x), FY (y)], where CX,Y is the unique copula for X and Y . Since FX(X) and FY (Y ) are marginally uniformly distributed on [0, 1], CX,Y is the cdf of a probability distribution on the unit square [0, 1] × [0, 1] with uniform marginals. Figure 1 shows plots of the copula densities for three parametric copula models: Gaussian, Student’s t and the symmetrized Joe Clayton (SJC) copulas. Copula models can be learnt in a two step process [10]. First, the marginals FX and FY are learnt by fitting univariate models. Second, the data are mapped to the unit square by U = FX(X), V = FY (Y ) (i.e. a probability integral transform) and then CX,Y is then fit to the transformed data."
    }, {
      "heading" : "2.1 Conditional Copulas",
      "text" : "When one has access to a covariate vector Z, one may wish to estimate a conditional version of a copula model i.e. FX,Y |Z(x, y|z) = CX,Y |Z [ FX|Z(x|z), FY |Z(y|z)|z ] . (1)\nHere, the same two-step estimation process can be used to estimate FX,Y |Z(x, y|z). The estimation of the marginals FX|Z and FY |Z can be implemented using standard methods for univariate conditional distribution estimation. However, the estimation of CX,Y |Z is constrained to have uniform marginal distributions; this is a problem that has only been considered recently [12]. We propose a general Bayesian non-parametric framework for the estimation of conditional copulas based on GPs and an alternating expectation propagation (EP) algorithm for efficient approximate inference."
    }, {
      "heading" : "3 Gaussian Process Conditional Copulas",
      "text" : "Let DZ = {zi}ni=1 and DU,V = {(ui, vi)}ni=1 where (ui, vi) is a sample drawn from CX,Y |zi . We assume that CX,Y |Z is a parametric copula model Cpar[u, v|θ1(z), . . . , θk(z)] specified by k parameters θ1, . . . , θk that may be functions of the conditioning variable z. Let θi(z) = σi[fi(z)],\nwhere fi is an arbitrary real function and σi is a function that maps the real line to a set Θi of valid configurations for θi. For example, Cpar could be a Student’s t copula. In this case, k = 2 and θ1 and θ2 are the correlation and the degrees of freedom in the Student’s t copula, Θ1 = (−1, 1) and Θ2 = (0,∞). One could then choose σ1(·) = 2Φ(·)− 1, where Φ is the standard Gaussian cdf and σ2(·) = exp(·) to satisfy the constraint sets Θ1 and Θ2 respectively. Once we have specified the parametric form of Cpar and the mapping functions σ1, . . . , σk, we need to learn the latent functions f1, . . . , fk. We perform a Bayesian non-parametric analysis by placing GP priors on these functions and computing their posterior distribution given the observed data.\nLet fi = (fi(z1), . . . , fi(zn))T. The prior distribution for fi given DZ is p(fi|DZ) = N (fi|mi,Ki), where mi = (mi(z1), . . . ,mi(zn))T for some mean function mi(z) and Ki is an n× n covariance matrix generated by the squared exponential covariance function, i.e.\n[Ki]jk = Cov[fi(zj), fi(zk)] = βi exp { −(zj − zk)Tdiag(λi)(zj − zk) } + γi , (2)\nwhere λi is a vector of inverse length-scales and βi, γi are amplitude and noise parameters. The posterior distribution for f1, . . . , fk given DU,V and DZ is\np(f1, . . . , fk|DU,V ,DZ) =\n[∏n i=1 cpar [ ui, vi|σ1 [f1(zi)] , . . . , σk [fk(zi)] ]] [∏k i=1N (fi|mi,Ki) ] p(DU,V |DZ) , (3)\nwhere cpar is the density of the parametric copula model and p(DU,V |DZ) is a normalization constant often called the model evidence. Given a particular value of Z denoted by z?, we can make predictions about the conditional distribution of U and V using the standard GP prediction formula\np(u?, v?|z?) = ∫ cpar(u ?, v?|σ1[f?1 ], . . . , σk[f?k ])p(f?|f1, . . . , fk, z?,Dz)\np(f1, . . . , fk|DU,V ,DZ) df1 · · · dfk df? , (4)\nwhere f? = (f?1 , . . . , f ? k ) T, p(f?|f1, . . . , fk, z?,Dz) = ∏k i=1 p(f ? i |fi, z?,Dz), f?i = fi(z?), p(f?i |fi, z?,Dz) = N (f?i |mi(z?) + kTiK −1 i (fi −mi), ki − kTiK −1 i ki), ki = Cov[fi(z ?), fi(z ?)] and ki = (Cov[fi(z?), fi(z1)], . . . ,Cov[fi(z?), fi(zn)])T. Unfortunately, (3) and (4) cannot be computed analytically, so we approximate them using expectation propagation (EP) [13]."
    }, {
      "heading" : "3.1 An Alternating EP Algorithm for Approximate Bayesian Inference",
      "text" : "The joint distribution for f1, . . . , fk and DU,V given DZ can be written as a product of n+k factors:\np(f1, . . . , fk,DU,V |DZ) = [ n∏ i=1 gi(f1i, . . . , fki, ) ][ k∏ i=1 hi(fi) ] , (5)\nwhere fji = fj(zi), hi(fi) = N (fi|mi,Ki) and gi(f1i, . . . , fki) = cpar[ui, vi|σ1[f1i], . . . , σk[fki]]. EP approximates each factor gi with an approximate Gaussian factor g̃i that may not integrate to one, i.e. g̃i(f1i, . . . , fki) = si ∏k j=1 exp { −(fji − m̃ji)2/[2ṽji] } , where si > 0, m̃ji and ṽji are parameters to be calculated by EP. The other factors hi already have a Gaussian form so they do not need to be approximated. Since all the g̃i and hi are Gaussian, their product is, up to a normalization constant, a multivariate Gaussian distribution q(f1, . . . , fk) which approximates the exact posterior (3) and factorizes across f1, . . . , fk. The predictive distribution (4) is approximated by first integrating p(f?|f1, . . . , fk, z?,Dz) with respect to q(f1, . . . , fk). This results in a factorized Gaussian distribution q?(f?) which approximates p(f?|DU,V ,DZ). Finally, (4) is approximated by Monte-Carlo by sampling from q? and then averaging cpar(u?, v?|σ1[f?1 ], . . . , σk[f?k ]) over the samples.\nEP iteratively updates each g̃i until convergence by first computing q\\i ∝ q/g̃i and then minimizing the Kullback-Leibler divergence [3] between giq\\i and g̃iq\\i. This involves updating g̃i so that the first and second marginal moments of giq\\i and g̃iq\\i match. However, it is not possible to compute the moments of giq\\i analytically due to the complicated form of gi. A solution is to use numerical methods to compute these k-dimensional integrals. However, this typically has an exponentially large computational cost in k which is prohibitive for k > 1. Instead we perform an additional approximation when computing the marginal moments of fji with respect to giq\\i. Without loss of\ngenerality, assume that we want to compute the expectation of f1i with respect to giq\\i. We make the following approximation:∫\nf1igi(f1i, . . . , fki)q \\i(f1i, . . . ,fki) df1i, . . . , dfki ≈\nC × ∫ f1igi(f1i, f̄2i, . . . , f̄ki)q \\i(f1i, f̄2i, . . . , f̄ki) df1i , (6)\nwhere f̄1i, . . . , f̄ki are the means of f1i, . . . , fki with respect to q\\i, and C is a constant that approximates the width of the integrand around its maximum in all dimensions except f1i. In practice all moments are normalized by the 0-th moment soC can be ignored. The right hand side of (6) is a onedimensional integral that can be easily computed using numerical techniques. The approximation above is similar to approximating an integral by the product of the maximum value of the integrand and an estimate of its width. However, instead of maximizing gi(f1i, . . . , fki)q\\i(f1i, . . . , fki) with respect to f2i, . . . , fki, we are maximizing q\\i. This is a much easier task because q\\i is Gaussian and its maximizer is its own mean vector. In practice, gi(f1i, . . . , fki) is very flat when compared to q\\i and the maximizer of q\\i approximates well the maximizer of gi(f1i, . . . , fki)q\\i(f1i, . . . , fki).\nSince q factorizes across f1, . . . , fk (as well as q\\i), our implementation of EP decouples into k EP sub-routines among which we alternate; the j-th sub-routine approximates the posterior distribution of fj using as input the means of q\\i generated by the other EP sub-routines. Each sub-routine finds a Gaussian approximation to a set of n one-dimensional factors; one factor per data point. In the j-th EP sub-routine, the i-th factor is given by gi(f1i, . . . , fki), where each {f1i, . . . , fki} \\ {fji} is kept fixed to the current mean of q\\i, as estimated by the other EP sub-routines. We iteratively alternate between sub-routines, running each one until convergence before re-running the next one. Convergence is achieved very quickly; we only run each EP sub-routine four times.\nThe EP sub-routines are implemented using the parallel EP update scheme described in [21]. To speed up GP related computations, we use the generalized FITC approximation [19, 14]: Each n × n covariance matrix Ki is approximated by K′i = Qi + diag(Ki − Qi), where Qi = Kinn0 [K i n0n0 ] −1[Kinn0 ] T, Kin0n0 is the n0 × n0 covariance matrix generated by evaluating (2) at n0 n pseudo-inputs, and Kinn0 is the n×n0 matrix with the covariances between training points and pseudo-inputs. The cost of EP is O(knn20). Each time we call the j-th EP subroutine, we optimize the corresponding kernel hyper-parameters λj , βj and γj and the pseudo-inputs by maximizing the EP approximation of the model evidence [17]."
    }, {
      "heading" : "4 Related Work",
      "text" : "The model proposed here is an extension of the conditional copula model of [12]. In the case of bivariate data and a copula based on one parameter the models are identical. We have extended the approximate inference for this model to accommodate copulas with multiple parameters; previously computationally infeasible due to requiring the numerical calculation of multidimensional integrals within an inner loop of EP inference. We have also demonstrated that one can use this model to produce excellent predictive results on financial time series by conditioning the copula on time."
    }, {
      "heading" : "4.1 Dynamic Copula Models",
      "text" : "In [11] a dynamic copula model is proposed based on a two-state hidden Markov model (HMM) (St ∈ {0, 1}) that assumes that the data generating process changes between two regimes of low/high correlation. At any time t the copula density is Student’s t with different parameters for the two values of the hidden state St. Maximum likelihood estimation of the copula parameters and transition probabilities is performed using an EM algorithm [e.g. 3].\nA time-varying correlation (TVC) model based on the Student’s t copula is described in [20, 11]. The correlation parameter1of a Student’s t copula is assumed to satisfy ρt = (1 − α − β)ρ + αεt−1 + βρt−1, where εt−1 is the empirical correlation of the previous 10 observations and ρ, α and β satisfy −1 ≤ ρ ≤ 1, 0 ≤ α, β ≤ 1 and α + β ≤ 1. The number of degrees of freedom ν\nis assumed to be constant. The previous formula is the GARCH equation for correlation instead of variance. Estimation of ρ, α, β and ν is easily performed by maximum likelihood.\nIn [15] a dynamic copula based on the SJC copula (DSJCC) is introduced. In this method, the parameters τU and τL of an SJC copula are assumed to depend on time according to\nτU (t) = 0.01 + 0.98Λ [ ωU + αUεt−1 + βUτ U (t− 1) ] , (7)\nτL(t) = 0.01 + 0.98Λ [ ωL + αLεt−1 + βLτ L(t− 1) ] , (8)\nwhere Λ[·] is the logistic function, εt−1 = 110 ∑10 j=1 |ut−j − vt−j |, (ut, vt) is a copula sample at time t and the constants are used to avoid numerical instabilities. These formulae are the GARCH equation for correlations, with an additional logistic function to constrain parameter values. The estimation of ωU , αU , βU , ωL, αL and βL is performed by maximum likelihood.\nWe go beyond this prior work by allowing copula parameters to depend on an arbitrary conditioning variables rather than time alone. Also, the models above either assume Markov independence or GARCH-like updates to copula parameters. These assumptions have been empirically proven to be effective for the estimation of univariate variances, but the consistent performance gains of our proposed method suggest these assumptions are less applicable for the estimation of dependencies."
    }, {
      "heading" : "4.2 Other Dynamic Covariance Models",
      "text" : "A direct extension of the GARCH equations to multiple time series, VEC, was proposed by [5]. Let x(t) be a multivariate time series assumed to satisfy x(t) ∼ N (0,Σ(t)). VEC(p, q) models the dynamics of Σ(t) by an equation of the form\nvech(Σ(t)) = c+ p∑ k=1 Ak vech(x(t− k)x(t− k)T) + q∑ k=1 Bk vech(Σ(t− k)) (9)\nwhere vech is the operation that stacks the lower triangular part on a matrix into a column vector. The VEC model has a very large number of parameters and hence a more commonly used model is the BEKK(p, q) model [7] which assumes the following dynamics\nΣ(t) = CTC + p∑ k=1 ATkx(t− k)x(t− k)TAk + q∑ k=1 BTkΣ(t− k)Bk. (10)\nThis model also has many parameters and many restricted versions of these models have been proposed to avoid over-fitting (see e.g. section 2 of [1]).\nAn alternative solution to over-fitting due to over-parameterization is the Bayesian approach of [23] where Bayesian inference is performed in a dynamic BEKK(1, 1) model. Other Bayesian approaches include the non-parametric generalized Wishart process [22, 8]. In these works Σ(t) is modeled by a generalized Wishart process i.e.\nΣ(t) = ν∑ i=1 Lui(t)ui(t) TLT (11)\nwhere uid(·) are distributed as independent GPs."
    }, {
      "heading" : "5 Experiments",
      "text" : "We evaluate the proposed Gaussian process conditional copula models (GPCC) on a one-step-ahead prediction task with synthetic data and financial time series. We use time as the conditioning variable and consider three parametric copula families; Gaussian (GPCC-G), Student’s t (GPCC-T) and symmetrized Joe Clayton (GPCC-SJC). The parameters of these copulas are presented in Table 1 along with the transformations used to model them. Figure 1 shows plots of the densities of these three parametric copula models. The code and data are publicly available at http://jmhl.org.\n1The parameterization used in this paper is related by ρ = sin(0.5τπ)\nThe three variants of GPCC were compared against three dynamic copula methods and three constant copula models. The three dynamic methods include the HMM based model, TVC and DSJCC introduced in Section 4. The three constant copula models use Gaussian, Student’s t and SJC copulas with parameter values that do not change with time (CONST-G, CONST-T and CONST-SJC). We perform a one-step-ahead rolling-window prediction task on bivariate time series {(ut, vt)}. Each model is trained on the first nW data points and the predictive log-likelihood of the (nW+1)−th data point is recorded, where nW = 1000. This is then repeated, shifting the training and test windows forward by one data point. The methods are then compared by average predictive log-likelihood; an appropriate performance measure for copula estimation since copulas are probability distributions."
    }, {
      "heading" : "5.1 Synthetic Data",
      "text" : "We generated three synthetic datasets of length 5001 from copula models (Gaussian, Student’s t, SJC) whose parameters vary as periodic functions of time, as specified in Table 1. Table 2 reports the average predictive log-likelihood for each method on each synthetic time series. The results of the best performing method on each synthetic time series are shown in bold. The results of any other method are underlined when the differences with respect to the best performing method are not statistically significant according to a paired t test at α = 0.05.\nGPCC-T and GPCC-SJC obtain the best results in the Student’s t and SJC time series respectively. However, HMM is the best performing method for the Gaussian time series. This technique successfully captures the two regimes of low/high correlation corresponding to the peaks and troughs of the sinusoid that maps time t to correlation τ . The proposed methods GPCC-[G,T,SJC] are more flexible and hence less efficient than HMM in this particular problem. However, HMM performs significantly worse in the Student’s t and SJC time series since the different periods for the different copula parameter functions cannot be captured by a two state model. Figure 2 shows how GPCC-T successfully tracks τ(t) and ν(t) in the Student’s t time series. The plots display the mean (red) and confidence bands (orange, 0.1 and 0.9 quantiles) for the predictive distribution of τ(t) and ν(t) as well as the ground truth values (blue). Finally, Table 2 also shows that the static copula methods CONST-[G,T,SJC] are usually outperformed by all dynamic techniques GPCC-[G,T,SJC], DSJCC, TVC and HMM."
    }, {
      "heading" : "5.2 Foreign Exchange Time Series",
      "text" : "We evaluated each method on the daily logarithmic returns of nine currencies shown in Table 3 (all priced with respect to the U.S. dollar).The date range of the data is 02-01-1990 to 15-01-2013; a total of 6011 observations. We evaluated the methods on eight bivariate time series, pairing each currency pair with the Swiss franc (CHF). CHF is known to be a safe haven currency, meaning that investors flock to it during times of uncertainty [16]. Consequently we expect correlations between CHF and other currencies to have large variability across time in response to changes in financial conditions.\nWe first process our data using an asymmetric AR(1)-GARCH(1,1) process with non-parametric innovations [9] to estimate the univariate marginal cdfs at all time points. We train this GARCH model on nW = 2016 data points and then predict the cdf of the next data point; subsequent cdfs are predicted by shifting the training window by one data point in a rolling-window methodology. The cdf estimates are used to transform the raw logarithmic returns (xt, yt) into a pseudo-sample of the underlying copula (ut, vt) as described in Section 2. We note that any method for predicting univariate cdfs could have been used to produce pseudo-samples from the copula. We then perform\nthe rolling-window predictive likelihood experiment on the transformed data. The results are shown in Table 4; overall the best technique is GPCC-T, followed by GPCC-G. The dynamic copula methods GPCC-[G,T,SJC], HMM, and TVC outperform the static methods CONST-[G,T,SJC] in all the analyzed series. The dynamic method DSJCC occasionally performed poorly; worse than the static methods for 3 experiments.\nMethod AUD CAD JPY NOK SEK EUR GBP NZD GPCC-G 0.1260 0.0562 0.1221 0.4106 0.4132 0.8842 0.2487 0.1045 GPCC-T 0.1319 0.0589 0.1201 0.4161 0.4192 0.8995 0.2514 0.1079 GPCC-SJC 0.1168 0.0469 0.1064 0.3941 0.3905 0.8287 0.2404 0.0921 HMM 0.1164 0.0478 0.1009 0.4069 0.3955 0.8700 0.2374 0.0926 TVC 0.1181 0.0524 0.1038 0.3930 0.3878 0.7855 0.2301 0.0974 DSJCC 0.0798 0.0259 0.0891 0.3994 0.3937 0.8335 0.2320 0.0560 CONST-G 0.0925 0.0398 0.0771 0.3413 0.3426 0.6803 0.2085 0.0745 CONST-T 0.1078 0.0463 0.0898 0.3765 0.3760 0.7732 0.2231 0.0875 CONST-SJC 0.1000 0.0425 0.0852 0.3536 0.3544 0.7113 0.2165 0.0796\nTable 4: Avg. test log-likelihood of each method on the currency data.\nThe proposed method GPCC-T can capture changes across time in the parameters of the Student’s t copula. The left and middle plots in Figure 3 show predictions for ν(t) and τ(t) generated by GPCCT. In the left plot, we observe a reduction in ν(t) at the onset of the 2008-2012 global recession indicating that the return series became more prone to outliers. The plot for τ(t) (middle) also shows large changes across time. In particular, we observe large drops in the dependence level between EUR-USD and CHF-USD during the fall of 2008 (at the onset of the global recession) and the summer of 2010 (corresponding to the worsening European sovereign debt crisis).\nFor comparison, we include predictions for τL(t) and τU (t) made by GPCC-SJC in the right plot of Figure 3. In this case, the prediction for τU (t) is similar to the one made by GPCC-T for τ(t),\nbut the prediction for τL(t) is much noisier and erratic. This suggests that GPCC-SJC is less robust than GPCC-T. All the copula densities in Figure 1 take large values in the proximity of the points (0,0) and (1,1) i.e. positive correlation. However, the Student’s t copula is the only one of these three copulas which can take high values in the proximity of the points (0,1) and (1,0) i.e. negative correlation. The plot in the left of Figure 3 shows how ν(t) takes very low values at the end of the time period, increasing the robustness of GPCC-T to negatively correlated outliers."
    }, {
      "heading" : "5.3 Equity Time Series",
      "text" : "As a further comparison, we evaluated each method on the logarithmic returns of 8 equity pairs, from the same date range and processed using the same AR(1)-GARCH(1,1) model discussed previously. The equities were chosen to include pairs with both high correlation (e.g. RBS and BARC) and low correlation (e.g. AXP and BA).\nThe results are shown in Table 5; again the best technique is GPCC-T, followed by GPCC-G.\nFigure 4 shows predictions for ν(t) generated by GPCC-T. We observe low values of ν during 2010 suggesting that a Gaussian copula would be a bad fit to the data. Indeed, GPCC-G performs significantly worse than GPCC-T on this equity pair."
    }, {
      "heading" : "6 Conclusions and Future Work",
      "text" : "We have proposed an inference scheme to fit a conditional copula model to multivariate data where the copula is specified by multiple parameters. The copula parameters are modeled as unknown nonlinear functions of arbitrary conditioning variables. We evaluated this framework by estimating timevarying copula parameters for bivariate financial time series. Our method consistently outperforms static copula models and other dynamic copula models.\nIn this initial investigation we have focused on bivariate copulas. Higher dimensional copulas are typically constructed using bivariate copulas as building blocks [2, 12]. Our framework could be applied to these constructions and our empirical predictive performance gains will likely transfer to this setting. Evaluating the effectiveness of this approach compared to other models of multivariate covariance would be a profitable area of empirical research.\nOne could also extend the analysis presented here by including additional conditioning variables as well as time. For example, including a prediction of univariate volatility as a conditioning variable would allow copula parameters to change in response to changing volatility. This would pose inference challenges as the dimension of the GP increases, but could create richer models."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We thank David López-Paz and Andrew Gordon Wilson for interesting discussions. José Miguel Hernández-Lobato acknowledges support from Infosys Labs, Infosys Limited. Daniel HernandezLobato acknowledges support from the Spanish Dirección General de Investigación, project ALLS (TIN2010-21575-C02-02)."
    } ],
    "references" : [ {
      "title" : "Multivariate GARCH models: a survey",
      "author" : [ "L. Bauwens", "S. Laurent", "J.V.K. Rombouts" ],
      "venue" : "Journal of Applied Econometrics,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2006
    }, {
      "title" : "Probability density decomposition for conditionally dependent random variables modeled by vines",
      "author" : [ "T. Bedford", "R.M. Cooke" ],
      "venue" : "Annals of Mathematics and Artificial Intelligence,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2001
    }, {
      "title" : "Pattern Recognition and Machine Learning (Information Science and Statistics)",
      "author" : [ "C.M. Bishop" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2007
    }, {
      "title" : "Generalized autoregressive conditional heteroskedasticity",
      "author" : [ "T. Bollerslev" ],
      "venue" : "Journal of Econometrics,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1986
    }, {
      "title" : "A capital asset pricing model with time-varying covariances",
      "author" : [ "T. Bollerslev", "R.F. Engle", "J.M. Wooldridge" ],
      "venue" : "The Journal of Political Economy,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1988
    }, {
      "title" : "Copulas and machine learning",
      "author" : [ "G. Elidan" ],
      "venue" : "In Invited survey to appear in the proceedings of the Copulae in Mathematical and Quantitative Finance workshop,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2012
    }, {
      "title" : "Multivariate simultaneous generalized ARCH",
      "author" : [ "R.F. Engle", "K.F. Kroner" ],
      "venue" : "Econometric theory,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1995
    }, {
      "title" : "Bayesian nonparametric covariance regression",
      "author" : [ "E.B. Fox", "D.B. Dunson" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2017
    }, {
      "title" : "GARCH processes with non-parametric innovations for market risk estimation",
      "author" : [ "J.M. Hernández-Lobato", "D. Hernández-Lobato", "A. Suárez" ],
      "venue" : "In Artificial Neural Networks ICANN 2007,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2007
    }, {
      "title" : "Asymptotic efficiency of the two-stage estimation method for copula-based models",
      "author" : [ "H. Joe" ],
      "venue" : "Journal of Multivariate Analysis,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2005
    }, {
      "title" : "The Copula-GARCH model of conditional dependencies: An international stock market application",
      "author" : [ "E. Jondeau", "M. Rockinger" ],
      "venue" : "Journal of International Money and Finance,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2006
    }, {
      "title" : "Gaussian process vine copulas for multivariate dependence",
      "author" : [ "D. Lopez-Paz", "J.M. Hernández-Lobato", "Z. Ghahramani" ],
      "venue" : "JMLR W&CP",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2013
    }, {
      "title" : "Expectation Propagation for approximate Bayesian inference",
      "author" : [ "T.P. Minka" ],
      "venue" : "Proceedings of the 17th Conference in Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2001
    }, {
      "title" : "The generalized fitc approximation",
      "author" : [ "A. Naish-Guzman", "S. Holden" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2008
    }, {
      "title" : "Modelling asymmetric exchange rate dependence",
      "author" : [ "A.J. Patton" ],
      "venue" : "International Economic Review,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2006
    }, {
      "title" : "Safe haven currencies",
      "author" : [ "A. Ranaldo", "P. Söderlind" ],
      "venue" : "Review of Finance,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2010
    }, {
      "title" : "Gaussian Processes for Machine Learning",
      "author" : [ "C.E. Rasmussen", "C.K.I. Williams" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2006
    }, {
      "title" : "Fonctions de répartition à n dimensions et leurs marges",
      "author" : [ "A. Sklar" ],
      "venue" : "Publ. Inst. Statis. Univ. Paris,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1959
    }, {
      "title" : "Sparse gaussian processes using pseudo-inputs",
      "author" : [ "E. Snelson", "Z. Ghahramani" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2006
    }, {
      "title" : "A multivariate generalized autoregressive conditional heteroscedasticity model with time-varying correlations",
      "author" : [ "Y.K. Tse", "A.K.C. Tsui" ],
      "venue" : "Journal of Business & Economic Statistics,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2002
    }, {
      "title" : "Efficient bayesian multivariate fmri analysis using a sparsifying spatio-temporal prior",
      "author" : [ "M.A.J. van Gerven", "B. Cseke", "F.P. de Lange", "T. Heskes" ],
      "venue" : null,
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2010
    }, {
      "title" : "Generalised Wishart processes",
      "author" : [ "A.G. Wilson", "Z. Ghahramani" ],
      "venue" : "Proceedings of the Twenty-Seventh Conference Annual Conference on Uncertainty in Artificial Intelligence",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2011
    }, {
      "title" : "Dynamic covariance models for multivariate financial time series",
      "author" : [ "Y. Wu", "J.M. Hernandez-Lobato", "Z. Ghahramani" ],
      "venue" : "Proceedings of the 30th International Conference on Machine Learning (ICML-13),",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "Classical methods estimate these dependencies in terms of a covariance matrix (possibly time varying) which is induced from the data [4, 5, 7, 1].",
      "startOffset" : 133,
      "endOffset" : 145
    }, {
      "referenceID" : 4,
      "context" : "Classical methods estimate these dependencies in terms of a covariance matrix (possibly time varying) which is induced from the data [4, 5, 7, 1].",
      "startOffset" : 133,
      "endOffset" : 145
    }, {
      "referenceID" : 6,
      "context" : "Classical methods estimate these dependencies in terms of a covariance matrix (possibly time varying) which is induced from the data [4, 5, 7, 1].",
      "startOffset" : 133,
      "endOffset" : 145
    }, {
      "referenceID" : 0,
      "context" : "Classical methods estimate these dependencies in terms of a covariance matrix (possibly time varying) which is induced from the data [4, 5, 7, 1].",
      "startOffset" : 133,
      "endOffset" : 145
    }, {
      "referenceID" : 5,
      "context" : "However, a more general approach is to use copula functions to model dependencies [6].",
      "startOffset" : 82,
      "endOffset" : 85
    }, {
      "referenceID" : 16,
      "context" : "These latent functions are approximated using Gaussian processes (GP) [17].",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 11,
      "context" : "GPs have previously been used to model conditional copulas in [12] but that work only applies to copulas specified by a single parameter.",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 10,
      "context" : "regime switching models [11] and methods proposing GARCH-style updates to copula parameters [20, 11].",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 19,
      "context" : "regime switching models [11] and methods proposing GARCH-style updates to copula parameters [20, 11].",
      "startOffset" : 92,
      "endOffset" : 100
    }, {
      "referenceID" : 10,
      "context" : "regime switching models [11] and methods proposing GARCH-style updates to copula parameters [20, 11].",
      "startOffset" : 92,
      "endOffset" : 100
    }, {
      "referenceID" : 5,
      "context" : "Copulas provide a powerful framework for the construction of multivariate probabilistic models by separating the modeling of univariate marginal distributions from the modeling of dependencies between variables [6].",
      "startOffset" : 211,
      "endOffset" : 214
    }, {
      "referenceID" : 17,
      "context" : "Sklar’s theorem [18] states that given two one-dimensional random variables, X and Y , with continuous marginal cumulative distribution functions (cdfs) FX(X) and FY (Y ), we can express their joint cdf FX,Y as FX,Y (x, y) = CX,Y [FX(x), FY (y)], where CX,Y is the unique copula for X and Y .",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 9,
      "context" : "Copula models can be learnt in a two step process [10].",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 11,
      "context" : "However, the estimation of CX,Y |Z is constrained to have uniform marginal distributions; this is a problem that has only been considered recently [12].",
      "startOffset" : 147,
      "endOffset" : 151
    }, {
      "referenceID" : 12,
      "context" : "Unfortunately, (3) and (4) cannot be computed analytically, so we approximate them using expectation propagation (EP) [13].",
      "startOffset" : 118,
      "endOffset" : 122
    }, {
      "referenceID" : 2,
      "context" : "EP iteratively updates each g̃i until convergence by first computing q\\i ∝ q/g̃i and then minimizing the Kullback-Leibler divergence [3] between giq and g̃iq.",
      "startOffset" : 133,
      "endOffset" : 136
    }, {
      "referenceID" : 20,
      "context" : "The EP sub-routines are implemented using the parallel EP update scheme described in [21].",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 18,
      "context" : "To speed up GP related computations, we use the generalized FITC approximation [19, 14]: Each n × n covariance matrix Ki is approximated by Ki = Qi + diag(Ki − Qi), where Qi = Kinn0 [K i n0n0 ] [Knn0 ] T, Kin0n0 is the n0 × n0 covariance matrix generated by evaluating (2) at n0 n pseudo-inputs, and Kinn0 is the n×n0 matrix with the covariances between training points and pseudo-inputs.",
      "startOffset" : 79,
      "endOffset" : 87
    }, {
      "referenceID" : 13,
      "context" : "To speed up GP related computations, we use the generalized FITC approximation [19, 14]: Each n × n covariance matrix Ki is approximated by Ki = Qi + diag(Ki − Qi), where Qi = Kinn0 [K i n0n0 ] [Knn0 ] T, Kin0n0 is the n0 × n0 covariance matrix generated by evaluating (2) at n0 n pseudo-inputs, and Kinn0 is the n×n0 matrix with the covariances between training points and pseudo-inputs.",
      "startOffset" : 79,
      "endOffset" : 87
    }, {
      "referenceID" : 16,
      "context" : "Each time we call the j-th EP subroutine, we optimize the corresponding kernel hyper-parameters λj , βj and γj and the pseudo-inputs by maximizing the EP approximation of the model evidence [17].",
      "startOffset" : 190,
      "endOffset" : 194
    }, {
      "referenceID" : 11,
      "context" : "The model proposed here is an extension of the conditional copula model of [12].",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 10,
      "context" : "In [11] a dynamic copula model is proposed based on a two-state hidden Markov model (HMM) (St ∈ {0, 1}) that assumes that the data generating process changes between two regimes of low/high correlation.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 19,
      "context" : "A time-varying correlation (TVC) model based on the Student’s t copula is described in [20, 11].",
      "startOffset" : 87,
      "endOffset" : 95
    }, {
      "referenceID" : 10,
      "context" : "A time-varying correlation (TVC) model based on the Student’s t copula is described in [20, 11].",
      "startOffset" : 87,
      "endOffset" : 95
    }, {
      "referenceID" : 14,
      "context" : "In [15] a dynamic copula based on the SJC copula (DSJCC) is introduced.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 4,
      "context" : "A direct extension of the GARCH equations to multiple time series, VEC, was proposed by [5].",
      "startOffset" : 88,
      "endOffset" : 91
    }, {
      "referenceID" : 6,
      "context" : "The VEC model has a very large number of parameters and hence a more commonly used model is the BEKK(p, q) model [7] which assumes the following dynamics",
      "startOffset" : 113,
      "endOffset" : 116
    }, {
      "referenceID" : 22,
      "context" : "An alternative solution to over-fitting due to over-parameterization is the Bayesian approach of [23] where Bayesian inference is performed in a dynamic BEKK(1, 1) model.",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 21,
      "context" : "Other Bayesian approaches include the non-parametric generalized Wishart process [22, 8].",
      "startOffset" : 81,
      "endOffset" : 88
    }, {
      "referenceID" : 7,
      "context" : "Other Bayesian approaches include the non-parametric generalized Wishart process [22, 8].",
      "startOffset" : 81,
      "endOffset" : 88
    }, {
      "referenceID" : 15,
      "context" : "CHF is known to be a safe haven currency, meaning that investors flock to it during times of uncertainty [16].",
      "startOffset" : 105,
      "endOffset" : 109
    }, {
      "referenceID" : 8,
      "context" : "We first process our data using an asymmetric AR(1)-GARCH(1,1) process with non-parametric innovations [9] to estimate the univariate marginal cdfs at all time points.",
      "startOffset" : 103,
      "endOffset" : 106
    }, {
      "referenceID" : 1,
      "context" : "Higher dimensional copulas are typically constructed using bivariate copulas as building blocks [2, 12].",
      "startOffset" : 96,
      "endOffset" : 103
    }, {
      "referenceID" : 11,
      "context" : "Higher dimensional copulas are typically constructed using bivariate copulas as building blocks [2, 12].",
      "startOffset" : 96,
      "endOffset" : 103
    } ],
    "year" : 2013,
    "abstractText" : "The estimation of dependencies between multiple variables is a central problem in the analysis of financial time series. A common approach is to express these dependencies in terms of a copula function. Typically the copula function is assumed to be constant but this may be inaccurate when there are covariates that could have a large influence on the dependence structure of the data. To account for this, a Bayesian framework for the estimation of conditional copulas is proposed. In this framework the parameters of a copula are non-linearly related to some arbitrary conditioning variables. We evaluate the ability of our method to predict time-varying dependencies on several equities and currencies and observe consistent performance gains compared to static copula models and other timevarying copula methods.",
    "creator" : null
  }
}