{"title": "The Pareto Regret Frontier", "abstract": "Performance guarantees for online learning algorithms typically take the form of regret bounds, which express that the cumulative loss overhead compared to the best expert in hindsight is small. In the common case of large but structured expert sets we typically wish to keep the regret especially small compared to simple experts, at the cost of modest additional overhead  compared to more complex others. We study which such regret trade-offs can be achieved, and how.  We analyse regret w.r.t. each individual expert as a multi-objective criterion in the simple but fundamental case of absolute loss. We characterise the achievable and Pareto optimal trade-offs, and the corresponding optimal strategies for each sample size both exactly for each finite horizon and asymptotically.", "id": "74071a673307ca7459bcf75fbd024e09", "authors": ["Wouter M. Koolen"], "conference": "NIPS2013", "accepted": true, "reviews": [{"comments": "This paper concerns regret against individual actions in the full-information online prediction setting. Instead of trying to bound the regret uniformly for all experts (actions), the work gives characterization of what \"regret profiles\" are achievable for the most basic case of binary prediction with absolute loss. The author(s) call a profile < r0,r1 > T-realizable if there exists an algorithm that guarantees regret r0 and r1 against constant predictions 0 and 1, respectively, given any (non-oblivious) adversary. An example for a trivial T-realizable profile is < 0,T >. \n\nThe paper exactly (even constants) characterizes the Pareto-front of all T-realizable profiles for any T in the basic case of two actions and absolute loss. Then they use the result to prove an asymptotic bound. The paper also provides algorithms that achieve the realizable profiles. \n\nThe paper is well written, the problem is well motivated, the proofs seem sound. The problem of satisfying non-uniform regret bounds is an interesting new line of research. This paper takes the first steps in this new direction. \n\n\n\nSome comments: \n\nIn Definition 1, the paper reveals that the adversary model considered is the non-oblivious (adaptive) one. I would prefer if it was mentioned more explicitly and at an earlier point in the paper. Especially because Lemma 3 does not go through for oblivious adversaries. \n\nI found the second part of Theorem 6 confusing. First I thought it was a full description of the algorithm that achieves the vertices of the Pareto-front. Only later I realized that it is just some fact about what the algorithm does at three particular time steps. Maybe say this explicitly or just leave out this part. \n\nHow do the new bounds relate to the old uniform regret bound of \\sqrt{T/2 \\ln K}? I would have liked to see some discussion about this, especially since the above bound is asymptotically optimal. \n\nThe algorithms that prove the upper bounds seem to be highly inefficient computationally. It would be nice to have algorithms that are more efficient and have regret bounds close to the optimal ones. This work gives optimal bounds for regret-profiles against each constant action in online learning. The paper is technically sound and it opens a new line of research in regret analysis.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The authors give an exact characterization of the tradeoffs achievable between regret-vs-expert-0 and regret-vs-expert-1 in a two expert problem with known horizon T. They provide an algorithm for achieving any tradeoff on the Pareto frontier, with the point corresponding to an equal bound on each expert\u2019s regret recovering the standard definition. They also consider the asymptotic behavior of this tradeoff curve. \n\nThe primary contributions of the paper are Theorems 6 and 8. These are nice results, particularly Thm 6 which provides a tight minimax characterization. It would be nice if more motivation for the key function f_T(i) was provided, it seems to appear magically. I suspect there are some Rademacher random variables and binomial probabilities underneath this somewhere, with Thm 8 coming from something like a normal approximation to the binomial. Unfortunately, these results are also quite limited in that they only apply to the K=2 expert case. Sec 4.1 points out that for K=2 the the sqrt(min log prior) frontier is weaker, but this does not seem surprising, since this bound comes from an algorithm that is not minimax optimal. \n\nTheorem 10 is also important, as it shows Thms 6 and 8 apply to the general experts problem in 2 dimensions, rather than just to the special case of the absolute loss. The proof suggests, in fact, that one could simply re-state the paper in terms of the more general problem; I think this would be a better presentation, but at a minimum Thm 10 should be moved earlier in the paper. \n\nI\u2019m not clear on what Sec 5.2 is trying to accomplish. It seems to indicate that standard sqrt(T log K) bounds can be recovered from the K=2 algorithm presented here. But the authors need to be clear about this, and argue why it is useful or interesting. After all, we already have much simpler algorithms that achieve this bound. \n\nThe main drawback of the paper is that it does not address the K > 2 case, which is clearly the one of the most practical interest. \n\n The authors fully characterize the Pareto frontier for prediction with expert advice, but unfortunately only in the rather limited case of 2 experts.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper studies regret guarantees in prediction with expert advice that are simultaneously achievable against each individual expert. The problem is essentially solved for the case of two constant binary experts under the absolute loss (or dot loss). In particular, the finite-time and asymptotical region of achievable pairs are computed. Connections to random playout and bounds in terms of log prior weights are discussed. \n\nThis is a solid and well written paper that explores a new direction in the theory of prediction with expert advice. The results are precise and mathematically elegant, although a bit narrow in scope. I do not expect a significant impact on the NIPS community, although there is a latent potential here that futher research might be able to fully express. \n\nThe techniques seem to strongly rely on the linearity of the loss, it would be good to say something about, say, convex and Lipschitz losses. \n\nThe minimax algorithm for absolute loss and fixed horizon has been first proposed in: N. Cesa-Bianchi et al., How to use expert advice. Journal of the ACM, 44(3):427-485, 1997. Please fix the reference. \n\n=============================== \n\nI have read the authors' rebuttal. A solid and elegant paper with somewhat narrow results. I would accept it, although I expect it to be interesting only for a small fraction of the NIPS community", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
