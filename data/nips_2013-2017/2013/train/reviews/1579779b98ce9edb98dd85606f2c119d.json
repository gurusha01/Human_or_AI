{"title": "Convergence of Monte Carlo Tree Search in Simultaneous Move Games", "abstract": "", "id": "1579779b98ce9edb98dd85606f2c119d", "authors": ["Viliam Lisy", "Vojta Kovarik", "Marc Lanctot", "Branislav Bosansky"], "conference": "NIPS2013", "accepted": true, "reviews": [{"comments": "This paper studies Monte Carlo tree search in zero-sum extensive form games with perfect information and simultaneous moves. It is proved that the MCTS algorithm converges to an approximate Nash equilibrium under certain conditions. Empirical study confirms the formal result. \n\nThe detailed comments are as follows. \n1. Overall I think it is a good paper which provides a sufficient condition for the convergence of MCTS algorithms. The result is useful and the presentation is clear. However, as the main contribution of the paper should be the theoretical part, I have concern on the novelty of the proof technique. \n2. UCB algorithms are widely used algorithms in the literature but they are not analyzed in this paper. Given there have been some analysis on the UCB for Trees, it will be better that the authors also consider UCB algorithms and compares them with other algorithms in the paper. \n3. It is only proved that the propagation of the mean has good convergence. However, in the experiments the propagation of current sample value also seems good under different criteria. Can you give some explanation? \n This paper studies Monte Carlo tree search in zero-sum extensive form games with perfect information and simultaneous moves. The findings in the paper are interesting, however, technically speaking, the paper is not very outstanding.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper analyzes the class of zero-sum perfect-information simultaneous move games. There are some interesting games in this class e.g. goofspiel and Tron. The authors analyze MCTS, implemented with regret-matching for this class of games and prove convergence to an approximate Nash equilibrium. \n\nThe paper is clear and well-written, and the results are well-presented. The main contribution is new results in the formal analysis. Previous work, that the authors cited [20] Lanctot et al, 2013, looks at the setup but has more preliminary analysis. The proof is inductive - with optimal strategies at the leaf nodes. \n\nI think the biggest weakness in this type of approach is that not very interesting things can be proved about the inner nodes of the game tree. This misses out on some key ideas in game theory: Subgame perfect nash equilibria. I think the paper can be improved by tying the analysis to those concepts. Recommended citation: \n\"Existence of subgame perfect equilibria in games with simultaneous moves\". C. Harris 1990. This paper presents novel analyses of regret-matching strategy with MTCS in zero-sum perfect information simultaneous move games. While interesting from a computational standpoint, the analyses misses out on tying to powerful tools of sub-game perfect Nash equilibria for these class of games; something that has been well-studied by Game Theorists.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The authors present an analysis for a class of Monte Carlo tree search algorithms using essentially (with some mild restrictions), any no-regret selection method. Their primary theoretical contribution is a proof of convergence to epsilon-Nash in the case of simultaneous moves. \n\nOne weakness is that the convergence is asymptotic (no rates are provided) which is a necessary consequence of the authors' analysis since the selection method is assumed only to be epsilon-Hannan consistent. This is not necessarily detrimental since, as far as I can tell, there don't seem to exist any proofs of convergence for MCTS methods for extensive-form games with simultaneous moves. \n\nHowever, I think the question of rates is important, since we know that backwards induction will give us an exact equilibrium anyway. Do the authors know what rates are attained when a specific regret rate is assumed for the selection method, for example, by using the \\sqrt{T} guaranteed by exp? \n\nThe authors conclude with some experiments. They compare the approach of propagating mean reward values used in their analysis to the standard approach of propagating the current sample value. They find that mean values slightly underperform experimentally. Finally, they attempt to experimentally derive some insight on the convergence rate. \n\nTo conclude: This is a well-written paper that is technically correct. I have a mild reservation regarding the ultimate significance of the work given the lack of convergence rates. On the one hand, MCTS methods are knows to work well in practice, so even if rates don't follow from the authors' analysis, establishing asymptotic convergence is a good first step. On the other hand, convergence results are already known for MCTS with sequential moves, so the result feels a little incremental. \n\nNitpicks \nFigure 1: leafs --> leaves \nLine 144: negated, not \"inverted,\" right? \nLine 10 of Algorithm 1: I think (a_1,a_2) should be (i,j), or possibly (\\sigma_1,\\sigma_2). This is especially confusing since a_{i,j} was introduced as notation for the payoffs in a single-stage matrix game. \nLine 172: It seems like notation hiccups from (i,j) to a's might continue throughout the paper. I'll stop pointing them out, but these should be edited.  This was a well-written paper, that I enjoyed reading. I have some reservations about its impact, given the lack of convergence rates in the analysis.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
