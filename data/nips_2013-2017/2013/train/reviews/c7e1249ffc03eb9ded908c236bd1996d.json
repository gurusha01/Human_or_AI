{"title": "Generalized Random Utility Models with Multiple Types", "abstract": "We propose a model for demand estimation in multi-agent, differentiated product settings and present an estimation algorithm that uses reversible jump MCMC techniques to classify agents' types. Our model extends the popular setup in Berry, Levinsohn and Pakes (1995) to allow for the data-driven classification of agents' types using agent-level data. We focus on applications involving data on agents' ranking over alternatives, and present theoretical conditions that establish the identifiability of the model and uni-modality of the likelihood/posterior. Results on both real and simulated data provide support for the scalability of our approach.", "id": "c7e1249ffc03eb9ded908c236bd1996d", "authors": ["Hossein Azari Soufiani", "Hansheng Diao", "Zhenyu Lai", "David C. Parkes"], "conference": "NIPS2013", "accepted": true, "reviews": [{"comments": "This paper is related with the problem of demand estimation in multi-heterogeneous agents, specifically, to classify agents and estimate preferences of each agent type using agents\u2019 ranking data of different alternatives. The problem is important since it has great practical value in studying underlying preference distributions of multiple agents. To tackle the problem, the authors introduce generalized random utility models (GRUM), provide RJMCMC algorithms for parameter estimation in GRUM and theoretically establish conditions for identifiability for the model. Experimental results on both synthetic and real dataset show the model\u2019s effectiveness. \n\nIn general, this paper is a comprehensive and solid work. Not only does it provide a detailed algorithm for parameter estimation in the model, as well as experiments to verify it, but also it gives non-trivial theoretical analysis for the conditions of model\u2019s identifiability. I have gone through most of the lengthy proof and to my knowledge found no bugs. Therefore even though the GRUM model has been proposed in an earlier work in UAI, which decreases the innovation of this work by some content, I think this paper deserves to be accepted. \n\nSome minor suggestions: \n1) The authors should clarify the relation of their work with the original GRUM models, including what the former works have done, and what needs to be analyzed more deeply (such as analysis of identifiability). These should be included in Related Literature. \n2) To verify the effectiveness of the new model, the experiments\u2019 scale can be more enlarged, since setting K=4 and L=3 (these two corresponds to feature number) includes too little information of agents and alternatives. \n The paper studies an important problem, and the proposal is solid.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper addresses the problem of identifying the type of each agents from his/her partial preference data, in order to use this information to better estimate the underlying preferences for each type. The authors propose a Generalized RUM to model the behavior of such clustered agents. A reversible jump MCMC technique is used to estimate the latent variables, including the types of the agents. A theoretical analysis of the identifiability of the model and uni-modality of the likelihood posterior are presented. \n\nQuality \n\nThere are three contributions of this paper. The new GRUM model, theoretical analysis, and inference algorithm. The model is a generalization of RUM model to multiple agents with types, which is new. Theoretical guarantees are interesting, but have limitations discussed below in the significance section. The inference algorithm is quite standard and the numerical analysis is not impressive, either on the simulated data or the real world datasets. Only the performance of estimating the number of clusters is addressed, while the main problem is in clustering agents. A much more relevant numerical simulation would be simulating how the number of misclustering depends on problem parameters such as number of clusters, how much the matrix W differ between clusters, missing data, etc. \n\nClarity \n\nSome claims could be better explained. \n\nOn page 2, it is not clear what the authors mean by the first paragraph of section 1.1. Which aspects of the model eliminates unrealistic substitution patterns? and avoid the situation where removing the top choices result in the same alternative choice? \n\nOn page 2, it is not clear from the numerical results that \"the clustering of types provides a better fit to real world data\". \n\nOn page 5, in the definition of `nice' pdfs, $\\phi^{(n)}(x)$ is used without proper definition, which makes the conditions difficult to understand. For instance, given \\phi is a pdf, g_n should be non-negative. But g_n(x1)/g_n(x_2) converges to -1. \n\nThe definition of `nice' cdf's is not intuitive and no explanation is given as to why the model might not be identifiable if noise cdf is not `nice'. \n\nOn page 7, it is claimed that \"It can be seen that GRUM with 3 types has significantly better performance than...\". However, from the table, it seems like the gain is only marginal. How significant is the gain of 2~3 % in the log posterior? \n\nOriginality \n\nThis paper extends the definition of RUM model to the setting where there are multiple alternatives and multiple agents. The correlation between the agents are modelled via types that an agent belongs to. RJ-MCMC approach seems to be quite standard. \n\nSignificance \n\nThe main results on the theoretical guarantees are interesting, but the application is limited. For theorem 1, unimodality is only established when the types are known (as clearly explained in the paper). This limits the convergence of MCMC approach, and it is not clear how long one should run the MCMC in practice. This paper does not explain why the proposed problem is difficult. Why has this problem not been addresses so far, as the authors claim? Further, because there is no comparisons either in theoretical results or numerical results, it is difficult to judge how good the proposed algorithm is. \n Theoretical guarantees are interesting, but has limitations. A comparison to fundamental limit or other approaches is lacking, either in theory or simulations.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "the paper discussed random utility models with \"Types\". The definition of \"type\" in this work is the formula that \ncombines agent's attributes with those of a given alternative, giving rise to a perceived value. It doesn't necessarily \nmean that two agents of the same \"type\" have the same taste, or preference profile. In that sense, this model is \nquite expressive. the observations are complete rankings of the set of alternatives, as induced by the perceived valures. \n\nAside from defining this model, the theoretical contribution, as far as I can see, is as follows: \n(1) identifiability of the model in case the types are known \n(2) identifiability of the model in case of unobserved types for a certain class of cdfs governing the noise. \n\nThe algorithmic contribution is a RJMCMC heuristic for recovering the model parameters from the observations. \nExperiments contain both synthetic data and data from a sushi response experiment from [26]. \n\nStrengths \n--------- \nThis model is new, as far as I know. The sushi experiments somewhat justifies it because the best fit \ncomes from assuming 3 \"types\", and not just \"1\". (see also my remark below). \nThe identifiability result (2) is intesting [note that identifiability result (1) is not very \nsurprising - it is basically the same as the full rank requirement in linear regression]. \n\nWeaknesses \n---------- \n1. Although the model is original, I am not sure I see why latent \"types\" are better than, say, assuming \nthat each individual and each alternative have some more features that are latent. This is basically what you often do in \ncollaborative filtering. From a computational point of view this would give a non-convex optimization problem, but \nthen, so is the model here. It would have been nice to compare both approaches. \n\n2. In section 1.2 you say that this paper allows for inference at finer levels of aggregation such as the individual level, \nwhereas the cited works (e.g. [7]) do not. In the experiments however, I don't see any attempt to showcase this \nfiner inference ability, and hence I conclude that you could have compared your results with those cited in section 1.2 \nin some way. I mean, it is very nice to know that the sushi data has best fit with 3 types, but this in no way supports \nyour claim on \"individual level inference\". \n\n\n\ndetailed comments \n----------------- \nlast paragraph in page 1 (continuing on page 2) - Regarding the \"unresolved issue\" of \"restrictive functional \nassumptions about the distribution...\". The reader feels like this work is about to resolve this issue, but \nI don't see how. don't you still make assumptions about the \"taste shock\"? \n\nsection 3.1: first sentence is very bad \n\nlast sentence on page 4: which equality? put the equality in display math and refer to it using \\ref{} \n\nlast sentence on page 5: why is a theorem a problem? \n\npage 6: \"a enough\"---> \"enough\" \n random utility model with \"types\" with statistical identifiability results, a proposed algorithm and experiments. model new, some theoretical novelty, experiments a bit disappointing.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
