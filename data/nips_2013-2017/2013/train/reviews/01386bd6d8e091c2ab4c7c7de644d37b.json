{"title": "Inferring neural population dynamics from multiple partial recordings of the same neural circuit", "abstract": "Simultaneous recordings of the activity of large neural populations are extremely valuable as they can be used to infer the dynamics and interactions of neurons in a local circuit, shedding light on the computations performed. It is now possible to measure the activity of hundreds of neurons  using 2-photon calcium imaging. However, many computations are thought to involve circuits consisting of thousands of neurons, such as cortical barrels in rodent somatosensory cortex. Here we contribute a statistical method for stitching\" together sequentially imaged sets of neurons into one model  by phrasing the problem as fitting a latent dynamical system with missing observations. This method allows us to substantially expand the population-sizes for which population dynamics can be characterized---beyond the number of simultaneously imaged neurons. In particular, we demonstrate using recordings in mouse somatosensory cortex that this method makes it possible to predict noise correlations between non-simultaneously recorded neuron pairs.\"", "id": "01386bd6d8e091c2ab4c7c7de644d37b", "authors": ["Srini Turaga", "Lars Buesing", "Adam M. Packer", "Henry Dalgleish", "Noah Pettit", "Michael Hausser", "Jakob H. Macke"], "conference": "NIPS2013", "accepted": true, "reviews": [{"comments": "The paper contributes a statistical method to \u201cstitch\u201d together sequentially imaged sets of neurons. Such a method expands the population sizes for which population dynamics can be characterized beyond the number of simultaneously imaged neurons and provide a better image of the circuit which cannot be imaged as a whole for experimental and technical limitations. The method is then applied on simulated data as well as on experimental calcium imaging data in mice. Authors show that they can estimate correlations in variability across two populations which were not imaged simultaneously. \nThe Authors model the problem as fitting a latent dynamical system with missing observations. In this case they used simple linear Gaussian system. Four parameters were defined in the model: a functional coupling matrix, a stimuli receptive fields\u2019 matrix which models the stimulus dependence of the population activity and two covariance matrices for neural and measurement noise. The parameters were estimated from experimental data using a variant of standard EM algorithm. \n\nQuality \nThe model works nicely on the simulated data with two non-overlapping populations of neurons but when applying on real data populations must have a certain level of overlap to get reasonable results. It is clear why the greater the overlap the better the results are, the question is why wasn\u2019t overlap necessary in the simulated data example? \nAlso, the authors do not address the source for the great difference in correlation shown when applying the model on simulated data as in fig 2c and on real data as in fig 3b \nThe beauty of the model is the recovery of pairwise correlations between non-simultaneously measured neuron pairs. \n\nClarity \nThe paper is well written, although all figure legends are not descriptive enough and the text related to the figures in the body of the paper does not elaborate enough on the figures. \n\nOriginality \nThe authors list several works which have addressed the question of inferring functional connectivity from 2-photon imaging data or electrophysiological measurements. However, these works do not infer functional connections of non-simultaneously imaged neurons. \n\nSignificance \nThere are many fundamental limits to the number of neurons which can be simultaneously imaged. That of course, limits our capabilities to reveal the nature of the neural computation at the level of the circuit (or more than a few hundreds of cells). This paper suggests a method for expanding these limited capabilities. \n Overall, this is a good model paper, which uses a relatively simple linear dynamics model and captures measures which are not easy to retrieve otherwise.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper shows that you can infer network properties of a large network by sequentially recording from subnetworks and then stitching the resulting sub-models. Extended to point-process data, this could be applied to a lot of datasets where the typically a few of the channels are moved every day. I am not really aware of any similar work (J. W. Pillow and P. Latham, \u201cNeural characterization in partially observed populations of spiking neurons\u201d seems to come the closest), and it seems like a powerful idea. \n\nIn practice it's not clear how much this method is limited to data that is close to linear-Gaussian, and I don't get a good intuition from the paper how the fitting might break down from various deviations to the assumption. In the extreme case, where the full model can be estimated from one subset (up to a linear transformation of the latent dimensions, as the authors state), it's not clear how much additional information about the coupling matrix is gained from adding on other subsets, as opposed to, say, just using more data from one of the subsets. \n\nAnother point that raises some questions is, why does the model on real data only work if there is some overlap between the two population? Obviously this suggests that the linear-Gaussian simulated data does not tell the full story, but it would be nice to have at least some intuition what the overlap does to better constrain the model. \n\nIn the experiments on real data, where the linearity assumption probably breaks, one must also wonder how much of the explained noise correlations (which are fit well, the couplings themselves hardly correlate to the true couplings at all in 3b) are due to common input and not direct, pair-wise couplings. I would assume that the noise correlations could be better modeled with latent variables than pairwise couplings. \n\nThe authors devote a lot of space to intro and discussion, but are awefully light on the details of the estimation. The equation for the M step on the bottom of page 3 is presented as the main contribution, but not really explained or derived. Maybe it's a trivial result to LDS experts, but that would erode a lot of the novelty of the paper. I think the authors had a very good idea, but it just needs to be explained better to properly convey the significance of the result. \n\n A neat idea tested against real data, but some details aren't clear.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
