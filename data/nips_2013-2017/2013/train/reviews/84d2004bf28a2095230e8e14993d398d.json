{"title": "Distributed Submodular Maximization: Identifying Representative Elements in Massive Data", "abstract": "Many large-scale machine learning problems (such as clustering, non-parametric learning, kernel machines, etc.) require selecting, out of a massive data set, a manageable, representative subset. Such problems can often be reduced to maximizing a submodular set function subject to cardinality constraints. Classical approaches require centralized access to the full data set; but for truly large-scale problems, rendering the data centrally is often impractical.  In this paper, we consider the problem of submodular function maximization in a distributed fashion. We develop a simple, two-stage protocol GreeDI, that is easily implemented using MapReduce style computations. We theoretically analyze our approach, and show, that under certain natural conditions, performance close to the (impractical) centralized approach can be achieved. In our extensive experiments, we demonstrate the effectiveness of our approach on several applications, including sparse Gaussian process inference on tens of millions of examples using Hadoop.", "id": "84d2004bf28a2095230e8e14993d398d", "authors": ["Baharan Mirzasoleiman", "Amin Karbasi", "Rik Sarkar", "Andreas Krause"], "conference": "NIPS2013", "accepted": true, "reviews": [{"comments": "This paper describes a two-stage approach to distributed submodular maximization, known as GreeDi. Error bounds are derived for the GreeDi algorithm, which provide a theoretical guarantee on the greedy approximate solution to the centralized solution. The authors demonstrated the effectiveness on 6 data sets. \n\nHere are my comments. \n1. It is confusing to have kappa and k in Theorem 4.2. It is hard to distinguish them in reading. \n2. Regarding the bound in Theorem 4.2, it would be helpful to comment on the tightness. I note that there is a factor min(m,k) inside. \n3. In experiments, it would be informative to report generalized performance, such as negative log predictive probability. The decrease on objective functional is expected, while it is interesting to know how much it affect generalization. \n4. It is unclear which experiments are handling decomposable functions in Section 5. \n5. In Figure 1(e), the label on x axis should be k. \n6. In Figure 1(f), why the ratio at the smallest m starts below 1, while it starts from 1 in Figure 1(a)-1(d). \n7. How do we explain the dip when k=10 in Figure 1(c)? \n8. Adding references to Today Module of Yahoo!, that helps readers carry out related research. \n It is an interesting study for distributed data mining.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "I think this is a really nice paper. It's addressing an important problem area, gives a simple practical algorithm that's easily implemented, and the empirical results are good. The theoretical analysis is well done and honest (this approach won't always work well, but the assumptions that need to be made are reasonable for learning tasks). \n\nMy main criticism of the paper is that it feels squeezed for space. The experimental section, in particular, is much too terse around explanations of baseline comparison methods and explication of the results. (Figure 1 has a ton going on in it.) I find the strong performance of greedy/max interesting in itself any maybe worth a little discussion. Also, there's no discussion of run-time or cpu cost for any of the methods -- odd for a paper that's pushing on scalability, and should definitely be addressed. \n\nI'm surprised that the idea of lazy evaluation wasn't discussed more in this paper. This seems to give huge wins for efficiency, and should certainly be mentioned as a practical trick for a scalability paper, since some of the folks looking at this may be more engineering-oriented and not know about this. I also wonder if lazy-evaluation + mapreduce is a useful way to get by without the approximation method of this paper -- if you can eat the cost of the first round to select the first element, subsequent rounds will be really very cheap. (You can do things like \"evaluate next 100 from the list\" in parallel; if you hit on #55 on the list you've wasted some computation but are still doing fine compared to a full evaluation of all candidates). The first paragraph of 3.2 suggests that this is impractical for large k, but for large k things are expensive anyway. \n\nThe phrase \"diminishing returns\" should be mentioned in the introductory part of section 3 (or in the introduction). I feel this is the most intuitive way to understand submodularity, for those who are not familiar with it. \n\nIn the paper, it's not clear what's meant by \"fit on one machine\". Is the issue what can fit in RAM? On disk? The amount of CPU processing available? The first paragraph of section 2 makes it seem like CPU cost is the main bottleneck, but often times disk i/o is equally large an issue. What benefits (if any) can we get from a large-RAM machine with 16 or more cores? \n\nSince I'm asking for more detail in some places, I need to propose some things to cut: \n-- I'd definitely cut section 6 -- it doesn't add anything to the paper. \n-- I think we can also live without pseudo-code for algorithm 1. \n-- The first two sentences of paragraph 3 of section 1, and the last sentence of this paragraph, can be cut. The remaining sentence can be merged with the one above it. \n-- The first paragraph of section 2 can be significantly shortened. \n-- Paragraphs 2 and 3 of section 3.2 can be cut. (You might also mention the naive approach of sampling the data set down to a size that can fit on one machine and run the standard algorithm here.) \n\n\n The paper proposes a simple but novel method for submodular maximization in a distributed framework. They show that it is a sound approach with theoretical analysis under some reasonable assumptions, and report good results across several possible applications.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper introduces the GreeDi algorithm to maximize monotone submodular functions subject to a cardinality constraint in a distributed system environment, in particular mapreduce. The authors experiment against an exhaustive array of datasets and also prove that the distributing of work across many machines maintains the objective to within a reasonable bound of a centralized algorithm. \n\nThe function optimized must be \"decomposable\" i.e. composed of the sum of many submodular functions, so that the function does not depend on the entire dataset. \n\nI would like to see the following questions explicitly answered: \n\n1) Exactly How much communication is required between the mappers and reducers in the mapreduce implementation? i.e. how much data needs to be shuffled? this is the communication cost in this setup. \n\n2) Exactly how many items could be reduced to a single key? This measures how overloaded a single machine may become. \n\n3) How many iterations needed in the worst case? This paper introduces the GreeDi algorithm to maximize monotone submodular functions subject to a cardinality constraint in a distributed system environment, in particular mapreduce. The authors experiment against an exhaustive array of datasets and also prove that the distributing of work across many machines maintains the objective to within a reasonable bound of a centralized algorithm.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper provides a novel algorithm for large scale submodular function maximization. The main contribution is a distributed algorithm, using MapReduce, where the ground set is partitioned and each machine operates on a subsets of the ground set. These solutions are merged, to find an approximate subset. They provide approximation guarantees for their approach and also show that it is tight. They also investigate the performance of their algorithm under specific assumptions on the datasets or the function. \n\nI think overall the authors try to solve a very challenging problem, which could have a lot of utility in large scale real world applications. I also feel that the experimental validation is thorough and extensive. I also appreciate that this problem is very challenging and it would really hard to obtain satisfactory performance guarantees without additional assumptions. \n\nI was somewhat disappointed with the theoretical analysis. It seems that the guarantees are pretty weak; I acknowledge that the worst case analysis shows that the algorithm is tight. However, this is expected particularly for a very bad choice of partitions V1, V2, ... I was expecting some kind of dependence on the choice of the the distributions, or even a heuristic of what choices of distributions might work. The main guarantee (Theorem 5.1) seems almost a linear factor in m and k, which is somewhat discouraging. As the proof technique reveals, and even otherwise, it is easy to see that a simple modular upper bound based approximation gives a factor k approximation. Given this, it is not immediately clear how GREEDI performs theoretically w.r.t a simple modular upper bound particularly for large m (which is of practical relevance), though I am sure the modular upper bound based algorithm will perform very badly in practice. \n\nThere is one extremely important aspect, however, which is very loosely described in the paper. I think this should be clarified much better. A number of practical submodular functions are graph based submodular functions (this includes, for example, the graph cut like function and the exemplar based clustering objective from 3.1 -- A small clarification here is this objective is essentially a form of facility-location objective with a similarity instead of a distance function) In these cases, evaluating the function requires a sum over all the elements in V, even though the set under which the function needs to be evaluated is considerably smaller. In these cases, it is not clear how to evaluate the function. More specifically, a main motivation of this approach (lines 122-127) is that the datasets are extremely large and would possibly not fit within any single machine. However each of the individual machines would still need to compute the outer sum over V in a graph based objective (say the facility location objective). Under these circumstances, it is not clear how to run the algorithm. Possibly, there could be a time reduction due to the distribution, but it is not clear how this will help in terms of memory. One solution could be to evaluate the function just on the subsets Vi (i.e the outer sum may only be over the Vi's), but this would then change the submodular function and the guarantees would no longer hold. Overall, I think this is a major issue which should be clarified in the rebuttal. \n\nSome minor suggestions are that the proof of theorem 4.1 (specifically the tight instance) is very hard to grasp. Maybe that can be better explained? Also, I think over smaller datasets the actual greedy algorithm should be compared to GREEDI (just to see how the performance is with respect to the best serial algorithm). I would also love to see a timing analysis of the algorithms and memory requirements etc. in the experimental results. \n I think the paper addresses a novel (and challenging) problem of distributed techniques for submodular maximization. This algorithm could have a lot of practical impact. However, the theoretical contribution of this paper is weak.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper is on solving submodular maximization problems at scale. \nIn particular, the paper looks at the classical greedy algorithm for \nsubmodular maximization under cardinality constraints and offers \nmodifications to run these algorithms on massive data. \n\nThe problem itself is quite motivated. There have been a few earlier \nwork on trying to \"speed up\" or \"parallelize\" the inherently \nsequential greedy algorithm for the submodular maximization problem. \nMapReduce as a programming paradigm to express the algorithm is also \nwell motivated. \n\nThe main technical contribution of the paper is an analysis of the \nfollowing two-round algorithm: the input is split across the machines \nand each machine approximates the solution to its part of the input \n(by running a sequential greedy algorithm) and then the individual \nsolutions are combined to obtain the final algorithm. The key point \nhere is for each machine to output a solution of size more than k/m (k \n= desired solution size, m = number of machines). The analysis itself \nis quite simple and the paper shows inherent dependence on both k and \nm. The paper also has sundry results for special cases, for eg, \nsmooth spaces and for decomposable functions. \n\nThe experimental results are reasonable showing the efficacy of the \ntwo-round algorithm when compared to standard greedy. \n\nOn the positive side, the paper addresses an important problem and \nproposes a practical modification of the standard algorithm. \n\nThe main negatives of the paper are the following: \n\n1. The paper is near-trivial on the theory front. The analysis is so \nobvious from a theoretical perspective. Some of the proofs are \nrepetitive in nature and the seemingly strong results stem from quite \nstrong assumptions. Randomized input partition is not taken advantage \nof in Theorem 4.2 (or show a lower bound). \n\n2. There is no round-memory-approximation tradeoff. The paper is \nrestrictive in its results and the approach itself is unclear to be \ngeneralized to multiple rounds. In this sense, it is significantly \nweaker than the earlier work (WWW paper of Chierichetti et al or the \nSPAA paper of Lattanzi et al). \n\n3. The experimental results contain several needless baselines \n(random/random, for example). The authors do not try to bring out the \nimportance of oversampling by modifying the greedy/merge to make \ngreedy as a function of the size of the local solutions. \n\nAdditional comments: \n\n1. The paper should investigate if slightly stronger bounds can be \nproved for Theorem 4.2 when the inputs are randomly partitioned. \n\n2. The authors may want to look at the SPAA 2013 paper of Kumar, \nMoseley, Vassilvitskii, and Vattani that addresses a similar problem \nbut in more general context and provides a multi-round and better \napproximation algorithm. \n\n3. It might be possible to \"merge\" the results in Theorem 4.3 and 4.4 \nsince they seem to be using related assumptions (neighborhood size for \nmetric spaces vs. growth function of a metric, which is the volume). \n\n4. The authors may want to compare their algorithm with the Chierichetti \net al paper and the SPAA 2013 paper. \n\n5. page 4, line 167: \"explain what is \"suitable choice\"\" \n\n6. page 5, line 227: didnt get the comment about \"... unless P = NP\". why does it follow? \n\n A theoretically weak paper addressing an important problem.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
