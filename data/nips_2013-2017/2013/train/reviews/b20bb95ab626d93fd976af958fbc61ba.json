{"title": "Flexible sampling of discrete data correlations without the marginal distributions", "abstract": "Learning the joint dependence of discrete variables is a fundamental problem in machine learning, with many applications including prediction, clustering and dimensionality reduction. More recently, the framework of copula modeling has gained popularity due to its modular parametrization of joint distributions. Among other properties, copulas provide a recipe for combining flexible models for univariate marginal distributions with parametric families suitable for potentially high dimensional dependence structures. More radically, the extended rank likelihood approach of Hoff (2007) bypasses learning marginal models completely when such information is ancillary to the learning task at hand as in, e.g., standard dimensionality reduction problems or copula parameter estimation. The main idea is to represent data by their observable rank statistics, ignoring any other information from the marginals. Inference is typically done in a Bayesian framework with Gaussian copulas, and it is complicated by the fact this implies sampling within a space where the number of constraints increase quadratically with the number of data points. The result is slow mixing when using off-the-shelf Gibbs sampling. We present an efficient algorithm based on recent advances on constrained Hamiltonian Markov chain Monte Carlo that is simple to implement and does not require paying for a quadratic cost in sample size.", "id": "b20bb95ab626d93fd976af958fbc61ba", "authors": ["Alfredo Kalaitzis", "Ricardo Silva"], "conference": "NIPS2013", "accepted": true, "reviews": [{"comments": "The focus is on efficient posterior sampling in copula models for discrete data relying on the Hoff extended rank likelihood. Efficient posterior inference in copula models for discrete data is a topic of substantial interest in my view. The authors algorithm builds on the Hamiltonian MC approach of Pakman and Paninski (2012) for sampling from multivariate Gaussians subject to linear inequality constraints. However, they do not just directly apply the algorithm, but propose a novel approach to reduce the computational burden to O(n) in the sample size by relying on Hough Envelope algorithm. I find the paper very well written and to contain interesting ideas. Hence, the quality, clarity and originality is high. \n\nHowever, I have questions about the significance (see below), which the authors have effectively addressed in their rebuttal. It is important for them to carefully revise their paper to include these improved experiments. \n\nPrevious concerns: \nThe experiment is obviously not compelling. I have applied the Hoff algorithm they are attempting to improve upon and haven't noticed major mixing problems, and Murray et al. (2013) additionally note good mixing in their copula factor model case relying on a similar sampling algorithm. The proposed algorithm is substantially more complicated and in the author's code has 50 times the computational burden per MCMC step while improving effective sample size only modestly. Examining the trace plots presented, it seems that perhaps convergence is substantially faster for the proposed algorithm but not mixing. Also, I wonder if the example shown is carefully chosen to show problems with Hoff's approach in involving a quite big sample size relative to the dimension of the model. In more modest sample sizes, I wonder whether such \"gains\" will be shown. Obviously it would be *much* more compelling to show gains in effective sample size per CPU time, while containing some discussion about the settings in which the gains are expected to be relatively small or large. It seems that Hoff wins easily under such a metric and additionally has the advantage of being substantially simpler. I would have trouble implementing the proposed algorithm based on the brief description given, but wouldn't bother anyway based on these results. \n\n Interesting algorithm addressing an important problem and the paper is well written. In the initial submitted paper the experimental results were extremely weak. However, in the rebuttal, the authors included some additional much more compelling experiments. If these new experiments can be included, then I think the paper is acceptable.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "Summary: \nThe authors develop a novel algorithm for Bayesian inference in copula models for multivariate discrete distributions. Their work follows and extends the work of Hoff (2007), who assumes a Gaussian copula. The aim is inference on the correlation matrix of the Gaussian copula, and Hoff (2007) proposes a Gibbs sampling algorithm that proceeds by first introducing latent variables Z. Conditioned on the latent variables Z and the data, the correlation matrix has an inverse-Wishart distribution and can easily be sampled. Conditioned on the data and the correlation matrix, the latent variables Z have a multivariate truncated normal distribution with regions defined by the order statistics of the data. This last step is the key contribution of the authors; whereas, Hoff (2007) used a separate Gibbs step for each latent Z_{i,j}, the authors proposing using recent advances in constrained Hamiltonian MCMC, which allows them to sample the latent (Z_{i,j}, i=1,...,n) jointly. This improves mixing and speeds up computations. \n\nStrengths: \nThis is a nice, well written paper, and I particularly like how the authors highlight their contribution over previous work. \nAlthough there are no methodological developments, the algorithm developed is practically useful, as it speeds up computations and improves mixing. \n\nWeaknesses: \nThe authors do not mention the work of Damian and Walker (2001) who discuss techniques to sample from multivariate truncated normals using latent variables. How would this approach (or an extension) compare? \npg. 2, line 107, the authors could improve notation by possibly replacing the truncation region D by D(y), so that it is more explicit that the truncation region depends on the data. Otherwise, it appears that the posterior of Z and C doesn't depend on Y. \npg. 3 line 144, should this read log(p(x)) \\propto \u2026 ? \npg. 5 line 258, the notation used in this sentence is not explained. Also should the sentence read Z_{i,j} conditioned on Z_{/i,/j} for Hoff's algorithm? \n\nQuality: This is a technically sound paper that combines recent advances in Hamiltonian MCMC to improve Hoff's algorithm for Gaussian copula models of multivariate discrete distributions. \n\nClarity: This is a clear, well written paper. I especially appreciate the clear emphasis on the contribution of their work over previous work. \n\nOriginality: While there are no novel developments in this paper, they do apply Hamiltonian MCMC methods to produce a practically useful improvement over Hoff's algorithm. \n\nSignificance: The results are important, and I believe will likely be incorporated in extensions of the Gaussian copula models of multivariate discrete distributions. The authors develop a novel algorithm for Bayesian inference in copula models for multivariate discrete distributions that improves upon the algorithm developed by Hoff(2002) by incorporating Hamiltonian MCMC methods. This results in improved mixing and faster computations.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper is concerned with learning Gaussian copulas after the empirical cdf is used to transform the marginals of all data. The challenge in this scenario seems to be linear constraints on the sampling domain, the number of which increases quadratically with the number of data points. The paper proposes a Hamiltonian Monte Carlo sampler where the constraints are handled by the sample trajectory \"bouncing\" off them. Empirical results are given, in particular showing superior performance, for the same number of steps, against the Hoff algorithm. \n\nThe paper seems technically sound, although I have some concerns regarding the empirical results. The presentation is fine, although note minor points below. I have not seen an approach such as this before and believe it to be original, although am not well-abreast of the copula literature, and my confidence score reflects this. The approach does seem quite computationally expensive, and the authors even admit that their MATLAB implementation is not particularly fast, which leaves question marks over potential impact. \n\nMy concerns with the empirical results are: \n\n* The HMC is only run for 1000 steps, while the Hoff is run for 2000. The Hoff is clearly seen to make a few switches after the 1000 step mark, and a reader might worry that the HMC method could do the same. I presume this has been done because the HMC is much more expensive to run (the authors say 50 times so in Footnote 7). I don't doubt the final result, especially looking at the plots in the supplementary material, but for thoroughness it would be good to see the HMC run for 2000 steps, or a plot of posterior densities of each sample that indicates that the jumps of the Hoff algorithm are not due to a second mode, or a discussion point affirming that the posterior is definitely unimodal (which I think is knowable in this case a priori). \n\n* I'd like to see more discussion on the relative computational expense of the HMC and Hoff methods. Footnote 7 makes an excuse, whereas I'd rather see an explanation. Should I expect a good implementation of HMC to be as fast as Hoff? At the moment, with HMC taking 50 times longer, it may be fairer to compare HMC at iteration #50 with Hoff at iteration #2500 in the bottom row of Figure 3. \n\nA few minor points on presentation: \n\n* There's a citation, [12], given for the first time in the conclusion. If this is important it should probably be introduced as related work in the introduction. \n\n* The footnoting might be considered excessive. I'd suggest that some of these could be moved into the text without distracting the reader, especially 2, as it ends a paragraph anyway, but 3, 5, and 7 as well. In fact 5 should be, as it introduces notation, which is required knowledge rather than an aside, and I think 7 also, as, in the context of comments on the empirical results above, it's important to know that the HMC steps take a lot longer to run. \n A decent paper, but a few question marks over the fairness of the empirical results.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
