{"title": "Local Privacy and Minimax Bounds: Sharp Rates for Probability Estimation", "abstract": "We provide a detailed study of the estimation of probability distributions---discrete and continuous---in a stringent setting in which data is kept private even from the statistician.  We give sharp minimax rates of convergence for estimation in these locally private settings, exhibiting fundamental tradeoffs between privacy and convergence rate, as well as providing tools to allow movement along the privacy-statistical efficiency continuum. One of the consequences of our results is that Warner's classical work on randomized response is an optimal way to perform survey sampling while maintaining privacy of the respondents.", "id": "5807a685d1a9ab3b599035bc566ce2b9", "authors": ["John Duchi", "Martin J. Wainwright", "Michael I. Jordan"], "conference": "NIPS2013", "accepted": true, "reviews": [{"comments": "SUMMARY: This paper is a NIPS-formatted version of an ArXiV manuscript, and uses a Fano/LeCam-style argument to derive a lower bound on estimation algorithms that operate on private data when the algorithm is not trusted by the data holder. As a corollary, randomized response turns out to be an optimal strategy in some sense. \n\nAs a caveat to this review, I did not go through the supplementary material. \n\npros and cons: \n- the results provide characterize the limitations of learning from data that has been perturbed to guarantee privacy \n- there is some imprecision in the commentary on the results which could lead a casual reader to become confused (see below) \n- connections to existing results on differential privacy seems to be missing \n\nadditional comments: \n- The restriction to local privacy, which is important for the results, makes the privacy model quite different than the differential privacy model, a fact which many readers may not appreciate. This confusion may be exacerbated by statements such as those at the bottom of page 4: \"Thus, for suitably large sample sizes n, the effect of providing differential privacy at a level $\\alpha$\u2026\" The authors should avoid making such overly broad (and perhaps incorrect) statements when describing their results. \n\n- Is the restriction on alpha in Theorem 1 necessary? In particular, experimental results suggest that $\\alpha \\approx 1$ may be the most one can expect for certain learning problems (under differential privacy), so it is unclear the the bound tells us about this case. \n\n- Some commentary on the possible choices of $\\rho$ may be nice, so that readers can see how different utility measures can be captured by the analysis. \n\n- How does this density estimator compare to the M-estimation procedure of Lei? This paper is not cited at all, but I imagine the authors should be aware of it. \n\n- There are many other approaches to histogram estimation for discrete data. While randomized response achieves the optimal rate of convergence, how do these other algorithms stack up? \n\nADDENDUM AFTER REBUTTAL: \n* I think the distinction between the population vs. sample statistics needs to be explained more clearly and more explicitly at the beginning of the paper (c.f. response to Rev.9) \n* A comparison to related work (Lei and those brought up by another reviewer) is important for context. \n* A closer inspection of [10], which has now appeared, makes me construe the additional contribution of this paper more narrowly. While the venues (and hence audiences) for this and [10] are different, the contribution of this paper is twofold: a careful exposition of the local privacy model, and bounds for density estimation. The latter are new but the former is essentially contained in [10]. \n\n\n This paper is a NIPS-formatted version of an ArXiV manuscript, and uses a LeCam-style argument to derive a lower bound on estimation algorithms that operate on private data when the algorithm is not trusted by the data holder. As a corollary, randomized response turns out to be an optimal strategy in some sense.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper studies minimax bounds for probability estimation under the constraint that the estimation must preserve privacy of the individual data. The authors consider a privacy definition called local privacy. They study two probability estimation problems, multinomial estimation and density estimation. In both problems, the authors show sharp minimax rates of convergence. They demonstrate that, for the discrete multinomial estimation problem, local privacy causes a reduction in the effective sample size quadratic in the privacy parameter alpha. Since alpha can often be seen as a small constant, the effective sample size is of the same order as the non-private case. For the density estimation problem, the authors demonstrate that the optimal rate for the non-private setting is no longer attainable if local privacy must be preserved. \n\nOverall the results are very interesting. As far as I could read, the proofs are correct. To the best of my knowledge, the minimax bound for density estimation under privacy constraint has not been considered before. \n\nMy main comment is that the minimax bound of the multinomial estimation is closely related to previous works on the noise complexity for differential privacy, but there is a lack of mention. In particular, two papers consider highly relevant problems, Hardt&Talwar, On the geometry of differential privacy, STOC, 2010; and De, Lower bounds in differential privacy, TCC, 2012. These two papers study worst case lower bounds for the error of linear queries under the constraint of differential privacy. The probability estimation problem considered in this paper is actually a special case of the linear counting query studied in those two papers. Also, the measures used for the error are the same L_2 metric. The only difference is that this paper considers local differential privacy while Hardt&Talwar and De consider differential privacy. Local privacy posts stronger constraint than differential privacy, and therefore lower bounds for differential privacy are also lower bounds for local privacy. I am wondering if the bound for local privacy given in this paper improves over previous bounds for differential privacy. \n\nFor the density estimation problem, the statement of the result is a bit confusing. The authors state that the lower bound in the local privacy setting is higher than the non-private setting. But the minimax bound in this paper is for the special case that the density can be expanded with trigonometric basis. I am wondering if the lower bound for the non-private setting eq.(13) holds for the general Sobolev space as given in definition 1 or for the special case of trigonometric basis. It is a fair comparison only if the non-private lower bound holds for the trigonometric basis. \n\nAdditional comments to the rebuttal: \n\nThe feedback partially clarifies the relation to previous worst case lower bounds. But note the work of Nikolov, Talwar, and Zhang, The Geometry of Differential Privacy: The Sparse and Approximate Cases (STOC 2013) also considers Mean Square Error. I suggest the authors add their explanations and missing references to the paper. \n This paper proves sharp minimax bounds for pmf and pdf estimation with privacy guarantee. The results are interesting and the paper is well written. But there is a lack of mention about known results on the noise complexity lower bound for differential privacy which are very relevant to this paper.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "Local Privacy and Minimax Bounds: Sharp Rates for Probability Estimations \n------------------------------------------------------------------------------------------------------ \nThe paper deals with local privacy -- a setting in which each user outputs a \\alpha-differentially private signal based on her own type and the signals of the other n-1 users, and reports the data curator that type. The paper analyzes this setting using the framework of min-max expected error -- the adversary picks a distribution over inputs (types for the n users) and we pick a \\alpha-DP local scheme so to minimize the distance between an estimation derived from the original data and a similar estimation derived from the reported signals. (Typically, sums, aggregations or averages.) The authors then give a lower bound for the min-max rate for l_2 distance estimations and users drawn from a discreet distribution over d types. They show that the simple technique of randomized response achieves meets this bound, and therefore, it is optimal. The authors then proceed to analyze the problem of density estimations, where again the lower bound on the min-max rate is met by a perturbation scheme in which each person perturbs only her own type. \n\nThe paper is nice and important -- it shows that some classic procedure is the best we can attain, since it meets certain lower bounds. I think that the NIPS community would find it interesting, and I therefore recommend acceptance. \n\nI do have a few reservations though. First, style-wise, the explanation regarding min-max bounds could have been simpler. The paper also has lots of cumbersome notations -- in particular, since all bound given apply for l_2 norm, couldn't the bounds be phrased w.r.t this norm? Secondly, I would have loved seeing a comment about l_1 norm, which is the more restrictive, or a comment relating the given bounds to l_1 norms, as well as other lower bound in differential privacy (which granted, apply more to a classical, non-local, setting). Lastly, it seems as though the min-max bound discussed are \"tailored\" for this local-privacy setting. I wish the authors could have considered a broader set of settings and give min-max lower bounds for them too. I do like however that whereas local-setting allows users to randomize the type they report based on the remaining n-1 users, it turns out that the simple scheme in which each person randomizes the report solely based on her type is optimal. I wish the authors would state that explicitly in the text. \n\n****A new reservation: by now, the list of FOCS 2013 accepted papers has been published. And so, I now feel that the paper is now an extension of an existing paper, especially the results of Section 3. I therefore still recommend acceptance, but not as strongly as before. \n The paper analyzes the framework of local privacy using the min-max rate bounds, give lower bounds on the rate and show that the upper bound is met by randomized response. A nice result.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
