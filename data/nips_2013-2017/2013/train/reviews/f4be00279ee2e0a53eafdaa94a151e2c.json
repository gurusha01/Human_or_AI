{"title": "Approximate inference in latent Gaussian-Markov models from continuous time observations", "abstract": "We propose an approximate inference algorithm for continuous time Gaussian-Markov process models with both discrete and continuous time likelihoods. We show that the continuous time limit of the expectation propagation algorithm exists and results in a hybrid fixed point iteration consisting of (1) expectation propagation updates for the discrete time terms and (2) variational updates for the continuous time term. We introduce corrections methods that improve on the marginals of the approximation. This approach extends the classical Kalman-Bucy smoothing procedure to non-Gaussian observations, enabling continuous-time inference in a variety of models, including spiking neuronal models (state-space models with point process observations) and box likelihood models. Experimental results on real and simulated data demonstrate high distributional accuracy and significant computational savings compared to discrete-time approaches in a neural application.", "id": "f4be00279ee2e0a53eafdaa94a151e2c", "authors": ["Botond Cseke", "Manfred Opper", "Guido Sanguinetti"], "conference": "NIPS2013", "accepted": true, "reviews": [{"comments": "\b-- Update \nJust a few other thoughts. Simo Saarka has more recent work on continuous-discrete time systems (as you referenced) that might be interesting to contrast against - there, using Gaussian cubature that provides a nice alternative deterministic approximation method. This might be useful for additional discussion and future work. In addition I also now wondered if it is possible to derive an algorithm directly using the variational Gaussian approach. This would be more appealing from the point of having a well defined objective function with which to optimise, potentially fewer numerical issues and interpretation directly in terms of the marginal likelihood. We could afterwards add low-order marginal corrections using cumulant perturbations (like those of Opper for EP) - the only place I think shows this is Barber and van de Laar (http://arxiv.org/pdf/1105.5455.pdf). I do look forward to reading the final version of the paper. \n\n-- Original \nThe paper presents an algorithm for approximate Bayesian inference in models \nwith continuous and discrete time observations. The model can be \ncast in the framework of latent Gaussian models and a parallel \nexpectation propagation algorithm can be used to derive a principled approach for \ninference and learning dealing with both continuous and discrete time. This EP inference algorithm is \nembedded within an EM algorithm to both learn parameters of the model as \nwell as marginal distributions. The algorithm is shown to be effective in \nthe number of experimental settings. \n\nOverall I enjoyed the paper and thoughts that it extends the \napplicability of approximately message passing to a wider class of models. \n\nIn particular I thought it was interesting that EP updates for a \ncontinuous time limit collapsed to the variational Gaussian updates. This is \nrelated to the latent Gaussian structure but I wondered if there is a \ndeeper reason underlying this connection. \n\nThe algorithm seems robust due to be implied fractional updating but \nI wondered if you could comment on any experienced \ndifficulties in implementation, such as issues of slow convergence of parameter learning, \nnumerical stability, etc. \n\nThe algorithm is still cubic due to the inverses is in the inference \nas well as the M-step updating - could comment on approaches to scaling up such algorithms. \n\nIn the experimental section it would be nice to see plots giving \ninsight into the convergence of the algorithm. Can we also demonstrate the advantages \nobtained by of having an estimate of the marginal likelihood. \nFor example, it could be possible in figure 3C to plot \neach of the individual points with a size proportional the marginal likelihood value. \n\n Overall the paper is well written and extend the applicability ofapproximate Bayesian inference methods to the class of continuous anddiscrete time settings, which many will find interesting.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper applies approximate inference to nonlinear diffusion equations by taking the continuous-time limit of the expectation-propagation technique. The result is a tracking algorithm which is, naturally, much faster than sampling methods, and on the experiments shown is rather accurate. I'm curious if a linearization of the loss function + the application of Kalman-Bucy (ie, extended KB), possibly applied iteratively, would lead to a more/less effective algorithm. It would also be interesting to see more substantial experiments, for instance with high-frequency financial data where this framework is often use and existing benchmarks are available. \n\nQuality: the paper is technically solid. \nClarity: the paper is clearly written and well organized. \nOriginality: relatively high. \nSignificance: the speedup over MC achieved here is potentially important. \n This paper applies an approximate inference method, namely, expectation-propagation, to nonlinear diffusion processes and obtains a significant speedup over sampling methods. The paper is clear and straightforward to follow.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This is a theoretically strong and interesting paper that proposes a novel EP-type inference approach for continuous-time stochastic dynamical systems. The paper is well structured and the theory clearly presented. However, the authors should have better motivated the approach with a stronger experimental section. The only comparison with other approaches is in the first example in Section 3.1, where the authors use a MCMC approach as a benchmark. A part from not completely agreeing in using MCMC approaches as a benchmark, as the proposed method performs as well as the MCMC approach, what is the advantage in using it? The authors should discuss \nthis point in detail. In the third example, the authors seem to suggest that the results are similar to those in Zammit Mangion et al. They then justify the use of their approach from a computational viewpoint. The authors should give some quantification of the advantage -- it is not useful for the community to introduce a new approach without giving an idea of its characteristics with respect to existing ones. I would really appreciate some quantitative answers on this point in the rebuttal period. Very interesting paper but the experimental section is not completely satisfactory.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
