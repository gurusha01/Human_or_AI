{"title": "Generalized Method-of-Moments for Rank Aggregation", "abstract": "In this paper we propose a class of efficient Generalized Method-of-Moments(GMM) algorithms for computing parameters of the Plackett-Luce model, where the data consists of full rankings over alternatives. Our technique is based on breaking the full rankings into pairwise comparisons, and then computing parameters that satisfy a set of generalized moment conditions. We identify conditions for the output of GMM to be unique, and identify a general class of consistent and inconsistent breakings. We then show by theory and experiments that our algorithms run significantly faster than the classical Minorize-Maximization (MM) algorithm, while achieving competitive statistical efficiency.", "id": "dc4c44f624d600aa568390f1f1104aa0", "authors": ["Hossein Azari Soufiani", "William Chen", "David C. Parkes", "Lirong Xia"], "conference": "NIPS2013", "accepted": true, "reviews": [{"comments": "The paper investigates a technique for efficiently combining multiple rankings into a Placket Luce model. The key idea is to use so-called breakings, which are subsets of the total ranking information. The authors show that consistency is an important property, which is, e.g., satisfied by top-k rankings (1,2 > 3,4,5), but not by an adjanceny ranking (1 > 2,2 > 3,3 > 4,4 > 5). \n\nThe paper is o.k. The presentation of the method appears occassionally overly formal, but the examples make the message quite clear. \n\nI did not understand why the method is called \"Generalized Method of Moments\". What is the method of moments, and how has it been generalized here? For a while I thought that the MM in the experimental comparison stands for the non-generalized MM, but it stands for \"Minorize Maximization\". \n\nThe authors also assume that the reader is familiar with the MM method (which I am not). Thus, it is difficult to appreciate the contribution. The authors claim that MM is standard method for rank aggregation, but I think they should have also considered other methods. \n\nWhy are the top-k and the bottom-k breaking not symmetric in structure? Why would anyone use the bottom-k breaking? \n\n\n Overall, the paper appears quite reasonable, but I don't think that this contribution will make a strong impact. In any case, the experimental evidence (improvement over MM on synthetic datasets and on the Sushi datasets) does not strike me as convincing enough.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper proposes a class of algorithms for rank aggregation, referred to as GMM algorithms. The key idea of the algorithms is to employ GMM for rank aggregation and to break the full rankings in rank aggregation into pairwise comparisons. The paper gives conditions for the uniqueness and consistency of GMM algorithms. It also shows by theory and experiments that the proposed algorithms run faster than the baseline algorithm of MM, while achieving competitive statistical efficiency. \n\nThe paper is very well written, and it is easy to understand the major points of the paper. The proposed methods appear to be sound, and theoretical and empirical studies on the algorithms are also convincing. The work is novel and represents significant contribution to the research on learning to rank. \n\nMinor issues: \n* Page 4, line 173, position-k breaking G_P^k is only defined for k \\ge 2. However, in line 200, G_P^1 is given. \n* Page 3, line 152, it is not clear whether Definition 1 is about breaking, or about the GMM method GMM_G(D). \n This paper is well written, and the work is sound, novel, and significant. I vote for accept for the paper.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The authors propose a generalized method of moments (GMM) approach for computing parameters of the Plackett-Luce model. The method first 'breaks' the complete rankings into pairwise comparisons which are then used to estimate the necessary quantities at each iteration of the algorithm. \n\nI find the proposed approach to be interesting, I especially like the analysis of the relationship between the breaking type and consistency/quality of found solutions which leads to a trade-off between time and efficiency. \n\nThe major drawback of the GMM methods is its applicability. All results in the paper hold for full rankings only while in practice most preference aggregation problems typically have partial rankings/preferences. The authors mention extension to the partial case in future work but I think having at least some results on that would significantly increase the impact of the paper. \n\nI also have some comments regarding the experiments which are summarized below. \n\n-The real data experiment is not very convincing. It seems strange to compare models on a dataset where neither model provides a good fit, especially since solution from one of these models is used as ground truth. Why was this data chosen? \n\n-I would want to see a comparison with a gradient descent procedure on the PL log likelihood. In my experience gradient descent works well on PL models especially in settings where relative order of \\gamma's is more important than the absolute magnitude (i.e. Kendall correlation criteria). Careful implementation should also be more efficient than GMM per iteration and require less storage. Do you have any results on this? I find the proposed approach to be interesting and promising but in the current state it will have limited impact on the relevant research area.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper proposes a generalized method of moments approach to rank aggregation, specifically by estimating the parameters of a Plackett-Luce (PL) model from a sample of rankings. The proposed method works by decomposing rankings into pairwise comparisons, which are then used to build a transition matrix, the stationary distribution of which is used to parameterize the PL model. The authors establish consistency results for different ways of \"breaking\" the input rankings into pairwise comparisons, and experimentally validate the efficiency of the approach on two datasets. \n\nOverall, the paper is clearly written, and the method seems sound. The \"breaking\" technique is both interesting and intuitive. \n\nMy two main concerns with this paper are the practical applicability of the method, and the thoroughness of experimental evaluation. \n\nIn both the analysis and the experiments, the authors focus on a small-m/large-n regime, where a large number of rankings are given over a small set of items. While consistency is generally a desirable property, I'm not convinced that it's the main quality of interest for rank aggregation. Many of the practical applications mentioned by the authors in the introduction (e.g., meta-search) are large-m/small-n settings in which relatively few rankings are provided over a large set of items. The authors do discuss the computational complexity of inference, but there is no discussion or evaluation of accuracy in this regime, and it's not clear how well the proposed method would perform. \n\nThe experiments on synthetic and real data do illustrate qualitative differences between different breaking strategies, both for speed and accuracy (RMSE and Kendall correlation). However, neither metric seems specifically appropriate for top-k breakings (figure 4), as the scores may be polluted by errors low in the ranking which have no qualitative effect in practice. It would be helpful to see at least one position-dependent score here. \n\n\nMinor comments: \n\nLine 83: \\gamma* is not used in the definition of Pr_PL. Should this be \\gamma? \n\nLine 95: should the norm ||a||_W be squared here? Is this intended as a proper norm (i.e., W positive definite), or is it just meant as a convenient notation? Is it necessary to introduce the W notation here anyway, since it seems that the remainder of the paper sets W=I? \n\nLine 102: GMM_g(D,W) is set-valued, should converge to the set {\\gamma*}, not the point \\gamma*. \n\nLine 124: section 3 title misspells \"Plackett\" \n\nLine 245, Eq. 2: should both the numerator and denominator here be in terms of Pos(c, d)? Or Pos(c)? \n\nLine 377: broken reference in footnote 4 \n This paper proposes a generalized method of moments approach to estimating the parameter vector for a Plackett-Luce ranking model. The paper is clearly written and the analysis is interesting, but it's not entirely clear how practically applicable the method is, and the experimental evaluation could be more thorough.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
