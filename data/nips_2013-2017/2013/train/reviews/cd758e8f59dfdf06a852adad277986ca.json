{"title": "Cluster Trees on Manifolds", "abstract": "", "id": "cd758e8f59dfdf06a852adad277986ca", "authors": ["Sivaraman Balakrishnan", "Srivatsan Narayanan", "Alessandro Rinaldo", "Aarti Singh", "Larry Wasserman"], "conference": "NIPS2013", "accepted": true, "reviews": [{"comments": "The paper discusses the estimation of the cluster tree when the probability density function is supported on a d dimension manifold in a D dimensional space. They show that the algorithm RSL proposed in (1) is consistent and the convergence rate, very roughly, depends on d-the dimension of the manifold and not on D - the dimension of the ambient space (but then the convergence rate also depends on tau-the conditional number and an epsilon^{d+2} factor instead of an epsilon^2 factor). \n\nThe main result is achieved by repeating the technique in (1). To do that, the authors had to show: First,a bound on a size of an s-net in the manifold setting. Second, bounds on the deformation of the volume (i.e. that B(x,r)cap M has roughly the volume of a d-dimensional ball of radius r where d is the dimension of M). The authors are able to show both under the assumption of small conditional number. \n\nI think it is interesting to know how convergence rate changes under this assumption (i.e. manifold assumption) and the paper give both lower bounds and upper bounds that are not trivial. So even though the convergence rate depends on sizes that are not available (the dimension of the manifold and the conditional number), still the results are interesting. \n\nI found the writing very unclear and certain definitions are even confusing: \n******************************* \n1) The statement in thm.4 is wrong. A much stronger statement is proved in thm.6 of [1] than def.3-consistency. (see also, remark after thm.6 in [1]). \n\nTheorem 6 states that with high probability: uniformly, every A A' that satisfy (\\sigma,\\epsilon)-separation: we get separation and conectedness. \n\nTheorem 4 states that for every A A' that satisfy (\\sigma, \\epsilon)-seperation, with high probability we get separation and connectedness. \n\nThese are not equivalent statements. Please correct this. \n***************************** \n2) Still in definition 3: what is n? who is C_n (is it a random variable? how is it defined? is it different than hat{C}) I had to rely on the definition in (1) to understand what is meant here. \n3) When using Lemma 16: It is worth indexing and mentioning which inequality is used and how at each step. Not all steps are clear, it seems that at last step you use \n(1+4r/t(1+4r/t))(1+4r/t) < (1+6r/t) but that's not even hinted. The steps should be clearer. \n\n4) Lemma 18: \nI think a 1/2 is missing from the definition of v_cap. \nWorth mentioning that Gamma(1/2)=sqrt(pi) otherwise it's not clear where it went. \n\n\nFurther suggestions: \n\nThe lower bound you produce depends on the conditional number, it might be worth mentioning the lower bound you produce are not an improvement over the lower bound in (1), but are different (e.g. in a linear subspace that has 1/tau=0 your lower bound is meaningless while (1) gives a sensible lower bound). \n\nRegarding the parameter \\rho, does it really make sense to choose salience parameter 2\\sigma > tau? won't it be easier to simply assume (3\\sigma/16) < (\\tau/16)? The authors demonstrate how one can generalize results to the manifold case by having interesting bounds on s-net. I found the paper not clear enough, and definition 3 is wrong as far as I can see.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper analyzes the robust single linkage algorithm for finding the cluster tree when the support of the density lies on a manifold. Previous work [1] proposed and analyzed the algorithm for the same, when the density is supported on the entire space. This paper shows that the same algorithm could be used in the manifold case with rates depending just on the manifold dimension rather than the ambient dimension. The proof flow is very similar to that of [1] with several modifications to handle the fact that the density is actually supported on a manifold. \n\nThe main point conveyed by the paper seems to be not emphasized sufficiently - despite the fact that the density lies on a manifold, the same RSL algorithm that is based on euclidean distance achieves rates that depend only the manifold dimension - giving some intuition for this fact (say even with a simple synthetic example) might help the reader a lot. Since the proofs are more or less based on similar arguments as that of [1], it is not clear what is the fundamental idea that is behind this phenomenon- at least in the way the proofs are presented. \n\nI went over the proofs and it seems ok to me. More discussion about the parameter $\\rho$ might be helpful to the reader - I guess the previous point is related to this fact. Also I do not really agree with what authors call the 'class of RSL' algorithm (which has some consequences in terms of understanding the implications of the lower bound). Specifically what does ' of the form described in the algorithm in Figure 1' mean - isn't just this one algorithm in that case ? \n\n This paper analyzes the robust single linkage algorithm for finding the cluster tree when the support of the density lies on a manifold and shows that RSL algorithm that is based on euclidean distance achieves rates that depend only the manifold dimension.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper presents an analysis of a k-nearest neighbor based algorithm recently proposed by Chaudhuri and Dasgupta for the case where the data is on or concentrated on a manifold. The key result is that the convergence rate depends on the dimension of the underlying manifold. To obtain the result on the manifold the authors adapt the theory used in Chaudhuri and Dasgupta to the manifold case using the sampling tools developed in Niyogi, Smale, Weinberger. In the case where the data is concentrated on a manifold the use the tools developed by a serious of papers by Rinaldi and others. \n\nThe theory seems correct and these are nice results. The algorithm analyzed may be more appropriate for stratified spaces than manifolds but this is a more minor point. The one negative about this paper is that the algorithm is not novel and many of the theoretical tools used are not novel. However, this complaint can be made of many theoretical papers in NIPs. The authors present a theoretical analysis of cluster trees on manifolds and show the rate is a function of the manifold.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
