{"title": "Wavelets on Graphs via Deep Learning", "abstract": "An increasing number of applications require processing of signals defined on weighted graphs. While wavelets provide a flexible tool for signal processing in the classical setting of regular domains, the existing graph wavelet constructions are less flexible -- they are guided solely by the structure of the underlying graph and do not take directly into consideration the particular class of signals to be processed. This paper introduces a machine learning framework for constructing graph wavelets that can sparsely represent a given class of signals. Our construction uses the lifting scheme, and is based on the observation that the recurrent nature of the lifting scheme gives rise to a structure resembling a deep auto-encoder network. Particular properties that the resulting wavelets must satisfy determine the training objective and the structure of the involved neural networks. The training is unsupervised, and is conducted similarly to the greedy pre-training of a stack of auto-encoders. After training is completed, we obtain a linear wavelet transform that can be applied to any graph signal in time and memory linear in the size of the graph. Improved sparsity of our wavelet transform for the test signals is confirmed via experiments both on synthetic and real data.", "id": "33e8075e9970de0cfea955afd4644bb2", "authors": ["Raif Rustamov", "Leonidas J. Guibas"], "conference": "NIPS2013", "accepted": true, "reviews": [{"comments": "The paper proposes an approach for constructing a linear wavelet transform on weighted graphs based on the lifting scheme, which has a number of favourable properties: 1) linear in memory and time with the size of the graph, 2) adaptive to a class of signals, 3) exact analysis and synthesis, i.e. allows for perfect signal reconstruction, 4) efficient training through resemblance with deep auto-encoder networks. \n\nThe paper is presented well: it is clearly structured and well written. After a nice overview and introduction, the authors give a detailed derivation of their construction and show in a number of experiments the validity and versatility of their approach. \n\nThe proposed approach and wavelet construction builds on previous work but makes a non-trivial contribution to the field of graph-based signal processing by deriving a general-purpose wavelet transform with a number of favourable properties. \n\nThe authors make an interesting connection between wavelet construction on graphs and auto-encoder networks. It is likely that this paper will trigger further development in this line of research. It is also likely to serve as a flexible tool in the analysis of signals on graphs. \n\nAdditional comments: \n* great if the authors could be more precise what sufficient in section 4.5 means? In a general problem how would one determine how many eigenvectors need to be taken into account? \n* What is the meaning of the colorbars in Fig. 4 and 5. ? \n* In Sec. 4.7 change \"It is also possible o\" -> \"It is also possible to\" \n The paper elaborates a non-trivial general-purpose wavelet transform for signals on weighted graphs, which exhibits a number of favourable properties. It makes an interesting connection to auto-encoder networks and is likely to trigger further work along these lines.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This work is aimed to provide interface between the signal processing theory of wavelets and the deep neural network. What is presented is only a small step toward this goal, but is interesting in demonstrating the feasibility of the approach. \n\nIt is interesting to see the various connections among wavelet construction and deep auto-encoder. \n\nThe detail is difficult to follow, and I hope the presentation can be drastically improved to enhance the readability. \n interesting work to bridge signal processing theory of wavelets and deep learning. But details are difficult to follow, and the presentation should be drastically improved to enhance the readability.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "Summary: The authors present a method for constructing wavelets on weighted graphs that can adapt to a class of signals. The approach uses the lifting scheme and by connecting this scheme to a deep auto-encoder network, the authors are able to perform unsupervised training similar to the pre-training of a stack of auto-encoders. The approach is linear in the size of the graph. The authors explore the performance of the wavelet construction approach through application to several data sets. \n\nQuality: The authors provide an elegant approach for taking into account the class of signals when forming wavelets on a graph. Most constructions are based solely on the graph structure, and those few methods that do allow adaptivity based on the signals [19,21] have significant limitations. \n\nThe technical development is clearly described, novel, and leads to an efficient algorithm that produces wavelets with desirable properties. \n\nThe partitioning approach is described very briefly and there is almost no discussion of how sensitive the approach is to the partitioning method. The spectral clustering algorithm of [20] has some limitations (performance being poor for some kinds of graphs) and it would be nice to see more information about how sensitive the overall wavelet construct is to the partitioning scheme. \n\nFor their results on irregular graphs, where I think the construction is of most interest, the authors do not make a comparison to compression or reconstruction using any other type of graph wavelet. Instead, the comparison is to (somewhat dated) learning techniques that are suited to manifold analysis. This constitutes one significant weakness of the paper. \n\nClarity: The paper is very well written and the development is easy to follow. As discussed above, more detail on some of the \n\nOriginality: The authors provide a new method for constructing wavelets on graphs that has the important ability to adapt to the class of functions that the wavelets will be used to represent. The method is highly original. \n\nSignificance: The paper represents a useful contribution in the field of wavelets and multiresolution analysis on graphs, a field of growing interest due to the numerous potential applications. I consider that the signal adaptivity, while preserving linearity and efficiency of construction, represents a significant advance. \n The paper makes a significant original contribution, providing an important advance in the field of wavelets on graphs. The lack of a thorough comparison to other wavelet graphs for compression and reconstruction is the major weakness of the paper.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
