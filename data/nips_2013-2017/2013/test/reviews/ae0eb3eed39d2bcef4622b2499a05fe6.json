{"title": "Optimistic Concurrency Control for Distributed Unsupervised Learning", "abstract": "Research on distributed machine learning algorithms has focused primarily on one of two extremes---algorithms that obey strict concurrency constraints or algorithms that obey few or no such constraints.  We consider an intermediate alternative in which algorithms optimistically assume that conflicts are unlikely and if conflicts do arise a conflict-resolution protocol is invoked. We view this optimistic concurrency control'' paradigm as particularly appropriate for large-scale machine learning algorithms, particularly in the unsupervised setting.  We demonstrate our approach in three problem areas: clustering, feature learning and online facility location.  We evaluate  our methods via large-scale experiments in a cluster computing environment.  \"", "id": "ae0eb3eed39d2bcef4622b2499a05fe6", "authors": ["Xinghao Pan", "Joseph E. Gonzalez", "Stefanie Jegelka", "Tamara Broderick", "Michael I. Jordan"], "conference": "NIPS2013", "accepted": true, "reviews": [{"comments": "The author essentially tried to propose parallel algorithms for a clustering method (OFL as an extension of DP-means) and a feature selection method. These algorithm is then unified into optimistic concurrency control that was introduced in parallel database community. \n\nIt seems that the algorithm that the author proposed can be perfectly fitted into the mapreduce framework. The map stage is the parallel operation, and the reduce stage is the serial operation. \n\nThe theoretical analysis provides little added value, as they are mostly straight-forward. The experiment is not impressive because with speedup is only 4x on 8 processors. \n\n--- update--- \n\nThe problem of the paper is obvious: too ad-hoc algorithms for the demonstration and poor performance evaluation. If the paper could position itself as a parallelized DP-means algorithm with extended discussion on OCC, it could be a better paper. Algorithm too ad-hoc and the performance of the algorithms is questionable.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "Running machine learning algorithms on larger datasets is becomming more and more a necessity. Recently, a practically very relevant line of research has been to look at various programming paradigms for turning well known machine learning algorithms into distributed algorithms - meaning they can run on an infrastructure with no shared memory and slow communication between processing units. \n\nThis paper introduces a well known pattern called \"optimistic concurrency control\" into the machine learning literature. As the authors point out, there has been some work on embarrasingly parallel algorithms, distributed algorithm using the locking paradigm and coordination-free approaches to distributed algorithms. Optimistic concurrency control is a technique which starts out by assuming that each individual processing unit can freely access shared state. At certain points in the computation the algorithms checkpoint and verify the assumption didn't harm the correctness; if the assumption was deemed incorrect, part of the computation is rolled back or corrected. \n\nThe authors make a convincing case that optimistic concurrency control (OCC henceforth) is worthwhile investigating in the machine learning context. They go on to apply OCC to three algorithms DP-means, the Facility Location problem and BP-means. I found the explanation of the algorithm very clear and understandable. A very minor point that might deserve a mention in the appendix is how the first clusters are assigned (i.e. how do we argmin_{\\mu \\in C} when C is empty)? \n\nReading through Algorithm 3, one thing I wondered about is how expensive it is for a distributed algorithm to be sending x_i between different processing units? I'm not sure how to solve this problem, but in my experience moving the dataset around the cluster is more expensive than moving the parameters around the cluster. I'd love to see some discussion on this point. \n\nThe authors continue to discuss correctness proofs for the algorithms. I've only skimmed the proofs in the appendix but they seem correct. In the evaluation the authors first run the algorithms on a small synthetic dataset to drive the point home that the number of corrections that need to be made is modest. In a larger experiment using Spark on Amazon AWS, the authors show convincing results on large datasets. It wasn't clear to me what data was used for this experiment (synthetic?). \n\n\nline 33: iid => i.i.d. A well written paper on how to use optimistic concurrency control to implement distributed machine learning algorithms.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper studies the problem of large scale unsupervised learning. It proposes the paradigm of \u201coptimistic concurrency control\u201d, which assumes that conflicts are unlikely and if conflicts do arise a conflict-resolution protocol is invoked. The paper then applies the approach to three clustering related problems: clustering, feature learning and online facility location. It also proves the serializability of the proposed algorithms. It provides the experimental results on simulated data sets. \n\nThis paper is well-organized and clearly written. It provides enough technical details and theoretical support. The idea of OOC is neat and practical. Although the paper presents the idea from the point view of concurrency control, however in more general speaking, the key point of large scale machine learning is how to update the global parameter from the local parameters from each parallelized parts. The proposed approach provides a simple and practical way to update the global parameters (global cluster assignments) from local ones (local cluster assignments). However, this update strategy does not necessarily work for other unsupervised learning or supervised learning algorithms. In general, the update strategy is algorithm-dependent. My major concern about this work is its experimental results. The experiments cannot prove the usefulness of the proposed algorithms. First, it is only based on simulated data, which does not provide insights how the algorithm will be useful for real data sets. Second, it should provide cluster quality comparison with other distributed clustering algorithms in the literature. \n The paper provides a neat idea for distribute unsupervised learning (clustering) with a good presentation. However, the experiments are not strong enough to support the usefulness of the proposed algorithms.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
