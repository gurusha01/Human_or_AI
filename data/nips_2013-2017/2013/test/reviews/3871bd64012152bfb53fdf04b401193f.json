{"title": "Learning with Noisy Labels", "abstract": "In this paper, we theoretically study the problem of binary classification in the presence of random classification noise --- the learner, instead of seeing the true labels, sees labels that have independently been flipped with some small probability. Moreover, random label noise is \\emph{class-conditional} --- the flip probability depends on the class. We provide two approaches to suitably modify any given surrogate loss function. First, we provide a simple unbiased estimator of any loss, and obtain performance bounds for empirical risk minimization in the presence of iid data with noisy labels. If the loss function satisfies a simple symmetry condition, we show that the method leads to an efficient algorithm for empirical minimization. Second, by leveraging a reduction of risk minimization under noisy labels to classification with weighted 0-1 loss, we suggest the use of a simple weighted surrogate loss, for which we are able to obtain strong empirical risk bounds. This approach has a very remarkable consequence --- methods used in practice such as biased SVM and weighted logistic regression are provably noise-tolerant. On a synthetic non-separable dataset, our methods achieve over 88\\% accuracy even when 40\\% of the labels are corrupted, and are competitive with respect to recently proposed methods for dealing with label noise in several benchmark datasets.", "id": "3871bd64012152bfb53fdf04b401193f", "authors": ["Nagarajan Natarajan", "Inderjit S. Dhillon", "Pradeep K. Ravikumar", "Ambuj Tewari"], "conference": "NIPS2013", "accepted": true, "reviews": [{"comments": "The authors study the problem of binary classification in the presence of random, class-conditional noise in the training data. They propose two approaches based on a suitable modification of a given surrogate loss function and derive performance bounds. More specifically, they provide guarantees for risk minimization of convex surrogates under random label noise in the general setting, and without any assumptions on the true distribution. Moreover, they provide two alternative approaches for modifying a given surrogate loss function. Experiments are presented on synthetic data and some benchmark datasets. \n\nThe paper is well-written and appears to be technically sound. The theoretical results are non-trivial but not extremely profound either, especially in light of existing work on related setting. \n\nWhat could be called into question is the relevance of the setting. Is the assumption of having constant class noise in the training data indeed a realistic one? This question appears to be legitimate despite the theoretical nature of the paper.  The paper is well-written and appears to be technically sound. The theoretical results are non-trivial but not very profound either, especially in light of existing work on related setting. What could be called into question is the relevance of the setting.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "Learning with Noisy Labels \n\nThe paper addresses the problem of binary classification in the situation \nwhere the training labels are corrupted by class-conditional random noise. \nThe authors propose 2 surrogate-loss based learning methods to address the problem: \nthe first exploits a simple symmetry condition on the loss function used to \nprovide a simple unbiased estimator of the non-noisy risk and the second \npromotes the use of a weighted 0-1 loss that comes from an appropriate reduction \nof the problem of learning from noisy labels. \n\nThe paper is a very clean and strong contribution. It provides original \ntheoretical results (e.g. learnability with convex surrogate in the case \nof noise, noise-tolerance of SVMs, and so on) as well as compelling empirical \nresults. Everything is wrapped up in a nicely written paper. \n\nI essentially have questions on future directions: \n- the authors mention adversarial noise: before going to this point, is there something that can be said \nabout learnability with monotonic noise, as defined by Bylander ? \n- what about richer noise models like Constant Partition Classification Noise (CPCN) noise ? \n Very good paper, providing significant result to learn binary classifiers from noisy labels using convex surrogates. Technical results are important, the writing is good and the experiments are compelling.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "Overall, I found the paper quite well-written. \n\nI think the assertion in the abstract (and then again in the Experiments \nsection), that you learn with 88% accuracy when 80% labels are flipped is \nincorrect. You are only flipping 40% of the labels (the probability of \nflip is convex combination of \\rho_+ and \\rho_- and not their sum). In \nany, case the goal is to get better accuracy as noise rate goes to half, \nnot one (where the problem is trivially easy with just all labels \nflipped). \n\nI wonder if it is worthwhile to compare your methods with Kearns' SQ \nsetting. Since minimizing a convex loss can be done by gradient methods \n(which have statistical analogues). And so you would get tolerance to \nrandom classification noise for free. (Kearns does not allow \nclass-conditional noise, but I think that part can be handled easily.) I'm \nnot sure what kind of excess risk bounds you would get by such \nSQ-simulation. \n\nMinor quibbles: \n-------------- \n1. You use the term PU learning, without ever defining it. \n2. You use \"so-called\" very often. Especially for zero-one loss. Why is it \nso-called? If you have objection to the name you should state it. \n\n--- \nUpdate: Regarding using the SQ model. Even if you are using surrogate loss, your optimization problem can be solved using an algorithm that only makes statistical queries rather than data points. \n This paper considers the problem of learning in the presence of randomclassification noise. In contrast with the PAC-like models, the maingoal here is if the goal is to minimize some convex loss function (withrespect to the true models), this can be done by suitable modificationseven when the labels are noisy (in many cases).The paper also contains some experiments studying the proposed methods andother related techniques.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
