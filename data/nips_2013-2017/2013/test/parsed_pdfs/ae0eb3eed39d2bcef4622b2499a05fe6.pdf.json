{
  "name" : "ae0eb3eed39d2bcef4622b2499a05fe6.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Optimistic Concurrency Control for Distributed Unsupervised Learning",
    "authors" : [ "Xinghao Pan", "Joseph Gonzalez", "Stefanie Jegelka", "Tamara Broderick", "Michael I. Jordan" ],
    "emails" : [ "xinghao@eecs.berkeley.edu", "jegonzal@eecs.berkeley.edu", "stefje@eecs.berkeley.edu", "tab@eecs.berkeley.edu", "jordan@eecs.berkeley.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The desire to apply machine learning to increasingly larger datasets has pushed the machine learning community to address the challenges of distributed algorithm design: partitioning and coordinating computation across the processing resources. In many cases, when computing statistics of iid data or transforming features, the computation factors according to the data and coordination is only required during aggregation. For these embarrassingly parallel tasks, the machine learning community has embraced the map-reduce paradigm, which provides a template for constructing distributed algorithms that are fault tolerant, scalable, and easy to study.\nHowever, in pursuit of richer models, we often introduce statistical dependencies that require more sophisticated algorithms (e.g., collapsed Gibbs sampling or coordinate ascent) which were developed and studied in the serial setting. Because these algorithms iteratively transform a global state, parallelization can be challenging and often requires frequent and complex coordination.\nRecent efforts to distribute these algorithms can be divided into two primary approaches. The mutual exclusion approach, adopted by [1] and [2], guarantees a serializable execution preserving the theoretical properties of the serial algorithm but at the expense of parallelism and costly locking overhead. Alternatively, in the coordination-free approach, proposed by [3] and [4], processors communicate frequently without coordination minimizing the cost of contention but leading to stochasticity, data-corruption, and requiring potentially complex analysis to prove algorithm correctness.\nIn this paper we explore a third approach, optimistic concurrency control (OCC) [5] which offers the performance gains of the coordination-free approach while at the same time ensuring a serializable execution and preserving the theoretical properties of the serial algorithm. Like the coordinationfree approach, OCC exploits the infrequency of data-corrupting operations. However, instead of allowing occasional data-corruption, OCC detects data-corrupting operations and applies correcting computation. As a consequence, OCC automatically ensures correctness, and the analysis is only necessary to guarantee optimal scaling performance.\nWe apply OCC to distributed nonparametric unsupervised learning—including but not limited to clustering—and implement distributed versions of the DP-Means [6], BP-Means [7], and online facility location (OFL) algorithms. We demonstrate how to analyze OCC in the context of the DP-Means algorithm and evaluate the empirical scalability of the OCC approach on all three of the proposed algorithms. The primary contributions of this paper are:\n1. Concurrency control approach to distributing unsupervised learning algorithms.\n2. Reinterpretation of online nonparametric clustering in the form of facility location with approximation guarantees.\n3. Analysis of optimistic concurrency control for unsupervised learning.\n4. Application to feature modeling and clustering."
    }, {
      "heading" : "2 Optimistic Concurrency Control",
      "text" : "Many machine learning algorithms iteratively transform some global state (e.g., model parameters or variable assignment) giving the illusion of serial dependencies between each operation. However, due to sparsity, exchangeability, and other symmetries, it is often the case that many, but not all, of the state-transforming operations can be computed concurrently while still preserving serializability: the equivalence to some serial execution where individual operations have been reordered.\nThis opportunity for serializable concurrency forms the foundation of distributed database systems. For example, two customers may concurrently make purchases exhausting the inventory of unrelated products, but if they try to purchase the same product then we may need to serialize their purchases to ensure sufficient inventory. One solution (mutual exclusion) associates locks with each product type and forces each purchase of the same product to be processed serially. This might work for an unpopular, rare product but if we are interested in selling a popular product for which we have a large inventory the serialization overhead could lead to unnecessarily slow response times. To address this problem, the database community has adopted optimistic concurrency control (OCC) [5] in which the system tries to satisfy the customers requests without locking and corrects transactions that could lead to negative inventory (e.g., by forcing the customer to checkout again).\nOptimistic concurrency control exploits situations where most operations can execute concurrently without conflicting or violating serialization invariants. For example, given sufficient inventory the order in which customers are satisfied is immaterial and concurrent operations can be executed serially to yield the same final result. However, in the rare event that inventory is nearly depleted two concurrent purchases may not be serializable since the inventory can never be negative. By shifting the cost of concurrency control to rare events we can admit more costly concurrency control mechanisms (e.g., re-computation) in exchange for an efficient, simple, coordination-free execution for the majority of the events.\nFormally, to apply OCC we must define a set of transactions (i.e., operations or collections of operations), a mechanism to detect when a transaction violates serialization invariants (i.e., cannot be executed concurrently), and a method to correct (e.g., rollback) transactions that violate the serialization invariants. Optimistic concurrency control is most effective when the cost of validating concurrent transactions is small and conflicts occur infrequently.\nMachine learning algorithms are ideal for optimistic concurrency control. The conditional independence structure and sparsity in our models and data often leads to sparse parameter updates substantially reducing the chance of conflicts. Similarly, symmetry in our models often provides the flexibility to reorder serial operations while preserving algorithm invariants. Because the models encode the dependency structure, we can easily detect when an operation violates serial invariants and correct by rejecting the change and rerunning the computation. Alternatively, we can exploit the semantics of the operations to resolve the conflict by accepting a modified update. As a consequence OCC allows us to easily construct provably correct and efficient distributed algorithms without the need to develop new theoretical tools to analyze complex non-deterministic distributed behavior."
    }, {
      "heading" : "2.1 The OCC Pattern for Machine Learning",
      "text" : "Optimistic concurrency control can be distilled to a simple pattern (meta-algorithm) for the design and implementation of distributed machine learning systems. We begin by evenly partitioning N data points (and the corresponding computation) across the P available processors. Each processor maintains a replicated view of the global state and serially applies the learning algorithm as a sequence of operations on its assigned data and the global state. If an operation mutates the global state in a way that preserves the serialization invariants then the operation is accepted locally and its effect on the global state, if any, is eventually replicated to other processors.\nHowever, if an operation could potentially conflict with operations on other processors then it is sent to a unique serializing processor where it is rejected or corrected and the resulting global state change is eventually replicated to the rest of the processors. Meanwhile the originating processor either tentatively accepts the state change (if a rollback operator is defined) or proceeds as though the operation has been deferred to some point in the future.\nWhile it is possible to execute this pattern asynchronously with minimal coordination, for simplicity we adopt the bulk-synchronous model of [8] and divide the computation into epochs. Within an epoch t, b data points B(p, t) are evenly assigned to each of the P processors. Any state changes or serialization operations are transmitted at the end of the epoch and processed before the next epoch. While potentially slower than an asynchronous execution, the bulk-synchronous execution is deterministic and can be easily expressed using existing systems like Hadoop or Spark [9]."
    }, {
      "heading" : "3 OCC for Unsupervised Learning",
      "text" : "Much of the existing literature on distributed machine learning algorithms has focused on classification and regression problems, where the underlying model is continuous. In this paper we apply the OCC pattern to machine learning problems that have a more discrete, combinatorial flavor—in particular unsupervised clustering and latent feature learning problems. These problems exhibit symmetry via their invariance to both data permutation and cluster or feature permutation. Together with the sparsity of interacting operations in their existing serial algorithms, these problems offer a unique opportunity to develop OCC algorithms.\nThe K-means algorithm provides a paradigm example; here the inferential goal is to partition the data. Rather than focusing solely on K-means, however, we have been inspired by recent work in which a general family of K-means-like algorithms have been obtained by taking Bayesian nonparametric (BNP) models based on combinatorial stochastic processes such as the Dirichlet process, the beta process, and hierarchical versions of these processes, and subjecting them to smallvariance asymptotics where the posterior probability under the BNP model is transformed into a cost function that can be optimized [7]. The algorithms considered to date in this literature have been developed and analyzed in the serial setting; our goal is to explore distributed algorithms for optimizing these cost functions that preserve the structure and analysis of their serial counterparts."
    }, {
      "heading" : "3.1 OCC DP-Means",
      "text" : "We first consider the DP-means algorithm (Alg. 1) introduced by [6]. Like the K-means algorithm, DP-Means alternates between updating the cluster assignment zi for each point xi and recomputing the centroids C = {µk}Kk=1 associated with each clusters. However, DP-Means differs in that the number of clusters is not fixed a priori. Instead, if the distance from a given data point to all existing cluster centroids is greater than a parameter λ, then a new cluster is created. While the second phase is trivially parallel, the process of introducing clusters in the first phase is inherently serial. However, clusters tend to be introduced infrequently, and thus DP-Means provides an opportunity for OCC.\nIn Alg. 3 we present an OCC parallelization of the DP-Means algorithm in which each iteration of the serial DP-Means algorithm is divided into N/(Pb) bulk-synchronous epochs. The data is evenly partitioned {xi}i∈B(p,t) across processor-epochs into blocks of size b = |B(p, t)|. During each epoch t, each processor p evaluates the cluster membership of its assigned data {xi}i∈B(p,t) using the cluster centers C from the previous epoch and optimistically proposes a new set of cluster centers Ĉ. At the end of each epoch the proposed cluster centers, Ĉ, are serially validated using Alg. 2.\nAlgorithm 1: Serial DP-means Input: data {xi}Ni=1, threshold λ C ← ∅ while not converged do\nfor i = 1 to N do µ∗ ← argminµ∈C ‖xi − µ‖ if ‖xi − µ∗‖ > λ then\nzi ← xi C ← C ∪ xi // New cluster else zi ← µ∗ // Use nearest for µ ∈ C do // Recompute Centers\nµ← Mean({xi | zi = µ}) Output: Accepted cluster centers C\nAlgorithm 2: DPValidate Input: Set of proposed cluster centers Ĉ C ← ∅ for x ∈ Ĉ do\nµ∗ ← argminµ∈C ‖x− µ‖ if ‖xi − µ∗‖ < λ then // Reject\nRef(x)← µ∗ // Rollback Assgs else C ← C ∪ x // Accept\nOutput: Accepted cluster centers C\nAlgorithm 3: Parallel DP-means Input: data {xi}Ni=1, threshold λ Input: Epoch size b and P processors Input: Partitioning B(p, t) of data {xi}i∈B(p,t) to processor-epochs where b = |B(p, t)| C ← ∅ while not converged do\nfor epoch t = 1 to N/(Pb) do Ĉ ← ∅ // New candidate centers for p ∈ {1, . . . , P} do in parallel\n// Process local data for i ∈ B(p, t) do\nµ∗ ← argminµ∈C ‖xi − µ‖ // Optimistic Transaction if ‖xi − µ∗‖ > λ then\nzi ← Ref(xi) Ĉ ← Ĉ ∪ xi\nelse zi ← µ∗ // Always Safe\n// Serially validate clusters\nC ← C ∪ DPValidate(Ĉ) for µ ∈ C do // Recompute Centers\nµ← Mean({xi | zi = µ}) Output: Accepted cluster centers C\nFigure 1: The Serial DP-Means algorithm and distributed implementation using the OCC pattern.\nThe validation process accepts cluster centers that are not covered by (i.e., not within λ of) already accepted cluster centers. When a cluster center is rejected we update its reference to point to the already accepted center, thereby correcting the original point assignment."
    }, {
      "heading" : "3.2 OCC Facility Location",
      "text" : "The DP-Means objective turns out to be equivalent to the classic Facility Location (FL) objective: J(C) =∑x∈X minµ∈C ‖x− µ‖ 2 + λ2|C|,which selects the set of cluster centers (facilities) µ ∈ C that minimizes the shortest distance ‖x− µ‖2 to each point (customer) x as well as the penalized cost of the clusters λ2 |C|. However, while DP-Means allows the clusters to be arbitrary points (e.g., C ∈ RD), FL constrains the clusters to be points C ⊆ F in a set of candidate locations F . Hence, we obtain a link between combinatorial Bayesian models and FL allowing us to apply algorithms with known approximation bounds to Bayesian inspired nonparametric models. As we will see in Section 4, our OCC algorithm provides constant-factor approximations for both FL and DP-means.\nFacility location has been studied intensely. We build on the online facility location (OFL) algorithm described by Meyerson [10]. The OFL algorithm processes each data point x serially in a single pass by either adding x to the set of clusters with probability min(1,minµ∈C ‖x− µ‖2 /λ2) or assigning x to the nearest existing cluster. Using OCC we are able to construct a distributed OFL algorithm (Alg. 4) which is nearly identical to the OCC DP-Means algorithm (Alg. 3) but which provides strong approximation bounds. The OCC OFL algorithm differs only in that clusters are introduced and validated stochastically—the validation process ensures that the new clusters are accepted with probability equal to the serial algorithm."
    }, {
      "heading" : "3.3 OCC BP-Means",
      "text" : "BP-means is an algorithm for learning collections of latent binary features, providing a way to define groupings of data points that need not be mutually exclusive or exhaustive like clusters.\nAlgorithm 4: Parallel OFL Input: Same as DP-Means for epoch t = 1 to N/(Pb) do Ĉ ← ∅\nfor p ∈ {1, . . . , P} do in parallel for i ∈ B(p, t) do\nd← minµ∈C ‖xi − µ‖ with probability min { d2, λ2 } /λ2\nĈ ← Ĉ ∪ (xi, d)\nC ← C ∪ OFLValidate(Ĉ) Output: Accepted cluster centers C\nAlgorithm 5: OFLValidate Input: Set of proposed cluster centers Ĉ C ← ∅ for (x, d) ∈ Ĉ do\nd∗ ← minµ∈C ‖x− µ‖ with probability min { d∗2, d2 } /d2\nC ← C ∪ x // Accept Output: Accepted cluster centers C\nFigure 2: The OCC algorithm for Online Facility Location (OFL).\nAs with serial DP-means, there are two phases in serial BP-means (Alg. 6). In the first phase, each data point xi is labeled with binary assignments from a collection of features (zik = 0 if xi doesn’t belong to feature k; otherwise zik = 1) to construct a representation xi ≈ ∑ k zikfk. In the second phase, parameter values (the feature means fk ∈ Ĉ) are updated based on the assignments. The first step also includes the possibility of introducing an additional feature. While the second phase is trivially parallel, the inherently serial nature of the first phase combined with the infrequent introduction of new features points to the usefulness of OCC in this domain.\nThe OCC parallelization for BP-means follows the same basic structure as OCC DP-means. Each transaction operates on a data point xi in two phases. In the first, analysis phase, the optimal representation ∑ k zikfk is found. If xi is not well represented (i.e., ‖xi − ∑ k zikfk‖ > λ), the difference is proposed as a new feature in the second validation phase. At the end of epoch t, the proposed features {fnewi } are serially validated to obtain a set of accepted features C̃. For each proposed feature fnewi , the validation process first finds the optimal representation f new i ≈∑\nfk∈C̃ zikfk using newly accepted features. If f new i is not well represented, the difference f new i −∑\nfk∈C̃ zikfk is added to C̃ and accepted as a new feature. Finally, to update the feature means, let F be the K-row matrix of feature means. The feature means update F ← (ZTZ)−1ZTX can be evaluated as a single transaction by computing the sums ZTZ = ∑ i ziz T i (where zi is a K × 1 column vector so zizTi is a K × K matrix) and\nZTX = ∑ i zix T i in parallel.\nWe present the pseudocode for the OCC parallelization of BP-means in Appendix A."
    }, {
      "heading" : "4 Analysis of Correctness and Scalability",
      "text" : "In contrast to the coordination-free pattern in which scalability is trivial and correctness often requires strong assumptions or holds only in expectation, the OCC pattern leads to simple proofs of correctness and challenging scalability analysis. However, in many cases it is preferable to have algorithms that are correct and probably fast rather than fast and possibly correct. We first establish serializability:\nTheorem 4.1 (Serializability). The distributed DP-means, OFL, and BP-means algorithms are serially equivalent to DP-means, OFL and BP-means, respectively.\nThe proof (Appendix B) of Theorem 4.1 is relatively straightforward and is obtained by constructing a permutation function that describes an equivalent serial execution for each distributed execution. The proof can easily be extended to many other machine learning algorithms.\nSerializability allows us to easily extend important theoretical properties of the serial algorithm to the distributed setting. For example, by invoking serializability, we can establish the following result for the OCC version of the online facility location (OFL) algorithm:\nTheorem 4.2. If the data is randomly ordered, then the OCC OFL algorithm provides a constantfactor approximation for the DP-means objective. If the data is adversarially ordered, then OCC OFL provides a log-factor approximation to the DP-means objective.\nThe proof (Appendix B) of Theorem 4.2 is first derived in the serial setting then extended to the distributed setting through serializability. In contrast to divide-and-conquer schemes, whose approximation bounds commonly depend multiplicatively on the number of levels [11], Theorem 4.2 is unaffected by distributed processing and has no communication or coarsening tradeoffs. Furthermore, to retain the same factors as a batch algorithm on the full data, divide-and-conquer schemes need a large number of preliminary centers at lower levels [11, 12]. In that case, the communication cost can be high, since all proposed clusters are sent at the same time, as opposed to the OCC approach. We address the communication overhead (the number of rejections) for our scheme next.\nScalability The scalability of the OCC algorithms depends on the number of transactions that are rejected during validation (i.e., the rejection rate). While a general scalability analysis can be challenging, it is often possible to gain some insight into the asymptotic dependencies by making simplifying assumptions. In contrast to the coordination-free approach, we can still safely apply OCC algorithms in the absence of a scalability analysis or when simplifying assumptions do not hold.\nTo illustrate the techniques employed in OCC scalability analysis we study the DP-Means algorithm, whose scalability limiting factor is determined by the number of points that must be serially validated. We show that the communication cost only depends on the number of clusters and processing resources and does not directly depend on the number of data points. The proof is in Appendix C.\nTheorem 4.3 (DP-Means Scalability). Assume N data points are generated iid to form a random number (KN ) of well-spaced clusters of diameter λ: λ is an upper bound on the distances within clusters and a lower bound on the distance between clusters. Then the expected number of serially validated points is bounded above by Pb+E [KN ] for P processors and b points per epoch.\nUnder the separation assumptions of the theorem, the number of clusters present in N data points, KN , is exactly equal to the number of clusters found by DP-Means in N data points; call this latter quantity kN . The experimental results in Figure 3 suggest that the bound of Pb + kN may hold more generally beyond the assumptions above. Since the master must process at least kN points, the overhead caused by rejections is Pb and independent of N ."
    }, {
      "heading" : "5 Evaluation",
      "text" : "For our experiments, we generated synthetic data for clustering (DP-means and OFL) and feature modeling (BP-means). The cluster and feature proportions were generated nonparametrically as described below. All data points were generated in R16 space. We fixed threshold parameter λ = 1.\nClustering: The cluster proportions and indicators were generated simultaneously using the stickbreaking procedure for Dirichlet processes—‘sticks’ are ‘broken’ on-the-fly to generate new clusters as necessary. For our experiments, we used a fixed concentration parameter θ = 1. Cluster means were sampled µk ∼ N(0, I16), and data points were generated at xi ∼ N(µzi , 14I16). Feature modeling: We use the stick-breaking procedure of [13] to generate feature weights. Unlike with Dirichlet processes, we are unable to perform stick-breaking on-the-fly with Beta processes. Instead, we generate enough features so that with high probability (> 0.9999) the remaining non-generated features will have negligible weights (< 0.0001). The concentration parameter was also fixed at θ = 1. We generated feature means fk ∼ N(0, I16) and data points xi ∼ N( ∑ k zikfk, 1 4I16)."
    }, {
      "heading" : "5.1 Simulated experiments",
      "text" : "To test the efficiency of our algorithms, we simulated the first iteration (one complete pass over all the data, where most clusters / features are created and thus greatest coordination is needed) of each algorithm in MATLAB. The number of data points, N , was varied from 256 to 2560 in intervals of 256. We also varied Pb, the number of data points processed in one epoch, from 16 to 256 in powers of 2. For each value of N and Pb, we empirically measured kN , the number of accepted clusters /\nfeatures, and MN , the number of proposed clusters / features. This was repeated 400 times to obtain the empirical average Ê[MN − kN ] of the number of rejections. For OCC DP-means, we observe Ê[MN − kN ] is bounded above by Pb (Fig. 3a), and that this bound is independent of the data set size, even when the assumptions of Thm 4.3 are violated. (We also verified that similar empirical results are obtained when the assumptions are not violated; see Appendix C.) The same behavior is observed for the other two OCC algorithms (Fig. 3b and Fig. 3c)."
    }, {
      "heading" : "5.2 Distributed implementation and experiments",
      "text" : "We also implemented1 the distributed algorithms in Spark [9], an open-source cluster computing system. The DP-means and BP-means algorithms were initialized by pre-processing a small number of data points (1/16 of the first Pb points)—this reduces the number of data points sent to the master on the first epoch, while still preserving serializability of the algorithms. Our Spark implementations were tested on Amazon EC2 by processing a fixed data set on 1, 2, 4, 8 m2.4xlarge instances. Ideally, to process the same amount of data, an algorithm and implementation with perfect scaling would take half the runtime on 8 machines as it would on 4, and so on. The plots in Figure 4 shows this comparison by dividing all runtimes by the runtime on one machine.\nDP-means: We ran the distributed DP-means algorithm on 227 ≈ 134M data points, using λ = 2. The block size b was chosen to keep Pb = 223 ≈ 8M constant. The algorithm was run for 5 iterations (complete pass over all data in 16 epochs). We were able to get perfect scaling (Figure 4a) in all but the first iteration, when the master has to perform the most synchronization of proposed centers.\nOFL: The distributed OFL algorithm was run on 220 ≈ 1M data points, using λ = 2. Unlike DP-means and BP-means, OFL is a single-pass algorithm and we did not perform any initialization clustering. The block size b was chosen such that Pb = 216 ≈ 66K data points are processed each epoch, which gives us 16 epochs. Figure 4b shows that we get no scaling in the first epoch, where all Pb data points are sent to the master. Scaling improves in the later epochs, as the master’s workload decreases with fewer proposals but the workers’ workload increases with more centers.\nBP-means: Distributed BP-means was run on 223 ≈ 8M data points, with λ = 1; block size was chosen such that Pb = 219 ≈ 0.5M is constant. Five iterations were run, with 16 epochs per iteration. As with DP-means, we were able to achieve nearly perfect scaling; see Figure 4c."
    }, {
      "heading" : "6 Related work",
      "text" : "Others have proposed alternatives to mutual exclusion and coordination-free parallelism for machine learning algorithm design. [14] proposed transforming the underlying model to expose additional parallelism while preserving the marginal posterior. However, such constructions can be challenging or infeasible and many hinder mixing or convergence. Likewise, [15] proposed a reparameterization of the underlying model to expose additional parallelism through conditional independence. Additional\n1Code will be made available at our project page https://amplab.cs.berkeley.edu/projects/ccml/.\nwork similar in spirit to ours using OCC-like techniques includes [16] who proposed an approximate parallel sampling algorithm for the IBP which is made exact by introducing an additional MetropolisHastings step, and [17] who proposed a look-ahead strategy in which future samples are computed optimistically based on the likely outcomes of current samples.\nThere has been substantial work on scalable clustering algorithms [18, 19, 20]. Several authors [11, 21, 22, 12] have proposed streaming approximation algorithms that rely on hierarchical divideand-conquer schemes. The approximation factors in these algorithms are multiplicative in the hierarchy and demand a careful tradeoff between communication and approximation quality which is obviated in the OCC framework. Several methods [12, 25, 21] first collect and then re-cluster a set of centers, and therefore need to communicate all intermediate centers. Our approach avoids these stages, since a center causes no rejections in the epochs after it is established: the rejection rate does not grow with K. Finally, the OCC framework can easily integrate and exploit many of the ideas in the cited works."
    }, {
      "heading" : "7 Discussion",
      "text" : "In this paper we have shown how optimistic concurrency control can be usefully employed in the design of distributed machine learning algorithms. As opposed to previous approaches, this preserves correctness, in most cases at a small cost. We established the equivalence of our distributed OCC DPmeans, OFL and BP-means algorithms to their serial counterparts, thus preserving their theoretical properties. In particular, the strong approximation guarantees of serial OFL translate immediately to the distributed algorithm. Our theoretical analysis ensures OCC DP-means achieves high parallelism without sacrificing correctness. We implemented and evaluated all three OCC algorithms on a distributed computing platform and demonstrate strong scalability in practice.\nWe believe that there is much more to do in this vein. Indeed, machine learning algorithms have many properties that distinguish them from classical database operations and may allow going beyond the classic formulation of OCC. In particular we may be able to partially or probabilistically accept non-serializable operations in a way that preserves underlying algorithm invariants. Laws of large numbers and concentration theorems may provide tools for designing such operations. Moreover, the conflict detection mechanism can be treated as a control knob, allowing us to softly switch between stable, theoretically sound algorithms and potentially faster coordination-free algorithms."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This research is supported in part by NSF CISE Expeditions award CCF-1139158 and DARPA XData Award FA8750-12-2-0331, and gifts from Amazon Web Services, Google, SAP, Blue Goji, Cisco, Clearstory Data, Cloudera, Ericsson, Facebook, General Electric, Hortonworks, Intel, Microsoft, NetApp, Oracle, Samsung, Splunk, VMware and Yahoo!. This material is also based upon work supported in part by the Office of Naval Research under contract/grant number N00014-11-1-0688. X. Pan’s work is also supported in part by a DSO National Laboratories Postgraduate Scholarship. T. Broderick’s work is supported by a Berkeley Fellowship."
    } ],
    "references" : [ {
      "title" : "Parallel Gibbs sampling: From colored fields to thin junction trees",
      "author" : [ "J. Gonzalez", "Y. Low", "A. Gretton", "C. Guestrin" ],
      "venue" : "In Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS),",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2011
    }, {
      "title" : "Distributed GraphLab: A framework for machine learning and data mining in the cloud",
      "author" : [ "Yucheng Low", "Joseph Gonzalez", "Aapo Kyrola", "Danny Bickson", "Carlos Guestrin", "J.M. Hellerstein" ],
      "venue" : "In Proceedings of the 38th International Conference on Very Large Data Bases (VLDB, Istanbul,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2012
    }, {
      "title" : "Hogwild: A lock-free approach to parallelizing stochastic gradient descent",
      "author" : [ "Benjamin Recht", "Christopher Re", "Stephen J. Wright", "Feng Niu" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS)",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2011
    }, {
      "title" : "Scalable inference in latent variable models",
      "author" : [ "Amr Ahmed", "Mohamed Aly", "Joseph Gonzalez", "Shravan Narayanamurthy", "Alexander J. Smola" ],
      "venue" : "In Proceedings of the 5th ACM International Conference on Web Search and Data Mining (WSDM),",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2012
    }, {
      "title" : "On optimistic methods for concurrency control",
      "author" : [ "Hsiang-Tsung Kung", "John T Robinson" ],
      "venue" : "ACM Transactions on Database Systems (TODS),",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1981
    }, {
      "title" : "Revisiting k-means: New algorithms via Bayesian nonparametrics",
      "author" : [ "Brian Kulis", "Michael I. Jordan" ],
      "venue" : "In Proceedings of 29th International Conference on Machine Learning (ICML), Edinburgh,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2012
    }, {
      "title" : "MAD-bayes: MAP-based asymptotic derivations from Bayes",
      "author" : [ "Tamara Broderick", "Brian Kulis", "Michael I. Jordan" ],
      "venue" : "In Proceedings of the 30th International Conference on Machine Learning (ICML),",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2013
    }, {
      "title" : "A bridging model for parallel computation",
      "author" : [ "Leslie G. Valiant" ],
      "venue" : "Communications of the ACM,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1990
    }, {
      "title" : "Spark: Cluster computing with working sets",
      "author" : [ "Matei Zaharia", "Mosharaf Chowdhury", "Michael J Franklin", "Scott Shenker", "Ion Stoica" ],
      "venue" : "In Proceedings of the 2nd USENIX Conference on Hot Topics in Cloud Computing,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2010
    }, {
      "title" : "Online facility location",
      "author" : [ "A. Meyerson" ],
      "venue" : "In Proceedings of the 42nd Annual Symposium on Foundations of Computer Science (FOCS), Las Vegas,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2001
    }, {
      "title" : "Clustering data streams: Theory and practice",
      "author" : [ "A. Meyerson", "N. Mishra", "R. Motwani", "L. O’Callaghan" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2003
    }, {
      "title" : "Streaming k-means approximation",
      "author" : [ "N. Ailon", "R. Jaiswal", "C. Monteleoni" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS)",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2009
    }, {
      "title" : "Stick-breaking Beta processes and the Poisson process",
      "author" : [ "John Paisley", "David Blei", "Michael I Jordan" ],
      "venue" : "In Proceedings of the 15th International Conference on Artificial Intelligence and Statistics (AISTATS),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2012
    }, {
      "title" : "Distributed inference for Latent Dirichlet Allocation",
      "author" : [ "D. Newman", "A. Asuncion", "P. Smyth", "M. Welling" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS)",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2007
    }, {
      "title" : "ClusterCluster: Parallel Markov chain Monte Carlo for Dirichlet process mixtures",
      "author" : [ "D. Lovell", "J. Malmaud", "R.P. Adams", "V.K. Mansinghka" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2013
    }, {
      "title" : "Large scale nonparametric Bayesian inference: Data parallelisation in the Indian Buffet process",
      "author" : [ "F. Doshi-Velez", "D. Knowles", "S. Mohamed", "Z. Ghahramani" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS)",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2009
    }, {
      "title" : "Multicore Gibbs sampling in dense, unstructured graphs",
      "author" : [ "Tianbing Xu", "Alexander Ihler" ],
      "venue" : "In Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS)",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2011
    }, {
      "title" : "A data-clustering algorithm on distributed memory multiprocessors",
      "author" : [ "I. Dhillon", "D.S. Modha" ],
      "venue" : "In Workshop on Large-Scale Parallel KDD Systems,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2000
    }, {
      "title" : "Google news personalization: Scalable online collaborative filtering",
      "author" : [ "A. Das", "M. Datar", "A. Garg", "S. Ragarajam" ],
      "venue" : "In Proceedings of the 16th World Wide Web Conference,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2007
    }, {
      "title" : "Fast clustering using MapReduce",
      "author" : [ "A. Ene", "S. Im", "B. Moseley" ],
      "venue" : "In Proceedings of the 17th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, San Diego,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2011
    }, {
      "title" : "Fast and accurate k-means for large datasets",
      "author" : [ "M. Shindler", "A. Wong", "A. Meyerson" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS)",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2011
    }, {
      "title" : "Better streaming algorithms for clustering problems",
      "author" : [ "Moses Charikar", "Liadan O’Callaghan", "Rina Panigrahy" ],
      "venue" : "In Proceedings of the 35th Annual ACM Symposium on Theory of Computing (STOC),",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2003
    }, {
      "title" : "Approximate clustering via core-sets",
      "author" : [ "Mihai Bǎdoiu", "Sariel Har-Peled", "Piotr Indyk" ],
      "venue" : "In Proceedings of the 34th Annual ACM Symposium on Theory of Computing (STOC),",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2002
    }, {
      "title" : "Scalable training of mixture models via coresets",
      "author" : [ "D. Feldman", "A. Krause", "M. Faulkner" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS)",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2011
    }, {
      "title" : "Scalable kmeans++",
      "author" : [ "B. Bahmani", "B. Moseley", "A. Vattani", "R. Kumar", "S. Vassilvitskii" ],
      "venue" : "In Proceedings of the 38th International Conference on Very Large Data Bases (VLDB), Istanbul,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "The mutual exclusion approach, adopted by [1] and [2], guarantees a serializable execution preserving the theoretical properties of the serial algorithm but at the expense of parallelism and costly locking overhead.",
      "startOffset" : 42,
      "endOffset" : 45
    }, {
      "referenceID" : 1,
      "context" : "The mutual exclusion approach, adopted by [1] and [2], guarantees a serializable execution preserving the theoretical properties of the serial algorithm but at the expense of parallelism and costly locking overhead.",
      "startOffset" : 50,
      "endOffset" : 53
    }, {
      "referenceID" : 2,
      "context" : "Alternatively, in the coordination-free approach, proposed by [3] and [4], processors communicate frequently without coordination minimizing the cost of contention but leading to stochasticity, data-corruption, and requiring potentially complex analysis to prove algorithm correctness.",
      "startOffset" : 62,
      "endOffset" : 65
    }, {
      "referenceID" : 3,
      "context" : "Alternatively, in the coordination-free approach, proposed by [3] and [4], processors communicate frequently without coordination minimizing the cost of contention but leading to stochasticity, data-corruption, and requiring potentially complex analysis to prove algorithm correctness.",
      "startOffset" : 70,
      "endOffset" : 73
    }, {
      "referenceID" : 4,
      "context" : "In this paper we explore a third approach, optimistic concurrency control (OCC) [5] which offers the performance gains of the coordination-free approach while at the same time ensuring a serializable execution and preserving the theoretical properties of the serial algorithm.",
      "startOffset" : 80,
      "endOffset" : 83
    }, {
      "referenceID" : 5,
      "context" : "We apply OCC to distributed nonparametric unsupervised learning—including but not limited to clustering—and implement distributed versions of the DP-Means [6], BP-Means [7], and online facility location (OFL) algorithms.",
      "startOffset" : 155,
      "endOffset" : 158
    }, {
      "referenceID" : 6,
      "context" : "We apply OCC to distributed nonparametric unsupervised learning—including but not limited to clustering—and implement distributed versions of the DP-Means [6], BP-Means [7], and online facility location (OFL) algorithms.",
      "startOffset" : 169,
      "endOffset" : 172
    }, {
      "referenceID" : 4,
      "context" : "To address this problem, the database community has adopted optimistic concurrency control (OCC) [5] in which the system tries to satisfy the customers requests without locking and corrects transactions that could lead to negative inventory (e.",
      "startOffset" : 97,
      "endOffset" : 100
    }, {
      "referenceID" : 7,
      "context" : "While it is possible to execute this pattern asynchronously with minimal coordination, for simplicity we adopt the bulk-synchronous model of [8] and divide the computation into epochs.",
      "startOffset" : 141,
      "endOffset" : 144
    }, {
      "referenceID" : 8,
      "context" : "While potentially slower than an asynchronous execution, the bulk-synchronous execution is deterministic and can be easily expressed using existing systems like Hadoop or Spark [9].",
      "startOffset" : 177,
      "endOffset" : 180
    }, {
      "referenceID" : 6,
      "context" : "Rather than focusing solely on K-means, however, we have been inspired by recent work in which a general family of K-means-like algorithms have been obtained by taking Bayesian nonparametric (BNP) models based on combinatorial stochastic processes such as the Dirichlet process, the beta process, and hierarchical versions of these processes, and subjecting them to smallvariance asymptotics where the posterior probability under the BNP model is transformed into a cost function that can be optimized [7].",
      "startOffset" : 502,
      "endOffset" : 505
    }, {
      "referenceID" : 9,
      "context" : "We build on the online facility location (OFL) algorithm described by Meyerson [10].",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 10,
      "context" : "In contrast to divide-and-conquer schemes, whose approximation bounds commonly depend multiplicatively on the number of levels [11], Theorem 4.",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 10,
      "context" : "Furthermore, to retain the same factors as a batch algorithm on the full data, divide-and-conquer schemes need a large number of preliminary centers at lower levels [11, 12].",
      "startOffset" : 165,
      "endOffset" : 173
    }, {
      "referenceID" : 11,
      "context" : "Furthermore, to retain the same factors as a batch algorithm on the full data, divide-and-conquer schemes need a large number of preliminary centers at lower levels [11, 12].",
      "startOffset" : 165,
      "endOffset" : 173
    }, {
      "referenceID" : 12,
      "context" : "Feature modeling: We use the stick-breaking procedure of [13] to generate feature weights.",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 8,
      "context" : "We also implemented1 the distributed algorithms in Spark [9], an open-source cluster computing system.",
      "startOffset" : 57,
      "endOffset" : 60
    }, {
      "referenceID" : 13,
      "context" : "[14] proposed transforming the underlying model to expose additional parallelism while preserving the marginal posterior.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 14,
      "context" : "Likewise, [15] proposed a reparameterization of the underlying model to expose additional parallelism through conditional independence.",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 15,
      "context" : "work similar in spirit to ours using OCC-like techniques includes [16] who proposed an approximate parallel sampling algorithm for the IBP which is made exact by introducing an additional MetropolisHastings step, and [17] who proposed a look-ahead strategy in which future samples are computed optimistically based on the likely outcomes of current samples.",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 16,
      "context" : "work similar in spirit to ours using OCC-like techniques includes [16] who proposed an approximate parallel sampling algorithm for the IBP which is made exact by introducing an additional MetropolisHastings step, and [17] who proposed a look-ahead strategy in which future samples are computed optimistically based on the likely outcomes of current samples.",
      "startOffset" : 217,
      "endOffset" : 221
    }, {
      "referenceID" : 17,
      "context" : "There has been substantial work on scalable clustering algorithms [18, 19, 20].",
      "startOffset" : 66,
      "endOffset" : 78
    }, {
      "referenceID" : 18,
      "context" : "There has been substantial work on scalable clustering algorithms [18, 19, 20].",
      "startOffset" : 66,
      "endOffset" : 78
    }, {
      "referenceID" : 19,
      "context" : "There has been substantial work on scalable clustering algorithms [18, 19, 20].",
      "startOffset" : 66,
      "endOffset" : 78
    }, {
      "referenceID" : 10,
      "context" : "Several authors [11, 21, 22, 12] have proposed streaming approximation algorithms that rely on hierarchical divideand-conquer schemes.",
      "startOffset" : 16,
      "endOffset" : 32
    }, {
      "referenceID" : 20,
      "context" : "Several authors [11, 21, 22, 12] have proposed streaming approximation algorithms that rely on hierarchical divideand-conquer schemes.",
      "startOffset" : 16,
      "endOffset" : 32
    }, {
      "referenceID" : 21,
      "context" : "Several authors [11, 21, 22, 12] have proposed streaming approximation algorithms that rely on hierarchical divideand-conquer schemes.",
      "startOffset" : 16,
      "endOffset" : 32
    }, {
      "referenceID" : 11,
      "context" : "Several authors [11, 21, 22, 12] have proposed streaming approximation algorithms that rely on hierarchical divideand-conquer schemes.",
      "startOffset" : 16,
      "endOffset" : 32
    }, {
      "referenceID" : 11,
      "context" : "Several methods [12, 25, 21] first collect and then re-cluster a set of centers, and therefore need to communicate all intermediate centers.",
      "startOffset" : 16,
      "endOffset" : 28
    }, {
      "referenceID" : 24,
      "context" : "Several methods [12, 25, 21] first collect and then re-cluster a set of centers, and therefore need to communicate all intermediate centers.",
      "startOffset" : 16,
      "endOffset" : 28
    }, {
      "referenceID" : 20,
      "context" : "Several methods [12, 25, 21] first collect and then re-cluster a set of centers, and therefore need to communicate all intermediate centers.",
      "startOffset" : 16,
      "endOffset" : 28
    } ],
    "year" : 2013,
    "abstractText" : "Research on distributed machine learning algorithms has focused primarily on one of two extremes—algorithms that obey strict concurrency constraints or algorithms that obey few or no such constraints. We consider an intermediate alternative in which algorithms optimistically assume that conflicts are unlikely and if conflicts do arise a conflict-resolution protocol is invoked. We view this “optimistic concurrency control” paradigm as particularly appropriate for large-scale machine learning algorithms, particularly in the unsupervised setting. We demonstrate our approach in three problem areas: clustering, feature learning and online facility location. We evaluate our methods via large-scale experiments in a cluster computing environment.",
    "creator" : null
  }
}