{
  "name" : "f9b902fc3289af4dd08de5d1de54f68f.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Mid-level Visual Element Discovery as Discriminative Mode Seeking",
    "authors" : [ "Carl Doersch", "Abhinav Gupta", "Alexei A. Efros" ],
    "emails" : [ "cdoersch@cs.cmu.edu", "abhinavg@cs.cmu.edu", "efros@cs.berkeley.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "In terms of sheer size, visual data is, by most accounts, the biggest “Big Data” out there. But, unfortunately, most machine learning algorithms (with some notable exceptions, e.g. [13]) are not equipped to handle it directly, at the raw pixel level, making research on finding good visual representations particularly relevant and timely. Currently, the most popular visual representations in machine learning are based on “visual words” [24], which are obtained by unsupervised clustering (k-means) of local features (SIFT) over a large dataset. However, “visual words” is a very low-level representation, mostly capturing local edges and corners ([21] notes that “visual letters” or “visual phonemes” would have been a more accurate term). Part of the problem is that the local SIFT features are relatively low-dimensional (128D), and might not be powerful enough to capture anything of higher complexity. However, switching to a more descriptive feature (e.g. 2, 000-dimensional HOG) causes k-means to produce visually poor clusters due to the curse of dimensionality [5].\nRecently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i.e., entities which are more informative than “visual words,” and more frequently occurring and easier to detect than high-level objects. Most such approaches require some form of weak per-image labels, e.g., scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7]. But how are informative visual elements to be identified in the weakly-labeled visual dataset? The idea is to search for clusters of image patches that are both 1) representative, i.e. frequently occurring within the dataset, and 2) visually discriminative. Unfortunately, algorithms for finding patches that fit these criteria remain rather ad-hoc and poorly understood. and often do not even directly optimize these criteria. Hence, our goal in this work is to quantify the terms “representative” and “discriminative,” and show that a formulation which draws inspiration from"
    }, {
      "heading" : "2.58 2.92 3.07 3.10 3.16 1.01 1.13 1.13 1.15 1.17 Distance: Distance:",
      "text" : "the well-known, well-understood mean-shift algorithm can produce visual elements that are more representative and discriminative than those of previous approaches.\nMining visual elements from a large dataset is difficult for a number of reasons. First, the search space is huge: a typical dataset for visual data mining has tens of thousands of images, and finding something in an image (e.g., finding matches for a visual template) involves searching across tens of thousands of patches at different positions and scales. To make matters worse, patch descriptors tend to be on the order of thousands of dimensions; not only is the curse of dimensionality a constant problem, but we must sift through terabytes of data. And we are searching for a needle in a haystack: the vast majority of patches are actually uninteresting, either because they are rare (e.g., they may contain multiple random things in a configuration that never occurs again) or they are redundant due to the overlapping nature of patches. This suggests the need for an online algorithm, because we wish to discard much of the data while making as few passes through the dataset as possible.\nThe well-known mean-shift algorithm [2, 3, 8] has been proposed to address many of these problems. The goal of mean-shift is to find the local maxima (modes) of a density using a sample from that density. Intuitively, mean-shift initializes each cluster centroid to a single data point, then iteratively 1) finds data points that are sufficiently similar to each centroid, and, 2) averages these data points to update the cluster centroid. In the end, each cluster generally depends on only a tiny fraction of the data, thus eliminating the need to keep the entire dataset in memory.\nHowever, there is one issue with using classical mean-shift to solve our problem directly: it only finds local maxima of a single, unlabeled density, which may not be discriminative. But in our case, we can use the weak labels to divide our data into two different subsets (“positive” (+) and “negative” ( )) and seek visual elements which appear only in the “positive” set and not in the “negative” set. That is, we want to find points in feature space where the density of the positive set is large, and the density of the negative set is small. This can be achieved by maximizing the well-studied density ratio p+(x)/p (x) instead of maximizing the density. While a number of algorithms exist for estimating ratios of densities (see [25] for a review), we did not find any that were particularly suitable for finding local maxima of density ratios. Hence, the first contribution of our paper is to propose a discriminative variant of mean-shift for finding visual elements. Similar to the way mean-shift performs gradient ascent on a density estimate, our algorithm performs gradient ascent on the density ratio (section 2). When we perform gradient ascent separately for each element as in standard mean-shift, however, we find that the most frequently-occuring elements tend to be over-represented. Hence, section 3 describes a modification to our gradient ascent algorithm which uses inter-element communication to approximate common adaptive bandwidth procedures. Finally, in section 4 we demonstrate that our algorithms produce visual elements which are more representative and discriminative than previous methods, and in section 5 we show they significantly improve performance in scene classification."
    }, {
      "heading" : "2 Mode Seeking on Density Ratios",
      "text" : "Our goal is to extract discriminative visual elements by finding the local maxima of the density ratio. However, one issue with performing gradient ascent directly on standard density ratio estimates is that common estimators tend to use a fixed kernel bandwidth, for example:\nr̂(x) / nX\ni=1\n✓iK(kx xik/h)\nwhere r̂ is the ratio estimate, the parameters ✓i 2 R are weights associated with each datapoint, K is a kernel function (e.g., a Gaussian), and h is a globally-shared bandwidth parameter. The\nbandwidth defines how much the density is smoothed before gradient ascent is performed, meaning these estimators assume a roughly equal distribution of points in all regions of the space. Unfortunately, absolute distances in HOG feature space cannot be trusted, as shown in Figure 1: any kernel bandwidth which is large enough to work well in the left example will be far too large to work well in the right. One way to deal with the non-uniformity of the feature space is to use an adaptive bandwidth [4]: that is, different bandwidths are used in different regions of the space. However, previous algorithms are difficult to implement for large data in high-dimensional spaces; [4], for instance, requires a density estimate for every point used in computing the gradient of their objective, because their formulation relies on a per-point bandwidth rather than a per-cluster bandwidth. In our case, this is prohibitively expensive. While approximations exist [9], they rely on approximate nearest neighbor algorithms, which work for low-dimensional spaces ( 48 dimensions in [9]), but empirically we have found poor performance in HOG feature space (> 2000 dimensions). Hence, we take a different approach which we have tailored for density ratios.\nWe begin by using a result from [2] that classical mean-shift (using a flat kernel) is equivalent to finding the local maxima of the following density estimate:\nPn i=1 max(b d(xi, w), 0)\nz(b) (1)\nIn standard mean-shift, d is the Euclidean distance function, b is a constant that controls the kernel bandwidth, and z(b) is a normalization constant. Here, the flat kernel has been replaced by its shadow kernel, the triangular kernel, using Theorem 1 from [2]. We want to maximize the density ratio, so we simply divide the two density estimates. We allow an adaptive bandwidth, but rather than associating a bandwidth with each datapoint, we compute it as a function of w which depends on the data.\nPn pos\ni=1 max(B(w) d(x + i , w), 0)Pn\nneg i=1 max(B(w) d(x i , w), 0)\n(2)\nWhere the normalization term z(b) is cancelled. This expression, however, produces poor estimates of the ratio if the denominator is allowed to shrink to zero; in fact, it can produce arbitrarily large but spurious local maxima. Hence, we define B(w) as the value of b which satisfies:\nn negX\ni=1\nmax(b d(x i , w), 0) = (3)\nWhere is a constant analogous to the bandwidth parameter, except that it directly controls how many negative datapoints are in each cluster. Note the value of the sum is strictly increasing in b when it is nonzero, so the b satisfying the constraint is unique. With this definition of B(w), we are actually fixing the value of the denominator of (2) (We include the denominator here only to make the ratio explicit, and we will drop it in later formula). This approach makes the implicit assumption that the distribution of the negatives captures the overall density of the patch space. Note that if we assume the denominator distribution is uniform, then B(w) becomes fixed and our objective is identical to fixed-bandwidth mean-shift.\nReturning to our formulation, we must still choose the distance function d. In high-dimensional feature space, [20] suggests that normalized correlation provides a better metric than the Euclidean distance commonly used in mean-shift. Formulations of mean-shift exist for data constrained to the unit sphere [1], but again we must adapt them to the ratio setting. Surprisingly, replacing the Euclidean distance with normalized correlation leads to a simpler optimization problem. First, we mean-subtract and normalize all datapoints xi and rewrite (2) as:\nn posX\ni=1\nmax(w>x+i b, 0) s.t. Pn neg i=1 max(w >x i b, 0) =\nkwk2 = 1 (4)\nWhere B(w) has been replaced by b as in equation (3), to emphasize that we can treat B(w) as a constraint in an optimization problem. We can further rewrite the above equation as finding the local maxima of:\nn posX\ni=1\nmax(w>x+i b, 0) kwk 2 s.t.\nn negX\ni=1\nmax(w>x i b, 0) = (5)\nNote that (5) is equivalent to (4) for some appropriate rescaling of and . It can be easily shown that multiplying by a constant factor does not change the relative location of local maxima, as long as we divide by that same factor. Such a re-scaling will in fact result in re-scaling w by the same value, so we can choose a and which makes the norm of w equal to 1. 1\nAfter this rewriting, we are left with an objective that looks curiously like a margin-based method. Indeed, the negative set is treated very much like the negative set in an SVM (we penalize the linear sum of the margin violations), which follows [23]. However, unlike [23], which makes the ad-hoc choice of 5 positive examples, our algorithm allows each cluster to select the optimal number of positives based on the decision boundary. This is somewhat reminiscent of unsupervised marginbased clustering [29, 16].\nMean-shift prescribes that we initialize the procedure outlined above at every datapoint. In our setting, however, this is not practical, so we instead use a randomly-sampled subset. We run this as an online algorithm by breaking the dataset into chunks and then mining, one chunk at a time, for patches where w>x b > ✏ for some small ✏, akin to “hard mining” for SVMs. We perform gradient ascent after each mining phase. An example result for this algorithm is shown in in Figure 2, and we include further results below. Gradient ascent on our objective is surprisingly efficient, as described in Appendix A."
    }, {
      "heading" : "3 Better Adaptive Bandwidth via Inter-Element Communication",
      "text" : "Implicit in our formulation thus far is the idea that we do not want a single mode, but instead many distinct modes which each corresponds to a different element. In theory, mode-seeking will find every mode that is supported by the data. In practice, clusters often drift from weak modes to stronger modes, as demonstrated in Figure 2 (middle). One way to deal with this is to assign smaller bandwidths to patches in dense regions of the space [4], e.g., the window railing on row 1 of Figure 2 (middle) would hopefully have a smaller bandwidth and hence not match to the sidewalk barrier. However, estimating a bandwidth for every datapoint in our setting is not practical, so we seek an approach which only requires one pass through the data. Since patches in regions of the feature space with high density ratio will be members of many clusters, we want a mechanism that will reduce their bandwidth. To accomplish this, we extend the standard local (per-element) optimization of mean-shift into a joint optimization among the m different element clusters. Specifically, we control how a single patch can contribute to multiple clusters by introducing a sharing weight ↵i,j for each patch i that is contained in a cluster j, akin to soft-assignment in EM GMM fitting. Returning to our fomulation, we maximize (again with respect to the w’s and b’s):\nn posX\ni=1\nmX\nj=1\n↵i,j max(w > j x + i bj , 0)\nmX\nj=1\nkwjk2 s.t. 8j n negX\ni=1\nmax(w>j x i bj , 0) = (6)\nWhere each ↵i,j is chosen such that any patch which is a member of multiple clusters gets a lower weight. (6) also has a natural interpretation in terms of maximizing the “representativeness” of the set of clusters: clusters are rewarded for representing patches that are not represented by other clusters. But how can we set the ↵’s? One way is to set ↵i,j = max(w>j x + i bj , 0)/ Pm k=1 max(w > k x + i bk, 0), and alternate between setting the ↵’s and optimizing the w’s and\n1Admittedly this means that the norm of w has an indirect effect on the underlying bandwidth: specifically if the norm of w is increased, it has a similar effect as a proportional derease in in (4). However, since w is roughly proportional to the density of the positive data, the bandwidth is only reduced when the density of positive data is high.\nb’s at each iteration. Intuitively, this algorithm would be much like EM, alternating between softly assigning cluster memberships for each datapoint and then optimizing each cluster. However, this goes against our mean-shift intuition: if two patches are really instances of the same element, then clusters initialized from those two points should converge to the same mode and not “compete” with one another. So, our heuristic is to first cluster the elements. Let Cj be the assigned cluster for the j’th element. Then we set\n↵i,j = max(w>j x + i bj , 0)\nmax(w>j x + i bj , 0) + Pm k=1 I(Ck 6= Cj)max(w>k x + i bk, 0)\n(7)\nIn this way, any “competition” from elements that are too similar to each other is ignored. To obtain the clusters, we perform agglomerative (UPGMA) clustering on the set of element clusters, using the negative of the number of overlapping cluster members as a “distance” metric.\nIn practice, however, it is extremely rare that the exact same patch is a member of two different clusters; instead, clusters will have member patches that merely overlap with each other. Our heuristic deal with this is to compute a quantity ↵0i,j,p which is analogous to the ↵i,j defined above, but is defined for every pixel p. Then we compute ↵i,j for a given patch by averaging ↵0i,j,p over all pixels in the patch. Specifically, we compute ↵i,j for patch i as the mean over all pixels p in that patch of the following quantity:\n↵0i,j,p = max(w>j x + i bj , 0)\nmax(w>j x + i bj , 0) + P x2Ov(p) Pm k=1 I(Ck 6= Cj)max(w>k x + i bk, 0)\n(8)\nWhere Ov(p) denotes the set of features for positive patches that contain the pixel p.\nIt is admittedly difficult to analyze how well these heuristics approximate the adaptive bandwidth approach of [4], and even there the setting of the bandwidth for each datapoint has heuristic aspects. However, empirically our approach leads to improvements in performance as discussed below, and suggests a potential area for future work."
    }, {
      "heading" : "4 Evaluation via Purity-Coverage Plot",
      "text" : "Our aim is to discover visual elements that are maximally representative and discriminative. To measure this, we define two quantities for a set of visual elements: coverage (which captures representativeness) and purity (which captures discriminativeness). Given a held-out test set, visual elements will generate a set of patch detections. We define the coverage of this set of patches to be the fraction of the pixels from the positive images claimed by at least one patch. We define the purity of a set as the percentage of the patches that share the same label. For an individual visual element, of course, there is an inherent trade-off between purity and coverage: if we lower the detection threshold, we cover more pixels but also increase the likelihood of making mistakes. Hence, we can construct a purity-coverage curve for a set of elements, analogous to a precision-recall curve. We could perform this analysis on any dataset containing positive and negative images, but [5] presents a dataset which is particularly suitable. The goal is to mine visual elements which define the look and feel of a geographical locale, with a training set of 2,000 Paris Street View images and 8,000\nnon-Paris images, as well as 2,999 of both classes for testing. Purity-coverage curves for this dataset are shown in Figure 3.\nTo plot the curve for a given value of purity p, we rank all patches by w>x b independently for every element, and select, for a given element, all patches up until the last point where the element has the desired purity. We then compute the coverage as the union of patches selected for every element. Because we are taking a union of patches, adding more elements can only increase coverage, but in practice we prefer concise representations, both for interpretability and for computational reasons. Hence, to compare two element discovery methods, we must select exactly the same number of elements for both of them. Different works have proposed different heuristics for selecting elements, which would make the resulting curves incomparable. Hence, we select elements in the same way for all algorithms, which approximates an “ideal” selection for our measure. Specifically, we first fix a level of purity (95%) and greedily select elements to maximize coverage (on the testing data) for that level of purity. Hence, this ranking serves as an oracle to choose the “best” set of elements for covering the dataset at that level of purity. While this ranking has a bias toward large elements (which inherently cover more pixels per detection), we believe that it provides a valuable comparison between algorithms. Our purity-coverage curves are shown in Figure 3, for the 25 and 200 top elements, respectively. We can also slice the same data differently, fixing a level of purity for all elements and varying the number of elements, as shown in Figure 4.\nBaselines: We included five baselines of increasing complexity. Our goal is not only to analyze our own algorithm; we want to show the importance of the various components of previous algorithms as well. We initially train 20, 000 visual elements for all the baselines, and select the top elements using the method above. The simplest baseline is “Exemplar LDA,” proposed by [10]. Each cluster is represented by a hyperplane which maximally separates a single seed patch from the negative dataset learned via LDA, i.e. the negative distribution is approximated using a single multivariate Gaussian. To show the effects of re-clustering, “LDA Retrained” takes the top 5 positive-set patches retrieved in Exemplar LDA (including the initial patch itself), and repeats LDA, separating those 5 from the negative Gaussian. This is much like the well-established method of “query expansion” for retrieval, and is similar to [12] (although they use multiple iterations of query expansion). Finally, “LDA Retrained 5 times” begins with elements initialized via the LDA retraining method, and retrains the LDA classifier, each time throwing out the previous top 5 used to train the previous LDA, and selecting a new top 5 from held-out data. This is much like the iterative SVM training of [5], except that it uses LDA instead of an SVM. Finally, we include the algorithm of [5], which is a weakly supervised version of [23], except that knn is being used for initialization instead of kmeans. The iterations of retraining clearly improve performance, and it seems that replacing LDA with an SVM also gives improvement, especially for difficult elements.\nImplementation details: We use the same patch descriptors described in [5] and whiten them following [10]. We mine elements using the online version of our algorithm, with a chunk size of 1000 (200 Paris, 800 non-Paris per batch). We set ⇤ = t/500 where t is the iteration number, such that the bandwidth increases proportional to the number of samples. We train the elements for about 200\ngradient steps after each chunk of mining. To compute ↵i,j for patch i and detector j, we actually use scale-space voxels rather than pixels, since a large detection can completely cover a small detection but not vice versa. Hence, the set of scale-space voxels covered is a 3D box, the width of the bounding box by its height (both discretized by a factor of 8 for efficiency) by 5, covering exactly one “octave” of scale space (i.e. log2( p width ⇤ height) ⇤ 5 through log2( p width ⇤ height) ⇤ 5 + 4). For experiments without inter-element communication, we simply set ↵i,j to .1. Finally, to reduce the impact of highly redundant textures, we divide ↵i,j divided by the total number of detections for element j in the image containing i. Source code will be available online."
    }, {
      "heading" : "5 Scene Classification",
      "text" : "Finally, we evaluate whether our visual element representation is useful for scene classification. We use the MIT Scene-67 dataset [19], where machine performance remains substantially below human\nGround Truth (GT): deli GT: laundromat GT: corridor Guess: grocery store Guess: closet Guess: staircase\nperformance. For indoor scenes, objects within the scene are often more useful features than global scene statistics [12]: for instance, shoe shops are similar to other stores in global layout, but they mostly contain shoes.\nImplementation details: We used the original Indoor-67 train/test splits (80 training and 20 testing images per class). We learned 1600 elements per class, for a total of 107, 200 elements, following the procedure described above. We include right-left flipped images as extra positives. 5 batches were sufficient, as this dataset is smaller. We also used smaller descriptors: 6-by-6 HOG cells, corresponding to 64-by-64 patches and 1188-dimensional descriptors. We again select elements by fixing purity and greedily selecting elements to maximize coverage, as above. However, rather than defining coverage as the number of pixels (which is biased toward larger elements), we simply count the detections, penalizing for overlap: we penalize each individual detection by a factor of 1/(1 + noverlap), where noverlap is the number of detections from previously selected detectors that a given detection overlaps with. We select 200 top elements per class. To construct our final feature vector, we use a 2-level (1x1 and 2x2) spatial pyramid and take the max score per detector per region, thresholded at .5 (since below this value we do not expect the detection scores to be meaningful) resulting in a 67,000-dimensional vector. We average the feature vector for the right and left flips of the image, and classify using 67 one-vs-all linear SVM’s. Note that this differs from [23], which selects only the elements for a given class in each class-specific SVM.\nFigure 5 shows a few qualitative results of our algorithm. Quantitative results and comparisons are shown in Table 1. We significantly outperform other methods based on discriminative patches, suggesting that our training method is useful. We even outperform the Improved Fisher Vector of [12], as well as IFV combined with discriminative patches (IFV+BoP). Finally, although the optimally-performing representation is dense (about 58% of features are nonzero), it can be made much sparser without sacrificing much performance. For instance, if we trivially zero-out lowvalued features until fewer than 6% are nonzero, we still achieve 60.45% accuracy."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We developed an extension of the classic mean-shift algorithm to density ratio estimation, showing that the resulting algorithm could be used for element discovery, and demonstrating state-of-the-art results for scene classification. However, there is still much room for improvement in weaklysupervised element discovery algorithms. For instance, our algorithm is limited to binary labels, but image labels may be continuous (e.g., GPS coordinates or dates). Also, our elements are detected based only on individual patches, but images often contain global structures beyond patches. Acknowledgements: We thank Abhinav Shrivastava, Yong Jae Lee, Supreeth Achar, and Geoff Gordon for helpful insights and discussions. This work was partially supported by NDSEG fellowship to CD, An Amazon Web Services grant, a Google Research grant, ONR MURI N000141010934, and IARPA via Air Force Research Laboratory. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation thereon. Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, AFRL or the U.S. Government."
    } ],
    "references" : [ {
      "title" : "Intrinsic mean shift for clustering on Stiefel and Grassmann manifolds",
      "author" : [ "H.E. Cetingul", "R. Vidal" ],
      "venue" : "CVPR",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Mean shift",
      "author" : [ "Y. Cheng" ],
      "venue" : "mode seeking, and clustering. PAMI, 17(8):790–799",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Real-time tracking of non-rigid objects using mean shift",
      "author" : [ "D. Comaniciu", "V. Ramesh", "P. Meer" ],
      "venue" : "CVPR",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "The variable bandwidth mean shift and data-driven scale selection",
      "author" : [ "D. Comaniciu", "V. Ramesh", "P. Meer" ],
      "venue" : "ICCV",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "and A",
      "author" : [ "C. Doersch", "S. Singh", "A. Gupta", "J. Sivic" ],
      "venue" : "A. Efros. What makes Paris look like Paris? SIGGRAPH",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Learning collections of part models for object recognition",
      "author" : [ "I. Endres", "K. Shih", "J. Jiaa", "D. Hoiem" ],
      "venue" : "CVPR",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Data-driven 3D primitives for single image understanding",
      "author" : [ "D.F. Fouhey", "A. Gupta", "M. Hebert" ],
      "venue" : "ICCV",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "The estimation of the gradient of a density function",
      "author" : [ "K. Fukunaga", "L. Hostetler" ],
      "venue" : "with applications in pattern recognition. Information Theory",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 1975
    }, {
      "title" : "Mean shift based clustering in high dimensions: A texture classification example",
      "author" : [ "B. Georgescu", "I. Shimshoni", "P. Meer" ],
      "venue" : "CVPR",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Discriminative decorrelation for clustering and classification",
      "author" : [ "B. Hariharan", "J. Malik", "D. Ramanan" ],
      "venue" : "ECCV",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Representing videos using mid-level discriminative patches",
      "author" : [ "A. Jain", "A. Gupta", "M. Rodriguez", "L. Davis" ],
      "venue" : "CVPR",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Blocks that shout: Distinctive parts for scene classification",
      "author" : [ "M. Juneja", "A. Vedaldi", "C.V. Jawahar", "A. Zisserman" ],
      "venue" : "CVPR",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks",
      "author" : [ "A. Krizhevsky", "I. Sutskever", "G. Hinton" ],
      "venue" : "NIPS",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Object bank: A high-level image representation for scene classification and semantic feature sparsification",
      "author" : [ "L.-J. Li", "H. Su", "E.P. Xing", "L. Fei-Fei" ],
      "venue" : "NIPS",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Harvesting mid-level visual concepts from large-scale internet images",
      "author" : [ "Q. Li", "J. Wu", "Z. Tu" ],
      "venue" : "CVPR",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Recognition by association via learning per-exemplar distances",
      "author" : [ "T. Malisiewicz", "A.A. Efros" ],
      "venue" : "CVPR",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Scene recognition and weakly supervised object localization with deformable part-based models",
      "author" : [ "M. Pandey", "S. Lazebnik" ],
      "venue" : "ICCV",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Reconfigurable models for scene recognition",
      "author" : [ "S.N. Parizi", "J.G. Oberlin", "P.F. Felzenszwalb" ],
      "venue" : "CVPR",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Recognizing indoor scenes",
      "author" : [ "A. Quattoni", "A. Torralba" ],
      "venue" : "CVPR",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Nearest neighbors in high-dimensional data: The emergence and influence of hubs",
      "author" : [ "M. Radovanović", "A. Nanopoulos", "M. Ivanović" ],
      "venue" : "ICML",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Using multiple segmentations to discover objects and their extent in image collections",
      "author" : [ "B.C. Russell", "A.A. Efros", "J. Sivic", "W.T. Freeman", "A. Zisserman" ],
      "venue" : "CVPR",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Latent pyramidal regions for recognizing scenes",
      "author" : [ "F. Sadeghi", "M.F. Tappen" ],
      "venue" : "In ECCV",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2012
    }, {
      "title" : "Unsupervised discovery of mid-level discriminative patches",
      "author" : [ "S. Singh", "A. Gupta", "A.A. Efros" ],
      "venue" : "ECCV",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Video google: A text retrieval approach to object matching in videos",
      "author" : [ "J. Sivic", "A. Zisserman" ],
      "venue" : "ICCV",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Density ratio estimation: A comprehensive review",
      "author" : [ "M. Sugiyama", "T. Suzuki", "T. Kanamori" ],
      "venue" : "RIMS Kokyuroku",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Learning discriminative part detectors for image classification and cosegmentation",
      "author" : [ "J. Sun", "J. Ponce" ],
      "venue" : "ICCV",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Max-margin multiple-instance dictionary learning",
      "author" : [ "X. Wang", "B. Wang", "X. Bai", "W. Liu", "Z. Tu" ],
      "venue" : "ICML",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Centrist: A visual descriptor for scene categorization",
      "author" : [ "J. Wu", "J.M. Rehg" ],
      "venue" : "PAMI",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Maximum margin clustering",
      "author" : [ "L. Xu", "J. Neufeld", "B. Larson", "D. Schuurmans" ],
      "venue" : "NIPS",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Large margin learning of upstream scene understanding models",
      "author" : [ "J. Zhu", "L.-J. Li", "L. Fei-Fei", "E.P. Xing" ],
      "venue" : "NIPS",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "Several approaches [5, 6, 12, 23] have been proposed to discover mid-level visual elements, that are both 1) representative, i.",
      "startOffset" : 19,
      "endOffset" : 33
    }, {
      "referenceID" : 5,
      "context" : "Several approaches [5, 6, 12, 23] have been proposed to discover mid-level visual elements, that are both 1) representative, i.",
      "startOffset" : 19,
      "endOffset" : 33
    }, {
      "referenceID" : 11,
      "context" : "Several approaches [5, 6, 12, 23] have been proposed to discover mid-level visual elements, that are both 1) representative, i.",
      "startOffset" : 19,
      "endOffset" : 33
    }, {
      "referenceID" : 22,
      "context" : "Several approaches [5, 6, 12, 23] have been proposed to discover mid-level visual elements, that are both 1) representative, i.",
      "startOffset" : 19,
      "endOffset" : 33
    }, {
      "referenceID" : 1,
      "context" : "In this work, we pose visual element discovery as discriminative mode seeking, drawing connections to the the well-known and well-studied mean-shift algorithm [2, 1, 4, 8].",
      "startOffset" : 159,
      "endOffset" : 171
    }, {
      "referenceID" : 0,
      "context" : "In this work, we pose visual element discovery as discriminative mode seeking, drawing connections to the the well-known and well-studied mean-shift algorithm [2, 1, 4, 8].",
      "startOffset" : 159,
      "endOffset" : 171
    }, {
      "referenceID" : 3,
      "context" : "In this work, we pose visual element discovery as discriminative mode seeking, drawing connections to the the well-known and well-studied mean-shift algorithm [2, 1, 4, 8].",
      "startOffset" : 159,
      "endOffset" : 171
    }, {
      "referenceID" : 7,
      "context" : "In this work, we pose visual element discovery as discriminative mode seeking, drawing connections to the the well-known and well-studied mean-shift algorithm [2, 1, 4, 8].",
      "startOffset" : 159,
      "endOffset" : 171
    }, {
      "referenceID" : 4,
      "context" : "We also propose the Purity-Coverage plot as a principled way of experimentally analyzing and evaluating different visual discovery approaches, and compare our method against prior work on the Paris Street View dataset of [5].",
      "startOffset" : 221,
      "endOffset" : 224
    }, {
      "referenceID" : 12,
      "context" : "[13]) are not equipped to handle it directly, at the raw pixel level, making research on finding good visual representations particularly relevant and timely.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 23,
      "context" : "Currently, the most popular visual representations in machine learning are based on “visual words” [24], which are obtained by unsupervised clustering (k-means) of local features (SIFT) over a large dataset.",
      "startOffset" : 99,
      "endOffset" : 103
    }, {
      "referenceID" : 20,
      "context" : "However, “visual words” is a very low-level representation, mostly capturing local edges and corners ([21] notes that “visual letters” or “visual phonemes” would have been a more accurate term).",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 4,
      "context" : "2, 000-dimensional HOG) causes k-means to produce visually poor clusters due to the curse of dimensionality [5].",
      "startOffset" : 108,
      "endOffset" : 111
    }, {
      "referenceID" : 4,
      "context" : "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i.",
      "startOffset" : 29,
      "endOffset" : 59
    }, {
      "referenceID" : 5,
      "context" : "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i.",
      "startOffset" : 29,
      "endOffset" : 59
    }, {
      "referenceID" : 10,
      "context" : "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i.",
      "startOffset" : 29,
      "endOffset" : 59
    }, {
      "referenceID" : 11,
      "context" : "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i.",
      "startOffset" : 29,
      "endOffset" : 59
    }, {
      "referenceID" : 14,
      "context" : "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i.",
      "startOffset" : 29,
      "endOffset" : 59
    }, {
      "referenceID" : 22,
      "context" : "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i.",
      "startOffset" : 29,
      "endOffset" : 59
    }, {
      "referenceID" : 25,
      "context" : "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i.",
      "startOffset" : 29,
      "endOffset" : 59
    }, {
      "referenceID" : 26,
      "context" : "Recently, several approaches [5, 6, 11, 12, 15, 23, 26, 27] have proposed mining visual data for discriminative mid-level visual elements, i.",
      "startOffset" : 29,
      "endOffset" : 59
    }, {
      "referenceID" : 11,
      "context" : ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7].",
      "startOffset" : 19,
      "endOffset" : 23
    }, {
      "referenceID" : 4,
      "context" : ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7].",
      "startOffset" : 43,
      "endOffset" : 46
    }, {
      "referenceID" : 22,
      "context" : ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7].",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 11,
      "context" : ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7].",
      "startOffset" : 154,
      "endOffset" : 166
    }, {
      "referenceID" : 22,
      "context" : ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7].",
      "startOffset" : 154,
      "endOffset" : 166
    }, {
      "referenceID" : 26,
      "context" : ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7].",
      "startOffset" : 154,
      "endOffset" : 166
    }, {
      "referenceID" : 5,
      "context" : ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7].",
      "startOffset" : 185,
      "endOffset" : 188
    }, {
      "referenceID" : 4,
      "context" : ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7].",
      "startOffset" : 209,
      "endOffset" : 216
    }, {
      "referenceID" : 14,
      "context" : ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7].",
      "startOffset" : 209,
      "endOffset" : 216
    }, {
      "referenceID" : 10,
      "context" : ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7].",
      "startOffset" : 237,
      "endOffset" : 241
    }, {
      "referenceID" : 6,
      "context" : ", scene categories [12] or GPS coordinates [5] (but can also run unsupervised [23]), and have been recently used for tasks including image classification [12, 23, 27], object detection [6], visual data mining [5, 15], action recognition [11], and geometry estimation [7].",
      "startOffset" : 267,
      "endOffset" : 270
    }, {
      "referenceID" : 4,
      "context" : "We show two patches with their 5 nearest-neighbors from the Paris Street View dataset [5]; beneath each nearest neighbor is its distance from query.",
      "startOffset" : 86,
      "endOffset" : 89
    }, {
      "referenceID" : 1,
      "context" : "The well-known mean-shift algorithm [2, 3, 8] has been proposed to address many of these problems.",
      "startOffset" : 36,
      "endOffset" : 45
    }, {
      "referenceID" : 2,
      "context" : "The well-known mean-shift algorithm [2, 3, 8] has been proposed to address many of these problems.",
      "startOffset" : 36,
      "endOffset" : 45
    }, {
      "referenceID" : 7,
      "context" : "The well-known mean-shift algorithm [2, 3, 8] has been proposed to address many of these problems.",
      "startOffset" : 36,
      "endOffset" : 45
    }, {
      "referenceID" : 24,
      "context" : "While a number of algorithms exist for estimating ratios of densities (see [25] for a review), we did not find any that were particularly suitable for finding local maxima of density ratios.",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 3,
      "context" : "One way to deal with the non-uniformity of the feature space is to use an adaptive bandwidth [4]: that is, different bandwidths are used in different regions of the space.",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 3,
      "context" : "However, previous algorithms are difficult to implement for large data in high-dimensional spaces; [4], for instance, requires a density estimate for every point used in computing the gradient of their objective, because their formulation relies on a per-point bandwidth rather than a per-cluster bandwidth.",
      "startOffset" : 99,
      "endOffset" : 102
    }, {
      "referenceID" : 8,
      "context" : "While approximations exist [9], they rely on approximate nearest neighbor algorithms, which work for low-dimensional spaces ( 48 dimensions in [9]), but empirically we have found poor performance in HOG feature space (> 2000 dimensions).",
      "startOffset" : 27,
      "endOffset" : 30
    }, {
      "referenceID" : 8,
      "context" : "While approximations exist [9], they rely on approximate nearest neighbor algorithms, which work for low-dimensional spaces ( 48 dimensions in [9]), but empirically we have found poor performance in HOG feature space (> 2000 dimensions).",
      "startOffset" : 144,
      "endOffset" : 147
    }, {
      "referenceID" : 1,
      "context" : "We begin by using a result from [2] that classical mean-shift (using a flat kernel) is equivalent to finding the local maxima of the following density estimate: Pn i=1 max(b d(xi, w), 0) z(b) (1)",
      "startOffset" : 32,
      "endOffset" : 35
    }, {
      "referenceID" : 1,
      "context" : "Here, the flat kernel has been replaced by its shadow kernel, the triangular kernel, using Theorem 1 from [2].",
      "startOffset" : 106,
      "endOffset" : 109
    }, {
      "referenceID" : 19,
      "context" : "In high-dimensional feature space, [20] suggests that normalized correlation provides a better metric than the Euclidean distance commonly used in mean-shift.",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 0,
      "context" : "Formulations of mean-shift exist for data constrained to the unit sphere [1], but again we must adapt them to the ratio setting.",
      "startOffset" : 73,
      "endOffset" : 76
    }, {
      "referenceID" : 22,
      "context" : "Indeed, the negative set is treated very much like the negative set in an SVM (we penalize the linear sum of the margin violations), which follows [23].",
      "startOffset" : 147,
      "endOffset" : 151
    }, {
      "referenceID" : 22,
      "context" : "However, unlike [23], which makes the ad-hoc choice of 5 positive examples, our algorithm allows each cluster to select the optimal number of positives based on the decision boundary.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 28,
      "context" : "This is somewhat reminiscent of unsupervised marginbased clustering [29, 16].",
      "startOffset" : 68,
      "endOffset" : 76
    }, {
      "referenceID" : 15,
      "context" : "This is somewhat reminiscent of unsupervised marginbased clustering [29, 16].",
      "startOffset" : 68,
      "endOffset" : 76
    }, {
      "referenceID" : 3,
      "context" : "One way to deal with this is to assign smaller bandwidths to patches in dense regions of the space [4], e.",
      "startOffset" : 99,
      "endOffset" : 102
    }, {
      "referenceID" : 3,
      "context" : "It is admittedly difficult to analyze how well these heuristics approximate the adaptive bandwidth approach of [4], and even there the setting of the bandwidth for each datapoint has heuristic aspects.",
      "startOffset" : 111,
      "endOffset" : 114
    }, {
      "referenceID" : 4,
      "context" : "We could perform this analysis on any dataset containing positive and negative images, but [5] presents a dataset which is particularly suitable.",
      "startOffset" : 91,
      "endOffset" : 94
    }, {
      "referenceID" : 9,
      "context" : "The simplest baseline is “Exemplar LDA,” proposed by [10].",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 11,
      "context" : "This is much like the well-established method of “query expansion” for retrieval, and is similar to [12] (although they use multiple iterations of query expansion).",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 4,
      "context" : "This is much like the iterative SVM training of [5], except that it uses LDA instead of an SVM.",
      "startOffset" : 48,
      "endOffset" : 51
    }, {
      "referenceID" : 4,
      "context" : "Finally, we include the algorithm of [5], which is a weakly supervised version of [23], except that knn is being used for initialization instead of kmeans.",
      "startOffset" : 37,
      "endOffset" : 40
    }, {
      "referenceID" : 22,
      "context" : "Finally, we include the algorithm of [5], which is a weakly supervised version of [23], except that knn is being used for initialization instead of kmeans.",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 4,
      "context" : "Implementation details: We use the same patch descriptors described in [5] and whiten them following [10].",
      "startOffset" : 71,
      "endOffset" : 74
    }, {
      "referenceID" : 9,
      "context" : "Implementation details: We use the same patch descriptors described in [5] and whiten them following [10].",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 18,
      "context" : "Table 1: Results on MIT 67 scenes ROI + Gist [19] 26.",
      "startOffset" : 45,
      "endOffset" : 49
    }, {
      "referenceID" : 18,
      "context" : "We use the MIT Scene-67 dataset [19], where machine performance remains substantially below human",
      "startOffset" : 32,
      "endOffset" : 36
    }, {
      "referenceID" : 11,
      "context" : "For indoor scenes, objects within the scene are often more useful features than global scene statistics [12]: for instance, shoe shops are similar to other stores in global layout, but they mostly contain shoes.",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 22,
      "context" : "Note that this differs from [23], which selects only the elements for a given class in each class-specific SVM.",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 11,
      "context" : "We even outperform the Improved Fisher Vector of [12], as well as IFV combined with discriminative patches (IFV+BoP).",
      "startOffset" : 49,
      "endOffset" : 53
    } ],
    "year" : 2013,
    "abstractText" : "Recent work on mid-level visual representations aims to capture information at the level of complexity higher than typical “visual words”, but lower than full-blown semantic objects. Several approaches [5, 6, 12, 23] have been proposed to discover mid-level visual elements, that are both 1) representative, i.e., frequently occurring within a visual dataset, and 2) visually discriminative. However, the current approaches are rather ad hoc and difficult to analyze and evaluate. In this work, we pose visual element discovery as discriminative mode seeking, drawing connections to the the well-known and well-studied mean-shift algorithm [2, 1, 4, 8]. Given a weakly-labeled image collection, our method discovers visually-coherent patch clusters that are maximally discriminative with respect to the labels. One advantage of our formulation is that it requires only a single pass through the data. We also propose the Purity-Coverage plot as a principled way of experimentally analyzing and evaluating different visual discovery approaches, and compare our method against prior work on the Paris Street View dataset of [5]. We also evaluate our method on the task of scene classification, demonstrating state-of-the-art performance on the MIT Scene-67 dataset.",
    "creator" : null
  }
}