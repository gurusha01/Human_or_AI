{
  "name" : "3871bd64012152bfb53fdf04b401193f.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Learning with Noisy Labels",
    "authors" : [ "Nagarajan Natarajan", "Inderjit S. Dhillon", "Pradeep Ravikumar", "Ambuj Tewari" ],
    "emails" : [ "naga86@cs.utexas.edu", "inderjit@cs.utexas.edu", "pradeepr@cs.utexas.edu", "tewaria@umich.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Designing supervised learning algorithms that can learn from data sets with noisy labels is a problem of great practical importance. Here, by noisy labels, we refer to the setting where an adversary has deliberately corrupted the labels [Biggio et al., 2011], which otherwise arise from some “clean” distribution; learning from only positive and unlabeled data [Elkan and Noto, 2008] can also be cast in this setting. Given the importance of learning from such noisy labels, a great deal of practical work has been done on the problem (see, for instance, the survey article by Nettleton et al. [2010]). The theoretical machine learning community has also investigated the problem of learning from noisy labels. Soon after the introduction of the noise-free PAC model, Angluin and Laird [1988] proposed the random classification noise (RCN) model where each label is flipped independently with some probability ρ ∈ [0, 1/2). It is known [Aslam and Decatur, 1996, Cesa-Bianchi et al., 1999] that finiteness of the VC dimension characterizes learnability in the RCN model. Similarly, in the online mistake bound model, the parameter that characterizes learnability without noise — the Littestone dimension — continues to characterize learnability even in the presence of random label noise [Ben-David et al., 2009]. These results are for the so-called “0-1” loss. Learning with convex losses has been addressed only under limiting assumptions like separability or uniform noise rates [Manwani and Sastry, 2013].\nIn this paper, we consider risk minimization in the presence of class-conditional random label noise (abbreviated CCN). The data consists of iid samples from an underlying “clean” distribution D. The learning algorithm sees samples drawn from a noisy version Dρ of D — where the noise rates depend on the class label. To the best of our knowledge, general results in this setting have not been obtained before. To this end, we develop two methods for suitably modifying any given surrogate loss function ℓ, and show that minimizing the sample average of the modified proxy loss function\nℓ̃ leads to provable risk bounds where the risk is calculated using the original loss ℓ on the clean distribution.\nIn our first approach, the modified or proxy loss is an unbiased estimate of the loss function. The idea of using unbiased estimators is well-known in stochastic optimization [Nemirovski et al., 2009], and regret bounds can be obtained for learning with noisy labels in an online learning setting (See Appendix B). Nonetheless, we bring out some important aspects of using unbiased estimators of loss functions for empirical risk minimization under CCN. In particular, we give a simple symmetry condition on the loss (enjoyed, for instance, by the Huber, logistic, and squared losses) to ensure that the proxy loss is also convex. Hinge loss does not satisfy the symmetry condition, and thus leads to a non-convex problem. We nonetheless provide a convex surrogate, leveraging the fact that the non-convex hinge problem is “close” to a convex problem (Theorem 6).\nOur second approach is based on the fundamental observation that the minimizer of the risk (i.e. probability of misclassification) under the noisy distribution differs from that of the clean distribution only in where it thresholds η(x) = P (Y = 1|x) to decide the label. In order to correct for the threshold, we then propose a simple weighted loss function, where the weights are label-dependent, as the proxy loss function. Our analysis builds on the notion of consistency of weighted loss functions studied by Scott [2012]. This approach leads to a very remarkable result that appropriately weighted losses like biased SVMs studied by Liu et al. [2003] are robust to CCN.\nThe main results and the contributions of the paper are summarized below:\n1. To the best of our knowledge, we are the first to provide guarantees for risk minimization under random label noise in the general setting of convex surrogates, without any assumptions on the true distribution. 2. We provide two different approaches to suitably modifying any given surrogate loss function, that surprisingly lead to very similar risk bounds (Theorems 3 and 11). These general results include some existing results for random classification noise as special cases. 3. We resolve an elusive theoretical gap in the understanding of practical methods like biased SVM and weighted logistic regression — they are provably noise-tolerant (Theorem 11). 4. Our proxy losses are easy to compute — both the methods yield efficient algorithms. 5. Experiments on benchmark datasets show that the methods are robust even at high noise rates.\nThe outline of the paper is as follows. We introduce the problem setting and terminology in Section 2. In Section 3, we give our first main result concerning the method of unbiased estimators. In Section 4, we give our second and third main results for certain weighted loss functions. We present experimental results on synthetic and benchmark data sets in Section 5."
    }, {
      "heading" : "1.1 Related Work",
      "text" : "Starting from the work of Bylander [1994], many noise tolerant versions of the perceptron algorithm have been developed. This includes the passive-aggressive family of algorithms [Crammer et al., 2006], confidence weighted learning [Dredze et al., 2008], AROW [Crammer et al., 2009] and the NHERD algorithm [Crammer and Lee, 2010]. The survey article by Khardon and Wachman [2007] provides an overview of some of this literature. A Bayesian approach to the problem of noisy labels is taken by Graepel and Herbrich [2000] and Lawrence and Schölkopf [2001]. As Adaboost is very sensitive to label noise, random label noise has also been considered in the context of boosting. Long and Servedio [2010] prove that any method based on a convex potential is inherently ill-suited to random label noise. Freund [2009] proposes a boosting algorithm based on a non-convex potential that is empirically seen to be robust against random label noise.\nStempfel and Ralaivola [2009] proposed the minimization of an unbiased proxy for the case of the hinge loss. However the hinge loss leads to a non-convex problem. Therefore, they proposed heuristic minimization approaches for which no theoretical guarantees were provided (We address the issue in Section 3.1). Cesa-Bianchi et al. [2011] focus on the online learning algorithms where they only need unbiased estimates of the gradient of the loss to provide guarantees for learning with noisy data. However, they consider a much harder noise model where instances as well as labels are noisy. Because of the harder noise model, they necessarily require multiple noisy copies per clean example and the unbiased estimation schemes also become fairly complicated. In particular, their techniques break down for non-smooth losses such as the hinge loss. In contrast, we show that unbiased estimation is always possible in the more benign random classification noise setting. Manwani and Sastry [2013] consider whether empirical risk minimization of the loss itself on the\nnoisy data is a good idea when the goal is to obtain small risk under the clean distribution. But it holds promise only for 0-1 and squared losses. Therefore, if empirical risk minimization over noisy samples has to work, we necessarily have to change the loss used to calculate the empirical risk. More recently, Scott et al. [2013] study the problem of classification under class-conditional noise model. However, they approach the problem from a different set of assumptions — the noise rates are not known, and the true distribution satisfies a certain “mutual irreducibility” property. Furthermore, they do not give any efficient algorithm for the problem."
    }, {
      "heading" : "2 Problem Setup and Background",
      "text" : "Let D be the underlying true distribution generating (X,Y ) ∈ X × {±1} pairs from which n iid samples (X1, Y1), . . . , (Xn, Yn) are drawn. After injecting random classification noise (independently for each i) into these samples, corrupted samples (X1, Ỹ1), . . . , (Xn, Ỹn) are obtained. The class-conditional random noise model (CCN, for short) is given by:\nP (Ỹ = −1|Y = +1) = ρ+1, P (Ỹ = +1|Y = −1) = ρ−1, and ρ+1 + ρ−1 < 1 The corrupted samples are what the learning algorithm sees. We will assume that the noise rates ρ+1 and ρ−1 are known1 to the learner. Let the distribution of (X, Ỹ ) be Dρ. Instances are denoted by x ∈ X ⊆ Rd. Noisy labels are denoted by ỹ. Let f : X → R be some real-valued decision function. The risk of f w.r.t. the 0-1 loss is given by RD(f) = E(X,Y )∼D [ 1{sign(f(X)) 6=Y } ] . The optimal decision function (called Bayes optimal) that minimizes RD over all real-valued decision functions is given by f⋆(x) = sign(η(x) − 1/2) where η(x) = P (Y = 1|x). We denote by R∗ the corresponding Bayes risk under the clean distribution D, i.e. R∗ = RD(f∗). Let ℓ(t, y) denote a loss function where t ∈ R is a real-valued prediction and y ∈ {±1} is a label. Let ℓ̃(t, ỹ) denote a suitably modified ℓ for use with noisy labels (obtained using methods in Sections 3 and 4). It is helpful to summarize the three important quantities associated with a decision function f :\n1. Empirical ℓ̃-risk on the observed sample: R̂ℓ̃(f) := 1 n ∑n i=1 ℓ̃(f(Xi), Ỹi).\n2. As n grows, we expect R̂ℓ̃(f) to be close to the ℓ̃-risk under the noisy distribution Dρ:\nRℓ̃,Dρ(f) := E(X,Ỹ )∼Dρ\n[ ℓ̃(f(X), Ỹ ) ] .\n3. ℓ-risk under the “clean” distribution D: Rℓ,D(f) := E(X,Y )∼D [ℓ(f(X), Y )]. Typically, ℓ is a convex function that is calibrated with respect to an underlying loss function such as the 0-1 loss. ℓ is said to be classification-calibrated [Bartlett et al., 2006] if and only if there exists a convex, invertible, nondecreasing transformationψℓ (with ψℓ(0) = 0) such that ψℓ(RD(f)−R∗) ≤ Rℓ,D(f)−minf Rℓ,D(f). The interpretation is that we can control the excess 0-1 risk by controlling the excess ℓ-risk.\nIf f is not quantified in a minimization, then it is implicit that the minimization is over all measurable functions. Though most of our results apply to a general function class F , we instantiate F to be the set of hyperplanes of bounded L2 norm,W = {w ∈ Rd : ‖w‖2 ≤W2} for certain specific results. Proofs are provided in the Appendix A."
    }, {
      "heading" : "3 Method of Unbiased Estimators",
      "text" : "Let F : X → R be a fixed class of real-valued decision functions, over which the empirical risk is minimized. The method of unbiased estimators uses the noise rates to construct an unbiased estimator ℓ̃(t, ỹ) for the loss ℓ(t, y). However, in the experiments we will tune the noise rate parameters through cross-validation. The following key lemma tells us how to construct unbiased estimators of the loss from noisy labels.\nLemma 1. Let ℓ(t, y) be any bounded loss function. Then, if we define,\nℓ̃(t, y) := (1− ρ−y) ℓ(t, y)− ρy ℓ(t,−y)\n1− ρ+1 − ρ−1\nwe have, for any t, y, Eỹ [ ℓ̃(t, ỹ) ] = ℓ(t, y) .\n1This is not necessary in practice. See Section 5.\nWe can try to learn a good predictor in the presence of label noise by minimizing the sample average\nf̂ ← argmin f∈F R̂ℓ̃(f) .\nBy unbiasedness of ℓ̃ (Lemma 1), we know that, for any fixed f ∈ F , the above sample average converges to Rℓ,D(f) even though the former is computed using noisy labels whereas the latter depends on the true labels. The following result gives a performance guarantee for this procedure in terms of the Rademacher complexity of the function class F . The main idea in the proof is to use the contraction principle for Rademacher complexity to get rid of the dependence on the proxy loss ℓ̃. The price to pay for this is Lρ, the Lipschitz constant of ℓ̃. Lemma 2. Let ℓ(t, y) be L-Lipschitz in t (for every y). Then, with probability at least 1− δ,\nmax f∈F\n|R̂ℓ̃(f)−Rℓ̃,Dρ(f)| ≤ 2LρR(F) + √ log(1/δ)\n2n where R(F) := EXi,ǫi [ supf∈F 1 nǫif(Xi) ] is the Rademacher complexity of the function class F\nand Lρ ≤ 2L/(1 − ρ+1 − ρ−1) is the Lipschitz constant of ℓ̃. Note that ǫi’s are iid Rademacher (symmetric Bernoulli) random variables.\nThe above lemma immediately leads to a performance bound for f̂ with respect to the clean distribution D. Our first main result is stated in the theorem below.\nTheorem 3 (Main Result 1). With probability at least 1− δ,\nRℓ,D(f̂) ≤ min f∈F\nRℓ,D(f) + 4LρR(F) + 2 √ log(1/δ)\n2n .\nFurthermore, if ℓ is classification-calibrated, there exists a nondecreasing function ζℓ with ζℓ(0) = 0 such that,\nRD(f̂)−R∗ ≤ ζℓ ( min f∈F Rℓ,D(f)−min f Rℓ,D(f) + 4LρR(F) + 2 √ log(1/δ) 2n ) .\nThe term on the right hand side involves both approximation error (that is small if F is large) and estimation error (that is small if F is small). However, by appropriately increasing the richness of the class F with sample size, we can ensure that the misclassification probability of f̂ approaches the Bayes risk of the true distribution. This is despite the fact that the method of unbiased estimators computes the empirical minimizer f̂ on a sample from the noisy distribution. Getting the optimal empirical minimizer f̂ is efficient if ℓ̃ is convex. Next, we address the issue of convexity of ℓ̃."
    }, {
      "heading" : "3.1 Convex losses and their estimators",
      "text" : "Note that the loss ℓ̃ may not be convex even if we start with a convex ℓ. An example is provided by the familiar hinge loss ℓhin(t, y) = [1 − yt]+. Stempfel and Ralaivola [2009] showed that ℓ̃hin is not convex in general (of course, when ρ+1 = ρ−1 = 0, it is convex). Below we provide a simple condition to ensure convexity of ℓ̃.\nLemma 4. Suppose ℓ(t, y) is convex and twice differentiable almost everywhere in t (for every y) and also satisfies the symmetry property\n∀t ∈ R, ℓ′′(t, y) = ℓ′′(t,−y) .\nThen ℓ̃(t, y) is also convex in t.\nExamples satisfying the conditions of the lemma above are the squared loss ℓsq(t, y) = (t− y)2, the logistic loss ℓlog(t, y) = log(1 + exp(−ty)) and the Huber loss:\nℓHub(t, y) =   \n−4yt if yt < −1 (t− y)2 if − 1 ≤ yt ≤ 1 0 if yt > 1\nConsider the case where ℓ̃ turns out to be non-convex when ℓ is convex, as in ℓ̃hin. In the online learning setting (where the adversary chooses a sequence of examples, and the prediction of a learner at round i is based on the history of i − 1 examples with independently flipped labels), we could use a stochastic mirror descent type algorithm [Nemirovski et al., 2009] to arrive at risk bounds (See Appendix B) similar to Theorem 3. Then, we only need the expected loss to be convex and therefore\nℓhin does not present a problem. At first blush, it may appear that we do not have much hope of obtaining f̂ in the iid setting efficiently. However, Lemma 2 provides a clue.\nWe will now focus on the function classW of hyperplanes. Even though R̂ℓ̃(w) is non-convex, it is uniformly close to Rℓ̃,Dρ(w). Since Rℓ̃,Dρ(w) = Rℓ,D(w), this shows that R̂ℓ̃(w) is uniformly close to a convex function over w ∈ W . The following result shows that we can therefore approximately minimize F (w) = R̂ℓ̃(w) by minimizing the biconjugate F\n⋆⋆. Recall that the (Fenchel) biconjugate F ⋆⋆ is the largest convex function that minorizes F .\nLemma 5. Let F :W → R be a non-convex function defined on function classW such it is ε-close to a convex function G :W → R: ∀w ∈ W , |F (w)−G(w)| ≤ ε Then any minimizer of F ⋆⋆ is a 2ε-approximate (global) minimizer of F .\nNow, the following theorem establishes bounds for the case when ℓ̃ is non-convex, via the solution obtained by minimizing the convex function F ∗∗.\nTheorem 6. Let ℓ be a loss, such as the hinge loss, for which ℓ̃ is non-convex. Let W = {w : ‖w2‖ ≤ W2}, let ‖Xi‖2 ≤ X2 almost surely, and let ŵapprox be any (exact) minimizer of the convex problem\nmin w∈W\nF ⋆⋆(w) ,\nwhere F ⋆⋆(w) is the (Fenchel) biconjugate of the function F (w) = R̂ℓ̃(w). Then, with probability at least 1− δ, ŵapprox is a 2ε-minimizer of R̂ℓ̃(·) where\nε = 2LρX2W2√\nn +\n√ log(1/δ)\n2n .\nTherefore, with probability at least 1− δ, Rℓ,D(ŵapprox) ≤ min\nw∈W Rℓ,D(w) + 4ε .\nNumerical or symbolic computation of the biconjugate of a multidimensional function is difficult, in general, but can be done in special cases. It will be interesting to see if techniques from Computational Convex Analysis [Lucet, 2010] can be used to efficiently compute the biconjugate above."
    }, {
      "heading" : "4 Method of label-dependent costs",
      "text" : "We develop the method of label-dependent costs from two key observations. First, the Bayes classifier for noisy distribution, denoted f̃∗, for the case ρ+1 6= ρ−1, simply uses a threshold different from 1/2. Second, f̃∗ is the minimizer of a “label-dependent 0-1 loss” on the noisy distribution. The framework we develop here generalizes known results for the uniform noise rate setting ρ+1 = ρ−1 and offers a more fundamental insight into the problem. The first observation is formalized in the lemma below.\nLemma 7. Denote P (Y = 1|X) by η(X) and P (Ỹ = 1|X) by η̃(X). The Bayes classifier under the noisy distribution, f̃∗ = argminf E(X,Ỹ )∼Dρ [ 1{sign(f(X)) 6=Ỹ } ] is given by,\nf̃∗(x) = sign(η̃(x)− 1/2) = sign ( η(x) − 1/2− ρ−1\n1− ρ+1 − ρ−1\n) .\nInterestingly, this “noisy” Bayes classifier can also be obtained as the minimizer of a weighted 0-1 loss; which as we will show, allows us to “correct” for the threshold under the noisy distribution. Let us first introduce the notion of “label-dependent” costs for binary classification. We can write the 0-1 loss as a label-dependent loss as follows:\n1{sign(f(X)) 6=Y } = 1{Y=1}1{f(X)≤0} + 1{Y=−1}1{f(X)>0}\nWe realize that the classical 0-1 loss is unweighted. Now, we could consider an α-weighted version of the 0-1 loss as: Uα(t, y) = (1− α)1{y=1}1{t≤0} + α1{y=−1}1{t>0}, where α ∈ (0, 1). In fact we see that minimization w.r.t. the 0-1 loss is equivalent to that w.r.t. U1/2(f(X), Y ). It is not a coincidence that Bayes optimal f∗ has a threshold 1/2. The following lemma [Scott, 2012] shows that in fact for any α-weighted 0-1 loss, the minimizer thresholds η(x) at α.\nLemma 8 (α-weighted Bayes optimal [Scott, 2012]). Define Uα-risk under distribution D as\nRα,D(f) = E(X,Y )∼D[Uα(f(X), Y )].\nThen, f∗α(x) = sign(η(x) − α) minimizes Uα-risk. Now consider the risk of f w.r.t. the α-weighted 0-1 loss under noisy distribution Dρ:\nRα,Dρ(f) = E(X,Ỹ )∼Dρ [ Uα(f(X), Ỹ ) ] .\nAt this juncture, we are interested in the following question: Does there exist an α ∈ (0, 1) such that the minimizer of Uα-risk under noisy distribution Dρ has the same sign as that of the Bayes optimal f∗? We now present our second main result in the following theorem that makes a stronger statement — the Uα-risk under noisy distribution Dρ is linearly related to the 0-1 risk under the clean distribution D. The corollary of the theorem answers the question in the affirmative.\nTheorem 9 (Main Result 2). For the choices,\nα∗ = 1− ρ+1 + ρ−1\n2 and Aρ = 1− ρ+1 − ρ−1 2 ,\nthere exists a constant BX that is independent of f such that, for all functions f ,\nRα∗,Dρ(f) = AρRD(f) +BX .\nCorollary 10. The α⋆-weighted Bayes optimal classifier under noisy distribution coincides with that of 0-1 loss under clean distribution:\nargmin f Rα∗,Dρ(f) = argmin f\nRD(f) = sign(η(x) − 1/2)."
    }, {
      "heading" : "4.1 Proposed Proxy Surrogate Losses",
      "text" : "Consider any surrogate loss function ℓ; and the following decomposition:\nℓ(t, y) = 1{y=1}ℓ1(t) + 1{y=−1}ℓ−1(t)\nwhere ℓ1 and ℓ−1 are partial losses of ℓ. Analogous to the 0-1 loss case, we can define α-weighted loss function (Eqn. (1)) and the corresponding α-weighted ℓ-risk. Can we hope to minimize an αweighted ℓ-risk with respect to noisy distribution Dρ and yet bound the excess 0-1 risk with respect to the clean distributionD? Indeed, the α⋆ specified in Theorem 9 is precisely what we need. We are ready to state our third main result, which relies on a generalized notion of classification calibration for α-weighted losses [Scott, 2012]:\nTheorem 11 (Main Result 3). Consider the empirical risk minimization problem with noisy labels:\nf̂α = argmin f∈F\n1\nn\nn∑\ni=1\nℓα(f(Xi), Ỹi).\nDefine ℓα as an α-weighted margin loss function of the form:\nℓα(t, y) = (1− α)1{y=1}ℓ(t) + α1{y=−1}ℓ(−t) (1) where ℓ : R→ [0,∞) is a convex loss function with Lipschitz constantL such that it is classificationcalibrated (i.e. ℓ ′\n(0) < 0). Then, for the choices α∗ and Aρ in Theorem 9, there exists a nondecreasing function ζℓα⋆ with ζℓα⋆ (0) = 0, such that the following bound holds with probability at least 1− δ:\nRD(f̂α∗)−R∗ ≤ A−1ρ ζℓα⋆ ( min f∈F Rα∗,Dρ(f)−min f Rα∗,Dρ(f) + 4LR(F) + 2 √ log(1/δ) 2n ) .\nAside from bounding excess 0-1 risk under the clean distribution, the importance of the above theorem lies in the fact that it prescribes an efficient algorithm for empirical minimization with noisy labels: ℓα is convex if ℓ is convex. Thus for any surrogate loss function including ℓhin, f̂α∗ can be efficiently computed using the method of label-dependent costs. Note that the choice of α∗ above is quite intuitive. For instance, when ρ−1 ≪ ρ+1 (this occurs in settings such as Liu et al. [2003] where there are only positive and unlabeled examples), α∗ < 1 − α∗ and therefore mistakes on positives are penalized more than those on negatives. This makes intuitive sense since an observed negative may well have been a positive but the other way around is unlikely. In practice we do not need to know α∗, i.e. the noise rates ρ+1 and ρ−1. The optimization problem involves just one parameter that can be tuned by cross-validation (See Section 5)."
    }, {
      "heading" : "5 Experiments",
      "text" : "We show the robustness of the proposed algorithms to increasing rates of label noise on synthetic and real-world datasets. We compare the performance of the two proposed methods with state-of-the-art methods for dealing with random classification noise. We divide each dataset (randomly) into 3 training and test sets. We use a cross-validation set to tune the parameters specific to the algorithms. Accuracy of a classification algorithm is defined as the fraction of examples in the test set classified correctly with respect to the clean distribution. For given noise rates ρ+1 and ρ−1, labels of the training data are flipped accordingly and average accuracy over 3 train-test splits is computed2. For evaluation, we choose a representative algorithm based on each of the two proposed methods — ℓ̃log for the method of unbiased estimators and the widely-used C-SVM [Liu et al., 2003] method (which applies different costs on positives and negatives) for the method of label-dependent costs."
    }, {
      "heading" : "5.1 Synthetic data",
      "text" : "First, we use the synthetic 2D linearly separable dataset shown in Figure 1(a). We observe from experiments that our methods achieve over 90% accuracy even when ρ+1 = ρ−1 = 0.4. Figure 1 shows the performance of ℓ̃log on the dataset for different noise rates. Next, we use a 2D UCI benchmark non-separable dataset (‘banana’). The dataset and classification results using C-SVM (in fact, for uniform noise rates, α∗ = 1/2, so it is just the regular SVM) are shown in Figure 2. The results for higher noise rates are impressive as observed from Figures 2(d) and 2(e). The ‘banana’ dataset has been used in previous research on classification with noisy labels. In particular, the Random Projection classifier [Stempfel and Ralaivola, 2007] that learns a kernel perceptron in the presence of noisy labels achieves about 84% accuracy at ρ+1 = ρ−1 = 0.3 as observed from our experiments (as well as shown by Stempfel and Ralaivola [2007]), and the random hyperplane sampling method [Stempfel et al., 2007] gets about the same accuracy at (ρ+1, ρ−1) = (0.2, 0.4) (as reported by Stempfel et al. [2007]). Contrast these with C-SVM that achieves about 90% accuracy at ρ+1 = ρ−1 = 0.2 and over 88% accuracy at ρ+1 = ρ−1 = 0.4."
    }, {
      "heading" : "5.2 Comparison with state-of-the-art methods on UCI benchmark",
      "text" : "We compare our methods with three state-of-the-art methods for dealing with random classification noise: Random Projection (RP) classifier [Stempfel and Ralaivola, 2007]), NHERD\n2Note that training and cross-validation are done on the noisy training data in our setting. To account for randomness in the flips to simulate a given noise rate, we repeat each experiment 3 times — independent corruptions of the data set for same setting of ρ+1 and ρ−1, and present the mean accuracy over the trials.\n[Crammer and Lee, 2010]) (project and exact variants3), and perceptron algorithm with margin (PAM) which was shown to be robust to label noise by Khardon and Wachman [2007]. We use the standard UCI classification datasets, preprocessed and made available by Gunnar Rätsch(http://theoval.cmp.uea.ac.uk/matlab). For kernelized algorithms, we use Gaussian kernel with width set to the best width obtained by tuning it for a traditional SVM on the noise-free data. For ℓ̃log, we use ρ+1 and ρ−1 that give the best accuracy in cross-validation. For C-SVM, we fix one of the weights to 1, and tune the other. Table 1 shows the performance of the methods for different settings of noise rates. C-SVM is competitive in 4 out of 6 datasets (Breast cancer, Thyroid, German and Image), while relatively poorer in the other two. On the other hand, ℓ̃log is competitive in all the data sets, and performs the best more often. When about 20% labels are corrupted, uniform (ρ+1 = ρ−1 = 0.2) and non-uniform cases (ρ+1 = 0.3, ρ−1 = 0.1) have similar accuracies in all the data sets, for both C-SVM and ℓ̃log. Overall, we observe that the proposed methods are competitive and are able to tolerate moderate to high amounts of label noise in the data. Finally, in domains where noise rates are approximately known, our methods can benefit from the knowledge of noise rates. Our analysis shows that the methods are fairly robust to misspecification of noise rates (See Appendix C for results)."
    }, {
      "heading" : "6 Conclusions and Future Work",
      "text" : "We addressed the problem of risk minimization in the presence of random classification noise, and obtained general results in the setting using the methods of unbiased estimators and weighted loss functions. We have given efficient algorithms for both the methods with provable guarantees for learning under label noise. The proposed algorithms are easy to implement and the classification performance is impressive even at high noise rates and competitive with state-of-the-art methods on benchmark data. The algorithms already give a new family of methods that can be applied to the positive-unlabeled learning problem [Elkan and Noto, 2008], but the implications of the methods for this setting should be carefully analysed. We could consider harder noise models such as label noise depending on the example, and “nasty label noise” where labels to flip are chosen adversarially."
    }, {
      "heading" : "7 Acknowledgments",
      "text" : "This research was supported by DOD Army grant W911NF-10-1-0529 to ID; PR acknowledges the support of ARO via W911NF-12-1-0390 and NSF via IIS-1149803, IIS-1320894.\n3A family of methods proposed by Crammer and coworkers [Crammer et al., 2006, 2009, Dredze et al., 2008] could be compared to, but [Crammer and Lee, 2010] show that the 2 NHERD variants perform the best."
    } ],
    "references" : [ {
      "title" : "Learning from noisy examples",
      "author" : [ "D. Angluin", "P. Laird" ],
      "venue" : "Mach. Learn.,",
      "citeRegEx" : "Angluin and Laird.,? \\Q1988\\E",
      "shortCiteRegEx" : "Angluin and Laird.",
      "year" : 1988
    }, {
      "title" : "On the sample complexity of noise-tolerant learning",
      "author" : [ "Javed A. Aslam", "Scott E. Decatur" ],
      "venue" : "Inf. Process. Lett.,",
      "citeRegEx" : "Aslam and Decatur.,? \\Q1996\\E",
      "shortCiteRegEx" : "Aslam and Decatur.",
      "year" : 1996
    }, {
      "title" : "Convexity, classification, and risk bounds",
      "author" : [ "Peter L. Bartlett", "Michael I. Jordan", "Jon D. McAuliffe" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "Bartlett et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Bartlett et al\\.",
      "year" : 2006
    }, {
      "title" : "Agnostic online learning",
      "author" : [ "Shai Ben-David", "Dávid Pál", "Shai Shalev-Shwartz" ],
      "venue" : "In Proceedings of the 22nd Conference on Learning Theory,",
      "citeRegEx" : "Ben.David et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Ben.David et al\\.",
      "year" : 2009
    }, {
      "title" : "Support vector machines under adversarial label noise",
      "author" : [ "Battista Biggio", "Blaine Nelson", "Pavel Laskov" ],
      "venue" : "Journal of Machine Learning Research - Proceedings Track,",
      "citeRegEx" : "Biggio et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Biggio et al\\.",
      "year" : 2011
    }, {
      "title" : "Learning linear threshold functions in the presence of classification noise",
      "author" : [ "Tom Bylander" ],
      "venue" : "In Proc. of the 7th COLT,",
      "citeRegEx" : "Bylander.,? \\Q1994\\E",
      "shortCiteRegEx" : "Bylander.",
      "year" : 1994
    }, {
      "title" : "Sample-efficient strategies for learning in the presence of noise",
      "author" : [ "Nicolò Cesa-Bianchi", "Eli Dichterman", "Paul Fischer", "Eli Shamir", "Hans Ulrich Simon" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "Cesa.Bianchi et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Cesa.Bianchi et al\\.",
      "year" : 1999
    }, {
      "title" : "Online learning of noisy data",
      "author" : [ "Nicolò Cesa-Bianchi", "Shai Shalev-Shwartz", "Ohad Shamir" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "Cesa.Bianchi et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Cesa.Bianchi et al\\.",
      "year" : 2011
    }, {
      "title" : "Learning via gaussian herding",
      "author" : [ "K. Crammer", "D. Lee" ],
      "venue" : "In Advances in NIPS",
      "citeRegEx" : "Crammer and Lee.,? \\Q2010\\E",
      "shortCiteRegEx" : "Crammer and Lee.",
      "year" : 2010
    }, {
      "title" : "Online passive-aggressive algorithms",
      "author" : [ "Koby Crammer", "Ofer Dekel", "Joseph Keshet", "Shai Shalev-Shwartz", "Yoram Singer" ],
      "venue" : "J. Mach. Learn. Res.,",
      "citeRegEx" : "Crammer et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Crammer et al\\.",
      "year" : 2006
    }, {
      "title" : "Adaptive regularization of weight vectors",
      "author" : [ "Koby Crammer", "Alex Kulesza", "Mark Dredze" ],
      "venue" : "In Advances in NIPS",
      "citeRegEx" : "Crammer et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Crammer et al\\.",
      "year" : 2009
    }, {
      "title" : "Confidence-weighted linear classification",
      "author" : [ "Mark Dredze", "Koby Crammer", "Fernando Pereira" ],
      "venue" : "In Proceedings of the Twenty-Fifth ICML,",
      "citeRegEx" : "Dredze et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Dredze et al\\.",
      "year" : 2008
    }, {
      "title" : "Learning classifiers from only positive and unlabeled data",
      "author" : [ "C. Elkan", "K. Noto" ],
      "venue" : "In Proc. of the 14th ACM SIGKDD intl. conf. on Knowledge discovery and data mining,",
      "citeRegEx" : "Elkan and Noto.,? \\Q2008\\E",
      "shortCiteRegEx" : "Elkan and Noto.",
      "year" : 2008
    }, {
      "title" : "A more robust boosting algorithm, 2009. preprint arXiv:0905.2138 [stat.ML] available at http://arxiv.org/abs/0905.2138",
      "author" : [ "Yoav Freund" ],
      "venue" : null,
      "citeRegEx" : "Freund.,? \\Q2009\\E",
      "shortCiteRegEx" : "Freund.",
      "year" : 2009
    }, {
      "title" : "The kernel Gibbs sampler",
      "author" : [ "T. Graepel", "R. Herbrich" ],
      "venue" : "In Advances in NIPS",
      "citeRegEx" : "Graepel and Herbrich.,? \\Q2000\\E",
      "shortCiteRegEx" : "Graepel and Herbrich.",
      "year" : 2000
    }, {
      "title" : "Noise tolerant variants of the perceptron algorithm",
      "author" : [ "Roni Khardon", "Gabriel Wachman" ],
      "venue" : "J. Mach. Learn. Res.,",
      "citeRegEx" : "Khardon and Wachman.,? \\Q2007\\E",
      "shortCiteRegEx" : "Khardon and Wachman.",
      "year" : 2007
    }, {
      "title" : "Estimating a kernel Fisher discriminant in the presence of label noise",
      "author" : [ "Neil D. Lawrence", "Bernhard Schölkopf" ],
      "venue" : "In Proceedings of the Eighteenth ICML,",
      "citeRegEx" : "Lawrence and Schölkopf.,? \\Q2001\\E",
      "shortCiteRegEx" : "Lawrence and Schölkopf.",
      "year" : 2001
    }, {
      "title" : "Building text classifiers using positive and unlabeled examples",
      "author" : [ "Bing Liu", "Yang Dai", "Xiaoli Li", "Wee Sun Lee", "Philip S Yu" ],
      "venue" : "ICDM",
      "citeRegEx" : "Liu et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2003
    }, {
      "title" : "Random classification noise defeats all convex potential boosters",
      "author" : [ "Philip M. Long", "Rocco A. Servedio" ],
      "venue" : "Mach. Learn.,",
      "citeRegEx" : "Long and Servedio.,? \\Q2010\\E",
      "shortCiteRegEx" : "Long and Servedio.",
      "year" : 2010
    }, {
      "title" : "What shape is your conjugate? a survey of computational convex analysis and its applications",
      "author" : [ "Yves Lucet" ],
      "venue" : "SIAM Rev.,",
      "citeRegEx" : "Lucet.,? \\Q2010\\E",
      "shortCiteRegEx" : "Lucet.",
      "year" : 2010
    }, {
      "title" : "Noise tolerance under risk minimization",
      "author" : [ "Naresh Manwani", "P.S. Sastry" ],
      "venue" : "To appear in IEEE Trans. Syst. Man and Cybern. Part B,",
      "citeRegEx" : "Manwani and Sastry.,? \\Q2013\\E",
      "shortCiteRegEx" : "Manwani and Sastry.",
      "year" : 2013
    }, {
      "title" : "Robust stochastic approximation approach to stochastic programming",
      "author" : [ "A. Nemirovski", "A. Juditsky", "G. Lan", "A. Shapiro" ],
      "venue" : "SIAM J. on Opt.,",
      "citeRegEx" : "Nemirovski et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Nemirovski et al\\.",
      "year" : 2009
    }, {
      "title" : "A study of the effect of different types of noise on the precision of supervised learning techniques",
      "author" : [ "David F. Nettleton", "A. Orriols-Puig", "A. Fornells" ],
      "venue" : "Artif. Intell. Rev.,",
      "citeRegEx" : "Nettleton et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Nettleton et al\\.",
      "year" : 2010
    }, {
      "title" : "Calibrated asymmetric surrogate losses",
      "author" : [ "Clayton Scott" ],
      "venue" : "Electronic J. of Stat.,",
      "citeRegEx" : "Scott.,? \\Q2012\\E",
      "shortCiteRegEx" : "Scott.",
      "year" : 2012
    }, {
      "title" : "Classification with asymmetric label noise: Consistency and maximal denoising",
      "author" : [ "Clayton Scott", "Gilles Blanchard", "Gregory Handy" ],
      "venue" : "To appear in COLT,",
      "citeRegEx" : "Scott et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Scott et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning kernel perceptrons on noisy data using random projections",
      "author" : [ "G. Stempfel", "L. Ralaivola" ],
      "venue" : "In Algorithmic Learning Theory,",
      "citeRegEx" : "Stempfel and Ralaivola.,? \\Q2007\\E",
      "shortCiteRegEx" : "Stempfel and Ralaivola.",
      "year" : 2007
    }, {
      "title" : "Learning from noisy data using hyperplane sampling and sample averages",
      "author" : [ "G. Stempfel", "L. Ralaivola", "F. Denis" ],
      "venue" : null,
      "citeRegEx" : "Stempfel et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Stempfel et al\\.",
      "year" : 2007
    }, {
      "title" : "Learning SVMs from sloppily labeled data",
      "author" : [ "Guillaume Stempfel", "Liva Ralaivola" ],
      "venue" : "In Proc. of the 19th Intl. Conf. on Artificial Neural Networks: Part I,",
      "citeRegEx" : "Stempfel and Ralaivola.,? \\Q2009\\E",
      "shortCiteRegEx" : "Stempfel and Ralaivola.",
      "year" : 2009
    }, {
      "title" : "Online convex programming and generalized infinitesimal gradient ascent",
      "author" : [ "Martin Zinkevich" ],
      "venue" : "In Proceedings of the Twentieth ICML,",
      "citeRegEx" : "Zinkevich.,? \\Q2003\\E",
      "shortCiteRegEx" : "Zinkevich.",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "Here, by noisy labels, we refer to the setting where an adversary has deliberately corrupted the labels [Biggio et al., 2011], which otherwise arise from some “clean” distribution; learning from only positive and unlabeled data [Elkan and Noto, 2008] can also be cast in this setting.",
      "startOffset" : 104,
      "endOffset" : 125
    }, {
      "referenceID" : 12,
      "context" : ", 2011], which otherwise arise from some “clean” distribution; learning from only positive and unlabeled data [Elkan and Noto, 2008] can also be cast in this setting.",
      "startOffset" : 110,
      "endOffset" : 132
    }, {
      "referenceID" : 3,
      "context" : "Similarly, in the online mistake bound model, the parameter that characterizes learnability without noise — the Littestone dimension — continues to characterize learnability even in the presence of random label noise [Ben-David et al., 2009].",
      "startOffset" : 217,
      "endOffset" : 241
    }, {
      "referenceID" : 20,
      "context" : "Learning with convex losses has been addressed only under limiting assumptions like separability or uniform noise rates [Manwani and Sastry, 2013].",
      "startOffset" : 120,
      "endOffset" : 146
    }, {
      "referenceID" : 21,
      "context" : "The idea of using unbiased estimators is well-known in stochastic optimization [Nemirovski et al., 2009], and regret bounds can be obtained for learning with noisy labels in an online learning setting (See Appendix B).",
      "startOffset" : 79,
      "endOffset" : 104
    }, {
      "referenceID" : 9,
      "context" : "This includes the passive-aggressive family of algorithms [Crammer et al., 2006], confidence weighted learning [Dredze et al.",
      "startOffset" : 58,
      "endOffset" : 80
    }, {
      "referenceID" : 11,
      "context" : ", 2006], confidence weighted learning [Dredze et al., 2008], AROW [Crammer et al.",
      "startOffset" : 38,
      "endOffset" : 59
    }, {
      "referenceID" : 10,
      "context" : ", 2008], AROW [Crammer et al., 2009] and the NHERD algorithm [Crammer and Lee, 2010].",
      "startOffset" : 14,
      "endOffset" : 36
    }, {
      "referenceID" : 2,
      "context" : "l is said to be classification-calibrated [Bartlett et al., 2006] if and only if there exists a convex, invertible, nondecreasing transformationψl (with ψl(0) = 0) such that ψl(RD(f)−R∗) ≤ Rl,D(f)−minf Rl,D(f).",
      "startOffset" : 42,
      "endOffset" : 65
    }, {
      "referenceID" : 21,
      "context" : "In the online learning setting (where the adversary chooses a sequence of examples, and the prediction of a learner at round i is based on the history of i − 1 examples with independently flipped labels), we could use a stochastic mirror descent type algorithm [Nemirovski et al., 2009] to arrive at risk bounds (See Appendix B) similar to Theorem 3.",
      "startOffset" : 261,
      "endOffset" : 286
    }, {
      "referenceID" : 19,
      "context" : "It will be interesting to see if techniques from Computational Convex Analysis [Lucet, 2010] can be used to efficiently compute the biconjugate above.",
      "startOffset" : 79,
      "endOffset" : 92
    }, {
      "referenceID" : 23,
      "context" : "The following lemma [Scott, 2012] shows that in fact for any α-weighted 0-1 loss, the minimizer thresholds η(x) at α.",
      "startOffset" : 20,
      "endOffset" : 33
    }, {
      "referenceID" : 23,
      "context" : "Lemma 8 (α-weighted Bayes optimal [Scott, 2012]).",
      "startOffset" : 34,
      "endOffset" : 47
    }, {
      "referenceID" : 23,
      "context" : "We are ready to state our third main result, which relies on a generalized notion of classification calibration for α-weighted losses [Scott, 2012]: Theorem 11 (Main Result 3).",
      "startOffset" : 134,
      "endOffset" : 147
    }, {
      "referenceID" : 17,
      "context" : "For evaluation, we choose a representative algorithm based on each of the two proposed methods — l̃log for the method of unbiased estimators and the widely-used C-SVM [Liu et al., 2003] method (which applies different costs on positives and negatives) for the method of label-dependent costs.",
      "startOffset" : 167,
      "endOffset" : 185
    }, {
      "referenceID" : 25,
      "context" : "In particular, the Random Projection classifier [Stempfel and Ralaivola, 2007] that learns a kernel perceptron in the presence of noisy labels achieves about 84% accuracy at ρ+1 = ρ−1 = 0.",
      "startOffset" : 48,
      "endOffset" : 78
    }, {
      "referenceID" : 26,
      "context" : "3 as observed from our experiments (as well as shown by Stempfel and Ralaivola [2007]), and the random hyperplane sampling method [Stempfel et al., 2007] gets about the same accuracy at (ρ+1, ρ−1) = (0.",
      "startOffset" : 130,
      "endOffset" : 153
    }, {
      "referenceID" : 25,
      "context" : "We compare our methods with three state-of-the-art methods for dealing with random classification noise: Random Projection (RP) classifier [Stempfel and Ralaivola, 2007]), NHERD",
      "startOffset" : 139,
      "endOffset" : 169
    }, {
      "referenceID" : 8,
      "context" : "[Crammer and Lee, 2010]) (project and exact variants3), and perceptron algorithm with margin (PAM) which was shown to be robust to label noise by Khardon and Wachman [2007].",
      "startOffset" : 0,
      "endOffset" : 23
    }, {
      "referenceID" : 12,
      "context" : "The algorithms already give a new family of methods that can be applied to the positive-unlabeled learning problem [Elkan and Noto, 2008], but the implications of the methods for this setting should be carefully analysed.",
      "startOffset" : 115,
      "endOffset" : 137
    }, {
      "referenceID" : 8,
      "context" : ", 2008] could be compared to, but [Crammer and Lee, 2010] show that the 2 NHERD variants perform the best.",
      "startOffset" : 34,
      "endOffset" : 57
    } ],
    "year" : 2013,
    "abstractText" : "In this paper, we theoretically study the problem of binary classification in the presence of random classification noise — the learner, instead of seeing the true labels, sees labels that have independently been flipped with some small probability. Moreover, random label noise is class-conditional — the flip probability depends on the class. We provide two approaches to suitably modify any given surrogate loss function. First, we provide a simple unbiased estimator of any loss, and obtain performance bounds for empirical risk minimization in the presence of iid data with noisy labels. If the loss function satisfies a simple symmetry condition, we show that the method leads to an efficient algorithm for empirical minimization. Second, by leveraging a reduction of risk minimization under noisy labels to classification with weighted 0-1 loss, we suggest the use of a simple weighted surrogate loss, for which we are able to obtain strong empirical risk bounds. This approach has a very remarkable consequence — methods used in practice such as biased SVM and weighted logistic regression are provably noise-tolerant. On a synthetic non-separable dataset, our methods achieve over 88% accuracy even when 40% of the labels are corrupted, and are competitive with respect to recently proposed methods for dealing with label noise in several benchmark datasets.",
    "creator" : null
  }
}