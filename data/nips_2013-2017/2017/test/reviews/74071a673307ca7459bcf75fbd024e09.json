{"title": "A Screening Rule for l1-Regularized Ising Model Estimation", "abstract": "We discover a screening rule for l1-regularized Ising model estimation. The simple closed-form screening rule is a necessary and sufficient condition for exactly recovering the blockwise structure of a solution under any given regularization parameters. With enough sparsity, the screening rule can be combined with various optimization procedures to deliver solutions efficiently in practice. The screening rule is especially suitable for large-scale exploratory data analysis, where the number of variables in the dataset can be thousands while we are only interested in the relationship among a handful of variables within moderate-size clusters for interpretability. Experimental results on various datasets demonstrate the efficiency and insights gained from the introduction of the screening rule.", "id": "74071a673307ca7459bcf75fbd024e09", "authors": ["Zhaobin Kuang", "Sinong Geng", "David Page"], "conference": "NIPS2017", "accepted": true, "reviews": [{"comments": "The author(s) present a screening rule for block structure identification in Ising model. This screening rule combined with exact or inexact optimization procedure can lead to scalebale parameter estimation in Ising model. I have following thoughts on the proposed approach-\n\n(1) Finding a block structure can also be done by using spectral clustering or regularized spectral clustering. Once the block structure is recovered then the exact or inexact optimization can be carried out there as well. How different (or may be effective) the screening procedure compared to a eigenvalue decomposition on a graph Laplacian?\n\n(2) The second moment screening rule procedure proposed here is similar to the screening rule proposed in Witten et al. (2011) and Mazumder & Hastie (2012). How different/similar is the current approach with the existing ones in the literature?\n\n(3) How robust is the block wise parametrization of $theta$ is? If the true $\\theta$ does not have a block structure is the initial screening rule could lead to inaccurate parameter estimation?", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "SUMMARY:\n========\nThe authors propose an efficient screening for sparse Ising model structure estimation. The screening rule is shown to be optimal for locating non-interacting variables in an L1 regularized MLE. Combining this screening rule with approximate optimization allows efficient parallel computation of the full model structure, as demonstrated on several synthetic graph problems.\n\nPROS:\n=====\nThe screening rule can be calculated fairly efficiently, in time quadratic in the number of data elements, and as such could be easily adopted in practice. The authors also clearly show that the method is optimal in a regularized MLE sense, and computation of the screening rule also provides a range of valid regularization parameters including those that yield a fully disconnected graph.\n\nCONS:\n=====\nThe authors do not discuss the relationship between the proposed screening rule and the *nearly* identical \"correlation decay\" property considered in Loh and Wainwright (2013) and references therein. The work of Loh and Wainwright is referenced but not cited in the text. This oversight is curious since Loh and Wainwright provide a probabilistic bound of correct reconstruction using the nodewise method considered in the present paper. \n\nThis reviewer feels that the experimental results are lacking and too much material is referenced in the supplement. In particular, the authors claim experiments on real world data (L:228). However, the real world experiment is a single gene interaction network on which only the node-wise method is performed, and is entirely contained in the supplement (B.6). Moreover, the real world experiment is a small graph for which screening only yields a 20% speed improvement. This is an unfortunate omission as more detailed experimentation of real world data would have been beneficial.\n\nIn addition to the real world experiment, other experimental details are deferred to the supplement or not discussed at all. Discussion of model selection is omitted and references B.4, which in turn provides only a few sentences and references Liu et al. (2010). Approximations are only compared to exact inference in a single experiment (also in the supplement) for which exact computation is computed in 90s. Finally, inclusion of the \"mixed\" approach which uses NW for model selection and PL for estimation is both slower than PL and less accurate than NW, it is unclear why this approach would be considered.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "Review of paper 477 \"A Screening Rule for l1-Regularized Ising Model Estimation\"\n\nThis paper presents a simple closed-from screening for\nl1-regularized Ising model estimation. Specifically, the authors\nprove (in Theorem 1) a necessary and sufficient condition that\nensures that blockwise solution of the l1-regularized maximum\nlikelihood estimation is identical the complete l1-regularized\nmaximum likelihood solution. This result is based on the KKT\nconditions for the l1-regularized MLE and is elegant both in terms\nof its simplicity and the simplicity of its proof. The authors also\ndiscuss the challenges remaining, i.e., that the NP-hard problem is\nnow reduced to a set of lower dimension yet still NP-hard problems.\nHence, making progress in the right direction.\n\nOverall, an elegant result worthy of publication in NIPS.\n\nA thought:\n\n1. How does the hyper parameter tuning (finding \\lambda) affect\nthis problem? If one scans through lambda, then for low enough\nvalues of \\lambda only one block can be found and the computation\ntime will not be reduced. Some clarification would be helpful.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
