{
  "name" : "a00e5eb0973d24649a4a920fc53d9564.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Limitations on Variance-Reduction and Acceleration Schemes for Finite Sums Optimization",
    "authors" : [ "Yossi Arjevani" ],
    "emails" : [ "yossi.arjevani@weizmann.ac.il" ],
    "sections" : [ {
      "heading" : null,
      "text" : "√ nL/µ) ln(1/ )), unless the strong convexity parameter is given\nexplicitly. Lastly, we show that when this class of algorithms is used for minimizing L-smooth and convex finite sums, the iteration complexity is bounded from below by Ω(n + L/ ), assuming that (on average) the same update rule is used in any iteration, and Ω(n+ √ nL/ ) otherwise."
    }, {
      "heading" : "1 Introduction",
      "text" : "An optimization problem principal to machine learning and statistics is that of finite sums:\nmin w∈Rd\nF (w) := 1\nn n∑ i=1 fi(w), (1)\nwhere the individual functions fi are assumed to possess some favorable analytical properties, such as Lipschitz-continuity, smoothness or strong convexity (see [16] for details). We measure the iteration complexity of a given optimization algorithm by determining how many evaluations of individual functions (via some external oracle procedure, along with their gradient, Hessian, etc.) are needed in order to obtain an -solution, i.e., a point w ∈ Rd which satisfies E[F (w)−minw∈Rd F (w)] < (where the expectation is taken w.r.t. the algorithm and the oracle randomness).\nArguably, the simplest way of minimizing finite sum problems is by using optimization algorithms for general optimization problems. For concreteness of the following discussion, let us assume for the moment that the individual functions are L-smooth and µ-strongly convex. In this case, by applying vanilla Gradient Descent (GD) or Accelerated Gradient Descent (AGD, [16]), one obtains iteration complexity of\nÕ(nκ ln(1/ )) or Õ ( n √ κ ln(1/ ) ) , (2)\nrespectively, where κ := L/µ denotes the condition number of the problem and Õ hides logarithmic factors in the problem parameters. However, whereas such bounds enjoy logarithmic dependence on\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\nthe accuracy level, the multiplicative dependence on n renders this approach unsuitable for modern applications where n is very large.\nA different approach to tackle a finite sum problem is by reformulating it as a stochastic optimization problem, i.e., minw∈Rd Ei∼U([n])[fi(w)], and then applying a general stochastic method, such as SGD, which allows iteration complexity of O(1/ ) or O ( 1/ 2 ) (depending on the problem parameters). These methods offer rates which do not depend on n, and are therefore attractive for situations where one seeks for a solution of relatively low accuracy. An evident drawback of these methods is their broad applicability for stochastic optimization problems, which may conflict with the goal of efficiently exploiting the unique noise structure of finite sums (indeed, in the general stochastic setting, these rates cannot be improved, e.g., [1, 18]).\nIn recent years, a major breakthrough was made when stochastic methods specialized in finite sums (first SAG [19] and SDCA [21], and then SAGA [10], SVRG [11], SDCA without duality [20], and others) were shown to obtain iteration complexity of\nÕ((n+ κ) ln(1/ )). (3)\nThe ability of these algorithms to enjoy both logarithmic dependence on the accuracy parameter and an additive dependence on n is widely attributed to the fact that the noise of finite sum problems distributes over a finite set of size n. Perhaps surprisingly, in this paper we show that another key ingredient is crucial, namely, a mean of knowing which individual function is being referred to by the oracle at each iteration. In particular, this shows that variance-reduction mechanisms (see, e.g., [10, Section 3]) cannot be applied without explicitly knowing the ‘identity’ of the individual functions. On the more practical side, this result shows that when data augmentation (e.g., [14]) is done without an explicit enumeration of the added samples, it is impossible to obtain iteration complexity as stated in (3, see [7] for relevant upper bounds).\nAlthough variance-reduction mechanisms are essential for obtaining an additive dependence on n (as shown in (3)), they do not necessarily yield ‘accelerated’ rates which depend on the square root of the condition number (as shown in (2) for AGD). Recently, generic acceleration schemes were used by [13] and accelerated SDCA [22] to obtain iteration complexity of\nÕ ( (n+ √ nk) ln(1/ ) ) . (4)\nThe question of whether this rate is optimal was answered affirmatively by [23, 12, 5, 3]. The first category of lower bounds exploits the degree of freedom offered by a d- (or an infinite-) dimensional space to show that any first-order and a certain class of second-order methods cannot obtain better rates than (4) in the regime where the number of iterations is less than O(d/n). The second category of lower bounds is based on maintaining the complexity of the functional form of the iterates, thereby establishing bounds for first-order and coordinate-descent algorithms whose step sizes are oblivious to the problem parameters (e.g., SAG, SAGA, SVRG, SDCA, SDCA without duality) for any number of iterations, regardless of d and n.\nIn this work, we further extend the theory of oblivious finite sum algorithms, by showing that if a first-order and a coordinate-descent oracle are used, then acceleration is not possible without an explicit knowledge of the strong convexity parameter. This implies that in cases where only poor estimation of the strong convexity is available, faster rates may be obtained through ‘adaptive’ algorithms (see relevant discussions in [19, 4]).\nNext, we show that in the smooth and convex case, oblivious finite sum algorithms which, on average, apply the same update rule at each iteration (e.g., SAG, SDCA, SVRG, SVRG++ [2], and typically, other algorithms with a variance-reduction mechanism as described in [10, Section 3]), are bound to iteration complexity of Ω(n + L/ ), where L denotes the smoothness parameter (rather than Ω(n+ √ nL/ )). To show this, we employ a restarting scheme (see [4]) which explicitly introduces the strong convexity parameter into algorithms that are designed for smooth and convex functions. Finally, we use this scheme to establish a tight dimension-free lower bound for smooth and convex finite sums which holds for oblivious algorithms with a first-order and a coordinate-descent oracle.\nTo summarize, our contributions (in order of appearance) are the following:\n• In Section 2, we prove that in the setting of stochastic optimization, having finitely supported noise (as in finite sum problems) is not sufficient for obtaining linear convergence rates with\na linear dependence on n - one must also know exactly which individual function is being referred to by the oracle at each iteration. Deriving similar results for various settings, we show that SDCA, accelerated SDCA, SAG, SAGA, SVRG, SVRG++ and other finite sum algorithms must have a proper enumeration of the individual functions in order to obtain their stated convergence rate.\n• In Section 3.1, we lay the foundations of the framework of general CLI algorithms (see [3]), which enables us to formally address oblivious algorithms (e.g., when step sizes are scheduled regardless of the function at hand). In section 3.2, we improve upon [4], by showing that (in this generalized framework) the optimal iteration complexity of oblivious, deterministic or stochastic, finite sum algorithms with both first-order and coordinate-descent oracles cannot perform better than Ω(n+ κ ln(1/ )), unless the strong convexity parameter is provided explicitly. In particular, the richer expressiveness power of this framework allows addressing incremental gradient methods, such as Incremental Gradient Descent [6] and Incremental Aggregated Gradient [8, IAG].\n• In Section 3.3, we show that, in the L-smooth and convex case, the optimal complexity bound (in terms of the accuracy parameter) of oblivious algorithms whose update rules are (on average) fixed for any iteration is Ω(n+L/ ) (rather then Õ(n+ √ nL/ ), as obtained,\ne.g., by accelerated SDCA). To show this, we first invoke a restarting scheme (used by [4]) to explicitly introduce strong convexity into algorithms for finite sums with smooth and convex individuals, and then apply the result derived in Section 3.2.\n• In Section 3.4, we use the reduction introduced in Section 3.3, to show that the optimal iteration complexity of minimizing L-smooth and convex finite sums using oblivious algorithms equipped with a first-order and a coordinate-descent oracle is Ω ( n+ √ nL/ ) ."
    }, {
      "heading" : "2 The Importance of Individual Identity",
      "text" : "In the following, we address the stochastic setting of finite sum problems (1) where one is equipped with a stochastic oracle which, upon receiving a call, returns some individual function chosen uniformly at random and hides its index. We show that not knowing the identity of the function returned by the oracle (as opposed to an incremental oracle which addresses the specific individual functions chosen by the user), significantly harms the optimal attainable performance. To this end, we reduce the statistical problem of estimating the bias of a noisy coin into that of optimizing finite sums. This reduction (presented below) makes an extensive use of elementary definitions and tools from information theory, all of which can be found in [9].\nFirst, given n ∈ N, we define the following finite sum problem\nFσ := 1\nn\n( n− σ\n2 f+ +\nn+ σ 2 f− ) , (5)\nwhere n is w.l.o.g. assumed to be odd, σ ∈ {−1, 1} and f+, f− are some functions (to be defined later). We then define the following discrepancy measure between F1 and F−1 for different values of n (see also [1]),\nδ(n) = min w∈Rd\n{F1(w) + F−1(w)− F ∗1 − F ∗−1}, (6)\nwhere F ∗σ := infw Fσ(w). It is easy to verify that no solution can be δ(n)/4-optimal for both F1 and F−1, at the same time. Thus, by running a given optimization algorithm long enough to obtain δ(n)/4-solution w.h.p., we can deduce the value of σ. Also, note that, one can simplify the computation of δ(n) by choosing convex f+, f− such that f+(w) = f−(−w). Indeed, in this case, we have F1(w) = F−1(−w) (in particular, F ∗1 = F ∗−1), and since F1(w) +F−1(w)−F ∗1 −F ∗−1 is convex, it must attain its minimum at w = 0, which yields\nδ(n) = 2(F1(0)− F ∗1 ). (7)\nNext, we let σ ∈ {−1, 1} be drawn uniformly at random, and then use the given optimization algorithm to estimate the bias of a random variable X which, conditioned on σ, takes +1 w.p. 1/2 + σ/2n, and −1 w.p. 1/2 − σ/2n. To implement the stochastic oracle described above,\nconditioned on σ, we draw k i.i.d. copies of X , denoted by X1, . . . , Xk, and return f−, if Xi = σ, and f+, otherwise. Now, if k is such that\nE[Fσ(w(k))− F ∗σ |σ] ≤ δ(n)\n40 ,\nfor both σ = −1 and σ = 1, then by Markov inequality, we have that P ( Fσ(w (k))− F ∗σ ≥ δ(n)/4 ∣∣∣σ) ≤ 1/10 (8)\n(note that Fσ(w(k))− F ∗σ is a non-negative random variable). We may now try to guess the value of σ using the following estimator\nσ̂(w(k)) = argmin σ′∈{−1,1} {Fσ′(w(k))− F ∗σ′},\nwhose probability of error, as follows by Inequality (8), is\nP (σ̂ 6= σ) ≤ 1/10. (9)\nLastly, we show that the existence of an estimator for σ with high probability of success implies that k = Ω(n2). To this end, note that the corresponding conditional dependence structure of this probabilistic setting can be modeled as follows: σ → X1, . . . , Xk → σ̂. Thus, we have\nH(σ |X1, . . . , Xk) (a) ≤ H(σ | σ̂) (b) ≤ Hb(P (σ̂ 6= σ)) (c) ≤ 1 2 , (10)\nwhere H(·) and Hb(·) denote the Shannon entropy function and the binary entropy function, respectively, (a) follows by the data processing inequality (in terms of entropy), (b) follows by Fano’s inequality and (c) follows from Equation (9). Applying standard entropy identities, we get\nH(σ |X1, . . . , Xk) (d) = H(X1, . . . , Xk |σ) +H(σ)−H(X1, . . . , Xk) (e) = kH(X1 |σ) + 1−H(X1, . . . , Xk) (f)\n≥ kH(X1 |σ) + 1− kH(X1), (11)\nwhere (d) follows from Bayes rule, (e) follows by the fact that Xi, conditioned on σ, are i.i.d. and (f) follows from the chain rule and the fact that conditioning reduces entropy. Combining this with Inequality (10) and rearranging, we have\nk ≥ 1 2(H(X1)−H(X1 |σ)) ≥ 1 2 (1/n) 2 = n2 2 ,\nwhere the last inequality follows from the fact that H(X1) = 1 and the following estimation for the binary entropy function: Hb(p) ≥ 1− 4 (p− 1/2)2 (see Lemma 2, Appendix A). Thus, we arrive at the following statement. Lemma 1. The minimal number of stochastic oracle calls required to obtain δ(n)/40-optimal solution for problem (5) is ≥ n2/2.\nInstantiating this schemes for f+, f− of various analytical properties yields the following. Theorem 1. When solving a finite sum problem (defined in 1) with a stochastic oracle, one needs at least n2/2 oracle calls in order to obtain an accuracy level of:\n1. κ+140n2 for smooth and strongly convex individuals with condition κ.\n2. L40n2 for L-smooth and convex individuals.\n3. M 2\n40λn2 if M λn ≤ 1, and M 20n − λ 40 , otherwise, for (M +λ)-Lipschitz continuous and λ-strongly convex individuals.\nProof\n1. Define,\nf±(w) = 1 2 (w ± q)>A (w ± q) ,\nwhere A is a d × d diagonal matrix whose diagonal entries are κ, 1 . . . , 1, and q = (1, 1, 0, . . . , 0)> is a d-dimensional vector. One can easily verify that f± are smooth and strongly convex functions with condition number κ, and that\nFσ(w) = 1\n2\n( w − σ n q )> A ( w − σ n q ) + 1 2 ( 1− 1 n2 ) q>Aq.\nTherefore, the minimizer of Fσ is (σ/n)q, and using Equation (7), we see that δ(n) = κ+1n2 .\n2. We define\nf±(w) = L\n2 ‖w ± e1‖2 .\nOne can easily verify that f± are L-smooth and convex functions, and that the minimizer of Fσ is (σ/n)e1. By Equation (7), we get δ(n) = Ln2 .\n3. We define\nf±(w) = M‖w ± e1‖+ λ\n2 ‖w‖2 ,\nover the unit ball. Clearly, f± are (M + λ)-Lipschitz continuous and λ-strongly convex functions. It can be verified that the minimizer of Fσ is (σmin{Mλn , 1})e1. Therefore, by Equation (7), we see that in this case we have\nδ(n) =\n{ M2\nλn2 M λn ≤ 1 2M n − λ o.w. .\nA few conclusions can be readily made from Theorem 1. First, if a given optimization algorithm obtains an iteration complexity of an order of c(n, κ) ln(1/ ), up to logarithmic factors (including the norm of the minimizer which, in our construction, is of an order of 1/n and coupled with the accuracy parameter), for solving smooth and strongly convex finite sum problems with a stochastic oracle, then\nc(n, κ) = Ω̃\n( n2\nln(n2/(κ+ 1))\n) .\nThus, the following holds for optimization of finite sums with smooth and strongly convex individuals.\nCorollary 1. In order to obtain linear convergence rate with linear dependence on n, one must know the index of the individual function addressed by the oracle.\nThis implies that variance-reduction methods such as, SAG, SAGA, SDCA and SVRG (possibly combining with acceleration schemes), which exhibit linear dependence on n, cannot be applied when data augmentation is used. In general, this conclusion also holds for cases when one applies general first-order optimization algorithms, such as AGD, on finite sums, as this typically results in a linear dependence on n. Secondly, if a given optimization algorithm obtains an iteration complexity of an order of n + Lβ‖w(0) −w∗‖2/ α for solving smooth and convex finite sum problems with a stochastic oracle, then n+ Lβ−αn2(α−1) = Ω(n2). Therefore, β = α and α ≥ 2, indicating that an iteration complexity of an order of n+ L‖w(0) −w∗‖2/ , as obtained by, e.g., SVRG++, is not attainable with a stochastic oracle. Similar reasoning based on the Lipschitz and strongly convex case in Theorem 1 shows that the iteration complexity guaranteed by accelerated SDCA is also not attainable in this setting."
    }, {
      "heading" : "3 Oblivious Optimization Algorithms",
      "text" : "In the previous section, we discussed different situations under which variance-reduction schemes are not applicable. Now, we turn to study under what conditions can one apply acceleration schemes. First, we define the framework of oblivious CLI algorithms. Next, we show that, for this family of algorithms, knowing the strong convexity parameter is crucial for obtaining accelerated rates. We then describe a restarting scheme through which we establish that stationary algorithms (whose update rule are, on average, the same for every iteration) for smooth and convex functions are sub-optimal. Finally, we use this reduction to derive a tight lower bound for smooth and convex finite sums on the iteration complexity of any oblivious algorithm (not just stationary)."
    }, {
      "heading" : "3.1 Framework",
      "text" : "In the sequel, following [3], we present the analytic framework through which we derive iteration complexity bounds. This, perhaps pedantic, formulation will allows us to study somewhat subtle distinctions between optimization algorithms. First, we give a rigorous definition for a class of optimization problems which emphasizes the role of prior knowledge in optimization. Definition 1 (Class of Optimization Problems). A class of optimization problems is an ordered triple (F , I, Of ), where F is a family of functions defined over some domain designated by dom(F), I is the side-information given prior to the optimization process and Of is a suitable oracle procedure which upon receiving w ∈ domF and θ in some parameter set Θ, returns Of (w, θ) ⊆ dom(F) for a given f ∈ F (we shall omit the subscript in Of when f is clear from the context).\nIn finite sum problems, F comprises of functions as defined in (1); the side-information may contain the smoothness parameter L, the strong convexity parameter µ and the number of individual functions n; and the oracle may allow one to query about a specific individual function (as in the case of incremental oracle, and as opposed to the stochastic oracle discussed in Section 2). We now turn to define CLI optimization algorithms (see [3] for a more comprehensive discussion). Definition 2 (CLI). An optimization algorithm is called a Canonical Linear Iterative (CLI) optimization algorithm over a class of optimization problems (F , I, Of ), if given an instance f ∈ F and initialization points {w(0)i }i∈J ⊆ dom(F), where J is some index set, it operates by iteratively generating points such that for any i ∈ J ,\nw (k+1) i ∈ ∑ j∈J Of ( w (k) j ; θ (k) ij ) , k = 0, 1, . . . (12)\nholds, where θ(k)ij ∈ Θ are parameters chosen, stochastically or deterministically, by the algorithm, possibly based on the side-information. If the parameters do not depend on previously acquired oracle answers, we say that the given algorithm is oblivious. For notational convenience, we assume that the solution returned by the algorithm is stored in w(k)1 .\nThroughout the rest of the paper, we shall be interested in oblivious CLI algorithms (for brevity, we usually omit the ‘CLI’ qualifier) equipped with the following two incremental oracles:\nGeneralized first-order oracle: O(w;A,B, c, i) := A∇fi(w) +Bw + c, Steepest coordinate-descent oracle: O(w; j, i) := w + t∗ej , (13)\nwhere A,B ∈ Rd×d, c ∈ Rd, i ∈ [n], j ∈ [d], ej denotes the j’th d-dimensional unit vector and t∗ ∈ argmint∈R fj(w1, . . . , wj−1, wj + t, wj+1, . . . , wd). We restrict the oracle parameters such that only one individual function is allowed to be accessed at each iteration. We remark that the family of oblivious algorithms with a first-order and a coordinate-descent oracle is wide and subsumes SAG, SAGA, SDCA, SDCA without duality, SVRG, SVRG++ to name a few. Also, note that coordinate-descent steps w.r.t. partial gradients can be implemented using the generalized first-order oracle by setting A to be some principal minor of the unit matrix (see, e.g., RDCM in [15]). Further, similarly to [3], we allow both first-order and coordinate-descent oracles to be used during the same optimization process."
    }, {
      "heading" : "3.2 No Strong Convexity Parameter, No Acceleration for Finite Sum Problems",
      "text" : "Having described our analytic approach, we now turn to present some concrete applications. Below, we show that in the absence of a good estimation for the strong convexity parameter, the optimal\niteration complexity of oblivious algorithms is Ω(n+ k ln(1/ )). Our proof is based on the technique used in [3, 4] (see [3, Section 2.3] for a brief introduction of the technique).\nGiven 0 < < L, we define the following set of optimization problems (over Rd with d > 1)\nFµ(w) := 1\nn n∑ i=1 ( 1 2 w>Qµw − q>w ) ,where (14)\nQµ :=  L+µ 2 µ−L 2 µ−L 2 L+µ 2 µ\n. . . µ\n , q := R√ 2  1 1 0 ... 0  , parametrized by µ ∈ ( , L) (note that the individual functions are identical. We elaborate more on this below). It can be easily verified that the condition number of Fµ, which we denote by κ(Fµ), is L/µ, and that the corresponding minimizers are w∗(µ) = ( R/µ √ 2, R/µ √ 2, 0, . . . , 0)> with norm ≤ R. If we are allowed to use different optimization algorithm for different µ in this setting, then we know that the optimal iteration complexity is of an order of (n + √ nκ(Fµ)) ln(1/ ). However, if we allowed to use only one single algorithm, then we show that the optimal iteration complexity is of an order of n + κ(Fµ) ln(1/ ). The proof goes as follows. First, note that in this setting, the oracles defined in (13) take the following form,\nGeneralized first-order oracle: O(w;A,B, c, i) = A(Qµw − q) +Bw + c, (15) Steepest coordinate-descent oracle: O(w; j, i) = (I − (1/(Qµ)jj)ei(Qµ)j,∗)w − qj/(Qµ)jjej .\nNow, since the oracle answers are linear in µ and the k’th iterate is a k-fold composition of sums of the oracle answers, it follows that w(k)1 forms a d-dimensional vector of univariate polynomials in µ of degree ≤ k with (possibly random) coefficients (formally, see Lemma 3, Appendix A). Denoting the polynomial of the first coordinate of Ew(k)1 (µ) by s(µ), we see that for any µ ∈ ( , L),\nE‖w(k)1 (µ)−w∗(µ)‖ ≥ ‖Ew (k) 1 (µ)−w∗(µ)‖ ≥ ∣∣∣∣s(µ)− R √2µ ∣∣∣∣ ≥ R √2L ∣∣∣∣∣ √ 2s(µ)µ R − 1 ∣∣∣∣∣ , where the first inequality follows by Jensen inequality and the second inequality by focusing on the first coordinate of Ew(k)(η) and w∗(η). Lastly, since the coefficients of s(µ) do not depend on µ, we have by Lemma 4 in Appendix A, that there exists δ > 0, such that for any µ ∈ (L − δ, L) it holds that\nR √ 2L ∣∣∣∣∣ √ 2s(µ)µ R − 1 ∣∣∣∣∣ ≥ R √2L ( 1− 1 κ(Fµ) )k+1 ,\nby which we derive the following. Theorem 2. The iteration complexity of oblivious finite sum optimization algorithms equipped with a first-order and a coordinate-descent oracle whose side-information does not contain the strong convexity parameter is Ω̃(n+ κ ln(1/ )).\nThe n part of the lower bound holds for any type of finite sum algorithm and is proved in [3, Theorem 5]. The lower bound stated in Theorem 2 is tight up to logarithmic factors and is attained by, e.g., SAG [19]. Although relying on a finite sum with identical individual functions may seem somewhat disappointing, it suggests that some variance-reduction schemes can only give optimal dependence in terms of n, and that obtaining optimal dependence in terms of the condition number need to be done through other (acceleration) mechanisms (e.g., [13]). Lastly, note that, this bound holds for any number of iterations (regardless of the problem parameters)."
    }, {
      "heading" : "3.3 Stationary Algorithms for Smooth and Convex Finite Sums are Sub-optimal",
      "text" : "In the previous section, we showed that not knowing the strong convexity parameter reduces the optimal attainable iteration complexity. In this section, we use this result to show that whereas general\noptimization algorithms for smooth and convex finite sum problems obtain iteration complexity of Õ(n+ √ nL/ ), the optimal iteration complexity of stationary algorithms (whose expected update rules are fixed) is Ω(n+ L/ ).\nThe proof (presented below) is based on a general restarting scheme (see Scheme 1) used in [4]. The scheme allows one to apply algorithms which are designed for L-smooth and convex problems on smooth and strongly convex finite sums by explicitly incorporating the strong convexity parameter. The key feature of this reduction is its ability to ‘preserve’ the exponent of the iteration complexity from an order of C(f)(L/ )α in the non-strongly convex case to an order of (C(f)κ)α ln(1/ ) in the strongly convex case, where C(f) denotes some quantity which may depend on f but not on k, and α is some positive constant.\nSCHEME 1 RESTARTING SCHEME GIVEN AN OPTIMIZATION ALGORITHMA\nFOR SMOOTH CONVEX FUNCTIONS WITH\nf(w(k))− f∗ ≤ C(f) ∥∥∥w̄(0)−w∗∥∥∥2 kα FOR ANY INITIALIZATION POINT w̄0\nITERATE FOR t = 1, 2, . . . RESTART THE STEP SIZE SCHEDULE OFA INITIALIZEA AT w̄(0)\nRUNA FOR α √ 4C(f)/µ ITERATIONS\nSET w̄(0) TO BE THE POINT RETURNED BYA END\nThe proof goes as follows. Suppose A is a stationary CLI optimization algorithm for L-smooth and convex finite sum problems equipped with oracles (13). Also, assume that its convergence rate for k ≥ N, N ∈ N is of an order of n γLβ‖w(0)−w∗‖2\nkα , for some α, β, γ > 0. First, observe that in this case we must have β = 1. For otherwise, we get f(w(k))− f∗ = ((νf)(w(k))− (νf)∗)/ν ≤ nγ(νL)β/νkα = νβ−1nγLβ/kα, implying that, simply by scaling f , one can optimize to any level of accuracy using at most N iterations, which contradicts [3, Theorem 5]. Now, by [4, Lemma 1], Scheme 1 produces a new algorithm whose iteration complexity for smooth and strongly convex finite sums with condition number κ is\nO(N + nγ (L/ )α) −→ Õ(n+ nγκα ln(1/ )). (16)\nFinally, stationary algorithms are invariant under this restarting scheme. Therefore, the new algorithm cannot depend on µ. Thus, by Theorem 2, it must hold that that α ≥ 1 and that max{N,nγ} = Ω(n), proving the following. Theorem 3. If the iteration complexity of a stationary optimization algorithm for smooth and convex finite sum problems equipped with a first-order and a coordinate-descent oracle is of the form of the l.h.s. of (16), then it must be at least Ω(n+ L/ ).\nWe note that, this lower bound is tight and is attained by, e.g., SDCA."
    }, {
      "heading" : "3.4 A Tight Lower Bound for Smooth and Convex Finite Sums",
      "text" : "We now turn to derive a lower bound for finite sum problems with smooth and convex individual functions using the restarting scheme shown in the previous section. Note that, here we allow any oblivious optimization algorithm, not just stationary. The technique shown in Section 3.2 of reducing an optimization problem into a polynomial approximation problem was used in [3] to derive lower bounds for various settings. The smooth and convex case was proved only for n = 1, and a generalization for n > 1 seems to reduce to a non-trivial approximation problem. Here, using Scheme 1, we are able to avoid this difficulty by reducing the non-strongly case to the strongly convex case, for which a lower bound for a general n is known.\nThe proof follows the same lines of the proof of Theorem 3. Given an oblivious optimization algorithm for finite sums with smooth and convex individuals equipped with oracles (13), we apply again Scheme 1 to get an algorithm for the smooth and strongly convex case, whose iteration complexity is as in (16). Now, crucially, oblivious algorithm are invariant under Scheme 1 (that\nis, when applied on a given oblivious algorithm, Scheme 1 produces another oblivious algorithm). Therefore, using [3, Theorem 2], we obtain the following.\nTheorem 4. If the iteration complexity of an oblivious optimization algorithm for smooth and convex finite sum problems equipped with a first-order and a coordinate-descent oracle is of the form of the l.h.s. of (16), then it must be at least\nΩ ( n+ √ nL ) .\nThis bound is tight and is obtained by, e.g., accelerated SDCA [22]. Optimality in terms of L and can be obtained simply by applying Accelerate Gradient Descent [16], or alternatively, by using an accelerated version of SVRG as presented in [17]. More generally, one can apply acceleration schemes, e.g., [13], to get an optimal dependence on ."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank Raanan Tvizer and Maayan Maliach for several helpful and insightful discussions."
    } ],
    "references" : [ {
      "title" : "Informationtheoretic lower bounds on the oracle complexity of convex optimization",
      "author" : [ "Alekh Agarwal", "Martin J Wainwright", "Peter L Bartlett", "Pradeep K Ravikumar" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2009
    }, {
      "title" : "Improved svrg for non-strongly-convex or sum-of-nonconvex objectives",
      "author" : [ "Zeyuan Allen-Zhu", "Yang Yuan" ],
      "venue" : "Technical report, Technical report, arXiv preprint,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2016
    }, {
      "title" : "Dimension-free iteration complexity of finite sum optimization problems",
      "author" : [ "Yossi Arjevani", "Ohad Shamir" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2016
    }, {
      "title" : "On the iteration complexity of oblivious first-order optimization algorithms",
      "author" : [ "Yossi Arjevani", "Ohad Shamir" ],
      "venue" : "In Proceedings of the 33nd International Conference on Machine Learning,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2016
    }, {
      "title" : "Oracle complexity of second-order methods for finite-sum problems",
      "author" : [ "Yossi Arjevani", "Ohad Shamir" ],
      "venue" : "arXiv preprint arXiv:1611.04982,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2016
    }, {
      "title" : "A new class of incremental gradient methods for least squares problems",
      "author" : [ "Dimitri P Bertsekas" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1997
    }, {
      "title" : "Stochastic optimization with variance reduction for infinite datasets with finite-sum structure",
      "author" : [ "Alberto Bietti", "Julien Mairal" ],
      "venue" : "arXiv preprint arXiv:1610.00970,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2016
    }, {
      "title" : "A convergent incremental gradient method with a constant step size",
      "author" : [ "Doron Blatt", "Alfred O Hero", "Hillel Gauchman" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2007
    }, {
      "title" : "Elements of information theory",
      "author" : [ "Thomas M Cover", "Joy A Thomas" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2012
    }, {
      "title" : "Saga: A fast incremental gradient method with support for non-strongly convex composite objectives",
      "author" : [ "Aaron Defazio", "Francis Bach", "Simon Lacoste-Julien" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2014
    }, {
      "title" : "Accelerating stochastic gradient descent using predictive variance reduction",
      "author" : [ "Rie Johnson", "Tong Zhang" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2013
    }, {
      "title" : "An optimal randomized incremental gradient method",
      "author" : [ "Guanghui Lan" ],
      "venue" : "arXiv preprint arXiv:1507.02000,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2015
    }, {
      "title" : "A universal catalyst for first-order optimization",
      "author" : [ "Hongzhou Lin", "Julien Mairal", "Zaid Harchaoui" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2015
    }, {
      "title" : "Training invariant support vector machines using selective sampling",
      "author" : [ "Gaëlle Loosli", "Stéphane Canu", "Léon Bottou" ],
      "venue" : "Large scale kernel machines,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2007
    }, {
      "title" : "Efficiency of coordinate descent methods on huge-scale optimization problems",
      "author" : [ "Yu Nesterov" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2012
    }, {
      "title" : "Introductory lectures on convex optimization, volume 87",
      "author" : [ "Yurii Nesterov" ],
      "venue" : "Springer Science & Business Media,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2004
    }, {
      "title" : "Accelerated stochastic gradient descent for minimizing finite sums",
      "author" : [ "Atsushi Nitanda" ],
      "venue" : "In Artificial Intelligence and Statistics,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2016
    }, {
      "title" : "Information-based complexity, feedback and dynamics in convex programming",
      "author" : [ "Maxim Raginsky", "Alexander Rakhlin" ],
      "venue" : "Information Theory, IEEE Transactions on,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2011
    }, {
      "title" : "Minimizing finite sums with the stochastic average gradient",
      "author" : [ "Mark Schmidt", "Nicolas Le Roux", "Francis Bach" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2013
    }, {
      "title" : "Sdca without duality",
      "author" : [ "Shai Shalev-Shwartz" ],
      "venue" : "arXiv preprint arXiv:1502.06177,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2015
    }, {
      "title" : "Stochastic dual coordinate ascent methods for regularized loss",
      "author" : [ "Shai Shalev-Shwartz", "Tong Zhang" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2013
    }, {
      "title" : "Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization",
      "author" : [ "Shai Shalev-Shwartz", "Tong Zhang" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2016
    }, {
      "title" : "Tight complexity bounds for optimizing composite objectives",
      "author" : [ "Blake E Woodworth", "Nati Srebro" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 15,
      "context" : "where the individual functions fi are assumed to possess some favorable analytical properties, such as Lipschitz-continuity, smoothness or strong convexity (see [16] for details).",
      "startOffset" : 161,
      "endOffset" : 165
    }, {
      "referenceID" : 15,
      "context" : "In this case, by applying vanilla Gradient Descent (GD) or Accelerated Gradient Descent (AGD, [16]), one obtains iteration complexity of",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 18,
      "context" : "In recent years, a major breakthrough was made when stochastic methods specialized in finite sums (first SAG [19] and SDCA [21], and then SAGA [10], SVRG [11], SDCA without duality [20], and others) were shown to obtain iteration complexity of",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 20,
      "context" : "In recent years, a major breakthrough was made when stochastic methods specialized in finite sums (first SAG [19] and SDCA [21], and then SAGA [10], SVRG [11], SDCA without duality [20], and others) were shown to obtain iteration complexity of",
      "startOffset" : 123,
      "endOffset" : 127
    }, {
      "referenceID" : 9,
      "context" : "In recent years, a major breakthrough was made when stochastic methods specialized in finite sums (first SAG [19] and SDCA [21], and then SAGA [10], SVRG [11], SDCA without duality [20], and others) were shown to obtain iteration complexity of",
      "startOffset" : 143,
      "endOffset" : 147
    }, {
      "referenceID" : 10,
      "context" : "In recent years, a major breakthrough was made when stochastic methods specialized in finite sums (first SAG [19] and SDCA [21], and then SAGA [10], SVRG [11], SDCA without duality [20], and others) were shown to obtain iteration complexity of",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 19,
      "context" : "In recent years, a major breakthrough was made when stochastic methods specialized in finite sums (first SAG [19] and SDCA [21], and then SAGA [10], SVRG [11], SDCA without duality [20], and others) were shown to obtain iteration complexity of",
      "startOffset" : 181,
      "endOffset" : 185
    }, {
      "referenceID" : 13,
      "context" : ", [14]) is done without an explicit enumeration of the added samples, it is impossible to obtain iteration complexity as stated in (3, see [7] for relevant upper bounds).",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 6,
      "context" : ", [14]) is done without an explicit enumeration of the added samples, it is impossible to obtain iteration complexity as stated in (3, see [7] for relevant upper bounds).",
      "startOffset" : 139,
      "endOffset" : 142
    }, {
      "referenceID" : 12,
      "context" : "Recently, generic acceleration schemes were used by [13] and accelerated SDCA [22] to obtain iteration complexity of",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 21,
      "context" : "Recently, generic acceleration schemes were used by [13] and accelerated SDCA [22] to obtain iteration complexity of",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 22,
      "context" : "The question of whether this rate is optimal was answered affirmatively by [23, 12, 5, 3].",
      "startOffset" : 75,
      "endOffset" : 89
    }, {
      "referenceID" : 11,
      "context" : "The question of whether this rate is optimal was answered affirmatively by [23, 12, 5, 3].",
      "startOffset" : 75,
      "endOffset" : 89
    }, {
      "referenceID" : 4,
      "context" : "The question of whether this rate is optimal was answered affirmatively by [23, 12, 5, 3].",
      "startOffset" : 75,
      "endOffset" : 89
    }, {
      "referenceID" : 2,
      "context" : "The question of whether this rate is optimal was answered affirmatively by [23, 12, 5, 3].",
      "startOffset" : 75,
      "endOffset" : 89
    }, {
      "referenceID" : 18,
      "context" : "This implies that in cases where only poor estimation of the strong convexity is available, faster rates may be obtained through ‘adaptive’ algorithms (see relevant discussions in [19, 4]).",
      "startOffset" : 180,
      "endOffset" : 187
    }, {
      "referenceID" : 3,
      "context" : "This implies that in cases where only poor estimation of the strong convexity is available, faster rates may be obtained through ‘adaptive’ algorithms (see relevant discussions in [19, 4]).",
      "startOffset" : 180,
      "endOffset" : 187
    }, {
      "referenceID" : 1,
      "context" : ", SAG, SDCA, SVRG, SVRG++ [2], and typically, other algorithms with a variance-reduction mechanism as described in [10, Section 3]), are bound to iteration complexity of Ω(n + L/ ), where L denotes the smoothness parameter (rather than Ω(n+ √ nL/ )).",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 3,
      "context" : "To show this, we employ a restarting scheme (see [4]) which explicitly introduces the strong convexity parameter into algorithms that are designed for smooth and convex functions.",
      "startOffset" : 49,
      "endOffset" : 52
    }, {
      "referenceID" : 2,
      "context" : "1, we lay the foundations of the framework of general CLI algorithms (see [3]), which enables us to formally address oblivious algorithms (e.",
      "startOffset" : 74,
      "endOffset" : 77
    }, {
      "referenceID" : 3,
      "context" : "2, we improve upon [4], by showing that (in this generalized framework) the optimal iteration complexity of oblivious, deterministic or stochastic, finite sum algorithms with both first-order and coordinate-descent oracles cannot perform better than Ω(n+ κ ln(1/ )), unless the strong convexity parameter is provided explicitly.",
      "startOffset" : 19,
      "endOffset" : 22
    }, {
      "referenceID" : 5,
      "context" : "In particular, the richer expressiveness power of this framework allows addressing incremental gradient methods, such as Incremental Gradient Descent [6] and Incremental Aggregated Gradient [8, IAG].",
      "startOffset" : 150,
      "endOffset" : 153
    }, {
      "referenceID" : 3,
      "context" : "To show this, we first invoke a restarting scheme (used by [4]) to explicitly introduce strong convexity into algorithms for finite sums with smooth and convex individuals, and then apply the result derived in Section 3.",
      "startOffset" : 59,
      "endOffset" : 62
    }, {
      "referenceID" : 8,
      "context" : "This reduction (presented below) makes an extensive use of elementary definitions and tools from information theory, all of which can be found in [9].",
      "startOffset" : 146,
      "endOffset" : 149
    }, {
      "referenceID" : 0,
      "context" : "We then define the following discrepancy measure between F1 and F−1 for different values of n (see also [1]),",
      "startOffset" : 104,
      "endOffset" : 107
    }, {
      "referenceID" : 2,
      "context" : "In the sequel, following [3], we present the analytic framework through which we derive iteration complexity bounds.",
      "startOffset" : 25,
      "endOffset" : 28
    }, {
      "referenceID" : 2,
      "context" : "We now turn to define CLI optimization algorithms (see [3] for a more comprehensive discussion).",
      "startOffset" : 55,
      "endOffset" : 58
    }, {
      "referenceID" : 2,
      "context" : "Further, similarly to [3], we allow both first-order and coordinate-descent oracles to be used during the same optimization process.",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 2,
      "context" : "Our proof is based on the technique used in [3, 4] (see [3, Section 2.",
      "startOffset" : 44,
      "endOffset" : 50
    }, {
      "referenceID" : 3,
      "context" : "Our proof is based on the technique used in [3, 4] (see [3, Section 2.",
      "startOffset" : 44,
      "endOffset" : 50
    }, {
      "referenceID" : 3,
      "context" : "The proof (presented below) is based on a general restarting scheme (see Scheme 1) used in [4].",
      "startOffset" : 91,
      "endOffset" : 94
    }, {
      "referenceID" : 2,
      "context" : "2 of reducing an optimization problem into a polynomial approximation problem was used in [3] to derive lower bounds for various settings.",
      "startOffset" : 90,
      "endOffset" : 93
    }, {
      "referenceID" : 15,
      "context" : "Optimality in terms of L and can be obtained simply by applying Accelerate Gradient Descent [16], or alternatively, by using an accelerated version of SVRG as presented in [17].",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 16,
      "context" : "Optimality in terms of L and can be obtained simply by applying Accelerate Gradient Descent [16], or alternatively, by using an accelerated version of SVRG as presented in [17].",
      "startOffset" : 172,
      "endOffset" : 176
    }, {
      "referenceID" : 12,
      "context" : ", [13], to get an optimal dependence on .",
      "startOffset" : 2,
      "endOffset" : 6
    } ],
    "year" : 2017,
    "abstractText" : "We study the conditions under which one is able to efficiently apply variancereduction and acceleration schemes on finite sum optimization problems. First, we show that, perhaps surprisingly, the finite sum structure by itself, is not sufficient for obtaining a complexity bound of Õ((n + L/μ) ln(1/ )) for L-smooth and μ-strongly convex individual functions one must also know which individual function is being referred to by the oracle at each iteration. Next, we show that for a broad class of first-order and coordinate-descent finite sum algorithms (including, e.g., SDCA, SVRG, SAG), it is not possible to get an ‘accelerated’ complexity bound of Õ((n+ √ nL/μ) ln(1/ )), unless the strong convexity parameter is given explicitly. Lastly, we show that when this class of algorithms is used for minimizing L-smooth and convex finite sums, the iteration complexity is bounded from below by Ω(n + L/ ), assuming that (on average) the same update rule is used in any iteration, and Ω(n+ √ nL/ ) otherwise.",
    "creator" : null
  }
}