{
  "name" : "da0d1111d2dc5d489242e60ebcbaf988.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Online Convex Optimization with Stochastic Constraints",
    "authors" : [ "Hao Yu", "Michael J. Neely", "Xiaohan Wei" ],
    "emails" : [ "yuhao@usc.edu", "mjneely@usc.edu", "xiaohanw@usc.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "p T ) expected regret and constraint violations and O( p T log(T ))\nhigh probability regret and constraint violations. Experiments on a real-world data center scheduling problem further verify the performance of the new algorithm."
    }, {
      "heading" : "1 Introduction",
      "text" : "Online convex optimization (OCO) is a multi-round learning process with arbitrarily-varying convex loss functions where the decision maker has to choose decision x(t) 2 X before observing the corresponding loss function f t(·). For a fixed time horizon T , define the regret of a learning algorithm with respect to the best fixed decision in hindsight (with full knowledge of all loss functions) as\nregret(T ) = TX\nt=1\nf t(x(t)) min\nx2X\nTX\nt=1\nf t(x).\nThe goal of OCO is to develop dynamic learning algorithms such that regret grows sub-linearly with respect to T . The setting of OCO is introduced in a series of work [3, 14, 9, 29] and is formalized in [29]. OCO has gained considerable amount of research interest recently with various applications such as online regression, prediction with expert advice, online ranking, online shortest paths, and portfolio selection. See [23, 11] for more applications and background. In [29], Zinkevich shows O( p T ) regret can be achieved by using an online gradient descent (OGD) update given by\nx(t+ 1) = PX ⇥ x(t) rf t(x(t)) ⇤ (1)\nwhere rf t(·) is a subgradient of f t(·) and PX [·] is the projection onto set X . Hazan et al. in [12] show that better regret is possible under the assumption that each loss function is strongly convex but O( p T ) is the best possible if no additional assumption is imposed.\nIt is obvious that Zinkevich’s OGD in (1) requires the full knowledge of set X and low complexity of the projection PX [·]. However, in practice, the constraint set X , which is often described by\n⇤This work is supported in part by grant NSF CCF-1718477.\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\nmany functional inequality constraints, can be time varying and may not be fully disclosed to the decision maker. In [18], Mannor et al. extend OCO by considering time-varying constraint functions g t(x) which can arbitrarily vary and are only disclosed to us after each x(t) is chosen. In this setting, Mannor et al. in [18] explore the possibility of designing learning algorithms such that regret grows sub-linearly and lim supT!1 1 T PT t=1 g\nt(x(t))  0, i.e., the (cumulative) constraint violation PT t=1 g\nt(x(t)) also grows sub-linearly. Unfortunately, Mannor et al. in [18] prove that this is impossible even when both f t(·) and gt(·) are simple linear functions. Given the impossibility results shown by Mannor et al. in [18], this paper considers OCO where constraint functions gt(x) are not arbitrarily varying but independently and identically distributed (i.i.d.) generated from an unknown probability model (and functions f t(x) are still arbitrarily varying and possibly non-i.i.d.). Specifically, this paper considers online convex optimization (OCO) with stochastic constraint X = {x 2 X0 : E![gk(x;!)]  0, k 2 {1, 2, . . . ,m}} where X0 is a known fixed set; the expressions of stochastic constraints E![gk(x;!)] (involving expectations with respect to ! from an unknown distribution) are unknown; and subscripts k 2 {1, 2, . . . ,m} indicate the possibility of multiple functional constraints. In OCO with stochastic constraints, the decision maker receives loss function f t(x) and i.i.d. constraint function realizations gtk(x) = gk(x;!(t)) at each round t. However, the expressions of gtk(·) and f t(·) are disclosed to the decision maker only after decision x(t) 2 X0 is chosen. This setting arises naturally when decisions are restricted by stochastic environments or deterministic environments with noisy observations. For example, if we consider online routing (with link capacity constraints) in wireless networks [18], each link capacity is not a fixed constant (as in wireline networks) but an i.i.d. random variable since wireless channels are stochastically time-varying by nature [25]. OCO with stochastic constraints also covers important special cases such as OCO with long term constraints [16, 5, 13], stochastic constrained convex optimization [17] and deterministic constrained convex optimization [21]. Let x⇤ = argmin{x2X0:E[gk(x;!)]0,8k2{1,2,...,m}} PT t=1 f t(x) be the best fixed decision in hindsight (knowing all loss functions f t(x) and the distribution of stochastic constraint functions gk(x;!)). Thus, x⇤ minimizes the T -round cumulative loss and satisfies all stochastic constraints in expectation, which also implies lim supT!1 1 T PT t=1 g t k(x\n⇤)  0 almost surely by the strong law of large numbers. Our goal is to develop dynamic learning algorithms that guarantee both regretPT\nt=1 f t(x(t)) PT t=1 f t(x⇤) and constraint violations PT t=1 g t k(x(t)) grow sub-linearly.\nNote that Zinkevich’s algorithm in (1) is not applicable to OCO with stochastic constraints since X is unknown and it can happen that X (t) = {x 2 X0 : gk(x;!(t))  0, 8k 2 {1, 2, . . . ,m}} = ; for certain realizations !(t), such that projections PX [·] or PX (t)[·] required in (1) are not even well-defined.\nOur Contributions: This paper solves online convex optimization with stochastic constraints. In particular, we propose a new learning algorithm that is proven to achieve O( p T ) expected regret and constraint violations and O( p T log(T )) high probability regret and constraint violations. The proposed new algorithm also improves upon state-of-the-art results in the following special cases: • OCO with long term constraints: This is a special case where each gtk(x) ⌘ gk(x) is known\nand does not depend on time. Note that X = {x 2 X0 : gk(x)  0, 8k 2 {1, 2, . . . ,m}} can be complicated while X0 might be a simple hypercube. To avoid high complexity involved in the projection onto X as in Zinkevich’s algorithm, work in [16, 5, 13] develops low complexity algorithms that use projections onto a simpler set X0 by allowing gk(x(t)) > 0 for certain rounds but ensuring lim supT!1 1 T PT t=1 gk(x(t))  0. The best existing performance is O(Tmax{ ,1 }) regret and O(T 1 /2) constraint violations where 2 (0, 1) is an algorithm parameter [13]. This gives O( p T ) regret with worse O(T 3/4) constraint violations or O( p T ) constraint violations with worse O(T ) regret. In contrast, our algorithm, which only uses projections onto X0 as shown in Lemma 1, can achieve O( p T ) regret and O( p T ) constraint violations simultaneously. Note that by adapting the methodology presented in this paper, our other work [27] developed a different algorithm that can only solve the special case problem “OCO with long term constraints” but can achieve O( p T ) regret and O(1) constraint violations.\n• Stochastic constrained convex optimization: This is a special case where each f t(x) is i.i.d. generated from an unknown distribution. This problem has many applications in operations research and machine learning such as Neyman-Pearson classification and risk-mean portfolio.\nThe work [17] develops a (batch) offline algorithm that produces a solution with high probability performance guarantees only after sampling the problems for sufficiently many times. That is, during the process of sampling, there is no performance guarantee. The work [15] proposes a stochastic approximation based (batch) offline algorithm for stochastic convex optimization with one single stochastic functional inequality constraint. In contrast, our algorithm is an online algorithm with online performance guarantees and can deal with an arbitrary number of stochastic constraints.\n• Deterministic constrained convex optimization: This is a special case where each f t(x) ⌘ f(x) and gtk(x) ⌘ gk(x) are known and do not depend on time. In this case, the goal is to develop a fast algorithm that converges to a good solution (with a small error) with a few number of iterations; and our algorithm with O( p T ) regret and constraint violations is equivalent to an\niterative numerical algorithm with O(1/ p T ) convergence rate. Our algorithm is subgradient based and does not require the smoothness or differentiability of the convex program. The primal-dual subgradient method considered in [19] has the same O(1/ p T ) convergence rate but requires an upper bound of optimal Lagrange multipliers, which is usually unknown in practice."
    }, {
      "heading" : "2 Formulation and New Algorithm",
      "text" : "Let X0 be a known fixed compact convex set. Let f t(x) be a sequence of arbitrarily-varying convex functions. Let gk(x;!(t)), k 2 {1, 2, . . . ,m} be sequences of functions that are i.i.d. realizations of stochastic constraint functions g̃k(x) = E![gk(x;!)] with random variable ! 2 ⌦ from an unknown distribution. That is, !(t) are i.i.d. samples of !. Assume that each f t(·) is independent of all !(⌧) with ⌧ t+ 1 so that we are unable to predict future constraint functions based on the knowledge of the current loss function. For each ! 2 ⌦, we assume gk(x;!) are convex with respect to x 2 X0. At the beginning of each round t, neither the loss function f t(x) nor the constraint function realizations gk(x;!(t)) are known to the decision maker. However, the decision maker still needs to make a decision x(t) 2 X0 for round t; and after that f t(x) and gk(x,!(t)) are disclosed to the decision maker at the end of round t.\nFor convenience, we often suppress the dependence of each gk(x;!(t)) on !(t) and write g t k(x) = gk(x;!(t)). Recall g̃k(x) = E![gk(x;!)] where the expectation is with respect to !. Define X = {x 2 X0 : g̃k(x) = E[gk(x;!)]  0, 8k 2 {1, 2, . . . ,m}}. We further define the stacked vector of multiple functions gt1(x), . . . , gtm(x) as gt(x) = [gt1(x), . . . , gtm(x)]T and define g̃(x) = [E![g1(x;!)], . . . ,E![gm(x;!)]]T. We use k · k to denote the Euclidean norm for a vector. Throughout this paper, we have the following assumptions: Assumption 1 (Basic Assumptions).\n• Loss functions f t(x) and constraint functions gk(x;!) have bounded subgradients on X0. That is, there exists D1 > 0 and D2 > 0 such that krf t(x)k  D1 for all x 2 X0 and all t 2 {0, 1, . . .} and krgk(x;!)k  D2 for all x 2 X0, all ! 2 ⌦ and all k 2 {1, 2, . . . ,m}.2\n• There exists constant G > 0 such that kg(x;!)k  G for all x 2 X0 and all ! 2 ⌦. • There exists constant R > 0 such that kx yk  R for all x,y 2 X0.\nAssumption 2 (The Slater Condition). There exists ✏ > 0 and x̂ 2 X0 such that g̃k(x̂) = E![gk(x̂;!)]  ✏ for all k 2 {1, 2, . . . ,m}."
    }, {
      "heading" : "2.1 New Algorithm",
      "text" : "Now consider the following algorithm described in Algorithm 1. This algorithm chooses x(t+ 1) as the decision for round t+ 1 based on f t(·) and gt(·) without requiring f t+1(·) or gt+1(·). For each stochastic constraint function gk(x;!), we introduce Qk(t) and call it a virtual queue since its dynamic is similar to a queue dynamic. The next lemma summarizes that x(t+ 1) update in (2) can be implemented via a simple projection onto X0. Lemma 1. The x(t+ 1) update in (2) is given by x(t+ 1) = PX0 ⇥ x(t) 12↵d(t) ⇤ , where d(t) =\nVrf t(x(t)) + Pm\nk=1 Qk(t)rgtk(x(t)) and PX0 [·] is the projection onto convex set X0. 2 The notation rh(x) is used to denote a subgradient of a convex function h at the point x.; it is the same as\nthe gradient whenever the gradient exists.\nAlgorithm 1 Let V > 0 and ↵ > 0 be constant algorithm parameters. Choose x(1) 2 X0 arbitrarily and let Qk(1) = 0, 8k 2 {1, 2, . . . ,m}. At the end of each round t 2 {1, 2, . . .}, observe f t(·) and gt(·) and do the following: • Choose x(t+ 1) that solves\nmin x2X0\nV [rf t(x(t))]T[x x(t)] +\nmX\nk=1\nQk(t)[rgtk(x(t))]T[x x(t)] + ↵kx x(t)k2\n(2)\nas the decision for the next round t + 1, where rf t(x(t)) is a subgradient of f t(x) at point x = x(t) and rgtk(x(t)) is a subgradient of gtk(x) at point x = x(t).\n• Update each virtual queue Qk(t+ 1), 8k 2 {1, 2, . . . ,m} via\nQk(t+ 1) = max Qk(t) + g t k(x(t)) + [rgtk(x(t))]T[x(t+ 1) x(t)], 0 , (3)\nwhere max{·, ·} takes the larger one between two elements.\nProof. The projection by definition is minx2X0 kx [x(t) 12↵d(t)]k 2 and is equivalent to (2)."
    }, {
      "heading" : "2.2 Intuitions of Algorithm 1",
      "text" : "Note that if there are no stochastic constraints gtk(x), i.e., X = X0, then Algorithm 1 has Qk(t) ⌘ 0, 8t and becomes Zinkevich’s algorithm with = V2↵ in (1) since\nx(t+ 1) (a) = argmin\nx2X0\nV [rf t(x(t))]T[x x(t)] + ↵kx x(t)k2 | {z }\npenalty\n(b) = PX0 ⇥ x(t) V\n2↵ rf t(x(t))\n⇤ (4)\nwhere (a) follows from (2); and (b) follows from Lemma 1 by noting that d(t) = Vrf t(x(t)). Call the term marked by an underbrace in (4) the penalty. Thus, Zinkevich’s algorithm is to minimize the penalty term and is a special case of Algorithm 1 used to solve OCO over X0. Let Q(t) = ⇥ Q1(t), . . . , Qm(t) ⇤T be the vector of virtual queue backlogs. Let L(t) = 12kQ(t)k 2 be a Lyapunov function and define Lyapunov drift\n(t) = L(t+ 1) L(t) = 1 2 [kQ(t+ 1)k2 kQ(t)k2]. (5)\nThe intuition behind Algorithm 1 is to choose x(t+ 1) to minimize an upper bound of the expression\n(t)|{z} drift +V [rf t(x(t))]T[x x(t)] + ↵kx x(t)k2| {z } penalty\n(6)\nThe intention to minimize penalty is natural since Zinkevich’s algorithm (for OCO without stochastic constraints) minimizes penalty, while the intention to minimize drift is motivated by observing that g t k(x(t)) is accumulated into queue Qk(t+ 1) introduced in (3) such that we intend to have small queue backlogs. The drift (t) can be complicated and is in general non-convex. The next lemma (proven in Supplement 7.1) provides a simple upper bound on (t) and follows directly from (3). Lemma 2. At each round t 2 {1, 2, . . .}, Algorithm 1 guarantees\n(t)  mX\nk=1\nQk(t) ⇥ g t k(x(t)) + [rgtk(x(t))]T[x(t+ 1) x(t)] ⇤ + 1\n2 [G+\np mD2R] 2 , (7)\nwhere m is the number of constraint functions; and D2, G and R are defined in Assumption 1. At the end of round t, Pm\nk=1 Qk(t)g t k(x(t)) + 1 2 [G + p mD2R]2 is a given constant that is not\naffected by decision x(t+1). The algorithm decision in (2) is now transparent: x(t+1) is chosen to minimize the drift-plus-penalty expression (6), where (t) is approximated by the bound in (7)."
    }, {
      "heading" : "2.3 Preliminary Analysis and More Intuitions of Algorithm 1",
      "text" : "The next lemma (proven in Supplement 7.2) relates constraint violations and virtual queue values and follows directly from (3).\nLemma 3. For any T 1, Algorithm 1 guarantees PT\nt=1 g t k(x(t))  kQ(T+1)k+D2 PT t=1 kx(t+\n1) x(t)k, 8k 2 {1, 2, . . . ,m}, where D2 is defined in Assumption 1.\nRecall that function h : X0 ! R is said to be c-strongly convex if h(x) c2kxk 2 is convex over x 2 X0. It is easy to see that if q : X0 ! R is a convex function, then for any constant c > 0 and any vector b, the function q(x) + c2kx bk\n2 is c-strongly convex. Further, it is known that if h : X ! R is a c-strongly convex function that is minimized at a point xmin 2 X0, then (see, for example, Corollary 1 in [28]):\nh(xmin)  h(x) c 2 kx xmink2 8x 2 X0 (8)\nNote that the expression involved in minimization (2) in Algorithm 1 is strongly convex with modulus 2↵ and x(t+ 1) is chosen to minimize it. Thus, the next lemma follows. Lemma 4. Let z 2 X0 be arbitrary. For all t 1, Algorithm 1 guarantees\nV [rf t(x(t))]T[x(t+ 1) x(t)] + mX\nk=1\nQk(t)[rgtk(x(t))]T[x(t+ 1) x(t)] + ↵kx(t+ 1) x(t)k2\nV [rf t(x(t))]T[z x(t)] + mX\nk=1\nQk(t)[rgtk(x(t))]T[z x(t)] + ↵kz x(t)k2 ↵kz x(t+ 1)k2.\nThe next corollary follows by taking z = x(t) in Lemma 4 and is proven in Supplement 7.3. Corollary 1. For all t 1, Algorithm 1 guarantees kx(t+ 1) x(t)k  V D12↵ + p mD2 2↵ kQ(t)k.\nThe next corollary follows directly from Lemma 3 and Corollary 1 and shows that constraint violations are ultimately bounded by sequence kQ(t)k, t 2 {1, 2, . . . , T + 1}. Corollary 2. For any T 1, Algorithm 1 guarantees PT t=1 g t k(x(t))  kQ(T + 1)k+ V TD1D2 2↵ +p\nmD22 2↵ PT t=1 kQ(t)k, 8k 2 {1, 2, . . . ,m} where D1 and D2 are defined in Assumption 1.\nThis corollary further justifies why Algorithm 1 intends to minimize drift (t). As illustrated in the next section, controlled drift can often lead to boundedness of a stochastic process. Thus, the intuition of minimizing drift (t) is to yield small kQ(t)k bounds."
    }, {
      "heading" : "3 Expected Performance Analysis of Algorithm 1",
      "text" : "This section shows that if we choose V = p T and ↵ = T in Algorithm 1, then both expected regret and expected constraint violations are O( p T )."
    }, {
      "heading" : "3.1 A Drift Lemma for Stochastic Processes",
      "text" : "Let {Z(t), t 0} be a discrete time stochastic process adapted3 to a filtration {F(t), t 0}. For example, Z(t) can be a random walk, a Markov chain or a martingale. The drift analysis is the method of deducing properties, e.g., recurrence, ergodicity, or boundedness, about Z(t) from its drift E[Z(t + 1) Z(t)|F(t)]. See [6, 10] for more discussions or applications on drift analysis. This paper proposes a new drift analysis lemma for stochastic processes as follows: Lemma 5. Let {Z(t), t 0} be a discrete time stochastic process adapted to a filtration {F(t), t 0} with Z(0) = 0 and F(0) = {;,⌦}. Suppose there exists an integer t0 > 0, real constants ✓ > 0, max > 0 and 0 < ⇣  max such that\n|Z(t+ 1) Z(t)|  max, (9)\nE[Z(t+ t0) Z(t)|F(t)]  ⇢\nt0 max, if Z(t) < ✓ t0⇣, if Z(t) ✓ . (10)\nhold for all t 2 {1, 2, . . .}. Then, the following holds\n1. E[Z(t)]  ✓ + t0 max + t0 4 2 max ⇣ log ⇥ 8 2max ⇣2 ⇤ , 8t 2 {1, 2, . . .}.\n2. For any constant 0 < µ < 1, we have Pr(Z(t) z)  µ, 8t 2 {1, 2, . . .} where z = ✓ + t0 max + t0 4 2max ⇣ log ⇥ 8 2max ⇣2 ⇤ + t0 4 2max ⇣ log( 1 µ ).\n3Random variable Y is said to be adapted to -algebra F if Y is F -measurable. In this case, we often write Y 2 F . Similarly, random process {Z(t)} is adapted to filtration {F(t)} if Z(t) 2 F(t), 8t. See e.g. [7].\nThe above lemma is proven in Supplement 7.4 and provides both expected and high probability bounds for stochastic processes based on a drift condition. It will be used to establish upper bounds of virtual queues kQ(t)k, which further leads to expected and high probability constraint performance bounds of our algorithm. For a given stochastic process Z(t), it is possible to show the drift condition (10) holds for multiple t0 with different ⇣ and ✓. In fact, we will show in Lemma 7 that kQ(t)k yielded by Algorithm 1 satisfies (10) for any integer t0 > 0 by selecting ⇣ and ✓ according to t0. One-step drift conditions, corresponding to the special case t0 = 1 of Lemma 5, have been previously considered in [10, 20]. However, Lemma 5 (with general t0 > 0) allows us to choose the best t0 in performance analysis such that sublinear regret and constraint violation bounds are possible."
    }, {
      "heading" : "3.2 Expected Constraint Violation Analysis",
      "text" : "Define filtration {W(t), t 0} with W(0) = {;,⌦} and W(t) = (!(1), . . . ,!(t)) being the -algebra generated by random samples {!(1), . . . ,!(t)} up to round t. From the update rule in Algorithm 1, we observe that x(t + 1) is a deterministic function of f t(·),g(·;!(t)) and Q(t) where Q(t) is further a deterministic function of Q(t 1),g(·;!(t 1)), x(t) and x(t 1). By inductions, it is easy to show that (x(t)) ✓ W(t 1) and (Q(t)) ✓ W(t 1) for all t 1 where (Y ) denotes the -algebra generated by random variable Y . For fixed t 1, since Q(t) is fully determined by !(⌧), ⌧ 2 {1, 2, . . . , t 1} and !(t) are i.i.d., we know gt(x) is independent of Q(t). This is formally summarized in the next lemma. Lemma 6. If x⇤ 2 X0 satisfies g̃(x⇤) = E![g(x⇤;!)]  0, then Algorithm 1 guarantees:\nE[Qk(t)gtk(x⇤)]  0, 8k 2 {1, 2, . . . ,m}, 8t 1. (11)\nProof. Fix k 2 {1, 2, . . . ,m} and t 1. Since gtk(x⇤) = gk(x⇤;!(t)) is independent of Qk(t), which is determined by {!(1), . . . ,!(t 1)}, it follows that E[Qk(t)gtk(x⇤)] = E[Qk(t)]E[gtk(x⇤)] (a)  0, where (a) follows from the fact that E[gtk(x⇤)]  0 and Qk(t) 0.\nTo establish a bound on constraint violations, by Corollary 2, it suffices to derive upper bounds for kQ(t)k. In this subsection, we derive upper bounds for kQ(t)k by applying the new drift lemma (Lemma 5) developed at the beginning of this section. The next lemma shows that random process Z(t) = kQ(t)k satisfies the conditions in Lemma 5. Lemma 7. Let t0 > 0 be an arbitrary integer. At each round t 2 {1, 2, . . . , } in Algorithm 1, the following holds\nkQ(t+ 1)k kQ(t)k G+ p mD2R, and\nE[kQ(t+ t0)k kQ(t)k W(t 1)] \n⇢ t0(G+ p mD2R), if kQ(t)k < ✓\nt0 ✏2 , if kQ(t)k ✓ ,\nwhere ✓ = ✏2 t0 + (G+ p mD2R)t0 + 2↵R2 t0✏ + 2V D1R+[G+ p mD2R] 2 ✏ , m is the number of constraint functions; D1, D2, G and R are defined in Assumption 1; and ✏ is defined in Assumption 2. (Note\nthat ✏ < G by the definition of G.)\nLemma 7 (proven in Supplement 7.5) allows us to apply Lemma 5 to random process Z(t) = kQ(t)k and obtain E[kQ(t)k] = O( p T ), 8t by taking t0 = d p T e, V = p T and ↵ = T , where d p T e\nrepresents the smallest integer no less than p T . By Corollary 2, this further implies the expected constraint violation bound E[ PT t=1 gk(x(t))]  O( p T ) as summarized in the next theorem. Theorem 1 (Expected Constraint Violation Bound). If V = p T and ↵ = T in Algorithm 1, then for\nall T 1, we have\nE[ TX\nt=1\ng t k(x(t))]  O(\np T ), 8k 2 {1, 2, . . . ,m}. (12)\nwhere the expectation is taken with respect to all !(t).\nProof. Define random process Z(t) with Z(0) = 0 and Z(t) = kQ(t)k, t 1 and filtration F(t) with F(0) = {;,⌦} and F(t) = W(t 1), t 1. Note that Z(t) is adapted to F(t). By\nLemma 7, Z(t) satisfies the conditions in Lemma 5 with max = G + p mD2R, ⇣ = ✏2 and ✓ = ✏2 t0 + (G+ p mD2R)t0 + 2↵R2 t0✏ + 2V D1R+[G+ p mD2R] 2 ✏ . Thus, by part (1) of Lemma 5, for all t 2 {1, 2, . . .}, we have E[kQ(t)k]  ✏2 t0 + 2(G+ p mD2R)t0 + 2↵R2 t0✏ + 2V D1R+[G+ p mD2R] 2 ✏ + t0 8[G+ p mD2R] 2 ✏ log[ 32[G+ p mD2R] 2 ✏2 ]. Taking t0 = d p T e, V = p T and ↵ = T , we have\nE[kQ(t)k]  O( p T ) for all t 2 {1, 2, . . .}. Fix T 1. By Corollary 2 (with V = p T and ↵ = T ) , we have PT t=1 g t k(x(t))  kQ(T + 1)k+ p TD1D2 2 + p mD22 2T PT t=1 kQ(t)k, 8k 2 {1, 2, . . . ,m}. Taking expectations on both sides and\nsubstituting E[kQ(t)k] = O( p T ), 8t into it yields E[ PT t=1 g t k(x(t))]  O( p T )."
    }, {
      "heading" : "3.3 Expected Regret Analysis",
      "text" : "The next lemma (proven in Supplement 7.6) refines Lemma 4 and is useful to analyze the regret. Lemma 8. Let z 2 X0 be arbitrary. For all T 1, Algorithm 1 guarantees\nTX\nt=1\nf t(x(t)) \nTX\nt=1\nf t(z) + ↵\nV R2 + V D21 4↵ T + 1 2 [G + p mD2R] 2 T V| {z } (I) + 1 V TX t=1 ⇥ mX k=1 Qk(t)g t k(z) ⇤\n| {z } (II)\n(13)\nwhere m is the number of constraint functions; and D1, D2, G and R are defined in Assumption 1. Note that if we take V = p T and ↵ = T , then term (I) in (13) is O( p T ). Recall that the expectation of term (II) in (13) with z = x⇤ is non-positive by Lemma 6. The expected regret bound of Algorithm 1 follows by taking expectations on both sides of (13) and is summarized in the next theorem. Theorem 2 (Expected Regret Bound). Let x⇤ 2 X0 be any fixed solution that satisfies g̃(x⇤)  0, e.g., x⇤ = argminx2X PT t=1 f t(x). If V = p T and ↵ = T in Algorithm 1, then for all T 1,\nE[ TX\nt=1\nf t(x(t))]  E[\nTX\nt=1\nf t(x⇤)] +O( p T ).\nwhere the expectation is taken with respect to all !(t). Proof. Fix T 1. Taking z = x⇤ in Lemma 8 yields PT\nt=1 f t(x(t))  PT t=1 f t(x⇤) + ↵V R 2 +\nV D21 4↵ T + 1 2 [G+ p mD2R]2 T V + 1 V PT t=1 ⇥Pm k=1 Qk(t)g t k(x ⇤) ⇤ . Taking expectations on both sides and using (11) yields PT t=1 E[f t(x(t))]  PT t=1 E[f t(x⇤)]+R2 ↵V + D21 4 V ↵ T + 1 2 [G+ p mD2R]2 T V .\nTaking V = p T and ↵ = T yields PT t=1 E[f t(x(t))]  PT t=1 E[f t(x⇤)] +O( p T )."
    }, {
      "heading" : "3.4 Special Case Performance Guarantees",
      "text" : "Theorems 1 and 2 provide expected performance guarantees of Algorithm 1 for OCO with stochastic constraints. The results further imply the performance guarantees in the following special cases:\n• OCO with long term constraints: In this case, gk(x;!(t)) ⌘ gk(x) and there is no randomness. Thus, the expectations in Theorems 1 and 2 disappear. For this problem, Algorithm 1 can achieve O( p T ) (deterministic) regret and O( p T ) (deterministic) constraint violations.\n• Stochastic constrained convex optimization: Note that i.i.d. time-varying f(x;!(t)) is a special case of arbitrarily-varying f t(x) as considered in our OCO setting. Thus, Theorems 1 and 2 still hold when Algorithm 1 is applied to solve stochastic constrained convex optimization minx{E[f(x;!)] : E[gk(x;!)]  0, 8k 2 {1, 2, . . . ,m},x 2 X0} in an online fashion with i.i.d. realizations !(t) ⇠ !. Since Algorithm 1 chooses each x(t) without knowing !(t), it follows that x(t) is independent of !(t0) for any t0 t by the i.i.d. property of each !(t). Fix T > 0, if we run Algorithm 1 for T slots and use x(T ) = 1T PT t=1 x(t) as a fixed solu-\ntion for any future slot t0 T + 1, then E[f(x(T );!(t0)] (a)  1T PT t=1 E[f(x(t);!(t0))] (b) =\n1 T PT t=1 E[f(x(t);!(t))] (c)  1T PT t=1 E[f(x⇤;!(t))] + O( 1pT ) (d) = E[f(x⇤;!(t0))] + O( 1p T ) and E[gk(x(T );!(t0)] (a)  1T PT t=1 E[gk(x(T );!(t0)] (b) = 1T PT t=1 E[gk(x(t);!(t))] (c) \nO( 1p T ), 8k 2 {1, 2, . . . ,m} where (a) follows from Jensen’s inequality and the fact that x(T ) is independent of !(t0); (b) follows because each x(t) is independent of both !(t) and !(t0) and !(t),!(t0) are i.i.d. realizations of !; (c) follows from Theorems 1 and 2 by dividing both sides by T and (d) follows because E[f(x⇤;!(t))] = E[f(x⇤;!(t0))] for all t 2 {1, . . . , T} by the i.i.d. property of each !(t). Thus, if we use Algorithm 1 as a (batch) offline algorithm to solve stochastic constrained convex optimization, it has O(1/ p T ) convergence and ties with the algorithm developed in [15], which is by design a (batch) offline algorithm and can only solve stochastic optimization with a single constraint function.\n• Deterministic constrained convex optimization: Similarly to OCO with long term constraints, the expectations in Theorems 1 and 2 disappear in this case since f t(x) ⌘ f(x) and gk(x;!(t)) ⌘ gk(x). If we use x(T ) = 1T PT t=1 x(t) as the solution, then f(x(T )) \nf(x⇤) + O( 1p T ) and gk(x(T ))  O( 1pT ), which follows by dividing inequalities in Theorems 1 and 2 by T on both sides and applying Jensen’s inequality. Thus, Algorithm 1 solves deterministic constrained convex optimization with O( 1p\nT ) convergence."
    }, {
      "heading" : "4 High Probability Performance Analysis",
      "text" : "This section shows that if we choose V = p T and ↵ = T in Algorithm 1, then for any 0 < < 1, with probability at least 1 , regret is O( p T log(T ) log1.5( 1 )) and constraint violations are O p T log(T ) log( 1 ) ."
    }, {
      "heading" : "4.1 High Probability Constraint Violation Analysis",
      "text" : "Similarly to the expected constraint violation analysis, we can use part (2) of the new drift lemma (Lemma 5) to obtain a high probability bound of kQ(t)k, which together with Corollary 2 leads to a high probability constraint violation bound summarized in Theorem 3 (proven in Supplement 7.7). Theorem 3 (High Probability Constraint Violation Bound). Let 0 < < 1 be arbitrary. If V = p T and ↵ = T in Algorithm 1, then for all T 1 and all k 2 {1, 2, . . . ,m}, we have\nPr\n⇣ TX\nt=1\ngk(x(t))  O p T log(T ) log( 1 ) ⌘ 1 ."
    }, {
      "heading" : "4.2 High Probability Regret Analysis",
      "text" : "To obtain a high probability regret bound from Lemma 8, it remains to derive a high probability bound of term (II) in (13) with z = x⇤. The main challenge is that term (II) is a supermartingale with unbounded differences (due to the possibly unbounded virtual queues Qk(t)). Most concentration inequalities, e.g., the Hoeffding-Azuma inequality, used in high probability performance analysis of online algorithms are restricted to martingales/supermartingales with bounded differences. See for example [4, 2, 16]. The following lemma considers supermartingales with unbounded differences. Its proof (provided in Supplement 7.8) uses the truncation method to construct an auxiliary wellbehaved supermartingale. Similar proof techniques are previously used in [26, 24] to prove different concentration inequalities for supermartingales/martingales with unbounded differences. Lemma 9. Let {Z(t), t 0} be a supermartingale adapted to a filtration {F(t), t 0} with Z(0) = 0 and F(0) = {;,⌦}, i.e., E[Z(t+1)|F(t)]  Z(t), 8t 0. Suppose there exits a constant c > 0 such that {|Z(t + 1) Z(t)| > c} ✓ {Y (t) > 0}, 8t 0, where Y (t) is process with Y (t) adapted to F(t) for all t 0. Then, for all z > 0, we have\nPr(Z(t) z)  e z 2/(2tc2) +\nt 1X\n⌧=0\nPr(Y (⌧) > 0), 8t 1.\nNote that if Pr(Y (t) > 0) = 0, 8t 0, then Pr({|Z(t+ 1) Z(t)| > c}) = 0, 8t 0 and Z(t) is a supermartingale with differences bounded by c. In this case, Lemma 9 reduces to the conventional Hoeffding-Azuma inequality.\nThe next theorem (proven in Supplement 7.9) summarizes the high probability regret performance of Algorithm 1 and follows from Lemmas 5-9 .\nTheorem 4 (High Probability Regret Bound). Let x⇤ 2 X0 be any fixed solution that satisfies g̃(x⇤)  0, e.g., x⇤ = argminx2X PT t=1 f t(x). Let 0 < < 1 be arbitrary. If V = p T and ↵ = T in Algorithm 1, then for all T 1, we have\nPr\n⇣ TX\nt=1\nf t(x(t)) \nTX\nt=1\nf t(x⇤) +O( p T log(T ) log1.5( 1 )) ⌘ 1 ."
    }, {
      "heading" : "5 Experiment: Online Job Scheduling in Distributed Data Centers",
      "text" : "Consider a geo-distributed data center infrastructure consisting of one front-end job router and 100 geographically distributed servers, which are located at 10 different zones to form 10 clusters (10 servers in each cluster). See Fig. 1(a) for an illustration. The front-end job router receives job tasks and schedules them to different servers to fulfill the service. To serve the assigned jobs, each server purchases power (within its capacity) from its zone market. Electricity market prices can vary significantly across time and zones. For example, see Fig. 1(b) for a 5-minute average electricity price trace (between 05/01/2017 and 05/10/2017) at New York zone CENTRL [1]. This problem is to schedule jobs and control power levels at each server in real time such that all incoming jobs are served and electricity cost is minimized. In our experiment, each server power is adjusted every 5 minutes, which is called a slot. (In practice, server power can not be adjusted too frequently due to hardware restrictions and configuration delay.) Let x(t) = [x1(t), . . . , x100(t)] be the power vector at slot t, where each xi(t) must be chosen from an interval [xmini , xmaxi ] restricted by the hardware, and the service rate at each server i satisfies µi(t) = hi(xi(t)), where hi(·) is an increasing concave function. At each slot t, the job router schedules µi(t) amount of jobs to server i. The electricity cost at slot t is f t(x(t)) = P100 i=1 ci(t)xi(t) where ci(t) is the electricity price at server i’s zone. We use ci(t) from real-world 5-minute average electricity price data at 10 different zones in New York city between 05/01/2017 and 05/10/2017 obtained from NYISO [1]. At each slot t, the incoming job is given by !(t) and satisfies a Poisson distribution. Note that the amount of incoming jobs and electricity price ci(t) are unknown to us at the beginning of each slot t but can be observed at the end of each slot. This is an example of OCO with stochastic constraints, where we aim to minimize the electricity cost subject to the constraint that incoming jobs must be served in time. In particular, at each round t, we receive loss function f t(x(t)) and constraint function g t(x(t)) = !(t) P100 i=1 hi(xi(t)).\nWe compare our proposed algorithm with 3 baselines: (1) best fixed decision in hindsight; (2) react [8] and (3) low-power [22]. Both “react\" and “low-power\" are popular power control strategies used in distributed data centers. See Supplement 7.10 for more details of these 2 baselines and our experiment. Fig. 1(c)(d) plot the performance of 4 algorithms, where the running average is the time average up to the current slot. Fig. 1(c) compares electricity cost while Fig. 1(d) compares unserved jobs. (Unserved jobs accumulate if the service rate provided by an algorithm is less than the job arrival rate, i.e., the stochastic constraint is violated.) Fig. 1(c)(d) show that our proposed algorithm performs closely to the best fixed decision in hindsight over time, both in electricity cost and constraint violations. ‘React\" performs well in serving job arrivals but yields larger electricity cost, while “low-power\" has low electricity cost but fails to serve job arrivals."
    }, {
      "heading" : "6 Conclusion",
      "text" : "This paper studies OCO with stochastic constraints, where the objective function varies arbitrarily but the constraint functions are i.i.d. over time. A novel learning algorithm is developed that guarantees O( p T ) expected regret and constraint violations and O( p T log(T )) high probability regret and constraint violations."
    } ],
    "references" : [ {
      "title" : "High-probability regret bounds for bandit online linear optimization",
      "author" : [ "Peter L Bartlett", "Varsha Dani", "Thomas Hayes", "Sham Kakade", "Alexander Rakhlin", "Ambuj Tewari" ],
      "venue" : "In Proceedings of Conference on Learning Theory (COLT),",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2008
    }, {
      "title" : "Worst-case quadratic loss bounds for prediction using linear functions and gradient descent",
      "author" : [ "Nicolò Cesa-Bianchi", "Philip M Long", "Manfred K Warmuth" ],
      "venue" : "IEEE Transactions on Neural Networks,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1996
    }, {
      "title" : "Prediction, Learning, and Games",
      "author" : [ "Nicolò Cesa-Bianchi", "Gábor Lugosi" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2006
    }, {
      "title" : "A light touch for heavily constrained sgd",
      "author" : [ "Andrew Cotter", "Maya Gupta", "Jan Pfeifer" ],
      "venue" : "In Proceedings of Conference on Learning Theory (COLT),",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2015
    }, {
      "title" : "Probability: Theory and Examples",
      "author" : [ "Rick Durrett" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2010
    }, {
      "title" : "Are sleep states effective in data centers",
      "author" : [ "Anshul Gandhi", "Mor Harchol-Balter", "Michael A Kozuch" ],
      "venue" : "In International Green Computing Conference (IGCC),",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2012
    }, {
      "title" : "Regret bounds for prediction problems",
      "author" : [ "Geoffrey J Gordon" ],
      "venue" : "In Proceeding of Conference on Learning Theory (COLT),",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1999
    }, {
      "title" : "Hitting-time and occupation-time bounds implied by drift analysis with applications",
      "author" : [ "Bruce Hajek" ],
      "venue" : "Advances in Applied Probability,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1982
    }, {
      "title" : "Introduction to online convex optimization",
      "author" : [ "Elad Hazan" ],
      "venue" : "Foundations and Trends in Optimization,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2016
    }, {
      "title" : "Logarithmic regret algorithms for online convex optimization",
      "author" : [ "Elad Hazan", "Amit Agarwal", "Satyen Kale" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2007
    }, {
      "title" : "Adaptive algorithms for online convex optimization with long-term constraints",
      "author" : [ "Rodolphe Jenatton", "Jim Huang", "Cédric Archambeau" ],
      "venue" : "In Proceedings of International Conference on Machine Learning (ICML),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2016
    }, {
      "title" : "Exponentiated gradient versus gradient descent for linear predictors",
      "author" : [ "Jyrki Kivinen", "Manfred K Warmuth" ],
      "venue" : "Information and Computation,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1997
    }, {
      "title" : "Algorithms for stochastic optimization with expectation constraints",
      "author" : [ "Guanghui Lan", "Zhiqiang Zhou" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2016
    }, {
      "title" : "Trading regret for efficiency: online convex optimization with long term constraints",
      "author" : [ "Mehrdad Mahdavi", "Rong Jin", "Tianbao Yang" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2012
    }, {
      "title" : "Stochastic convex optimization with multiple objectives",
      "author" : [ "Mehrdad Mahdavi", "Tianbao Yang", "Rong Jin" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2013
    }, {
      "title" : "Online learning with sample path constraints",
      "author" : [ "Shie Mannor", "John N Tsitsiklis", "Jia Yuan Yu" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2009
    }, {
      "title" : "Subgradient methods for saddle-point problems",
      "author" : [ "Angelia Nedić", "Asuman Ozdaglar" ],
      "venue" : "Journal of Optimization Theory and Applications,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2009
    }, {
      "title" : "Energy-aware wireless scheduling with near optimal backlog and convergence time tradeoffs",
      "author" : [ "Michael J. Neely" ],
      "venue" : "IEEE/ACM Transactions on Networking,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2016
    }, {
      "title" : "Introductory Lectures on Convex Optimization: A Basic Course",
      "author" : [ "Yurii Nesterov" ],
      "venue" : "Springer Science & Business Media,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2004
    }, {
      "title" : "Cutting the electric bill for internet-scale systems",
      "author" : [ "Asfandyar Qureshi", "Rick Weber", "Hari Balakrishnan", "John Guttag", "Bruce Maggs" ],
      "venue" : "In ACM SIGCOMM,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2009
    }, {
      "title" : "Online learning and online convex optimization",
      "author" : [ "Shai Shalev-Shwartz" ],
      "venue" : "Foundations and Trends in Machine Learning,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2011
    }, {
      "title" : "Random matrices: universality of local spectral statistics of nonhermitian matrices",
      "author" : [ "Terence Tao", "Van Vu" ],
      "venue" : "The Annals of Probability,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2015
    }, {
      "title" : "Fundamentals of Wireless Communication",
      "author" : [ "David Tse", "Pramod Viswanath" ],
      "venue" : null,
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2005
    }, {
      "title" : "Concentration of non-lipschitz functions and applications",
      "author" : [ "Van Vu" ],
      "venue" : "Random Structures & Algorithms,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2002
    }, {
      "title" : "A low complexity algorithm with O(  p T ) regret and finite constraint violations for online convex optimization with long term constraints",
      "author" : [ "Hao Yu", "Michael J. Neely" ],
      "venue" : null,
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2016
    }, {
      "title" : "A simple parallel algorithm with an O(1/t) convergence rate for general convex programs",
      "author" : [ "Hao Yu", "Michael J. Neely" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2017
    }, {
      "title" : "Online convex programming and generalized infinitesimal gradient ascent",
      "author" : [ "Martin Zinkevich" ],
      "venue" : "In Proceedings of International Conference on Machine Learning (ICML),",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "The setting of OCO is introduced in a series of work [3, 14, 9, 29] and is formalized in [29].",
      "startOffset" : 53,
      "endOffset" : 67
    }, {
      "referenceID" : 11,
      "context" : "The setting of OCO is introduced in a series of work [3, 14, 9, 29] and is formalized in [29].",
      "startOffset" : 53,
      "endOffset" : 67
    }, {
      "referenceID" : 6,
      "context" : "The setting of OCO is introduced in a series of work [3, 14, 9, 29] and is formalized in [29].",
      "startOffset" : 53,
      "endOffset" : 67
    }, {
      "referenceID" : 26,
      "context" : "The setting of OCO is introduced in a series of work [3, 14, 9, 29] and is formalized in [29].",
      "startOffset" : 53,
      "endOffset" : 67
    }, {
      "referenceID" : 26,
      "context" : "The setting of OCO is introduced in a series of work [3, 14, 9, 29] and is formalized in [29].",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 20,
      "context" : "See [23, 11] for more applications and background.",
      "startOffset" : 4,
      "endOffset" : 12
    }, {
      "referenceID" : 8,
      "context" : "See [23, 11] for more applications and background.",
      "startOffset" : 4,
      "endOffset" : 12
    }, {
      "referenceID" : 26,
      "context" : "In [29], Zinkevich shows O( p T ) regret can be achieved by using an online gradient descent (OGD) update given by",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 9,
      "context" : "in [12] show that better regret is possible under the assumption that each loss function is strongly convex but O( p T ) is the best possible if no additional assumption is imposed.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 15,
      "context" : "in [18] explore the possibility of designing learning algorithms such that regret grows sub-linearly and lim supT!1 1 T PT t=1 g t(x(t))  0, i.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 15,
      "context" : "in [18] prove that this is impossible even when both f t(·) and gt(·) are simple linear functions.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 15,
      "context" : "in [18], this paper considers OCO where constraint functions gt(x) are not arbitrarily varying but independently and identically distributed (i.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 15,
      "context" : "For example, if we consider online routing (with link capacity constraints) in wireless networks [18], each link capacity is not a fixed constant (as in wireline networks) but an i.",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 22,
      "context" : "random variable since wireless channels are stochastically time-varying by nature [25].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 13,
      "context" : "OCO with stochastic constraints also covers important special cases such as OCO with long term constraints [16, 5, 13], stochastic constrained convex optimization [17] and deterministic constrained convex optimization [21].",
      "startOffset" : 107,
      "endOffset" : 118
    }, {
      "referenceID" : 3,
      "context" : "OCO with stochastic constraints also covers important special cases such as OCO with long term constraints [16, 5, 13], stochastic constrained convex optimization [17] and deterministic constrained convex optimization [21].",
      "startOffset" : 107,
      "endOffset" : 118
    }, {
      "referenceID" : 10,
      "context" : "OCO with stochastic constraints also covers important special cases such as OCO with long term constraints [16, 5, 13], stochastic constrained convex optimization [17] and deterministic constrained convex optimization [21].",
      "startOffset" : 107,
      "endOffset" : 118
    }, {
      "referenceID" : 14,
      "context" : "OCO with stochastic constraints also covers important special cases such as OCO with long term constraints [16, 5, 13], stochastic constrained convex optimization [17] and deterministic constrained convex optimization [21].",
      "startOffset" : 163,
      "endOffset" : 167
    }, {
      "referenceID" : 18,
      "context" : "OCO with stochastic constraints also covers important special cases such as OCO with long term constraints [16, 5, 13], stochastic constrained convex optimization [17] and deterministic constrained convex optimization [21].",
      "startOffset" : 218,
      "endOffset" : 222
    }, {
      "referenceID" : 13,
      "context" : "To avoid high complexity involved in the projection onto X as in Zinkevich’s algorithm, work in [16, 5, 13] develops low complexity algorithms that use projections onto a simpler set X0 by allowing gk(x(t)) > 0 for certain rounds but ensuring lim supT!1 1 T PT t=1 gk(x(t))  0.",
      "startOffset" : 96,
      "endOffset" : 107
    }, {
      "referenceID" : 3,
      "context" : "To avoid high complexity involved in the projection onto X as in Zinkevich’s algorithm, work in [16, 5, 13] develops low complexity algorithms that use projections onto a simpler set X0 by allowing gk(x(t)) > 0 for certain rounds but ensuring lim supT!1 1 T PT t=1 gk(x(t))  0.",
      "startOffset" : 96,
      "endOffset" : 107
    }, {
      "referenceID" : 10,
      "context" : "To avoid high complexity involved in the projection onto X as in Zinkevich’s algorithm, work in [16, 5, 13] develops low complexity algorithms that use projections onto a simpler set X0 by allowing gk(x(t)) > 0 for certain rounds but ensuring lim supT!1 1 T PT t=1 gk(x(t))  0.",
      "startOffset" : 96,
      "endOffset" : 107
    }, {
      "referenceID" : 10,
      "context" : "The best existing performance is O(Tmax{ ,1 }) regret and O(T 1 /2) constraint violations where 2 (0, 1) is an algorithm parameter [13].",
      "startOffset" : 131,
      "endOffset" : 135
    }, {
      "referenceID" : 24,
      "context" : "Note that by adapting the methodology presented in this paper, our other work [27] developed a different algorithm that can only solve the special case problem “OCO with long term constraints” but can achieve O( p T ) regret and O(1) constraint violations.",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 14,
      "context" : "The work [17] develops a (batch) offline algorithm that produces a solution with high probability performance guarantees only after sampling the problems for sufficiently many times.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 12,
      "context" : "The work [15] proposes a stochastic approximation based (batch) offline algorithm for stochastic convex optimization with one single stochastic functional inequality constraint.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 16,
      "context" : "The primal-dual subgradient method considered in [19] has the same O(1/ p T ) convergence rate but requires an upper bound of optimal Lagrange multipliers, which is usually unknown in practice.",
      "startOffset" : 49,
      "endOffset" : 53
    }, {
      "referenceID" : 25,
      "context" : "Further, it is known that if h : X ! R is a c-strongly convex function that is minimized at a point xmin 2 X0, then (see, for example, Corollary 1 in [28]):",
      "startOffset" : 150,
      "endOffset" : 154
    }, {
      "referenceID" : 7,
      "context" : "See [6, 10] for more discussions or applications on drift analysis.",
      "startOffset" : 4,
      "endOffset" : 11
    }, {
      "referenceID" : 7,
      "context" : "One-step drift conditions, corresponding to the special case t0 = 1 of Lemma 5, have been previously considered in [10, 20].",
      "startOffset" : 115,
      "endOffset" : 123
    }, {
      "referenceID" : 17,
      "context" : "One-step drift conditions, corresponding to the special case t0 = 1 of Lemma 5, have been previously considered in [10, 20].",
      "startOffset" : 115,
      "endOffset" : 123
    }, {
      "referenceID" : 12,
      "context" : "Thus, if we use Algorithm 1 as a (batch) offline algorithm to solve stochastic constrained convex optimization, it has O(1/ p T ) convergence and ties with the algorithm developed in [15], which is by design a (batch) offline algorithm and can only solve stochastic optimization with a single constraint function.",
      "startOffset" : 183,
      "endOffset" : 187
    }, {
      "referenceID" : 23,
      "context" : "Similar proof techniques are previously used in [26, 24] to prove different concentration inequalities for supermartingales/martingales with unbounded differences.",
      "startOffset" : 48,
      "endOffset" : 56
    }, {
      "referenceID" : 21,
      "context" : "Similar proof techniques are previously used in [26, 24] to prove different concentration inequalities for supermartingales/martingales with unbounded differences.",
      "startOffset" : 48,
      "endOffset" : 56
    }, {
      "referenceID" : 5,
      "context" : "We compare our proposed algorithm with 3 baselines: (1) best fixed decision in hindsight; (2) react [8] and (3) low-power [22].",
      "startOffset" : 100,
      "endOffset" : 103
    }, {
      "referenceID" : 19,
      "context" : "We compare our proposed algorithm with 3 baselines: (1) best fixed decision in hindsight; (2) react [8] and (3) low-power [22].",
      "startOffset" : 122,
      "endOffset" : 126
    } ],
    "year" : 2017,
    "abstractText" : "This paper considers online convex optimization (OCO) with stochastic constraints, which generalizes Zinkevich’s OCO over a known simple fixed set by introducing multiple stochastic functional constraints that are i.i.d. generated at each round and are disclosed to the decision maker only after the decision is made. This formulation arises naturally when decisions are restricted by stochastic environments or deterministic environments with noisy observations. It also includes many important problems as special case, such as OCO with long term constraints, stochastic constrained convex optimization, and deterministic constrained convex optimization. To solve this problem, this paper proposes a new algorithm that achieves O( p T ) expected regret and constraint violations and O( p T log(T )) high probability regret and constraint violations. Experiments on a real-world data center scheduling problem further verify the performance of the new algorithm.",
    "creator" : null
  }
}