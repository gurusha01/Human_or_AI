{"title": "Spectral Mixture Kernels for Multi-Output Gaussian Processes", "abstract": "Early approaches to multiple-output Gaussian processes (MOGPs) relied on linear combinations of independent, latent, single-output Gaussian processes (GPs). This resulted in cross-covariance functions with limited parametric interpretation, thus conflicting with the ability  of single-output GPs to understand lengthscales, frequencies and magnitudes to name a few. On the contrary, current approaches to MOGP are able to better interpret the relationship between different channels by directly modelling the cross-covariances as a spectral mixture kernel with a phase shift. We extend this rationale and propose a parametric family of complex-valued cross-spectral densities and then build on Cram\u00e9r's Theorem (the multivariate version of Bochner's Theorem) to provide a principled approach to design multivariate covariance functions. The so-constructed kernels are able to model delays among channels in addition to phase differences and are thus more expressive than previous methods, while also providing full parametric interpretation of the relationship across channels. The proposed method is first validated on synthetic data and then compared to existing MOGP methods on two real-world examples.", "id": "333cb763facc6ce398ff83845f224d62", "authors": ["Gabriel Parra", "Felipe Tobar"], "conference": "NIPS2017", "accepted": true, "reviews": [{"comments": "This paper presents a multi-output Gaussian process co-variance\nfunction that is defined in the spectral domain. The approach of\ndesigning co-variances in the spectral domain is an important\ncontribution to GPs that I personally feel have not gotten the\nattention that it deserves. This paper extends this to the\nmulti-output scenario. The paper is an extension of the work presented\nin [1]. However, considering the multi-output case the challenge is\nhow to describe cross-covariance which is does not have to be\npositive-definite. In this paper the authors describes just such an\napproach in a manner that leads to the spectral mixture covariance for\nmulti-output GPs. \n\nThe paper is well written with a short and clear introduction to the\nproblem and to GP fundamentals. The explanation of the spectral\nmixture kernel is clear and the extensions proposed are to my\nknowledge novel. The relationship to previous work is well explained\nand I believe that there is sufficient novelty in the work to justify\npublication.\n\nThe experiments are sufficient for a paper such as this, they do not\nprovide a lot of intuition however, especially the Jura data-set is\nhard to actually reason about. But, for a paper such as this I think\nthe experimental evaluation is sufficient.\n\n-[1] Wilson, A. G., & Adams, R. P. (2013). Gaussian process kernels for\n pattern discovery and extrapolation. In , Proceedings of the 30th\n International Conference on Machine Learning, {ICML} 2013, Atlanta,\n GA, USA, 16-21 June 2013 (pp. 1067\u20131075). : JMLR.org.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper formulates a new type of covariance function for multi-output Gaussian processes. Instead of directly specifying the cross-covariance functions, the authors propose to specify the cross-power spectral densities and using the inverse Fourier transform to find the corresponding cross-covariances. The paper follows a similar idea to the one proposed by [6] for single output Gaussian processes, where the power spectral density was represented through a mixture of Gaussians and then back-transformed to obtaining a powerful kernel function with extrapolation abilities. The authors applied the newly established covariance for a synthetic data example, and for two real data examples, the weather dataset and the Swiss Jura dataset for metal concentrations. \n\nExtending the idea from [6] sounds like a clever way to build new types of covariance functions for multiple-outputs. One of the motivations in [6] was to build a kernel function with the ability to perform extrapolation. It would have been interesting to provide this covariance function for multiple-outputs with the same ability. The experimental section only provides results with very common datasets, and the results obtained are similar to the ones obtained with other covariance functions for multiple-outputs. The impact of the paper could be increased by including experiments in datasets for which none of the other models are suitable. \n\nDid you test for the statistical significance of the results in Tables 1 and 2. It seems that, within the standard deviation, almost all models provide a similar performance.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper introduces a new covariance structure for multioutputs GPs, which corresponds to the generalisation of the spectral approach (Bochner Theorem) to build kernels from A. G. Adams and R. P. Adams. One particular asset of the proposed method is that the parameters of the model can be interpreted (such as delay between outputs or phase difference).\n\nThe definition of covariance structures for multioutputs GPs is a challenging topic and relatively few methods are currently available to do so. The method proposed by the authors is theoretically sound and its effectiveness is demonstrated on several datasets. \n\nThe method is clearly described in a well written paper, and the choices for the illustrations appear relevant to me. If the parameter learning isn't too troublesome (the paper does not contain much informations regarding this), I would expect this method to become a standard for multioutput GPs.\n\nQuestions \n * How does the method behaves when few training points are available?\n * (more a curiosity) A channel with a large length-scale cannot be highly correlated with a channel with a small length-scales. How does that appear in your model?\n\nComments\n * In the synthetic example (Section 4.1), the number of training points should be specified\n\nMinor remarks: I guess a word is missing in lines 74 and 140.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
