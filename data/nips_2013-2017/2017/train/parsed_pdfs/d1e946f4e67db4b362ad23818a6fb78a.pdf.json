{
  "name" : "d1e946f4e67db4b362ad23818a6fb78a.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Graph Matching via Multiplicative Update Algorithm",
    "authors" : [ "Bo Jiang", "Jin Tang", "Yihong Gong" ],
    "emails" : [ "jiangbo@ahu.edu.cn", "tj@ahu.edu.cn", "chqding@uta.edu", "ygong@mail.xjtu.edu.cn", "luobin@ahu.edu.cn" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "In computer vision and machine learning area, many problems of interest can be formulated by graph matching problem. Previous approaches [3–5, 15, 16] have formulated graph matching as a Quadratic Programming (QP) problem with both doubly stochastic and discrete constraints. Since it is known to be NP-hard, many approximate algorithms have been developed to find approximate solutions for this problem [8, 16, 21, 24, 20, 13].\nOne kind of approximate methods generally first develop a continuous problem by relaxing the discrete constraint and aim to find the optimal solution for this continuous problem. After that, they obtain the final discrete solution by using a discretization step such as Hungarian or greedy algorithm [3, 15, 16]. Obviously, the discretization step of these methods is generally independent of the matching objective optimization process which may lead to weak local optimum for the problem. Another kind of methods aim to obtain a discrete solution for QP matching problem [16, 1, 24]. For example, Leordeanu et al. [16] proposed an iterative matching method (IPFP) which optimized the QP matching problem in a discrete domain. Zhou et al. [24, 25] proposed an effective graph matching method (FGM) which optimized the QP matching problem approximately using a convexconcave relaxation technique [21] and thus returns a discrete solution for the problem. From optimization aspect, the core optimization algorithm used in both IPFP [16] and FGM [24] is related to Frank-Wolfe [9] algorithm and FGM [24, 25] further uses a path following procedure to alleviate the local-optimum problem more carefully. The core of Frank-Wolfe [9] algorithm is to optimize the quadratic problem by sequentially optimizing the linear approximations of QP problem. In addition\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\nto optimization-based methods, probabilistic methods can also be used for solving graph matching problems [3, 19, 23].\nIn this paper, we propose a new algorithm, called Multiplicative Update Graph Matching (MPGM), that develops a multiplicative update technique for the general QP problem with doubly stochastic constraint. Generally, MPGM has the following three main aspects. First, MPGM solves the general QP problem with doubly stochastic constraint directly and naturally. In MPGM algorithm, each update step has a closed-form solution and the convergence of the algorithm is also guaranteed. Moreover, the converged solution is guaranteed to be Karush-Kuhn-Tucker (KKT) optimality. Second, empirically, MPGM can generate a sparse solution and thus incorporates the discrete constraint naturally in optimization. Therefore, MPGM can obtain a local optimal discrete solution for the QP matching problem. Third, it is efficient and simple to implement. Experimental results on both synthetic and real-world matching tasks demonstrate the effectiveness and benefits of the proposed MPGM algorithm."
    }, {
      "heading" : "2 Problem Formulation and Related Works",
      "text" : "Problem Formulation. Assume G = (V,E) and G′ = (V ′, E′) are two attributed graphs to be matched, where each node vi ∈ V or edge eik ∈ E has an attribute vector ai or rik. The aim of graph matching problem is to establish the correct correspondences between V and V ′. For each correspondence (vi, v′j), there is an affinity Sa(ai, a′j) that measures how well node vi ∈ V matches node v′j ∈ V ′. Also, for each correspondence pair (vi, v′j) and (vk, v′l), there is an affinity Sr(rik, r′jl) that measures the compatibility between node pair (vi, vk) and (v′j , v ′ l). One can define an affinity matrix W whose diagonal term Wij,ij represents Sa(ai, a′j), and the non-diagonal element Wij,kl contains Sr(rik, r′jl). The one-to-one correspondences can be represented by a permutation matrix X ∈ {0, 1}n×n, where n = |V | = |V ′|1. Here, Xij = 1 implies that node vi in G corresponds to node v′j in G\n′, and Xij = 0 otherwise. In this paper, we denote x = (X11...Xn1, ...,X1n...Xnn)T as a column-wise vectorized replica of X. The graph matching problem is generally formulated as a Quadratic Programming (QP) problem with doubly stochastic and discrete constraints [16, 3, 10], i.e.,\nx∗ = argmax x (xTWx) s.t. x ∈ P, (1)\nwhere P is defined as, P = {x | ∀i ∑n j=1 xij = 1, ∀j ∑n i=1 xij = 1, xij ∈ {0, 1}} (2)\nThe above QP problem is NP-hard and thus approximate relaxations are usually required. One popular way is to relax the permutation domain P to the doubly stochastic domain D,\nD = {x|∀i ∑n j=1 xij = 1, ∀j ∑n\ni=1 xij = 1, xij ≥ 0}. (3) That is solving the following relaxed matching problem [21, 20, 10],\nx∗ = argmax x (xTWx) s.t. x ∈ D. (4)\nSince W is not necessarliy positive (or negative) semi-definite, thus this problem is generally not a concave or convex problem.\nRelated Works. Many algorithms have been proposed to find a local optimal solution for the above QP matching problem (Eq.(4)). One kind of popular methods is to use constraint relaxation and projection, such as GA [10] and RRWM [3]. Generally, they iteratively conduct the following two steps: (a) searching for a solution by ignoring the doubly stochastic constraint temporarily; (b) Projecting the current solution onto the desired doubly stochastic domain to obtain a feasible solution. Note that the projection step (b) is generally independent of the optimization step (a) and thus may lead to weak local optimum. Another kind of important methods is to use objective function approximation and thus solves the problem approximately, such as Frank-Wolfe algorithm [9]. Frank-Wolfe aims to optimize the above quadratic problem by sequentially solving the approximate linear problems. This algorithm has been widely adopted in many recent matching methods [16, 24, 21], such as IPFP [16] and FGM [24].\n1Here, we focus on equal-size graph matching problem. For graphs with different sizes, one can add dummy isolated nodes into the smaller graph and transform them to equal-size case [21, 10]"
    }, {
      "heading" : "3 Algorithm",
      "text" : "Our aim in this paper is to develop a new algorithm to solve the general QP matching problem Eq.(4). We call it as Multiplicative Update Graph Matching (MPGM). Formally, starting with an initial solution vector x(0), MPGM solves the problem Eq.(4) by iteratively updating a current solution vector x(t), t = 0, 1... as follows,\nx(t+1)kl = x (t) kl [2(Wx(t))kl +Λ−k + Γ−l Λ+k + Γ + l ]1/2 , (5)\nwhere Λ+k = (|Λk|+Λk)/2, Λ − k = (|Λk| −Λk)/2, Γ + k = (|Γk|+ Γk)/2, Γ − k = (|Γk| − Γk)/2, and the Lagrangian multipliers (Λ,Γ) are computed as,\nΓ =2 ( I − X(t) T X(t) )−1[ diag ( K(t) T X(t) ) − X(t) T diag ( K(t)X(t) T)] Λ =2diag ( K(t)X(t) T) − X(t)Γ (6)\nwhere K(t), X(t) are the matrix forms of vector (Wx(t)) and x(t), respectively, i.e., K(t),X(t) ∈ Rn×n and K(t)kl = (Wx (t))kl,X (t) kl = x (t) kl . Λ = (Λ1, · · ·Λn)T ∈ Rn×1,Γ = (Γ1, · · ·Γn)T ∈ Rn×1. The iteration starts with an initial x(0) and is repeated until convergence.\nComplexity. The main complexity in each iteration is on computing Wx(t). Thus, the total computational complexity for MPGM is less than O(MN2), where N = n2 is the length of vector x(t) and M is the maximum iteration. Our experience is that the algorithm converges quickly and the average maximum iteration M is generally less than 200. Theoretically, the complexity of MPGM is the same with RRWM [3] and IPFP [16], but obviously lower than GA [10] and FGM [24].\nComparison with Related Works. Multiplicative update algorithms have been studied in solving matching problems [6, 13, 11, 12]. Our work is significantly different from previous works in the following aspects. Previous works [6, 13, 11] generally first develop a kind of approximation (or relaxation) for QP matching problem by ignoring the doubly stochastic constraint, and then aim to find the optimum of the relaxation problem by developing an algorithm. In contrast, our work focus on the general and challengeable QP problem with doubly stochastic constraint (Eq.(4)), and derive a simple multiplicative algorithm to solve the problem Eq.(4) directly. Note that, the proposed algorithm is not limited to solving QP matching problem only. It can also be used in some other QP (or general continuous objective function) problems with doubly stochastic constraint (e.g. MAP inference, clustering) in machine learning area. In this paper, we focus on graph matching problem.\nStarting Point. To alleviate the local optima and provide a feasible starting point for MPGM algorithm, given an initial vector x(0), we first use the simple projection x(0) = P (Wx(0)) several times to obtain a kind of the feasible start point for MPGM algorithm. Here P denotes the projection [22] or normalization [20] to make x(0) satisfy the doubly stochastic constraint."
    }, {
      "heading" : "4 Theoretical Analysis",
      "text" : "Theorem 1. Under update Eq.(5), the Lagrangian function L(x) is monotonically increasing,\nL(x) = xTWx − n∑\ni=1\nΛi( n∑\nj=1\nxij − 1)− n∑\nj=1\nΓj( n∑\ni=1\nxij − 1) (7)\nwhere Λ,Γ are Lagrangian multipliers.\nProof. To prove it, we use the auxiliary function approach [7, 14]. An auxiliary function function Φ(x, x̃) of Lagrangian function L(x) satisfies following,\nΦ(x, x) = L(x),Φ(x, x̃) ≤ L(x). (8)\nUsing the auxiliary function Φ(x, x̃), we define\nx(t+1) = argmax x Φ(x, x(t)). (9)\nThen by construction of Φ(x, x̃), we have\nL(x(t)) = Φ(x(t), x(t)) ≤ L(x(t+1)). (10) This proves that L(x(t)) is monotonically increasing. The main step in the following of the proof is to provide an appropriate auxiliary function and find the global maximum for the auxiliary function. We rewrite Eq.(7) as\nL(x) = xT Wx − n∑\ni=1\nΛi( n∑ j=1 xij − 1)− n∑ j=1 Γj( n∑ i=1 xij − 1)\n= n∑ i=1 n∑ j=1 n∑ k=1 n∑ l=1 Wij,klxijxkl − n∑ i=1 Λi( n∑ j=1 xij − 1)− n∑ j=1 Γj( n∑ i=1 xij − 1). (11)\nWe show that one auxiliary function Φ(x, x̃) of L(x) is,\nΦ(x, x̃) = n∑\ni=1 n∑ j=1 n∑ k=1 n∑ l=1 Wij,klx̃ij x̃kl ( 1 + log xijxkl x̃ij x̃kl ) (12)\n− n∑\ni=1\nΛ+i [ n∑ j=1 1 2 ( x2ij x̃ij + x̃ij)− 1 ] + n∑ i=1 Λ−i [ n∑ j=1 x̃ij(1 + log xij x̃ij )− 1 ]\n− n∑\nj=1\nΓ+j [ n∑ i=1 1 2 ( x2ij x̃ij + x̃ij)− 1 ] + n∑ j=1 Γ−j [ n∑ i=1 x̃ij(1 + log xij x̃ij )− 1 ] .\nUsing the inequality z ≥ 1+ log z and ab ≤ 12 (a 2+ b2)(a ≤ 12 (\na2\nb + b)), one can prove that Eq.(12) is a lower bound of Eq.(11). Thus, Z(x, x̃) is an auxiliary function of L(x). According to Eq.(9), we need to find the global maximum of Φ(x, x̃) for x. The gradient is\n∂Φ(x, x̃) ∂xkl = 2(Wx̃)kl x̃kl xkl −Λ+k xkl x̃kl +Λ−k x̃kl xkl − Γ+l xkl x̃kl + Γ−l x̃kl xkl\nNote that, for graph matching problem, we have WT = W. Thus, the second derivative is ∂2Φ(x, x̃) ∂xkl∂xij = − [( 2(Wx̃)kl +Λ−k + Γ − l ) x̃kl x2kl + 1 x̃kl (Λ+k + Γ + l ) ] δkiδlj ≤ 0, (13)\nTherefore, Φ(x, x̃) is a concave function in x and has a unique global maximum. It can be obtained by setting the first derivative to zero (∂Φ(x,x̃)∂xkl = 0), which gives\nxkl = x̃kl [2(Wx̃)kl +Λ−k + Γ−l\nΛ+k + Γ + l\n]1/2 . (14)\nTherefore, we obtain the update rule in Eq.(5) by setting x(t+1) = x and x(t) = x̃. Theorem 2. Under update Eq.(5), the converged solution x∗ is Karush-Kuhn-Tucker (KKT) optimal. Proof. The standard Lagrangian function is\nL(x) = xTWx − n∑\ni=1\nΛi( n∑\nj=1\nxij − 1)− n∑\nj=1\nΓj( n∑\ni=1\nxij − 1)− n∑\ni=1 n∑ j=1 ∆ijxij (15)\nHere, we use the Lagrangian function to induce KKT optimal condition. Using Eq.(15), we have ∂L(x) ∂xkl = 2(Wx)kl − λk − µl. (16) The corresponding KKT condition is ∂L(x) ∂xkl = 2(Wx)kl −Λk − Γl −∆kl = 0 (17)\n∂L(x) ∂Λk = −( ∑ l xkl − 1) = 0 (18)\n∂L(x) ∂Γl = −( ∑ k xkl − 1) = 0 (19)\n∆klxkl = 0. (20)\nThis leads to the following KKT complementary slackness condition,[ 2(Wx)kl −Λk − Γl ] xkl = 0. (21)\nBecause ∑ l xkl = 1, ∑\nk xkl = 1, summing over indexes k and l respectively, we obtain the following two group equations,\n2 n∑\nl=1\nxkl(Wx)kl − n∑\nl=1\nΓlxkl −Λk = 0, (22)\n2 n∑ k=1 xkl(Wx)kl − n∑ k=1 Λkxkl − Γl = 0. (23)\nEqs.(22, 23) can be equivalently reformulated as the following matrix forms,\n2 diag(KXT)−Λ− XΓ = 0, (24) 2 diag(KTX)− Γ− XTΛ = 0. (25)\nwhere k = 1, 2, · · ·n, l = 1, 2, · · ·n. K, X are the matrix forms of vector (Wx) and x, respectively, i.e., K,X ∈ Rn×n and Kkl = (Wx)kl,Xkl = xkl. Thus, we can obtain the values for Λ and Γ as,\nΓ = 2(I − XTX)−1(diag(KTX)− XT diag(KXT)) (26) Λ = 2diag(KXT)− XΓ (27)\nOn the other hand, from update Eq.(5), at convergence,\nx∗kl = x ∗ kl [2(Wx∗)kl +Λ−k + Γ−l Λ+k + Γ + l ]1/2 (28)\nThus, we have (2(Wx∗)kl −Λk − Γl)x∗2kl = 0, which is identical to the following KKT condition,[ 2(Wx∗)kl −Λk − Γl ] x∗kl = 0. (29)\nSubstituting the values of Λk,Γl in Eq.(28) from Eqs.(26,27), we obtain update rule Eq.(5). Remark. Similar to the above analysis, we can also derive another similar update as,\nx(t+1)kl = x (t) kl\n2(Wx(t))kl +Λ−k + Γ − l\nΛ+k + Γ + l\n. (30)\nThe optimality and convergence of this update are also guaranteed. We omit the further discussion of them due to the lack of space. In real application, one can use both of these two update algorithms (Eq.(5), Eq.(30)) to obtain better results."
    }, {
      "heading" : "5 Sparsity and Discrete Solution",
      "text" : "One property of the proposed MPGM is that it can result in a sparse optimal solution, although the discrete binary constraint have been dropped in MPGM optimization process. This suggests that MPGM can search for an optimal solution nearly on the permutation domain P , i.e., the boundary of the doubly stochastic domain D. Unfortunately, here we cannot provide a theoretical proof on the sparsity of MPGM solution, but demonstrate it experimentally.\nFigure 1 (a) shows the solution x(t) across different iterations. Note that, regardless of initialization, as the iteration increases, the solution vector x(t) of MPGM becomes more and more sparse and converges to a discrete binary solution. Note that, in MPGM update Eq.(5), when xtkl closes to zero, it can keep closing to zero in the following update process because of the particular multiplicative operation. Therefore, as the iteration increases, the solution vector xt+1 is guaranteed to be more sparse than solution vector xt. Figure 1 (b) shows the objective and sparsity2 of the solution vector x(t). We can observe that (1) the objective of x(t) increases and converges after some iterations, demonstrating the convergence of MPGM algorithm. (2) The sparsity of the solution x(t) increases and converges to the baseline, which demonstrates the ability of MPGM algorithm to maintain the discrete constraint in the converged solution.\n2Sparsity measures the percentage of zero (close-to-zero) elements in Z. Firstly, set the threshold ϵ = 0.001 × mean(Z), then renew Zij = 0 if Zij ≤ ϵ. Finally, the sparsity is defined as the percentage of zero elements in the renewed Z."
    }, {
      "heading" : "6 Experiments",
      "text" : "We have applied MPGM algorithm to several matching tasks. Our method has been compared with some other state-of-the-art methods including SM [15], IPFP [16], SMAC [5], RRWM [3] and FGM [24]. We implemented IPFP [16] with two versions: (1) IPFP-U that is initialized by the uniform solution; (2) IPFP-S that is initialized by SM method [15]. In experiments, we initialize our MPGM with uniform solution and obtain similar results when initializing with SM solution."
    }, {
      "heading" : "6.1 Synthetic Data",
      "text" : "Similar to the works [3, 24], we have randomly generated data sets of nin 2D points as inlier nodes for G. We obtain the corresponding nodes in graph G′ by transforming the whole point set with a random rotation and translation and then adding Gaussian noise N(0, σ) to the point positions from graph G. In addition, we also added nout outlier nodes in both graphs respectively at random positions. The affinity matrix W has been computed as Wij,kl = exp(−∥rik − r′jl∥2F /0.0015), where rik is the Euclidean distance between two nodes in G and similarly for r′jl.\nFigure 2 summarizes the comparison results. We can note that: (1) similar to IPFP [16] and FGM [24] which return discrete matching solutions, MPGM always generates sparse solutions on doubly stochastic domain. (2) MPGM returns higher objective score and accuracy than IPFP [16] and FGM [24] methods, which demonstrate that MPGM can find the sparse solution more optimal than these methods. (3) MPGM generally performs better than the continuous domain methods including SM [15], SMAC [5] and RRWM [3]. Comparing with these methods, MPGM incorporates the doubly stochastic constraint more naturally and thus finds the solution more optimal than RRWM method. (4) MPGM generally has similar time cost with RRWM [3]. We have not shown the time cost of FGM [24] method in Fig.2, because FGM uses a hybrid optimization method and has obviously higher time cost than other methods."
    }, {
      "heading" : "6.2 Image Sequence Data",
      "text" : "In this section, we perform feature matching on CMU and YORK house sequences [3, 2, 18]. For CMU \"hotel\" sequence, we have matched all images spaced by 5, 10 · · · 75 and 80 frames and computed the average performances per separation gap. For YORK house sequence, we have matched all images spaced by 1, 2 · · · 8 and 9 frames and computed the average performances per separation gap. The affinity matrix has been computed by Wij,kl = exp(−∥rik − r′jl∥2F /1000), where rik is the Euclidean distance between two points.\nFigure 3 summarizes the performance results. It is noted that MPGM outperforms the other methods in both objective score and matching accuracy, indicating the effectiveness of MPGM method. Also,\nMPGM can generate sparse solutions. These are generally consistent with the results on the synthetic data experiments and further demonstrate the benefits of MPGM algorithm."
    }, {
      "heading" : "6.3 Real-world Image Data",
      "text" : "In this section, we tested our method on some real-world image datasets. We evaluate our MPGM on the dataset [17] whose images are selected from Pascal 2007 3. In this dataset, there are 30 pairs of car images and 20 pairs of motorbike images. For each image pair, feature points and groundtruth matches were manually marked and each pair contains 30-60 ground-truth correspondences. The affinity between two nodes is computed as Wij,ij = exp( −|pi−p′j | 0.05 ), where pi is the orientation of normal vector at the sampled point (node) i to the contour, similarly to p′j . Also, the affinity\n3http://www.pascalnetwork.org/challenges/VOC/voc2007/workshop/index.html\nbetween two correspondences has been computed as Wij,kl = exp( −|dik−d′jl|\n0.15 ), where dik denotes the Euclidean distance between feature point i and k, similarly to d′jl. Some matching examples are shown in Figure 4. To test the performance against outlier noise, we have randomly added 0- 20 outlier features for each image pair. The overall results of matching accuracy across different outlier features are summarized in Figure 5. From Figure 5, we can note that MPGM outperforms the other competing methods including RRWM [3] and FGM [24], which further demonstrates the effectiveness and practicality of MPGM on conducting real-world image matching tasks."
    }, {
      "heading" : "7 Conclusions and Future work",
      "text" : "This paper presents an effective algorithm, Multiplicative Update Graph Matching (MPGM), that develops a multiplicative update technique to solve the QP matching problem with doubly stochastic mapping constraint. The KKT optimality and convergence properties of MPGM algorithms are theoretically guaranteed. We show experimentally that MPGM solution is sparse and thus approximately incorporates the discrete constraint in optimization naturally. In our future, the theoretical analysis on the sparsity of MPGM needs to be further studied. Also, we will incorporate our MPGM in some path-following strategy to find a more optimal solution for the matching problem. We will adapt the proposed algorithm to solve some other optimization problems with doubly stochastic constraint in machine learning and computer vision area."
    }, {
      "heading" : "Acknowledgment",
      "text" : "This work is supported by the NBRPC 973 Program (2015CB351705); National Natural Science Foundation of China (61602001,61671018, 61572030); Natural Science Foundation of Anhui Province (1708085QF139); Natural Science Foundation of Anhui Higher Education Institutions of China (KJ2016A020); Co-Innovation Center for Information Supply & Assurance Technology, Anhui University; The Open Projects Program of National Laboratory of Pattern Recognition."
    } ],
    "references" : [ {
      "title" : "Discrete tabu search for graph matching",
      "author" : [ "K. Adamczewski", "Y. Suh", "K.M. Lee" ],
      "venue" : "In ICCV,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2015
    }, {
      "title" : "Learning graph matching",
      "author" : [ "T.S. Caetano", "J.J. McAuley", "L. Cheng", "Q.V. Le", "A.J. Smola" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2009
    }, {
      "title" : "Reweighted random walks for graph matching",
      "author" : [ "M. Cho", "J. Lee", "K.M. Lee" ],
      "venue" : "In European Conference on Computer Vision,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2010
    }, {
      "title" : "Thirty years of graph matching in pattern recognition",
      "author" : [ "D. Conte", "P. Foggia", "C. Sansone", "M. Vento" ],
      "venue" : "International Journal of Pattern Recognition and Artificial Intelligence,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2004
    }, {
      "title" : "Balanced graph matching",
      "author" : [ "M. Cour", "P. Srinivasan", "J.Shi" ],
      "venue" : "In Neural Information Processing Systems,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2006
    }, {
      "title" : "Nonnegative matrix factorization for combinatorial optimization: Spectral clustering, graph matching and clique finding",
      "author" : [ "C. Ding", "T. Li", "M.I. Jordan" ],
      "venue" : "In IEEE International Conference on Data Mining,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2008
    }, {
      "title" : "Convex and semi-nonnegative matrix factorization",
      "author" : [ "C. Ding", "T. Li", "M.I. Jordan" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2010
    }, {
      "title" : "Optimal correspondences from pairwise constraints",
      "author" : [ "O. Enqvist", "K. Josephon", "F. Kahl" ],
      "venue" : "In IEEE International Conference on Computer Vision,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2009
    }, {
      "title" : "An algorithm for quadratic programming",
      "author" : [ "M. Frank", "P. Wolfe" ],
      "venue" : "Naval Research Logistics Quarterly,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1956
    }, {
      "title" : "A graduated assignment algorithm for graph matching",
      "author" : [ "S. Gold", "A. Rangarajan" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1996
    }, {
      "title" : "A local sparse model for matching problem",
      "author" : [ "B. Jiang", "J. Tang", "C. Ding", "B. Luo" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2015
    }, {
      "title" : "Nonnegative orthogonal graph matching",
      "author" : [ "B. Jiang", "J. Tang", "C. Ding", "B. Luo" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2017
    }, {
      "title" : "A sparse nonnegative matrix factorization technique for graph matching problem",
      "author" : [ "B. Jiang", "H.F. Zhao", "J. Tang", "B. Luo" ],
      "venue" : "Pattern Recognition,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2014
    }, {
      "title" : "Algorithms for nonnegative matrix factorization",
      "author" : [ "D.D. Lee", "H.S. Seung" ],
      "venue" : "In Neural Information Processing Systems,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2001
    }, {
      "title" : "A spectral technique for correspondence problem using pairwise constraints",
      "author" : [ "M. Leordeanu", "M. Hebert" ],
      "venue" : "In IEEE International Conference on Computer Vision,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2005
    }, {
      "title" : "An integer projected fixed point method for graph macthing and map inference",
      "author" : [ "M. Leordeanu", "M. Hebert", "R. Sukthankar" ],
      "venue" : "In Neural Information Processing Systems,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2009
    }, {
      "title" : "Unsupervised learning for graph mathing",
      "author" : [ "M. Leordeanu", "R. Sukthankar", "M. Hebert" ],
      "venue" : "International Journal of Computer Vision,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2011
    }, {
      "title" : "Spectal embedding of graphs",
      "author" : [ "B. Luo", "R.C. Wilson", "E.R. Hancock" ],
      "venue" : "Pattern Recognition,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2003
    }, {
      "title" : "Fast matching of large point sets under occlusions",
      "author" : [ "J.J. MuAuley", "T.S. Caetano" ],
      "venue" : "Pattern Recognition,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2012
    }, {
      "title" : "A pocs-based graph matching algorithm",
      "author" : [ "B.J. van Wyk", "M.A. van Wyk" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2004
    }, {
      "title" : "A path following algorithm for the graph matching problem",
      "author" : [ "M. Zaslavskiy", "F. Bach", "J.P. Vert" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2009
    }, {
      "title" : "Doubly stochastic normalization for spectral clustering",
      "author" : [ "R. Zass", "A. Shashua" ],
      "venue" : "In Proceedings of the conference on Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2006
    }, {
      "title" : "Pairwise matching through max-weight bipartite belief propagation",
      "author" : [ "Z. Zhang", "Q. Shi", "J. McAuley", "W. Wei", "Y. Zhang", "A.V.D. Hengel" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2016
    }, {
      "title" : "Factorized graph matching",
      "author" : [ "F. Zhou", "F.D. la Torre" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2012
    }, {
      "title" : "Deformable graph matching",
      "author" : [ "F. Zhou", "F.D. la Torre" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : "Since it is known to be NP-hard, many approximate algorithms have been developed to find approximate solutions for this problem [8, 16, 21, 24, 20, 13].",
      "startOffset" : 128,
      "endOffset" : 151
    }, {
      "referenceID" : 15,
      "context" : "Since it is known to be NP-hard, many approximate algorithms have been developed to find approximate solutions for this problem [8, 16, 21, 24, 20, 13].",
      "startOffset" : 128,
      "endOffset" : 151
    }, {
      "referenceID" : 20,
      "context" : "Since it is known to be NP-hard, many approximate algorithms have been developed to find approximate solutions for this problem [8, 16, 21, 24, 20, 13].",
      "startOffset" : 128,
      "endOffset" : 151
    }, {
      "referenceID" : 23,
      "context" : "Since it is known to be NP-hard, many approximate algorithms have been developed to find approximate solutions for this problem [8, 16, 21, 24, 20, 13].",
      "startOffset" : 128,
      "endOffset" : 151
    }, {
      "referenceID" : 19,
      "context" : "Since it is known to be NP-hard, many approximate algorithms have been developed to find approximate solutions for this problem [8, 16, 21, 24, 20, 13].",
      "startOffset" : 128,
      "endOffset" : 151
    }, {
      "referenceID" : 12,
      "context" : "Since it is known to be NP-hard, many approximate algorithms have been developed to find approximate solutions for this problem [8, 16, 21, 24, 20, 13].",
      "startOffset" : 128,
      "endOffset" : 151
    }, {
      "referenceID" : 2,
      "context" : "After that, they obtain the final discrete solution by using a discretization step such as Hungarian or greedy algorithm [3, 15, 16].",
      "startOffset" : 121,
      "endOffset" : 132
    }, {
      "referenceID" : 14,
      "context" : "After that, they obtain the final discrete solution by using a discretization step such as Hungarian or greedy algorithm [3, 15, 16].",
      "startOffset" : 121,
      "endOffset" : 132
    }, {
      "referenceID" : 15,
      "context" : "After that, they obtain the final discrete solution by using a discretization step such as Hungarian or greedy algorithm [3, 15, 16].",
      "startOffset" : 121,
      "endOffset" : 132
    }, {
      "referenceID" : 15,
      "context" : "Another kind of methods aim to obtain a discrete solution for QP matching problem [16, 1, 24].",
      "startOffset" : 82,
      "endOffset" : 93
    }, {
      "referenceID" : 0,
      "context" : "Another kind of methods aim to obtain a discrete solution for QP matching problem [16, 1, 24].",
      "startOffset" : 82,
      "endOffset" : 93
    }, {
      "referenceID" : 23,
      "context" : "Another kind of methods aim to obtain a discrete solution for QP matching problem [16, 1, 24].",
      "startOffset" : 82,
      "endOffset" : 93
    }, {
      "referenceID" : 15,
      "context" : "[16] proposed an iterative matching method (IPFP) which optimized the QP matching problem in a discrete domain.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 23,
      "context" : "[24, 25] proposed an effective graph matching method (FGM) which optimized the QP matching problem approximately using a convexconcave relaxation technique [21] and thus returns a discrete solution for the problem.",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 24,
      "context" : "[24, 25] proposed an effective graph matching method (FGM) which optimized the QP matching problem approximately using a convexconcave relaxation technique [21] and thus returns a discrete solution for the problem.",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 20,
      "context" : "[24, 25] proposed an effective graph matching method (FGM) which optimized the QP matching problem approximately using a convexconcave relaxation technique [21] and thus returns a discrete solution for the problem.",
      "startOffset" : 156,
      "endOffset" : 160
    }, {
      "referenceID" : 15,
      "context" : "From optimization aspect, the core optimization algorithm used in both IPFP [16] and FGM [24] is related to Frank-Wolfe [9] algorithm and FGM [24, 25] further uses a path following procedure to alleviate the local-optimum problem more carefully.",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 23,
      "context" : "From optimization aspect, the core optimization algorithm used in both IPFP [16] and FGM [24] is related to Frank-Wolfe [9] algorithm and FGM [24, 25] further uses a path following procedure to alleviate the local-optimum problem more carefully.",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 8,
      "context" : "From optimization aspect, the core optimization algorithm used in both IPFP [16] and FGM [24] is related to Frank-Wolfe [9] algorithm and FGM [24, 25] further uses a path following procedure to alleviate the local-optimum problem more carefully.",
      "startOffset" : 120,
      "endOffset" : 123
    }, {
      "referenceID" : 23,
      "context" : "From optimization aspect, the core optimization algorithm used in both IPFP [16] and FGM [24] is related to Frank-Wolfe [9] algorithm and FGM [24, 25] further uses a path following procedure to alleviate the local-optimum problem more carefully.",
      "startOffset" : 142,
      "endOffset" : 150
    }, {
      "referenceID" : 24,
      "context" : "From optimization aspect, the core optimization algorithm used in both IPFP [16] and FGM [24] is related to Frank-Wolfe [9] algorithm and FGM [24, 25] further uses a path following procedure to alleviate the local-optimum problem more carefully.",
      "startOffset" : 142,
      "endOffset" : 150
    }, {
      "referenceID" : 8,
      "context" : "The core of Frank-Wolfe [9] algorithm is to optimize the quadratic problem by sequentially optimizing the linear approximations of QP problem.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 2,
      "context" : "to optimization-based methods, probabilistic methods can also be used for solving graph matching problems [3, 19, 23].",
      "startOffset" : 106,
      "endOffset" : 117
    }, {
      "referenceID" : 18,
      "context" : "to optimization-based methods, probabilistic methods can also be used for solving graph matching problems [3, 19, 23].",
      "startOffset" : 106,
      "endOffset" : 117
    }, {
      "referenceID" : 22,
      "context" : "to optimization-based methods, probabilistic methods can also be used for solving graph matching problems [3, 19, 23].",
      "startOffset" : 106,
      "endOffset" : 117
    }, {
      "referenceID" : 15,
      "context" : "The graph matching problem is generally formulated as a Quadratic Programming (QP) problem with doubly stochastic and discrete constraints [16, 3, 10], i.",
      "startOffset" : 139,
      "endOffset" : 150
    }, {
      "referenceID" : 2,
      "context" : "The graph matching problem is generally formulated as a Quadratic Programming (QP) problem with doubly stochastic and discrete constraints [16, 3, 10], i.",
      "startOffset" : 139,
      "endOffset" : 150
    }, {
      "referenceID" : 9,
      "context" : "The graph matching problem is generally formulated as a Quadratic Programming (QP) problem with doubly stochastic and discrete constraints [16, 3, 10], i.",
      "startOffset" : 139,
      "endOffset" : 150
    }, {
      "referenceID" : 20,
      "context" : "(3) That is solving the following relaxed matching problem [21, 20, 10], x∗ = argmax x (xWx) s.",
      "startOffset" : 59,
      "endOffset" : 71
    }, {
      "referenceID" : 19,
      "context" : "(3) That is solving the following relaxed matching problem [21, 20, 10], x∗ = argmax x (xWx) s.",
      "startOffset" : 59,
      "endOffset" : 71
    }, {
      "referenceID" : 9,
      "context" : "(3) That is solving the following relaxed matching problem [21, 20, 10], x∗ = argmax x (xWx) s.",
      "startOffset" : 59,
      "endOffset" : 71
    }, {
      "referenceID" : 9,
      "context" : "One kind of popular methods is to use constraint relaxation and projection, such as GA [10] and RRWM [3].",
      "startOffset" : 87,
      "endOffset" : 91
    }, {
      "referenceID" : 2,
      "context" : "One kind of popular methods is to use constraint relaxation and projection, such as GA [10] and RRWM [3].",
      "startOffset" : 101,
      "endOffset" : 104
    }, {
      "referenceID" : 8,
      "context" : "Another kind of important methods is to use objective function approximation and thus solves the problem approximately, such as Frank-Wolfe algorithm [9].",
      "startOffset" : 150,
      "endOffset" : 153
    }, {
      "referenceID" : 15,
      "context" : "This algorithm has been widely adopted in many recent matching methods [16, 24, 21], such as IPFP [16] and FGM [24].",
      "startOffset" : 71,
      "endOffset" : 83
    }, {
      "referenceID" : 23,
      "context" : "This algorithm has been widely adopted in many recent matching methods [16, 24, 21], such as IPFP [16] and FGM [24].",
      "startOffset" : 71,
      "endOffset" : 83
    }, {
      "referenceID" : 20,
      "context" : "This algorithm has been widely adopted in many recent matching methods [16, 24, 21], such as IPFP [16] and FGM [24].",
      "startOffset" : 71,
      "endOffset" : 83
    }, {
      "referenceID" : 15,
      "context" : "This algorithm has been widely adopted in many recent matching methods [16, 24, 21], such as IPFP [16] and FGM [24].",
      "startOffset" : 98,
      "endOffset" : 102
    }, {
      "referenceID" : 23,
      "context" : "This algorithm has been widely adopted in many recent matching methods [16, 24, 21], such as IPFP [16] and FGM [24].",
      "startOffset" : 111,
      "endOffset" : 115
    }, {
      "referenceID" : 20,
      "context" : "For graphs with different sizes, one can add dummy isolated nodes into the smaller graph and transform them to equal-size case [21, 10]",
      "startOffset" : 127,
      "endOffset" : 135
    }, {
      "referenceID" : 9,
      "context" : "For graphs with different sizes, one can add dummy isolated nodes into the smaller graph and transform them to equal-size case [21, 10]",
      "startOffset" : 127,
      "endOffset" : 135
    }, {
      "referenceID" : 2,
      "context" : "Theoretically, the complexity of MPGM is the same with RRWM [3] and IPFP [16], but obviously lower than GA [10] and FGM [24].",
      "startOffset" : 60,
      "endOffset" : 63
    }, {
      "referenceID" : 15,
      "context" : "Theoretically, the complexity of MPGM is the same with RRWM [3] and IPFP [16], but obviously lower than GA [10] and FGM [24].",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 9,
      "context" : "Theoretically, the complexity of MPGM is the same with RRWM [3] and IPFP [16], but obviously lower than GA [10] and FGM [24].",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 23,
      "context" : "Theoretically, the complexity of MPGM is the same with RRWM [3] and IPFP [16], but obviously lower than GA [10] and FGM [24].",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 5,
      "context" : "Multiplicative update algorithms have been studied in solving matching problems [6, 13, 11, 12].",
      "startOffset" : 80,
      "endOffset" : 95
    }, {
      "referenceID" : 12,
      "context" : "Multiplicative update algorithms have been studied in solving matching problems [6, 13, 11, 12].",
      "startOffset" : 80,
      "endOffset" : 95
    }, {
      "referenceID" : 10,
      "context" : "Multiplicative update algorithms have been studied in solving matching problems [6, 13, 11, 12].",
      "startOffset" : 80,
      "endOffset" : 95
    }, {
      "referenceID" : 11,
      "context" : "Multiplicative update algorithms have been studied in solving matching problems [6, 13, 11, 12].",
      "startOffset" : 80,
      "endOffset" : 95
    }, {
      "referenceID" : 5,
      "context" : "Previous works [6, 13, 11] generally first develop a kind of approximation (or relaxation) for QP matching problem by ignoring the doubly stochastic constraint, and then aim to find the optimum of the relaxation problem by developing an algorithm.",
      "startOffset" : 15,
      "endOffset" : 26
    }, {
      "referenceID" : 12,
      "context" : "Previous works [6, 13, 11] generally first develop a kind of approximation (or relaxation) for QP matching problem by ignoring the doubly stochastic constraint, and then aim to find the optimum of the relaxation problem by developing an algorithm.",
      "startOffset" : 15,
      "endOffset" : 26
    }, {
      "referenceID" : 10,
      "context" : "Previous works [6, 13, 11] generally first develop a kind of approximation (or relaxation) for QP matching problem by ignoring the doubly stochastic constraint, and then aim to find the optimum of the relaxation problem by developing an algorithm.",
      "startOffset" : 15,
      "endOffset" : 26
    }, {
      "referenceID" : 21,
      "context" : "Here P denotes the projection [22] or normalization [20] to make x satisfy the doubly stochastic constraint.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 19,
      "context" : "Here P denotes the projection [22] or normalization [20] to make x satisfy the doubly stochastic constraint.",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 6,
      "context" : "To prove it, we use the auxiliary function approach [7, 14].",
      "startOffset" : 52,
      "endOffset" : 59
    }, {
      "referenceID" : 13,
      "context" : "To prove it, we use the auxiliary function approach [7, 14].",
      "startOffset" : 52,
      "endOffset" : 59
    }, {
      "referenceID" : 14,
      "context" : "Our method has been compared with some other state-of-the-art methods including SM [15], IPFP [16], SMAC [5], RRWM [3] and FGM [24].",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 15,
      "context" : "Our method has been compared with some other state-of-the-art methods including SM [15], IPFP [16], SMAC [5], RRWM [3] and FGM [24].",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 4,
      "context" : "Our method has been compared with some other state-of-the-art methods including SM [15], IPFP [16], SMAC [5], RRWM [3] and FGM [24].",
      "startOffset" : 105,
      "endOffset" : 108
    }, {
      "referenceID" : 2,
      "context" : "Our method has been compared with some other state-of-the-art methods including SM [15], IPFP [16], SMAC [5], RRWM [3] and FGM [24].",
      "startOffset" : 115,
      "endOffset" : 118
    }, {
      "referenceID" : 23,
      "context" : "Our method has been compared with some other state-of-the-art methods including SM [15], IPFP [16], SMAC [5], RRWM [3] and FGM [24].",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 15,
      "context" : "We implemented IPFP [16] with two versions: (1) IPFP-U that is initialized by the uniform solution; (2) IPFP-S that is initialized by SM method [15].",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 14,
      "context" : "We implemented IPFP [16] with two versions: (1) IPFP-U that is initialized by the uniform solution; (2) IPFP-S that is initialized by SM method [15].",
      "startOffset" : 144,
      "endOffset" : 148
    }, {
      "referenceID" : 2,
      "context" : "1 Synthetic Data Similar to the works [3, 24], we have randomly generated data sets of nin 2D points as inlier nodes for G.",
      "startOffset" : 38,
      "endOffset" : 45
    }, {
      "referenceID" : 23,
      "context" : "1 Synthetic Data Similar to the works [3, 24], we have randomly generated data sets of nin 2D points as inlier nodes for G.",
      "startOffset" : 38,
      "endOffset" : 45
    }, {
      "referenceID" : 15,
      "context" : "We can note that: (1) similar to IPFP [16] and FGM [24] which return discrete matching solutions, MPGM always generates sparse solutions on doubly stochastic domain.",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 23,
      "context" : "We can note that: (1) similar to IPFP [16] and FGM [24] which return discrete matching solutions, MPGM always generates sparse solutions on doubly stochastic domain.",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 15,
      "context" : "(2) MPGM returns higher objective score and accuracy than IPFP [16] and FGM [24] methods, which demonstrate that MPGM can find the sparse solution more optimal than these methods.",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 23,
      "context" : "(2) MPGM returns higher objective score and accuracy than IPFP [16] and FGM [24] methods, which demonstrate that MPGM can find the sparse solution more optimal than these methods.",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 14,
      "context" : "(3) MPGM generally performs better than the continuous domain methods including SM [15], SMAC [5] and RRWM [3].",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 4,
      "context" : "(3) MPGM generally performs better than the continuous domain methods including SM [15], SMAC [5] and RRWM [3].",
      "startOffset" : 94,
      "endOffset" : 97
    }, {
      "referenceID" : 2,
      "context" : "(3) MPGM generally performs better than the continuous domain methods including SM [15], SMAC [5] and RRWM [3].",
      "startOffset" : 107,
      "endOffset" : 110
    }, {
      "referenceID" : 2,
      "context" : "(4) MPGM generally has similar time cost with RRWM [3].",
      "startOffset" : 51,
      "endOffset" : 54
    }, {
      "referenceID" : 23,
      "context" : "We have not shown the time cost of FGM [24] method in Fig.",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 2,
      "context" : "2 Image Sequence Data In this section, we perform feature matching on CMU and YORK house sequences [3, 2, 18].",
      "startOffset" : 99,
      "endOffset" : 109
    }, {
      "referenceID" : 1,
      "context" : "2 Image Sequence Data In this section, we perform feature matching on CMU and YORK house sequences [3, 2, 18].",
      "startOffset" : 99,
      "endOffset" : 109
    }, {
      "referenceID" : 17,
      "context" : "2 Image Sequence Data In this section, we perform feature matching on CMU and YORK house sequences [3, 2, 18].",
      "startOffset" : 99,
      "endOffset" : 109
    }, {
      "referenceID" : 16,
      "context" : "We evaluate our MPGM on the dataset [17] whose images are selected from Pascal 2007 3.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 2,
      "context" : "From Figure 5, we can note that MPGM outperforms the other competing methods including RRWM [3] and FGM [24], which further demonstrates the effectiveness and practicality of MPGM on conducting real-world image matching tasks.",
      "startOffset" : 92,
      "endOffset" : 95
    }, {
      "referenceID" : 23,
      "context" : "From Figure 5, we can note that MPGM outperforms the other competing methods including RRWM [3] and FGM [24], which further demonstrates the effectiveness and practicality of MPGM on conducting real-world image matching tasks.",
      "startOffset" : 104,
      "endOffset" : 108
    } ],
    "year" : 2017,
    "abstractText" : "As a fundamental problem in computer vision, graph matching problem can usually be formulated as a Quadratic Programming (QP) problem with doubly stochastic and discrete (integer) constraints. Since it is NP-hard, approximate algorithms are required. In this paper, we present a new algorithm, called Multiplicative Update Graph Matching (MPGM), that develops a multiplicative update technique to solve the QP matching problem. MPGM has three main benefits: (1) theoretically, MPGM solves the general QP problem with doubly stochastic constraint naturally whose convergence and KKT optimality are guaranteed. (2) Empirically, MPGM generally returns a sparse solution and thus can also incorporate the discrete constraint approximately. (3) It is efficient and simple to implement. Experimental results show the benefits of MPGM algorithm.",
    "creator" : null
  }
}