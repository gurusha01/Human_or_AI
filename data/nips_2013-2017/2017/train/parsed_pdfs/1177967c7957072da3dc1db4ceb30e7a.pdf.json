{
  "name" : "1177967c7957072da3dc1db4ceb30e7a.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Safe Adaptive Importance Sampling",
    "authors" : [ "Sebastian U. Stich", "Anant Raj", "Martin Jaggi" ],
    "emails" : [ "sebastian.stich@epfl.ch", "anant.raj@tuebingen.mpg.de", "martin.jaggi@epfl.ch" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Modern machine learning applications operate on massive datasets. The algorithms that are used for data analysis face the difficult challenge to cope with the enormous amount of data or the vast dimensionality of the problems. A simple and well established strategy to reduce the computational costs is to split the data and to operate only on a small part of it, as for instance in coordinate descent (CD) methods and stochastic gradient (SGD) methods. These kind of methods are state of the art for a wide selection of machine learning, deep leaning and signal processing applications [9, 11, 35, 27]. The application of these schemes is not only motivated by their practical preformance, but also well justified by theory [18, 19, 2].\nDeterministic strategies are seldom used for the data selection—examples are steepest coordinate descent [4, 34, 20] or screening algorithms [14, 15]. Instead, randomized selection has become ubiquitous, most prominently uniform sampling [27, 29, 7, 8, 28] but also non-uniform sampling based on a fixed distribution, commonly referred to as importance sampling [18, 19, 2, 33, 16, 6, 25, 24]. While these sampling strategies typically depend on the input data, they do not adapt to the information of the current parameters during optimization. In contrast, adaptive importance sampling strategies constantly re-evaluate the relative importance of each data point during training and thereby often surpass the performance of static algorithms [22, 5, 26, 10, 21, 23]. Common strategies are gradientbased sampling [22, 36, 37] (mostly for SGD) and duality gap-based sampling for CD [5, 23].\nThe drawbacks of adaptive strategies are twofold: often the provable theoretical guarantees can be worse than the complexity estimates for uniform sampling [23, 3] and often it is computationally\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\ninadmissible to compute the optimal adaptive sampling distribution. For instance gradient based sampling requires the computation of the full gradient in each iteration [22, 36, 37]. Therefore one has to rely on approximations based on upper bounds [36, 37], or stale values [22, 1]. But in general these approximations can again be worse than uniform sampling.\nThis makes it necessary to develop adaptive strategies that can efficiently be computed in every iteration and that come with theoretical guarantees that show their advantage over fixed sampling.\nOur contributions. In this paper we propose an efficient approximation of the gradient-based sampling in the sense that (i) it can efficiently be computed in every iteration, (ii) is provably better than uniform or fixed importance sampling and (iii) recovers the gradient-based sampling in the fullinformation setting. The scheme is completely generic and can easily be added as an improvement to both CD and SGD type methods.\nAs our key contributions, we\n(1) show that gradient-based sampling in CD methods is theoretically better than the classical fixed sampling, the speed-up can reach a factor of the dimension n (Section 2);\n(2) propose a generic and efficient adaptive importance sampling strategy that can be applied in CD and SGD methods and enjoys favorable properties—such as mentioned above (Section 3);\n(3) demonstrate how the novel scheme can efficiently be integrated in CD and SGD on an important class of structured optimization problems (Section 4);\n(4) supply numerical evidence that the novel sampling performs well on real data (Section 5).\nNotation. For x ∈ Rn define [x]i := 〈x, ei〉 with ei the standard unit vectors in Rn. We abbreviate ∇if := [∇f ]i. A convex function f : Rn → R with L-Lipschitz continuous gradient satisfies\nf(x + ηu) ≤ f(x) + η 〈u,∇f(x)〉+ η 2Lu 2 ‖u‖ 2 ∀x ∈ Rn,∀η ∈ R , (1)\nfor every direction u ∈ Rn and Lu = L. A function with coordinate-wise Li-Lipschitz continuous gradients1 for constants Li > 0, i ∈ [n] := {1, . . . , n}, satisfies (1) just along coordinate directions, i.e. u = ei, Lei = Li for every i ∈ [n]. A function is coordinate-wise L-smooth if Li ≤ L for i = 1, . . . , n. For convenience we introduce vector l = (L1, . . . , n)> and matrix L = diag(l). A probability vector p ∈ ∆n := {x ∈ Rn≥0 : ‖x‖1 = 1} defines a probability distribution P over [n] and we denote by i ∼ p a sample drawn from P ."
    }, {
      "heading" : "2 Adaptive Importance Sampling with Full Information",
      "text" : "In this section we argue that adaptive sampling strategies are theoretically well justified, as they can lead to significant improvements over static strategies. In our exhibition we focus first on CD methods, as we also propose a novel stepsize strategy for CD in this contribution. Then we revisit the results regarding stochastic gradient descent (SGD) already present in the literature."
    }, {
      "heading" : "2.1 Coordinate Descent with Adaptive Importance Sampling",
      "text" : "We address general minimization problems minx f(x). Let the objective f : Rn → R be convex with coordinate-wise Li-Lipschitz continuous gradients. Coordinate descent methods generate sequences {xk}k≥0 of iterates that satisfy the relation\nxk+1 = xk − γk∇ikf(xk)eik . (2)\nHere, the direction ik is either chosen deterministically (cyclic descent, steepest descent), or randomly picked according to a probability vector pk ∈ ∆n. In the classical literature, the stepsize is often chosen such as to minimize the quadratic upper bound (1), i.e. γk = L−1ik . In this work we propose to set γk = αk[pk]−1ik where αk does not depend on the chosen direction ik. This leads to\n1|∇if(x+ ηei)−∇if(x)| ≤ Li |η| , ∀x ∈ Rn, ∀η ∈ R.\ndirectionally-unbiased updates, like it is common among SGD-type methods. It holds\nEik∼pk [f(xk+1) | xk] (1) ≤ Eik∼pk [ f(xk)−\nαk [pk]ik (∇ikf(xk)) 2 + Likα\n2 k\n2[pk]2ik (∇ikf(xk))\n2 | xk ]\n= f(xk)− αk ‖∇f(xk)‖22 + n∑ i=1 Liα 2 k 2[pk]i (∇if(xk))2 . (3)\nIn adaptive strategies we have the freedom to chose both variables αk and pk as we like. We therefore propose to chose them in such a way that they minimize the upper bound (3) in order to maximize the expected progress. The optimal pk in (3) is independent of αk, but the optimal αk depends on pk. We can state the following useful observation. Lemma 2.1. If αk = αk(pk) is the minimizer of (3), then xk+1 := xk− αk[pk]ik∇ikf(xk)eik satisfies\nEik∼pk [f(xk+1) | xk] ≤ f(xk)− αk(pk) 2 ‖∇f(xk)‖22 . (4)\nConsider two examples. In the first one we pick a sub-optimal, but very common [18] distribution: Example 2.2 (Li-based sampling). Let pL ∈ ∆n defined as [pL]i = LiTr[L] for i ∈ [n], where L = diag(L1, . . . , Ln). Then αk(pL) = 1Tr[L] .\nThe distribution pL is often referred to as (fixed) importance sampling. In the special case when Li = L for all i ∈ [n], this boils down to uniform sampling. Example 2.3 (Optimal sampling2). Equation (3) is minimized for probabilities [p?k]i = √ Li|∇if(xk)| ‖√L∇f(xk)‖\n1\nand αk(p?k) = ‖∇f(xk)‖22 ‖√L∇f(xk)‖2\n1\n. Observe 1Tr[L] ≤ αk(p ? k) ≤ 1Lmin , where Lmin := mini∈[n] Li.\nTo prove this result, we rely on the following Lemma—the proof of which, as well as for the claims above, is deferred to Section A.1 of the appendix. Here |·| is applied entry-wise.\nLemma 2.4. Define V (p,x) := ∑n i=1 Li[x] 2 i [p]i . Then arg minp∈∆n V (p,x) = | √ Lx|\n‖√Lx‖ 1 .\nThe ideal adaptive algorithm. We propose to chose the stepsize and the sampling distribution for CD as in Example 2.3. One iteration of the resulting CD method is illustrated in Algorithm 1. Our bounds on the expected one-step progress can be used to derive convergence rates of this algorithm with the standard techniques. This is exemplified in Appendix A.1. In the next Section 3 we develop a practical variant of the ideal algorithm.\nEfficiency gain. By comparing the estimates provided in the examples above, we see that the expected progress of the proposed method is always at least as good as for the fixed sampling. For instance in the special case where L = Li for i ∈ [n], the Li-based sampling is just uniform sampling with αk(punif) = 1Ln . On the other hand αk(p ? k) = ‖∇f(xk)‖22 L‖∇f(xk)‖21\n, which can be n times larger than αk(punif). The expected one-step progress in this extreme case coincides with the one-step progress of steepest coordinate descent [20]."
    }, {
      "heading" : "2.2 SGD with Adaptive Sampling",
      "text" : "SGD methods are applicable to objective functions which decompose as a sum f(x) = 1n ∑n i=1 fi(x) (5)\nwith each fi : Rd → R convex. In previous work [22, 36, 37] is has been argued that the following gradient-based sampling [p̃?k]i = ‖∇fi(xk)‖2∑n i=1‖∇fi(xk)‖2\nis optimal in the sense that it maximizes the expected progress (3). Zhao and Zhang [36] derive complexity estimates for composite functions. For non-composite functions it becomes easier to derive the complexity estimate. For completeness, we add this simpler proof in Appendix A.2.\n2Here “optimal” refers to the fact that p?k is optimal with respect to the given model (1) of the objective function. If the model is not accurate, there might exist a sampling that yields larger expected progress on f .\nAlgorithm 1 Optimal sampling (compute full gradient) Compute∇f(xk) (define optimal sampling) Define (p?k, α ? k) as in Example 2.3 ik ∼ p?k\nxk+1 := xk − α ? k\n[p?k]ik ∇ikf(xk)\nAlgorithm 2 Proposed safe sampling (update l.- and u.-bounds) Update `, u (compute safe sampling) Define (p̂k, α̂k) as in (7) ik ∼ p̂k Compute∇ikf(xk) xk+1 := xk − α̂k[p̂k]ik∇ikf(xk) Algorithm 3 Fixed sampling (define fixed sampling) Define (pL, ᾱ) as in Example 2.2 ik ∼ pL Compute∇ikf(xk) xk+1 := xk − ᾱ[pL]ik∇ikf(xk)\nFigure 1: CD with different sampling strategies. Whilst Alg. 1 requires to compute the full gradient, the compute operation in Alg. 2 is as cheap as for fixed importance sampling, Alg. 3. Defining the safe sampling p̂k requires O(n log n) time."
    }, {
      "heading" : "3 Safe Adaptive Importance Sampling with Limited Information",
      "text" : "In the previous section we have seen that gradient-based sampling (Example 2.3) can yield a massive speed-up compared to a static sampling distribution (Example 2.2). However, sampling according to p?k in CD requires the knowledge of the full gradient ∇f(xk) in each iteration. And likewise, sampling from p̃?k in SGD requires the knowledge of the gradient norms of all components—both these operations are in general inadmissible, i.e. the compute cost would void all computational benefits of the iterative (stochastic) methods over full gradient methods.\nHowever, it is often possible to efficiently compute approximations of p?k or p̃ ? k instead. In contrast to previous contributions, we here propose a safe way to compute such approximations. By this we mean that our approximate sampling is provably never worse than static sampling, and moreover, we show that our solution is the best possible with respect to the limited information at hand."
    }, {
      "heading" : "3.1 An Optimization Formulation for Sampling",
      "text" : "Formally, we assume that we have in each iteration access to two vectors `k,uk ∈ Rn≥0 that provide safe upper and lower bounds on either the absolute values of the gradient entries ([`k]i ≤ |∇if(xk)| ≤ [uk]i) for CD, or of the gradient norms in SGD: ([`k]i ≤ ‖∇fi(xk)‖2 ≤ [uk]i). We postpone the discussion of this assumption to Section 4, where we give concrete examples.\nThe minimization of the upper bound (3) amounts to the equivalent problem3\nmin αk min pk∈∆n\n[ −αk ‖ck‖22 + α2k 2 V (pk, ck) ] ⇔ min pk∈∆n V (pk, ck)\n‖ck‖22 (6)\nwhere ck ∈ Rn represents the unknown true gradient. That is, with respect to the bounds `k,uk, we can write ck ∈ Ck := {x ∈ Rn : [`k]i ≤ [x]i ≤ [uk]i, i ∈ [n]}. In Example 2.3 we derived the optimal solution for a fixed ck ∈ Ck. However, this is not sufficient to find the optimal solution for an arbitrary ck ∈ Ck. Just computing the optimal solution for an arbitrary (but fixed) ck ∈ Ck is unlikely to yield a good solution. For instance both extreme cases ck = `k and ck = uk (the latter choice is quite common, cf. [36, 23]) might be poor. This is demonstrated in the next example. Example 3.1. Let ` = (1, 2)>, u = (2, 3)>, c = (2, 2)> and L1 = L2 = 1. Then V ( ` ‖`‖1 , c )\n= 9 4 ‖c‖ 2 2, V ( u ‖u‖1 , c ) = 2512 ‖c‖ 2 2, whereas for uniform sampling V ( c ‖c‖1 , c ) = 2 ‖c‖22.\nThe proposed sampling. As a consequence of these observations, we propose to solve the following optimization problem to find the best sampling distribution with respect to Ck:\nvk := min p∈∆n max c∈Ck\nV (p, c)\n‖c‖22 , and to set (αk,pk) :=\n( 1 vk , p̂k ) , (7)\nwhere p̂k denotes a solution of (7). The resulting algorithm for CD is summarized in Alg. 2.\nIn the remainder of this section we discuss the properties of the solution p̂k (Theorem 3.2) and how such a solution can be efficiently be computed (Theorem 3.4, Algorithm 4).\n3Although only shown here for CD, an equivalent optimization problem arises for SGD methods, cf. [36]."
    }, {
      "heading" : "3.2 Proposed Sampling and its Properties",
      "text" : "Theorem 3.2. Let (p̂, ĉ) ∈ ∆n × Rn≥0 denote a solution of (7). Then Lmin ≤ vk ≤ Tr [L] and\n(i) max c∈Ck\nV (p̂, c)\n‖c‖22 ≤ max c∈Ck\nV (p, c)\n‖c‖22 , ∀p ∈ ∆n; (p̂ has the best worst-case guarantee)\n(ii) V (p̂, c) ≤ Tr [L] · ‖c‖22, ∀c ∈ Ck. (p̂ is always better than Li-based sampling) Remark 3.3. In the special case Li = L for all i ∈ [n], the Li-based sampling boils down to uniform sampling (Example 2.2) and p̂ is better than uniform sampling: V (p̂, c) ≤ Ln ‖c‖22, ∀c ∈ Ck.\nProof. Property (i) is an immediate consequence of (7). Moreover, observe that the Li-based sampling pL is a feasible solution in (7) with value V (pL,c)\n‖c‖22 ≡ Tr [L] for all c ∈ Ck. Hence\nLmin ≤ ‖ √ Lc‖21 ‖c‖22 2.4 = min p∈∆n V (p, c) ‖c‖22 ≤ V (p̂, c) ‖c‖22 (∗) ≤ V (p̂, ĉ) ‖ĉ‖22 (7) ≤ max c∈Ck V (pL, c) ‖c‖22 = Tr [L] , (8)\nfor all c ∈ Ck, thus vk ∈ [Lmin,Tr [L]] and (ii) follows. We prove inequality (∗) in the appendix, by showing that min and max can be interchanged in (7).\nA geometric interpretation. We show in Appendix B that the optimization problem (7) can equivalently be written as √ vk = maxc∈Ck ‖ √ Lc‖1 ‖c‖2 = maxc∈Ck 〈 √ l,c〉 ‖c‖2\n, where [l]i = Li for i ∈ [n]. The maximum is thus attained for vectors c ∈ Ck that minimize the angle with the vector l. Theorem 3.4. Let c ∈ Ck, p = √ Lc\n‖ √ Lc‖1\nand denote m = ‖c‖22 · ‖ √ Lc‖−11 . If\n[c]i =  [uk]i if [uk]i ≤ √ Lim, [`k]i if [`k]i ≥ √ Lim,√\nLim otherwise, ∀i ∈ [n] , (9)\nthen (p, c) is a solution to (7). Moreover, such a solution can be computed in time O(n log n).\nProof. This can be proven by examining the optimality conditions of problem (7). This is deferred to Section B.1 of the appendix. A procedure that computes such a solution is depicted in Algorithm 4. The algorithm makes extensive use of (9). For simplicity, assume first L = In for now. In each iteration t , a potential solution vector ct is proposed, and it is verified whether this vector satisfies all optimality conditions. In Algorithm 4, ct is just implicit, with [ct]i = [c]i for decided indices i ∈ D and [ct]i = [ √ Lm]i for undecided indices i /∈ D. After at most n iterations a valid solution is found.\nBy sorting the components of √ L−1`k and √ L−1uk by their magnitude, at most a linear number of inequality checks in (9) have to be performed in total. Hence the running time is dominated by the O(n log n) complexity of the sorting algorithm. A formal proof is given in the appendix.\nAlgorithm 4 Computing the Safe Sampling for Gradient Information `,u 1: Input: 0n ≤ ` ≤ u, L, Initialize: c = 0n, u = 1, ` = n, D = ∅. 2: `sort := sort_asc( √ L−1`), usort := sort_asc( √ L−1u), m = max(`sort)\n3: while u ≤ ` do 4: if [`sort]` > m then (largest undecided lower bound is violated) 5: Set corresponding [c]index := [ √ L`sort]`; ` := `− 1; D := D ∪ {index} 6: else if [usort]u < m then (smallest undecided upper bound is violated) 7: Set corresponding [c]index := [ √ Lusort]u; u := u+ 1; D := D ∪ {index} 8: else 9: break (no constraints are violated)\n10: end if 11: m := ‖c‖22 · ‖ √ Lc‖−11 (update m as in (9)) 12: end while 13: Set [c]i := √ Lim for all i /∈ D and Return ( c,p = √ Lc\n‖ √ Lc‖1 , v = ‖ √ Lc‖21 ‖c‖22\n)\nCompetitive Ratio. We now compare the proposed sampling distribution p̂k with the optimal sampling solution in hindsight. We know that if the true (gradient) vector c̃ ∈ Ck would be given to us, then the corresponding optimal probability distribution would be p?(c̃) = √ Lc̃\n‖ √ Lc̃‖1 (Example 2.3).\nThus, for this c̃ we can now analyze the ratio V (p̂k,c̃)V (p?(c̃),c̃) . As we are interested in the worst case ratio among all possible candidates c̃ ∈ Ck, we define\nρk := max c∈Ck\nV (p̂, c)\nV (p?(c), c) = max c∈Ck\nV (p̂, c) ‖ √ Lc‖21 . (10)\nLemma 3.5. Let wk := minc∈Ck ‖ √ Lc‖21 ‖c‖22 . Then Lmin ≤ wk ≤ vk, and ρk ≤ vkwk (≤ vk Lmin ). Lemma 3.6. Let γ ≥ 1. If [Ck]i ∩ γ[Ck]i = ∅ and γ−1[Ck]i ∩ [Ck]i = ∅ for all i ∈ [n] (here [Ck]i denotes the projection on the i-th coordinate), then ρk ≤ γ4.\nThese two lemma provide bounds on the competitive ratio. Whilst Lemma 3.6 relies on a relative accuracy condition, Lemma 3.5 can always be applied. However, the corresponding minimization problem is non-convex. Note that knowledge of ρk is not needed to run the algorithm."
    }, {
      "heading" : "4 Example Safe Gradient Bounds",
      "text" : "In this section, we argue that for a large class of objective functions of interest in machine learning, suitable safe upper and lower bounds `,u on the gradient along every coordinate direction can be estimated and maintained efficiently during optimization. A similar argument can be given for the efficient approximation of component wise gradient norms in finite sum objective based stochastic gradient optimization.\nAs the guiding example, we will here showcase the training of generalized linear models (GLMs) as e.g. in regression, classification and feature selection. These models are formulated in terms of a given data matrix A ∈ Rd×n with columns ai ∈ Rd for i ∈ [n].\nCoordinate Descent - GLMs with Arbitrary Regularizers. Consider general objectives of the form f(x) := h(Ax) + ∑n i=1 ψi([x]i) with an arbitrary convex separable regularizer term given by the ψi : R → R for i ∈ [n]. A key example is when h : Rd → R describes the least-squares regression objective h(Ax) = 12 ‖Ax− b‖ 2 2 for a b ∈ Rd. Using that this h is twice differentiable with ∇2h(Ax) = In, it is easy to see that we can track the evolution of all gradient entries, when performing CD steps, as follows:\n∇if(xk+1)−∇if(xk) = γk〈ai,aik〉 , ∀i 6= ik . (11)\nfor ik being the coordinate changed in step k (here we also used the separability of the regularizer).\nTherefore, all gradient changes can be tracked exactly if the inner products of all datapoints are available, or approximately if those inner products can be upper and lower bounded. For computational efficiency, we in our experiments simply use Cauchy-Schwarz |〈ai,aik〉| ≤ ‖ai‖ · ‖aik‖. This results in safe upper and lower bounds [`k+1]i ≤ ∇if(xk+1) ≤ [uk+1]i for all inactive coordinates i 6= ik. (For the active coordinate ik itself one observes the true value without uncertainty). These bounds can be updated in linear time O(n) in every iteration.\nFor general smooth h (again with arbitrary separable regularizers ψi), (11) can readily be extended to hold [32, Lemma 4.1], the inner product change term becoming 〈ai,∇2f(Ax̃)aik〉 instead, when assuming h is twice-differentiable. Here x̃ will be an element of the line segment [xk,xk+1].\nStochastic Gradient Descent - GLMs. We now present a similar result for finite sum problems (5) for the use in SGD based optimization, that is f(x) := 1n ∑n i=1 fi(x) = 1 n ∑n i=1 hi(a > i x).\nLemma 4.1. Consider f : Rd → R as above, with twice differentiable hi : R→ R. Let xk,xk+1 ∈ Rd denote two successive iterates of SGD, i.e. xk+1 := xk − ηk aik∇hik(a>ikxk) = xk + γk aik . Then there exists x̃ ∈ Rd on the line segment between xk and xk+1, x̃ ∈ [xk,xk+1] with\n∇fi(xk+1)−∇fi(xk) = γk ∇2hi(a>i x̃) 〈ai,aik〉 ai , ∀ i 6= ik . (12)\nThis leads to safe upper and lower bounds for the norms of the partial gradient, [`k]i ≤ ‖∇fi(xk)‖2 ≤ [uk]i, that can be updated in linear time O(n), analogous to the coordinate case discussed above.4\nWe note that there are many other ways to track safe gradient bounds for relevant machine learning problems, including possibly more tight ones. We here only illustrate the simplest variants, highlighting the fact that our new sampling procedure works for any safe bounds `,u.\nComputational Complexity. In this section, we have demonstrated how safe upper and lower bounds `,u on the gradient information can be obtained for GLMs, and argued that these bounds can be updated in time O(n) per iteration of CD and SGD. The computation of the proposed sampling takes O(n log n) time (Theorem 3.4). Hence, the introduced overhead in Algorithm 2 compared to fixed sampling (Algorithm 3) is of the order O(n log n) in every iteration. The computation of one coordinate of the gradient, ∇ikf(xk), takes time Θ(d) for general data matrices. Hence, when d = Ω(n), the introduced overhead reduces to O(log n) per iteration."
    }, {
      "heading" : "5 Empirical Evaluation",
      "text" : "In this section we evaluate the empirical performance of our proposed adaptive sampling scheme on relevant machine learning tasks. In particular, we illustrate performance on generalized linear models with L1 and L2 regularization, as of the form (5),\nmin x∈Rd\n1\nn n∑ i=1 hi(a > i x) + λ · r(x) (13)\nWe use square loss, squared hinge loss as well as logistic loss for the data fitting terms hi, and ‖x‖1 and ‖x‖22 for the regularizer r(x). The datasets used in the evaluation are rcv1, real-sim and news20.5 The rcv1 dataset consists of 20,242 samples with 47,236 features, real-sim contains 72,309 datapoints and 20,958 features and news20 contains 19,996 datapoints and 1,355,191 features. For all datasets we set unnormalized features with all the non-zero entries set to 1 (bag-of-words features). By real-sim’ and rcv1’ we denote a subset of the data chosen by randomly selecting 10,000 features and 10,000 datapoints. By news20’ we denote a subset of the data chose by randomly selecting 15% of the features and 15% of the datapoints. A regularization parameter λ = 0.1 is used for all experiments.\nOur results show the evolution of the optimization objective over time or number of epochs (an epoch corresponding to n individual updates). To compute safe lower and upper bounds we use the methods presented in Section 4 with no special initialization, i.e. `0 = 0n, u0 = ∞n.\nCoordinate Descent. In Figure 2 we compare the effect of the fixed stepsize αk = 1Ln (denoted as “small”) vs. the time varying optimal stepsize (denoted as “big”) as discussed in Section 2. Results are shown for optimal sampling p?k (with optimal stepsize αk(p ? k), cf. Example 2.3), our proposed sampling p̂k (with optimal stepsize αk(p̂k) = v−1k , cf. (7)) and uniform sampling (with optimal stepsize αk(pL) = 1Ln , as here L = LIn, cf. Example 2.2). As the experiment aligns with theory—confirming the advantage of the varying “big” stepsizes—we only show the results for Algorithms 1–3 in the remaining plots.\nPerformance for squared hinge loss, as well as logistic regression with L1 and L2 regularization is presented in Figure 3 and Figure 4 respectively. In Figures 5 and 6 we report the iteration complexity vs. accuracy as well as timing vs. accuracy results on the full dataset for coordinate descent with square loss and L1 (Lasso) and L2 regularization (Ridge).\nTheoretical Sampling Quality. As part of the CD performance results in Figures 2–6 we include an additional evolution plot on the bottom of each figure to illustrate the values vk which determine the stepsize (α̂k = v−1k ) for the proposed Algorithm 2 (blue) and the optimal stepsizes of Algorithm 1 (black) which rely on the full gradient information. The plots show the normalized values vkTr[L] , i.e. the relative improvement over Li-based importance sampling. The results show that despite only relying on very loose safe gradient bounds, the proposed adaptive sampling is able to strongly benefit from the additional information.\n4Here we use the efficient representation∇fi(x) = θ(x) · ai for θ(x) ∈ R. 5All data are available at www.csie.ntu.edu.tw/˜cjlin/libsvmtools/datasets/\nStochastic Gradient Descent. Finally, we also evaluate the performance of our approach when used within SGD with L1 and L2 regularization and square loss. In Figures 7–8 we report the iteration complexity vs. accuracy results and in Figure 9 the timing vs. accuracy results. The time units in Figures 6 and 9 are not directly comparable, as the experiments were conducted on different machines.\nWe observe that on all three datasets SGD with the optimal sampling performs only slightly better than uniform sampling. This is in contrast with the observations for CD, where the optimal sampling yields a significant improvement. Consequently, the effect of the proposed sampling is less pronounced in the three SGD experiments.\nSummary. The main findings of our experimental study can be summarized as follows:\n• Adaptive importance sampling significantly outperforms fixed importance sampling in iterations and time. The results show that (i) convergence in terms of iterations is almost as good as for the optimal (but not efficiently computable) gradient-based sampling and (ii) the introduced computational overhead is small enough to outperform fixed importance sampling in terms of total computation time.\n• Adaptive sampling requires adaptive stepsizes. The adaptive stepsize strategies of Algorithms 1 and 2 allow for much faster convergence than conservative fixed-stepsize strategies. In the experiments, the measured value vk was always significantly below the worst case estimate, in alignment with the observed convergence.\n• Very loose safe gradient bounds are sufficient. Even the bounds derived from the the very naïve gradient information obtained by estimating scalar products resulted in significantly better sampling than using no gradient information at all. Further, no initialization of the gradient estimates is needed (at the beginning of the optimization process the proposed adaptive method performs close to the fixed sampling but accelerates after just one epoch)."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper we propose a safe adaptive importance sampling scheme for CD and SGD algorithms. We argue that optimal gradient-based sampling is theoretically well justified. To make the computation of the adaptive sampling distribution computationally tractable, we rely on safe lower and upper bounds on the gradient. However, in contrast to previous approaches, we use these bounds in a novel way: in each iteration, we formulate the problem of picking the optimal sampling distribution as a convex optimization problem and present an efficient algorithm to compute the solution. The novel sampling provably performs better than any fixed importance sampling—a guarantee which could not be established for previous samplings that were also derived from safe lower and upper bounds.\nThe computational cost of the proposed scheme is of the order O(n log n) per iteration—this is on many problems comparable with the cost to evaluate a single component (coordinate, sum-structure) of the gradient, and the scheme can thus be implemented at no extra computational cost. This is verified by timing experiments on real datasets.\nWe discussed one simple method to track the gradient information in GLMs during optimization. However, we feel that the machine learning community could profit from further research in that direction, for instance by investigating how such safe bounds can efficiently be maintained on more complex models. Our approach can immediately be applied when the tracking of the gradient is delegated to other machines in a distributed setting, like for instance in [1]."
    } ],
    "references" : [ {
      "title" : "Variance Reduction in SGD by Distributed Importance Sampling",
      "author" : [ "Guillaume Alain", "Alex Lamb", "Chinnadhurai Sankar", "Aaron Courville", "Yoshua Bengio" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2015
    }, {
      "title" : "Even Faster Accelerated Coordinate Descent Using Non-Uniform Sampling",
      "author" : [ "Zeyuan Allen-Zhu", "Zheng Qu", "Peter Richtárik", "Yang Yuan" ],
      "venue" : "In ICML 2017 - Proceedings of the 34th International Conference on Machine Learning,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2016
    }, {
      "title" : "Stochastic Primal Dual Coordinate Method with Non-Uniform Sampling Based on Optimality Violations",
      "author" : [ ],
      "venue" : "arXiv.org, October 2017",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2017
    }, {
      "title" : "Convex optimization",
      "author" : [ "Stephen P Boyd", "Lieven Vandenberghe" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2004
    }, {
      "title" : "Stochastic Dual Coordinate Ascent with Adaptive Probabilities",
      "author" : [ "Dominik Csiba", "Zheng Qu", "Peter Richtárik" ],
      "venue" : "In ICML 2015 - Proceedings of the 32th International Conference on Machine Learning,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2015
    }, {
      "title" : "Importance Sampling for Minibatches",
      "author" : [ "Dominik Csiba", "Peter Richtárik" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2016
    }, {
      "title" : "Pathwise coordinate optimization",
      "author" : [ "Jerome Friedman", "Trevor Hastie", "Holger Höfling", "Robert Tibshirani" ],
      "venue" : "The Annals of Applied Statistics,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2007
    }, {
      "title" : "Regularization Paths for Generalized Linear Models via Coordinate Descent",
      "author" : [ "Jerome Friedman", "Trevor Hastie", "Robert Tibshirani" ],
      "venue" : "Journal of Statistical Software,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2010
    }, {
      "title" : "Penalized regressions: The bridge versus the lasso",
      "author" : [ "Wenjiang J. Fu" ],
      "venue" : "Journal of Computational and Graphical Statistics,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1998
    }, {
      "title" : "Dual Free Adaptive Mini-batch SDCA for Empirical Risk Minimization",
      "author" : [ "Xi He", "Martin Takáč" ],
      "venue" : null,
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2015
    }, {
      "title" : "A Dual Coordinate Descent Method for Large-scale Linear SVM",
      "author" : [ "Cho-Jui Hsieh", "Kai-Wei Chang", "Chih-Jen Lin", "S Sathiya Keerthi", "S Sundararajan" ],
      "venue" : "In ICML 2008 - the 25th International Conference on Machine Learning,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2008
    }, {
      "title" : "Elementary proof for sion’s minimax theorem",
      "author" : [ "Hidetoshi Komiya" ],
      "venue" : "Kodai Math. J.,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1988
    }, {
      "title" : "A simpler approach to obtaining an O(1/t) convergence rate for projected stochastic subgradient descent",
      "author" : [ "Simon Lacoste-Julien", "Mark Schmidt", "Francis Bach" ],
      "venue" : null,
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2012
    }, {
      "title" : "Safe Screening with Variational Inequalities and Its Application to Lasso",
      "author" : [ "Jun Liu", "Zheng Zhao", "Jie Wang", "Jieping Ye" ],
      "venue" : "In ICML 2014 - Proceedings of the 31st International Conference on Machine Learning,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2014
    }, {
      "title" : "Gap Safe screening rules for sparsity enforcing penalties",
      "author" : [ "Eugene Ndiaye", "Olivier Fercoq", "Alexandre Gramfort", "Joseph Salmon" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2017
    }, {
      "title" : "Stochastic Gradient Descent, Weighted Sampling, and the Randomized Kaczmarz algorithm",
      "author" : [ "Deanna Needell", "Rachel Ward", "Nathan Srebro" ],
      "venue" : "In NIPS 2014 - Advances in Neural Information Processing Systems",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2014
    }, {
      "title" : "Robust stochastic approximation approach to stochastic programming",
      "author" : [ "A. Nemirovski", "A. Juditsky", "G. Lan", "A. Shapiro" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2009
    }, {
      "title" : "Efficiency of Coordinate Descent Methods on Huge-Scale Optimization Problems",
      "author" : [ "Yurii Nesterov" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2012
    }, {
      "title" : "Efficiency of the accelerated coordinate descent method on structured optimization problems",
      "author" : [ "Yurii Nesterov", "Sebastian U. Stich" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2017
    }, {
      "title" : "Coordinate Descent Converges Faster with the Gauss-Southwell Rule Than Random Selection",
      "author" : [ "Julie Nutini", "Mark W Schmidt", "Issam H Laradji", "Michael P Friedlander", "Hoyt A Koepke" ],
      "venue" : "In ICML,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2015
    }, {
      "title" : "Minding the gaps for block frank-wolfe optimization of structured svms",
      "author" : [ "Anton Osokin", "Jean-Baptiste Alayrac", "Isabella Lukasewitz", "Puneet K. Dokania", "Simon Lacoste-Julien" ],
      "venue" : "In Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2016
    }, {
      "title" : "Adaptive Sampling for Incremental Optimization Using Stochastic Gradient Descent",
      "author" : [ "Guillaume Papa", "Pascal Bianchi", "Stéphan Clémençon" ],
      "venue" : "ALT 2015 - 26th International Conference on Algorithmic Learning Theory,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2015
    }, {
      "title" : "Faster Coordinate Descent via Adaptive Importance Sampling",
      "author" : [ "Dmytro Perekrestenko", "Volkan Cevher", "Martin Jaggi" ],
      "venue" : "AISTATS",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2017
    }, {
      "title" : "Randomized Dual Coordinate Ascent with Arbitrary Sampling",
      "author" : [ "Zheng Qu", "Peter Richtárik", "Tong Zhang" ],
      "venue" : null,
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2014
    }, {
      "title" : "On optimal probabilities in stochastic coordinate descent methods",
      "author" : [ "Peter Richtárik", "Martin Takáč" ],
      "venue" : "Optimization Letters,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2016
    }, {
      "title" : "Non-Uniform Stochastic Average Gradient Method for Training Conditional Random Fields",
      "author" : [ "Mark Schmidt", "Reza Babanezhad", "Mohamed Ahmed", "Aaron Defazio", "Ann Clifton", "Anoop Sarkar" ],
      "venue" : "In AISTATS 2015 - Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2015
    }, {
      "title" : "Pegasos: Primal Estimated Sub-Gradient Solver for SVM",
      "author" : [ "Shai Shalev-Shwartz", "Yoram Singer", "Nathan Srebro", "Andrew Cotter" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2010
    }, {
      "title" : "Stochastic Methods for l1-regularized Loss Minimization",
      "author" : [ "Shai Shalev-Shwartz", "Ambuj Tewari" ],
      "venue" : null,
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2011
    }, {
      "title" : "Stochastic Dual Coordinate Ascent Methods for Regularized Loss Minimization",
      "author" : [ "Shai Shalev-Shwartz", "Tong Zhang" ],
      "venue" : null,
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2013
    }, {
      "title" : "On general minimax theorems",
      "author" : [ "Maurice Sion" ],
      "venue" : "Pacific Journal of Mathematics,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 1958
    }, {
      "title" : "Variable metric random pursuit",
      "author" : [ "S.U. Stich", "C.L. Müller", "B. Gärtner" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2016
    }, {
      "title" : "Approximate steepest coordinate descent",
      "author" : [ "Sebastian U. Stich", "Anant Raj", "Martin Jaggi" ],
      "venue" : "ICML 2017 - Proceedings of the 34th International Conference on Machine Learning,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2017
    }, {
      "title" : "A randomized kaczmarz algorithm with exponential convergence",
      "author" : [ "Thomas Strohmer", "Roman Vershynin" ],
      "venue" : "Journal of Fourier Analysis and Applications,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2008
    }, {
      "title" : "A coordinate gradient descent method for nonsmooth separable minimization",
      "author" : [ "Paul Tseng", "Sangwoon Yun" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2009
    }, {
      "title" : "Coordinate descent algorithms",
      "author" : [ "Stephen J Wright" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2015
    }, {
      "title" : "Stochastic optimization with importance sampling for regularized loss minimization",
      "author" : [ "Peilin Zhao", "Tong Zhang" ],
      "venue" : "In ICML 2015 - Proceedings of the 32nd International Conference on Machine Learning,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2015
    }, {
      "title" : "Gradient-based sampling: An adaptive importance sampling for least-squares",
      "author" : [ "Rong Zhu" ],
      "venue" : "In NIPS - Advances in Neural Information Processing Systems",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "These kind of methods are state of the art for a wide selection of machine learning, deep leaning and signal processing applications [9, 11, 35, 27].",
      "startOffset" : 133,
      "endOffset" : 148
    }, {
      "referenceID" : 10,
      "context" : "These kind of methods are state of the art for a wide selection of machine learning, deep leaning and signal processing applications [9, 11, 35, 27].",
      "startOffset" : 133,
      "endOffset" : 148
    }, {
      "referenceID" : 34,
      "context" : "These kind of methods are state of the art for a wide selection of machine learning, deep leaning and signal processing applications [9, 11, 35, 27].",
      "startOffset" : 133,
      "endOffset" : 148
    }, {
      "referenceID" : 26,
      "context" : "These kind of methods are state of the art for a wide selection of machine learning, deep leaning and signal processing applications [9, 11, 35, 27].",
      "startOffset" : 133,
      "endOffset" : 148
    }, {
      "referenceID" : 17,
      "context" : "The application of these schemes is not only motivated by their practical preformance, but also well justified by theory [18, 19, 2].",
      "startOffset" : 121,
      "endOffset" : 132
    }, {
      "referenceID" : 18,
      "context" : "The application of these schemes is not only motivated by their practical preformance, but also well justified by theory [18, 19, 2].",
      "startOffset" : 121,
      "endOffset" : 132
    }, {
      "referenceID" : 1,
      "context" : "The application of these schemes is not only motivated by their practical preformance, but also well justified by theory [18, 19, 2].",
      "startOffset" : 121,
      "endOffset" : 132
    }, {
      "referenceID" : 3,
      "context" : "Deterministic strategies are seldom used for the data selection—examples are steepest coordinate descent [4, 34, 20] or screening algorithms [14, 15].",
      "startOffset" : 105,
      "endOffset" : 116
    }, {
      "referenceID" : 33,
      "context" : "Deterministic strategies are seldom used for the data selection—examples are steepest coordinate descent [4, 34, 20] or screening algorithms [14, 15].",
      "startOffset" : 105,
      "endOffset" : 116
    }, {
      "referenceID" : 19,
      "context" : "Deterministic strategies are seldom used for the data selection—examples are steepest coordinate descent [4, 34, 20] or screening algorithms [14, 15].",
      "startOffset" : 105,
      "endOffset" : 116
    }, {
      "referenceID" : 13,
      "context" : "Deterministic strategies are seldom used for the data selection—examples are steepest coordinate descent [4, 34, 20] or screening algorithms [14, 15].",
      "startOffset" : 141,
      "endOffset" : 149
    }, {
      "referenceID" : 14,
      "context" : "Deterministic strategies are seldom used for the data selection—examples are steepest coordinate descent [4, 34, 20] or screening algorithms [14, 15].",
      "startOffset" : 141,
      "endOffset" : 149
    }, {
      "referenceID" : 26,
      "context" : "Instead, randomized selection has become ubiquitous, most prominently uniform sampling [27, 29, 7, 8, 28] but also non-uniform sampling based on a fixed distribution, commonly referred to as importance sampling [18, 19, 2, 33, 16, 6, 25, 24].",
      "startOffset" : 87,
      "endOffset" : 105
    }, {
      "referenceID" : 28,
      "context" : "Instead, randomized selection has become ubiquitous, most prominently uniform sampling [27, 29, 7, 8, 28] but also non-uniform sampling based on a fixed distribution, commonly referred to as importance sampling [18, 19, 2, 33, 16, 6, 25, 24].",
      "startOffset" : 87,
      "endOffset" : 105
    }, {
      "referenceID" : 6,
      "context" : "Instead, randomized selection has become ubiquitous, most prominently uniform sampling [27, 29, 7, 8, 28] but also non-uniform sampling based on a fixed distribution, commonly referred to as importance sampling [18, 19, 2, 33, 16, 6, 25, 24].",
      "startOffset" : 87,
      "endOffset" : 105
    }, {
      "referenceID" : 7,
      "context" : "Instead, randomized selection has become ubiquitous, most prominently uniform sampling [27, 29, 7, 8, 28] but also non-uniform sampling based on a fixed distribution, commonly referred to as importance sampling [18, 19, 2, 33, 16, 6, 25, 24].",
      "startOffset" : 87,
      "endOffset" : 105
    }, {
      "referenceID" : 27,
      "context" : "Instead, randomized selection has become ubiquitous, most prominently uniform sampling [27, 29, 7, 8, 28] but also non-uniform sampling based on a fixed distribution, commonly referred to as importance sampling [18, 19, 2, 33, 16, 6, 25, 24].",
      "startOffset" : 87,
      "endOffset" : 105
    }, {
      "referenceID" : 17,
      "context" : "Instead, randomized selection has become ubiquitous, most prominently uniform sampling [27, 29, 7, 8, 28] but also non-uniform sampling based on a fixed distribution, commonly referred to as importance sampling [18, 19, 2, 33, 16, 6, 25, 24].",
      "startOffset" : 211,
      "endOffset" : 241
    }, {
      "referenceID" : 18,
      "context" : "Instead, randomized selection has become ubiquitous, most prominently uniform sampling [27, 29, 7, 8, 28] but also non-uniform sampling based on a fixed distribution, commonly referred to as importance sampling [18, 19, 2, 33, 16, 6, 25, 24].",
      "startOffset" : 211,
      "endOffset" : 241
    }, {
      "referenceID" : 1,
      "context" : "Instead, randomized selection has become ubiquitous, most prominently uniform sampling [27, 29, 7, 8, 28] but also non-uniform sampling based on a fixed distribution, commonly referred to as importance sampling [18, 19, 2, 33, 16, 6, 25, 24].",
      "startOffset" : 211,
      "endOffset" : 241
    }, {
      "referenceID" : 32,
      "context" : "Instead, randomized selection has become ubiquitous, most prominently uniform sampling [27, 29, 7, 8, 28] but also non-uniform sampling based on a fixed distribution, commonly referred to as importance sampling [18, 19, 2, 33, 16, 6, 25, 24].",
      "startOffset" : 211,
      "endOffset" : 241
    }, {
      "referenceID" : 15,
      "context" : "Instead, randomized selection has become ubiquitous, most prominently uniform sampling [27, 29, 7, 8, 28] but also non-uniform sampling based on a fixed distribution, commonly referred to as importance sampling [18, 19, 2, 33, 16, 6, 25, 24].",
      "startOffset" : 211,
      "endOffset" : 241
    }, {
      "referenceID" : 5,
      "context" : "Instead, randomized selection has become ubiquitous, most prominently uniform sampling [27, 29, 7, 8, 28] but also non-uniform sampling based on a fixed distribution, commonly referred to as importance sampling [18, 19, 2, 33, 16, 6, 25, 24].",
      "startOffset" : 211,
      "endOffset" : 241
    }, {
      "referenceID" : 24,
      "context" : "Instead, randomized selection has become ubiquitous, most prominently uniform sampling [27, 29, 7, 8, 28] but also non-uniform sampling based on a fixed distribution, commonly referred to as importance sampling [18, 19, 2, 33, 16, 6, 25, 24].",
      "startOffset" : 211,
      "endOffset" : 241
    }, {
      "referenceID" : 23,
      "context" : "Instead, randomized selection has become ubiquitous, most prominently uniform sampling [27, 29, 7, 8, 28] but also non-uniform sampling based on a fixed distribution, commonly referred to as importance sampling [18, 19, 2, 33, 16, 6, 25, 24].",
      "startOffset" : 211,
      "endOffset" : 241
    }, {
      "referenceID" : 21,
      "context" : "In contrast, adaptive importance sampling strategies constantly re-evaluate the relative importance of each data point during training and thereby often surpass the performance of static algorithms [22, 5, 26, 10, 21, 23].",
      "startOffset" : 198,
      "endOffset" : 221
    }, {
      "referenceID" : 4,
      "context" : "In contrast, adaptive importance sampling strategies constantly re-evaluate the relative importance of each data point during training and thereby often surpass the performance of static algorithms [22, 5, 26, 10, 21, 23].",
      "startOffset" : 198,
      "endOffset" : 221
    }, {
      "referenceID" : 25,
      "context" : "In contrast, adaptive importance sampling strategies constantly re-evaluate the relative importance of each data point during training and thereby often surpass the performance of static algorithms [22, 5, 26, 10, 21, 23].",
      "startOffset" : 198,
      "endOffset" : 221
    }, {
      "referenceID" : 9,
      "context" : "In contrast, adaptive importance sampling strategies constantly re-evaluate the relative importance of each data point during training and thereby often surpass the performance of static algorithms [22, 5, 26, 10, 21, 23].",
      "startOffset" : 198,
      "endOffset" : 221
    }, {
      "referenceID" : 20,
      "context" : "In contrast, adaptive importance sampling strategies constantly re-evaluate the relative importance of each data point during training and thereby often surpass the performance of static algorithms [22, 5, 26, 10, 21, 23].",
      "startOffset" : 198,
      "endOffset" : 221
    }, {
      "referenceID" : 22,
      "context" : "In contrast, adaptive importance sampling strategies constantly re-evaluate the relative importance of each data point during training and thereby often surpass the performance of static algorithms [22, 5, 26, 10, 21, 23].",
      "startOffset" : 198,
      "endOffset" : 221
    }, {
      "referenceID" : 21,
      "context" : "Common strategies are gradientbased sampling [22, 36, 37] (mostly for SGD) and duality gap-based sampling for CD [5, 23].",
      "startOffset" : 45,
      "endOffset" : 57
    }, {
      "referenceID" : 35,
      "context" : "Common strategies are gradientbased sampling [22, 36, 37] (mostly for SGD) and duality gap-based sampling for CD [5, 23].",
      "startOffset" : 45,
      "endOffset" : 57
    }, {
      "referenceID" : 36,
      "context" : "Common strategies are gradientbased sampling [22, 36, 37] (mostly for SGD) and duality gap-based sampling for CD [5, 23].",
      "startOffset" : 45,
      "endOffset" : 57
    }, {
      "referenceID" : 4,
      "context" : "Common strategies are gradientbased sampling [22, 36, 37] (mostly for SGD) and duality gap-based sampling for CD [5, 23].",
      "startOffset" : 113,
      "endOffset" : 120
    }, {
      "referenceID" : 22,
      "context" : "Common strategies are gradientbased sampling [22, 36, 37] (mostly for SGD) and duality gap-based sampling for CD [5, 23].",
      "startOffset" : 113,
      "endOffset" : 120
    }, {
      "referenceID" : 22,
      "context" : "The drawbacks of adaptive strategies are twofold: often the provable theoretical guarantees can be worse than the complexity estimates for uniform sampling [23, 3] and often it is computationally",
      "startOffset" : 156,
      "endOffset" : 163
    }, {
      "referenceID" : 2,
      "context" : "The drawbacks of adaptive strategies are twofold: often the provable theoretical guarantees can be worse than the complexity estimates for uniform sampling [23, 3] and often it is computationally",
      "startOffset" : 156,
      "endOffset" : 163
    }, {
      "referenceID" : 21,
      "context" : "For instance gradient based sampling requires the computation of the full gradient in each iteration [22, 36, 37].",
      "startOffset" : 101,
      "endOffset" : 113
    }, {
      "referenceID" : 35,
      "context" : "For instance gradient based sampling requires the computation of the full gradient in each iteration [22, 36, 37].",
      "startOffset" : 101,
      "endOffset" : 113
    }, {
      "referenceID" : 36,
      "context" : "For instance gradient based sampling requires the computation of the full gradient in each iteration [22, 36, 37].",
      "startOffset" : 101,
      "endOffset" : 113
    }, {
      "referenceID" : 35,
      "context" : "Therefore one has to rely on approximations based on upper bounds [36, 37], or stale values [22, 1].",
      "startOffset" : 66,
      "endOffset" : 74
    }, {
      "referenceID" : 36,
      "context" : "Therefore one has to rely on approximations based on upper bounds [36, 37], or stale values [22, 1].",
      "startOffset" : 66,
      "endOffset" : 74
    }, {
      "referenceID" : 21,
      "context" : "Therefore one has to rely on approximations based on upper bounds [36, 37], or stale values [22, 1].",
      "startOffset" : 92,
      "endOffset" : 99
    }, {
      "referenceID" : 0,
      "context" : "Therefore one has to rely on approximations based on upper bounds [36, 37], or stale values [22, 1].",
      "startOffset" : 92,
      "endOffset" : 99
    }, {
      "referenceID" : 17,
      "context" : "In the first one we pick a sub-optimal, but very common [18] distribution: Example 2.",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 19,
      "context" : "The expected one-step progress in this extreme case coincides with the one-step progress of steepest coordinate descent [20].",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 21,
      "context" : "In previous work [22, 36, 37] is has been argued that the following gradient-based sampling [p̃k]i = ‖∇fi(xk)‖2 ∑n i=1‖∇fi(xk)‖2 is optimal in the sense that it maximizes the expected progress (3).",
      "startOffset" : 17,
      "endOffset" : 29
    }, {
      "referenceID" : 35,
      "context" : "In previous work [22, 36, 37] is has been argued that the following gradient-based sampling [p̃k]i = ‖∇fi(xk)‖2 ∑n i=1‖∇fi(xk)‖2 is optimal in the sense that it maximizes the expected progress (3).",
      "startOffset" : 17,
      "endOffset" : 29
    }, {
      "referenceID" : 36,
      "context" : "In previous work [22, 36, 37] is has been argued that the following gradient-based sampling [p̃k]i = ‖∇fi(xk)‖2 ∑n i=1‖∇fi(xk)‖2 is optimal in the sense that it maximizes the expected progress (3).",
      "startOffset" : 17,
      "endOffset" : 29
    }, {
      "referenceID" : 35,
      "context" : "Zhao and Zhang [36] derive complexity estimates for composite functions.",
      "startOffset" : 15,
      "endOffset" : 19
    } ],
    "year" : 2017,
    "abstractText" : "Importance sampling has become an indispensable strategy to speed up optimization algorithms for large-scale applications. Improved adaptive variants—using importance values defined by the complete gradient information which changes during optimization—enjoy favorable theoretical properties, but are typically computationally infeasible. In this paper we propose an efficient approximation of gradient-based sampling, which is based on safe bounds on the gradient. The proposed sampling distribution is (i) provably the best sampling with respect to the given bounds, (ii) always better than uniform sampling and fixed importance sampling and (iii) can efficiently be computed—in many applications at negligible extra cost. The proposed sampling scheme is generic and can easily be integrated into existing algorithms. In particular, we show that coordinate-descent (CD) and stochastic gradient descent (SGD) can enjoy significant a speed-up under the novel scheme. The proven efficiency of the proposed sampling is verified by extensive numerical testing.",
    "creator" : null
  }
}