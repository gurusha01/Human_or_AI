{
  "name" : "84b20b1f5a0d103f5710bb67a043cd78.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Accelerated Stochastic Greedy Coordinate Descent by Soft Thresholding Projection onto Simplex",
    "authors" : [ "Chaobing Song", "Shaobo Cui", "Yong Jiang", "Shu-Tao Xia" ],
    "emails" : [ "songcb16@mails.tsinghua.edu.cn", "cuishaobo16@mails.tsinghua.edu.cn", "xiast}@sz.tsinghua.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "√ 1/ ); meanwhile, it reduces the iteration\ncomplexity of greedy selection up to a factor of sample size. Both theoretically and empirically, we show that ASGCD has better performance for high-dimensional and dense problems with sparse solutions."
    }, {
      "heading" : "1 Introduction",
      "text" : "In large-scale convex optimization, first-order methods are widely used due to their cheap iteration cost. In order to improve the convergence rate and reduce the iteration cost further, two important strategies are used in first-order methods: Nesterov’s acceleration and stochastic optimization. Nesterov’s acceleration is referred to the technique that uses some algebra trick to accelerate firstorder algorithms; while stochastic optimization is referred to the method that samples one training example or one dual coordinate at random from the training data in each iteration. Assume the objective function F (x) is convex and smooth. Let F ∗ = minx∈Rd F (x) be the optimal value. In order to find an approximate solution x that satisfies F (x) − F ∗ ≤ , the vanilla gradient descent method needs O(1/ ) iterations. While after applying the Nesterov’s acceleration scheme [16], the resulted accelerated full gradient method (AFG) [16] only needs O( √ 1/ ) iterations, which is optimal for first-order algorithms [16]. Meanwhile, assume F (x) is also a finite sum of n sample convex functions. By sampling one training example, the resulted stochastic gradient descent (SGD) and its variants [13, 23, 1] can reduce the iteration complexity by a factor of the sample size. As an alternative of SGD, randomized coordinate descent (RCD) can also reduce the iteration complexity by a factor of the sample size [15] and obtain the optimal convergence rate O( √ 1/ ) by Nesterov’s acceleration [14, 12]. The development of gradient descent and RCD raises an interesting problem: can the Nesterov’s acceleration and stochastic optimization strategies be used to improve other existing first-order algorithms?\n∗This work is supported by the National Natural Science Foundation of China under grant Nos. 61771273, 61371078.\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\nIn this paper, we answer this question partly by studying coordinate descent with Gauss-Southwell selection, i.e., greedy coordinate descent (GCD). GCD is widely used for solving sparse optimization problems in machine learning [22, 9, 17]. If an optimization problem has a sparse solution, it is more suitable than its counterpart RCD. However, the theoretical convergence rate is still O(1/ ). Meanwhile if the iteration complexity is comparable, GCD will be preferable than RCD [17]. However in the general case, in order to do exact Gauss-Southwell selection, computing the full gradient beforehand is necessary, which causes GCD has much higher iteration complexity than RCD. To be concrete, in this paper we consider the well-known nonsmooth `1-regularized problem:\nmin x∈Rd\n{ F (x) def = f(x) + λ‖x‖1 def = 1\nn n∑ j=1 fj(x) + λ‖x‖1 } , (1)\nwhere λ ≥ 0 is a regularization parameter, f(x) = 1n ∑n j=1 fj(x) is a smooth convex function that is a finite average of n smooth convex function fj(x). Given samples {(a1, b1), (a2, b2), . . . , (an, bn)} with aj ∈ Rd (j ∈ [n] def = {1, 2, . . . , n}), if each fj(x) = fj(aTj x, bj), then (1) is an `1-regularized empirical risk minimization (`1-ERM) problem. For example, if bj ∈ R and fj(x) = 12 (bj − a T j x)\n2, (1) is Lasso; if bj ∈ {−1, 1} and fj(x) = log(1 + exp(−bjaTj x)), `1-regularized logistic regression is obtained.\nIn the above nonsmooth case, the Gauss-Southwell rule has 3 different variants [17, 22]: GS-s, GS-r and GS-q. The GCD algorithm with all the 3 rules can be viewed as the following procedure: in each iteration based on a quadratic approximation of f(x) in (1), one minimizes a surrogate objective function under the constraint that the direction vector used for update has at most 1 nonzero entry. The resulted problems under the 3 rules are easy to solve but are nonconvex due to the cardinality constraint of direction vector. While when using Nesterov’s acceleration scheme, convexity is needed for the derivation of the optimal convergence rate O( √ 1/ ) [16]. Therefore, it is impossible to accelerate GCD by the Nesterov’s acceleration scheme under the 3 existing rules.\nIn this paper, we propose a novel variant of Gauss-Southwell rule by using an `1-norm square approximation of f(x) rather than quadratic approximation. The new rule involves an `1-regularized `1-norm square approximation problem, which is nontrivial to solve but is convex. To exactly solve the challenging problem, we propose an efficient SOft ThreshOlding PrOjection (SOTOPO) algorithm. The SOTOPO algorithm has O(d+ |Q| log |Q|) cost, where it is often the case |Q| d. The complexity result O(d+ |Q| log |Q|) is better than O(d log d) of its counterpart SOPOPO [18], which is an Euclidean projection method. Then based on the new rule and SOTOPO, we accelerate GCD to attain the optimal convergence rate O( √ 1/ ) by combing a delicately selected mirror descent step. Meanwhile, we show that it is not necessary to compute full gradient beforehand: sampling one training example and computing a noisy gradient rather than full gradient is enough to perform greedy selection. This stochastic optimization technique reduces the iteration complexity of greedy selection by a factor of the sample size. The final result is an accelerated stochastic greedy coordinate descent (ASGCD) algorithm.\nAssume x∗ is an optimal solution of (1). Assume that each fj(x)(for all j ∈ [n]) is Lp-smooth w.r.t. ‖ · ‖p (p = 1, 2), i.e., for all x, y ∈ Rd,\n‖∇fj(x)−∇fj(y)‖q ≤ Lp‖x− y‖p, (2)\nwhere if p = 1, then q =∞; if p = 2, then q = 2. In order to find an x that satisfies F (x)− F (x∗) ≤ , ASGCD needs O (√ CL1‖x∗‖1√ ) iterations (see\n(16)), where C is a function of d that varies slowly over d and is upper bounded by log2(d). For high-dimensional and dense problems with sparse solutions, ASGCD has better performance than the state of the art. Experiments demonstrate the theoretical result.\nNotations: Let [d] denote the set {1, 2, . . . , d}. Let R+ denote the set of nonnegative real number. For x ∈ Rd, let ‖x‖p = ( ∑d i=1 |xi|p) 1 p (1 ≤ p < ∞) denote the `p-norm and ‖x‖∞ = maxi∈[d] |xi| denote the `∞-norm of x. For a vector x, let dim(x) denote the dimension of x; let xi denote the i-th element of x. For a gradient vector∇f(x), let ∇if(x) denote the i-th element of ∇f(x). For a set S, let |S| denote the cardinality of S. Denote the simplex4d = {θ ∈ Rd+ : ∑d i=1 θi = 1}."
    }, {
      "heading" : "2 The SOTOPO algorithm",
      "text" : "The proposed SOTOPO algorithm aims to solve the proposed new rule, i.e., minimize the following `1-regularized `1-norm square approximation problem,\nh̃ def = argmin\ng∈Rd\n{ 〈∇f(x), g〉+ 1\n2η ‖g‖21 + λ‖x+ g‖1\n} , (3)\nx̃ def = x+ h̃, (4)\nwhere x denotes the current iteration, η a step size, g the variable to optimize, h̃ the director vector for update and x̃ the next iteration. The number of nonzero entries of h̃ denotes how many coordinates will be updated in this iteration. Unlike the quadratic approximation used in GS-s, GS-r and GS-q rules, in the new rule the coordinate(s) to update is implicitly selected by the sparsity-inducing property of the `1-norm square ‖g‖21 rather than using the cardinality constraint ‖g‖0 ≤ 1 (i.e., g has at most 1 nonzero element) [17, 22]. By [6, §9.4.2], when the nonsmooth term λ‖x+ g‖1 in (1) does not exist, the minimizer of the `1-norm square approximation (i.e., `1-norm steepest descent) is equivalent to GCD. When λ‖x+ g‖1 exists, generally, there may be one or more coordinates to update in this new rule. Because of the sparsity-inducing property of ‖g‖21 and ‖x+ g‖1, both the direction vector h̃ and the iterative solution x̃ are sparse. In addition, (3) is an unconstrained problem and thus is feasible."
    }, {
      "heading" : "2.1 A variational reformulation and its properties",
      "text" : "(3) involves the nonseparable, nonsmooth term ‖g‖21 and the nonsmooth term ‖x + g‖1. Because there are two nonsmooth terms, it seems difficult to solve (3) directly. While by the variational identity ‖g‖21 = infθ∈4d ∑d i=1 g2i θi\nin [4] 2, in Lemma 1, it is shown that we can transform the original nonseparable and nonsmooth problem into a separable and smooth optimization problem on a simplex.\nLemma 1. By defining\nJ(g, θ) def = 〈∇f(x), g〉+ 1\n2η d∑ i=1 g2i θi + λ‖x+ g‖1, (5)\ng̃(θ) def = argming∈Rd J(g, θ), J(θ) def = J(g̃(θ), θ), (6)\nθ̃ def = arg infθ∈4d J(θ), (7)\nwhere g̃(θ) is a vector function. Then the minimization problem to find h̃ in (3) is equivalent to the problem (7) to find θ̃ with the relation h̃ = g̃(θ̃). Meanwhile, g̃(θ) and J(θ) in (6) are both coordinate separable with the expressions\n∀i ∈ [d], g̃i(θ) = g̃i(θi) def = sign(xi − θiη∇if(x)) ·max{0, |xi − θiη∇if(x)| − θiηλ} − xi, (8)\nJ(θ) = d∑ i=1 Ji(θi), where Ji(θi) def = ∇if(x) · g̃i(θi) + 1 2η d∑ i=1 g̃2i (θi) θi + λ|xi + g̃i(θi)|. (9)\nIn Lemma 1, (8) is obtained by the iterative soft thresholding operator [5]. By Lemma 1, we can reformulate (3) into the problem (5), which is about two parameters g and θ. Then by the joint convexity, we swap the optimization order of g and θ. Fixing θ and optimizing with respect to (w.r.t.) g, we can get a closed form of g̃(θ), which is a vector function about θ. Substituting g̃(θ) into J(g, θ), we get the problem (7) about θ. Finally, the optimal solution h̃ in (3) can be obtained by h̃ = g̃(θ̃).\nThe explicit expression of each Ji(θi) can be given by substituting (8) into (9). Because θ ∈ 4d, we have for all i ∈ [d], 0 ≤ θi ≤ 1. In the following Lemma 2, it is observed that the derivate J ′i(θi) can be a constant or have a piecewise structure, which is the key to deduce the SOTOPO algorithm.\n2The infima can be replaced by minimization if the convention “0/0 = 0” is used.\nLemma 2. Assume that for all i ∈ [d], J ′i(0) and J ′i(1) have been computed. Denote ri1 def = |xi|√ −2ηJ′i(0) and ri2 def = |xi|√ −2ηJ′i(1) , then J ′i(θi) belongs to one of the 4 cases,\n(case a) : J ′i(θi) = 0, 0 ≤ θi ≤ 1, (case b) : J ′i(θi) = J ′i(0) < 0, 0 ≤ θi ≤ 1,\n(case c) : J ′i(θi) = { J ′i(0), 0 ≤ θi ≤ ri1 − x 2 i\n2ηθ2i , ri1 < θi ≤ 1\n, (case d) : J ′i(θi) =  J ′i(0), 0 ≤ θi ≤ ri1 − x 2 i 2ηθ2i , ri1 < θi < ri2\nJ ′i(1), ri2 ≤ θi ≤ 1 .\nAlthough the formulation of J ′i(θi) is complicated, by summarizing the property of the 4 cases in Lemma 2, we have Corollary 1. Corollary 1. For all i ∈ [d] and 0 ≤ θi ≤ 1, if the derivate J ′i(θi) is not always 0, then J ′i(θi) is a non-decreasing, continuous function with value always less than 0.\nCorollary 1 shows that except the trivial (case a), for all i ∈ [d], whichever J ′i(θi) belong to (case b), (case c) or case (d), they all share the same group of properties, which makes a consistent iterative procedure possible for all the cases. The different formulations in the four cases mainly have impact about the stopping criteria of SOTOPO."
    }, {
      "heading" : "2.2 The property of the optimal solution",
      "text" : "The Lagrangian of the problem (7) is\nL(θ, γ, ζ) def= J(θ) + γ ( d∑ i=1 θi − 1 ) − 〈ζ, θ〉, (10)\nwhere γ ∈ R is a Lagrange multiplier and ζ ∈ Rd+ is a vector of non-negative Lagrange multipliers. Due to the coordinate separable property of J(θ) in (9), it follows that ∂J(θ)∂θi = J ′ i(θi). Then the KKT condition of (10) can be written as\n∀i ∈ [d], J ′i(θi) + γ − ζi = 0, ζiθi = 0, and d∑ i=1 θi = 1. (11)\nBy reformulating the KKT condition (11), we have Lemma 3.\nLemma 3. If (γ̃, θ̃, ζ̃) is a stationary point of (10), then θ̃ is an optimal solution of (7). Meanwhile, denote S def = {i : θ̃i > 0} and T\ndef = {j : θ̃j = 0}, then the KKT condition can be formulated as ∑ i∈S θ̃i = 1;\nfor all j ∈ T, θ̃j = 0; for all i ∈ S, γ̃ = −J ′i(θ̃i) ≥ maxj∈T −J ′j(0).\n(12)\nBy Lemma 3, if the set S in Lemma 3 is known beforehand, then we can compute θ̃ by simply applying the equations in (12). Therefore finding the optimal solution θ̃ is equivalent to finding the set of the nonzero elements of θ̃."
    }, {
      "heading" : "2.3 The soft thresholding projection algorithm",
      "text" : "In Lemma 3, for each i ∈ [d] with θ̃i > 0, it is shown that the negative derivate −J ′i(θ̃i) is equal to a single variable γ̃. Therefore, a much simpler problem can be obtained if we know the coordinates of these positive elements. At first glance, it seems difficult to identify these coordinates, because the number of potential subsets of coordinates is clearly exponential on the dimension d. However, the property clarified by Lemma 2 enables an efficient procedure for identifying the nonzero elements of θ̃. Lemma 4 is a key tool in deriving the procedure for identifying the non-zero elements of θ̃.\nLemma 4 (Nonzero element identification). Let θ̃ be an optimal solution of (7). Let s and t be two coordinates such that J ′s(0) < J ′ t(0). If θ̃s = 0, then θ̃t must be 0 as well; equivalently, if θ̃t > 0, then θ̃s must be greater than 0 as well.\nLemma 4 shows that if we sort u def= −∇J(0) such that ui1 ≥ ui2 ≥ · · · ≥ uid , where {i1, i2, . . . , id} is a permutation of [d], then the set S in Lemma 3 is of the form {i1, i2, . . . , i%}, where 1 ≤ % ≤ d. If % is obtained, then we can use the fact that for all j ∈ [%],\n−J ′ij (θ̃ij ) = γ̃ and %∑ j=1 θ̃ij = 1 (13)\nto compute γ̃. Therefore, by Lemma 4, we can efficiently identify the nonzero elements of the optimal solution θ̃ after a sort operation, which costs O(d log d). However based on Lemmas 2 and 3, the sort cost O(d log d) can be further reduced by the following Lemma 5.\nLemma 5 (Efficient identification). Assume θ̃ and S are given in Lemma 3. Then for all i ∈ S, −J ′i(0) ≥ max\nj∈[d] {−J ′j(1)}. (14)\nBy Lemma 5, before ordering u, we can filter out all the coordinates i’s that satisfy −J ′i(0) < maxj∈[d]−J ′j(1). Based on Lemmas 4 and 5, we propose the SOft ThreshOlding PrOjection (SOTOPO) algorithm in Alg. 1 to efficiently obtain an optimal solution θ̃. In the step 1, by Lemma 5, we find the quantity vm, im and Q. In the step 2, by Lemma 4, we sort the elements {−J ′i(0)| i ∈ Q}. In the step 3, because S in Lemma 3 is of the form {i1, i2, . . . , i%}, we search the quantity ρ from 1 to |Q|+ 1 until a stopping criteria is met. In Alg. 1, the number of nonzero elements of θ̃ is ρ or ρ − 1. In the step 4, we compute the γ̃ in Lemma 3 according to the conditions. In the step 5, the optimal θ̃ and the corresponding h̃, x̃ are given.\nAlgorithm 1 x̃ =SOTOPO(∇f(x), x, λ, η) 1. Find\n(vm, im) def = (maxi∈[d]{−J ′i(1)}, argmaxi∈[d]{−J ′i(1)}), Q def = {i ∈ [d]| − J ′i(0) > vm}.\n2. Sort {−J ′i(0)| i ∈ Q} such that −J ′i1(0) ≥ −J ′ i2 (0) ≥ · · · ≥ −J ′i|Q|(0), where\n{i1, i2, . . . , i|Q|} is a permutation of the elements in Q. Denote\nv def = (−J ′i1(0),−J ′ i2(0), . . . ,−J ′ i|Q| (0), vm), and i|Q|+1 def = im, v|Q|+1 def = vm.\n3. For j ∈ [|Q|+ 1], denote Rj = {ik|k ∈ [j]}. Search from 1 to |Q|+ 1 to find the quantity\nρ def = min { j ∈ [|Q|+ 1]| J ′ij (0) = J ′ ij (1) or ∑ l∈Rj |xl| ≥ √ 2ηvj or j = |Q|+ 1 } .\n4. The γ̃ in Lemma 3 is given by\nγ̃ =\n{(∑ l∈Rρ−1 |xl| )2 /(2η), if ∑ l∈Rρ−1 |xl| ≥ √ 2ηvρ;\nvρ, otherwise.\n5. Then the θ̃ in Lemma 3 and its corresponding h̃, x̃ in (3) and (4) are obtained by\n(θ̃l, h̃l, x̃l) =  ( |xl|√ 2ηγ̃ ,−xl, 0 ) , if l ∈ Rρ\\{iρ};( 1− ∑ k∈ Rρ\\{iρ} θ̃k, g̃l(θ̃l), xl + g̃l(θ̃l) ) , if l = iρ;\n(0, 0, xl), if l ∈ [d]\\Rρ.\nIn Theorem 1, we give the main result about the SOTOPO algorithm.\nTheorem 1. The SOTOPO algorihtm in Alg. 1 can get the exact minimizer h̃, x̃ of the `1-regularized `1-norm square approximation problem in (3) and (4).\nThe SOTOPO algorithm seems complicated but is indeed efficient. The dominant operations in Alg. 1 are steps 1 and 2 with the total cost O(d + |Q| log |Q|). To show the effect of the complexity reduction by Lemma 5, we give the following fact.\nProposition 1. For the optimization problem defined in (5)-(7), where λ is the regularization parameter of the original problem (1), we have that\n0 ≤ max i∈[d]\n{√ −2J ′i(0)\nη\n} −max j∈[d]  √ −2J ′j(1) η  ≤ 2λ. (15) Assume vm is defined in the step 1 of Alg. 1. By Proposition 1, for all i ∈ Q,√\n−2J ′i(0) η ≤ max k∈[d]\n{√ −2J ′k(0)\nη\n} ≤ max\nj∈[d]  √ −2J ′j(1) η + 2λ = √ 2vm η + 2λ,\nTherefore at least the coordinates j’s that satisfy √ −2J′j(0) η > √ 2vm η + 2λ will be not contained in Q. In practice, it can considerably reduce the sort complexity. Remark 1. SOTOPO can be viewed as an extension of the SOPOPO algorithm [18] by changing the objective function from Euclidean distance to a more general function J(θ) in (9). It should be noted that Lemma 5 does not have a counterpart in the case that the objective function is Euclidean distance [18]. In addition, some extension of randomized median finding algorithm [10] with linear time in our setting is also deserved to research. Due to the limited space, it is left for further discussion."
    }, {
      "heading" : "3 The ASGCD algorithm",
      "text" : "Now we can come back to our motivation, i.e., accelerating GCD to obtain the optimal convergence rate O(1/ √ ) by Nesterov’s acceleration and reducing the complexity of greedy selection by stochastic optimization. The main idea is that although like any (block) coordinate descent algorithm, the proposed new rule, i.e.,minimizing the problem in (3), performs update on one or several coordinates, it is a generalized proximal gradient descent problem based on `1-norm. Therefore this rule can be applied into the existing Nesterov’s acceleration and stochastic optimization framework “Katyusha” [1] if it can be solved efficiently. The final result is the accelerated stochastic greedy coordinate descent (ASGCD) algorithm, which is described in Alg. 2.\nAlgorithm 2 ASGCD δ = log(d)− 1− √ (log(d)− 1)2 − 1;\np = 1 + δ, q = pp−1 , C = d\n2δ 1+δ\nδ ; z0 = y0 = x̃0 = ϑ0 = 0; τ2 = 1 2 ,m = d n b e, η = 1\n(1+2 n−bb(n−1) )L1 ;\nfor s = 0, 1, 2, . . . , S − 1, do 1. τ1,s = 2s+4 , αs = η τ1,sC ;\n2. µs = ∇f(x̃s); 3. for l = 0, 1, . . . ,m− 1, do\n(a) k = (sm) + l; (b) randomly sample a mini batch B of size b from {1, 2, . . . , n} with equal probability; (c) xk+1 = τ1,szk + τ2x̃s + (1− τ1,s − τ2)yk; (d) ∇̃k+1 = µs + 1b ∑ j∈B(∇fj(xk+1)−∇fj(x̃s));\n(e) yk+1 =SOTOPO(∇̃k+1, xk+1, λ, η); (f) (zk+1, ϑk+1) = pCOMID(∇̃k+1, ϑk, q, λ, αs);\nend for 4. x̃s+1 = 1m ∑m l=1 ysm+l;\nend for Output: x̃S\nAlgorithm 3 (x̃, ϑ̃) = pCOMID(g, ϑ, q, λ, α)\n1. ∀i ∈ [d], ϑ̃i = sign(ϑi − αgi) ·max{0, |ϑi − αgi| − αλ};\n2. ∀i ∈ [d], x̃i = sign(ϑ̃i)|θ̃i| q−1\n‖ϑ̃‖q−2q ;\n3. Output: x̃, ϑ̃.\nIn Alg. 2, the gradient descent step 3(e) is solved by the proposed SOTOPO algorithm, while the mirror descent step 3(f) is solved by the COMID algorithm with p-norm divergence [11, Sec. 7.2]. We denote the mirror descent step as pCOMID in Alg. 3. All other parts are standard steps in the Katyusha framework except some parameter settings. For example, instead of the custom setting p = 1 + 1/log(d) [19, 11], a particular choice p = 1 + δ (δ is defined in Alg. 2) is used to minimize the C = d 2δ 1+δ\nδ . C varies slowly over d and is upper bounded by log 2(d). Meanwhile, αk+1 depends\non the extra constant C. Furthermore, the step size η = 1 (1+2 n−bb(n−1) )L1 is used, where L1 is defined in (2). Finally, unlike [1, Alg. 2], we let the batch size b as an algorithm parameter to cover both the stochastic case b < n and the deterministic case b = n. To the best of our knowledge, the existing GCD algorithms are deterministic, therefore by setting b = n, we can compare with the existing GCD algorithms better.\nBased on the efficient SOTOPO algorithm, ASGCD has nearly the same iteration complexity with the standard form [1, Alg. 2] of Katyusha. Meanwhile we have the following convergence rate. Theorem 2. If each fj(x)(j ∈ [n]) is convex, L1-smooth in (2) and x∗ is an optimum of the `1-regularized problem (1), then ASGCD satisfies\nE[F (x̃S)]− F (x∗) ≤ 4 (S + 3)2\n( 1 + 1 + 2β(b)\n2m C\n) L1‖x∗‖21 = O ( CL1‖x∗‖21\nS2\n) , (16)\nwhere β(b) = n−bb(n−1) , S, b, m and C are given in Alg. 2. In other words, ASGCD achieves an -additive error (i.e., E[F (x̃S)]− F (x∗) ≤ ) using at most O (√ CL1‖x∗‖1√ ) iterations.\nIn Table 1, we give the convergence rate of the existing algorithms and ASGCD to solve the `1- regularized problem (1). In the first column, “Acc” and “Non-Acc” denote the corresponding algorithms are Nesterov’s accelerated or not respectively, “Primal” and “Dual” denote the corresponding algorithms solves the primal problem (1) and its regularized dual problem [20] respectively, `2-norm and `1-norm denote the theoretical guarantee is based on `2-norm and `1-norm respectively. In terms of `2-norm based guarantee, Katyusha and APPROX give the state of the art convergence rate O (√ L2‖x∗‖2√ ) . In terms of `1-norm based guarantee, GCD gives the state of the art convergence rate\nO( L1‖x‖21\n), which is only applicable for the smooth case λ = 0 in (1). When λ > 0, the generalized GS-r, GS-s and GS-q rules generally have worse theoretical guarantee than GCD [17]. While the bound of ASGCD in this paper is O( √ L1‖x‖1 log d√ ), which can be viewed as an accelerated version\nof the `1-norm based guarantee O( L1‖x‖21 ). Meanwhile, because the bound depends on ‖x ∗‖1 rather than ‖x∗‖2 and on L1 rather than L2 (L1 and L2 are defined in (2)), for the `1-ERM problem, if the samples are high-dimensional, dense and the regularization parameter λ is relatively large, then it is possible that L1 L2 (in the extreme case, L2 = dL1 [9]) and ‖x∗‖1 ≈ ‖x∗‖2. In this case, the `1-norm based guarantee O( √ L1‖x‖1 log d√ ) of ASGCD is better than the `2-norm based guarantee\nO (√ L2‖x∗‖2√ ) of Katyusha and APPROX. Finally, whether the log d factor in the bound of ASGCD\n(which also appears in the COMID [11] analysis) is necessary deserves further research. Remark 2. When the batch size b = n, ASGCD is a deterministic algorithm. In this case, we can use a better smooth constant T1 that satisfies ‖∇f(x)−∇f(y)‖∞ ≤ T1‖x− y‖1 rather than L1 [1]. Remark 3. The necessity of computing the full gradient beforehand is the main bottleneck of GCD in applications [17]. There exists some work [9] to avoid the computation of full gradient by performing some approximate greedy selection. While the method in [9] needs preprocessing, incoherence\ncondition for dataset and is somewhat complicated. Contrary to [9], the proposed ASGCD algorithm reduces the complexity of greedy selection by a factor up to n in terms of the amortized cost by simply applying the existing stochastic variance reduction framework."
    }, {
      "heading" : "4 Experiments",
      "text" : "In this section, we use numerical experiments to demonstrate the theoretical results in Section 3 and show the empirical performance of ASGCD with batch size b = 1 and its deterministic version with b = n (In Fig. 1 they are denoted as ASGCD (b = 1) and ASGCD (b = n) respectively). In addition, following the claim to using data access rather than CPU time [19] and the recent SGD and RCD literature [13, 14, 1], we use the data access, i.e., the number of times the algorithm accesses the data matrix, to measure the algorithm performance. To show the effect of Nesterov’s acceleration, we compare ASGCD (b = n) with the non-accelerated greedy coordinate descent with GS-q rule, i.e., coordinate gradient descent (CGD) [22]. To show the effect of both Nesterov’s acceleration and stochastic optimization strategies, we compare ASGCD (b = 1) with Katyusha [1, Alg. 2]. To show the effect of the proposed new rule in Section 2, which is based on `1-norm square approximation, we compare ASGCD (b = n) with the `2-norm based proximal accelerated full gradient (AFG) implemented by the linear coupling framework [3]. Meanwhile, as a benchmark of stochastic optimization for the problems with finite-sum structure, we also show the performance of proximal stochastic variance reduced gradient (SVRG) [23]. In addition, based on [1] and our experiments, we find that “Katyusha” [1, Alg. 2] has the best empirical performance in general for the `1-regularized problem (1). Therefore other well-known state-of-art algorithms, such as APCG [14] and accelerated SDCA [21], are not included in the experiments.\nThe datasets are obtained from LIBSVM data [7] and summarized in Table 2. All the algorithms are used to solve the following lasso problem\nmin x∈Rd {f(x) + λ‖x‖1 =\n1\n2n ‖b−Ax‖22 + λ‖x‖1} (17)\non the 3 datasets, where A = (a1, a2, . . . , an)T = (h1, h2, . . . , hd) ∈ Rn×d with each aj ∈ Rd representing a sample vector and hi ∈ Rn representing a feature vector, b ∈ Rn is the prediction vector.\nFor ASGCD (b = 1) and Katyusha [1, Alg. 2], we can use the tight smooth constant L1 = maxj∈[n],i∈[d] |a2j,i| and L2 = maxj∈[n] ‖aj‖22 respectively in their implementation. While for AS-\nGCD (b = n) and AFG, the better smooth constant T1 = maxi∈[d] ‖hi‖22 n and T2 = ‖A‖2 n are used respectively. The learning rate of CGD and SVRG are tuned in {10−6, 10−5, 10−4, 10−3, 10−2, 10−1}.\nWe use λ = 10−6 and λ = 10−2 in the experiments. In addition, for each case (Dataset, λ), AFG is used to find an optimum x∗ with enough accuracy.\nThe performance of the 6 algorithms is plotted in Fig. 1. We use Log loss log(F (xk)−F (x∗)) in the y-axis. x-axis denotes the number that the algorithm access the data matrix A. For example, ASGCD (b = n) accesses A once in each iteration, while ASGCD (b = 1) accesses A twice in an entire outer iteration. For each case (Dataset, λ), we compute the rate (r1, r2) = (√ CL1‖x∗‖1√ L2‖x∗‖2 , √ CT1‖x∗‖1√ T2‖x∗‖2\n) in Table 3. First, because of the acceleration effect, ASGCD (b = n) are always better than the non-accelerated CGD algorithm; second, by comparing ASGCD(b = 1) with Katyusha and ASGCD (b = n) with AFG, we find that for the cases (Leu, 10−2), (Leu, 10−6) and (Gisette, 10−2), ASGCD (b = 1) dominates Katyusha [1, Alg.2] and ASGCD (b = n) dominates AFG. While the theoretical analysis in Section 3 shows that if r1 is relatively small such as around 1, then ASGCD (b = 1) will be better than [1, Alg.2]. For the other 3 cases, [1, Alg.2] and AFG are better. The consistency between Table 3 and Fig. 1 demonstrates the theoretical analysis."
    } ],
    "references" : [ {
      "title" : "Katyusha: The first direct acceleration of stochastic gradient methods",
      "author" : [ "Zeyuan Allen-Zhu" ],
      "venue" : "ArXiv e-prints,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2016
    }, {
      "title" : "Linear Coupling: An Ultimate Unification of Gradient and Mirror Descent",
      "author" : [ "Zeyuan Allen-Zhu", "Lorenzo Orecchia" ],
      "venue" : "ArXiv e-prints,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2014
    }, {
      "title" : "Linear coupling: An ultimate unification of gradient and mirror descent",
      "author" : [ "Zeyuan Allen-Zhu", "Lorenzo Orecchia" ],
      "venue" : "ArXiv e-prints,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2014
    }, {
      "title" : "Optimization with sparsityinducing penalties",
      "author" : [ "Francis Bach", "Rodolphe Jenatton", "Julien Mairal", "Guillaume Obozinski" ],
      "venue" : "Foundations and Trends R  © in Machine Learning,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2012
    }, {
      "title" : "A fast iterative shrinkage-thresholding algorithm for linear inverse problems",
      "author" : [ "Amir Beck", "Marc Teboulle" ],
      "venue" : "SIAM journal on imaging sciences,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2009
    }, {
      "title" : "Libsvm: Introduction and benchmarks",
      "author" : [ "Chih-Chung Chang" ],
      "venue" : "http://www. csie. ntn. edu. tw/ ̃ cjlin/libsvm,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2000
    }, {
      "title" : "Saga: A fast incremental gradient method with support for non-strongly convex composite objectives",
      "author" : [ "Aaron Defazio", "Francis Bach", "Simon Lacoste-Julien" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2014
    }, {
      "title" : "Nearest neighbor based greedy coordinate descent",
      "author" : [ "Inderjit S Dhillon", "Pradeep K Ravikumar", "Ambuj Tewari" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2011
    }, {
      "title" : "Efficient projections onto the l 1-ball for learning in high dimensions",
      "author" : [ "John Duchi", "Shai Shalev-Shwartz", "Yoram Singer", "Tushar Chandra" ],
      "venue" : "In Proceedings of the 25th international conference on Machine learning,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2008
    }, {
      "title" : "Composite objective mirror descent",
      "author" : [ "John C Duchi", "Shai Shalev-Shwartz", "Yoram Singer", "Ambuj Tewari" ],
      "venue" : "In COLT,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2010
    }, {
      "title" : "Accelerated, parallel, and proximal coordinate descent",
      "author" : [ "Olivier Fercoq", "Peter Richtárik" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2015
    }, {
      "title" : "Accelerating stochastic gradient descent using predictive variance reduction",
      "author" : [ "Rie Johnson", "Tong Zhang" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2013
    }, {
      "title" : "An accelerated proximal coordinate gradient method",
      "author" : [ "Qihang Lin", "Zhaosong Lu", "Lin Xiao" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2014
    }, {
      "title" : "Efficiency of coordinate descent methods on huge-scale optimization problems",
      "author" : [ "Yu Nesterov" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2012
    }, {
      "title" : "Introductory lectures on convex optimization: A basic course, volume 87",
      "author" : [ "Yurii Nesterov" ],
      "venue" : "Springer Science & Business Media,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2013
    }, {
      "title" : "Coordinate descent converges faster with the gauss-southwell rule than random selection",
      "author" : [ "Julie Nutini", "Mark Schmidt", "Issam H Laradji", "Michael Friedlander", "Hoyt Koepke" ],
      "venue" : "In Proceedings of the 32nd International Conference on Machine Learning",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2015
    }, {
      "title" : "Efficient learning of label ranking by soft projections onto polyhedra",
      "author" : [ "Shai Shalev-Shwartz", "Yoram Singer" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2006
    }, {
      "title" : "Stochastic methods for l1-regularized loss minimization",
      "author" : [ "Shai Shalev-Shwartz", "Ambuj Tewari" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2011
    }, {
      "title" : "Stochastic dual coordinate ascent methods for regularized loss minimization",
      "author" : [ "Shai Shalev-Shwartz", "Tong Zhang" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2013
    }, {
      "title" : "Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization",
      "author" : [ "Shai Shalev-Shwartz", "Tong Zhang" ],
      "venue" : "In ICML,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2014
    }, {
      "title" : "A coordinate gradient descent method for nonsmooth separable minimization",
      "author" : [ "Paul Tseng", "Sangwoon Yun" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2009
    }, {
      "title" : "A proximal stochastic gradient method with progressive variance reduction",
      "author" : [ "Lin Xiao", "Tong Zhang" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2014
    }, {
      "title" : "Stochastic primal-dual coordinate method for regularized empirical risk minimization",
      "author" : [ "Yuchen Zhang", "Lin Xiao" ],
      "venue" : "In Proceedings of the 32nd International Conference on Machine Learning,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 14,
      "context" : "While after applying the Nesterov’s acceleration scheme [16], the resulted accelerated full gradient method (AFG) [16] only needs O( √ 1/ ) iterations, which is optimal for first-order algorithms [16].",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 14,
      "context" : "While after applying the Nesterov’s acceleration scheme [16], the resulted accelerated full gradient method (AFG) [16] only needs O( √ 1/ ) iterations, which is optimal for first-order algorithms [16].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 14,
      "context" : "While after applying the Nesterov’s acceleration scheme [16], the resulted accelerated full gradient method (AFG) [16] only needs O( √ 1/ ) iterations, which is optimal for first-order algorithms [16].",
      "startOffset" : 196,
      "endOffset" : 200
    }, {
      "referenceID" : 11,
      "context" : "By sampling one training example, the resulted stochastic gradient descent (SGD) and its variants [13, 23, 1] can reduce the iteration complexity by a factor of the sample size.",
      "startOffset" : 98,
      "endOffset" : 109
    }, {
      "referenceID" : 21,
      "context" : "By sampling one training example, the resulted stochastic gradient descent (SGD) and its variants [13, 23, 1] can reduce the iteration complexity by a factor of the sample size.",
      "startOffset" : 98,
      "endOffset" : 109
    }, {
      "referenceID" : 0,
      "context" : "By sampling one training example, the resulted stochastic gradient descent (SGD) and its variants [13, 23, 1] can reduce the iteration complexity by a factor of the sample size.",
      "startOffset" : 98,
      "endOffset" : 109
    }, {
      "referenceID" : 13,
      "context" : "As an alternative of SGD, randomized coordinate descent (RCD) can also reduce the iteration complexity by a factor of the sample size [15] and obtain the optimal convergence rate O( √ 1/ ) by Nesterov’s acceleration [14, 12].",
      "startOffset" : 134,
      "endOffset" : 138
    }, {
      "referenceID" : 12,
      "context" : "As an alternative of SGD, randomized coordinate descent (RCD) can also reduce the iteration complexity by a factor of the sample size [15] and obtain the optimal convergence rate O( √ 1/ ) by Nesterov’s acceleration [14, 12].",
      "startOffset" : 216,
      "endOffset" : 224
    }, {
      "referenceID" : 10,
      "context" : "As an alternative of SGD, randomized coordinate descent (RCD) can also reduce the iteration complexity by a factor of the sample size [15] and obtain the optimal convergence rate O( √ 1/ ) by Nesterov’s acceleration [14, 12].",
      "startOffset" : 216,
      "endOffset" : 224
    }, {
      "referenceID" : 20,
      "context" : "GCD is widely used for solving sparse optimization problems in machine learning [22, 9, 17].",
      "startOffset" : 80,
      "endOffset" : 91
    }, {
      "referenceID" : 7,
      "context" : "GCD is widely used for solving sparse optimization problems in machine learning [22, 9, 17].",
      "startOffset" : 80,
      "endOffset" : 91
    }, {
      "referenceID" : 15,
      "context" : "GCD is widely used for solving sparse optimization problems in machine learning [22, 9, 17].",
      "startOffset" : 80,
      "endOffset" : 91
    }, {
      "referenceID" : 15,
      "context" : "Meanwhile if the iteration complexity is comparable, GCD will be preferable than RCD [17].",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 15,
      "context" : "In the above nonsmooth case, the Gauss-Southwell rule has 3 different variants [17, 22]: GS-s, GS-r and GS-q.",
      "startOffset" : 79,
      "endOffset" : 87
    }, {
      "referenceID" : 20,
      "context" : "In the above nonsmooth case, the Gauss-Southwell rule has 3 different variants [17, 22]: GS-s, GS-r and GS-q.",
      "startOffset" : 79,
      "endOffset" : 87
    }, {
      "referenceID" : 14,
      "context" : "While when using Nesterov’s acceleration scheme, convexity is needed for the derivation of the optimal convergence rate O( √ 1/ ) [16].",
      "startOffset" : 130,
      "endOffset" : 134
    }, {
      "referenceID" : 16,
      "context" : "The complexity result O(d+ |Q| log |Q|) is better than O(d log d) of its counterpart SOPOPO [18], which is an Euclidean projection method.",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 15,
      "context" : ", g has at most 1 nonzero element) [17, 22].",
      "startOffset" : 35,
      "endOffset" : 43
    }, {
      "referenceID" : 20,
      "context" : ", g has at most 1 nonzero element) [17, 22].",
      "startOffset" : 35,
      "endOffset" : 43
    }, {
      "referenceID" : 3,
      "context" : "While by the variational identity ‖g‖(2)1 = infθ∈4d ∑d i=1 g(2) i θi in [4] 2, in Lemma 1, it is shown that we can transform the original nonseparable and nonsmooth problem into a separable and smooth optimization problem on a simplex.",
      "startOffset" : 72,
      "endOffset" : 75
    }, {
      "referenceID" : 4,
      "context" : "In Lemma 1, (8) is obtained by the iterative soft thresholding operator [5].",
      "startOffset" : 72,
      "endOffset" : 75
    }, {
      "referenceID" : 16,
      "context" : "SOTOPO can be viewed as an extension of the SOPOPO algorithm [18] by changing the objective function from Euclidean distance to a more general function J(θ) in (9).",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 16,
      "context" : "It should be noted that Lemma 5 does not have a counterpart in the case that the objective function is Euclidean distance [18].",
      "startOffset" : 122,
      "endOffset" : 126
    }, {
      "referenceID" : 8,
      "context" : "In addition, some extension of randomized median finding algorithm [10] with linear time in our setting is also deserved to research.",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 0,
      "context" : "Therefore this rule can be applied into the existing Nesterov’s acceleration and stochastic optimization framework “Katyusha” [1] if it can be solved efficiently.",
      "startOffset" : 126,
      "endOffset" : 129
    }, {
      "referenceID" : 17,
      "context" : "For example, instead of the custom setting p = 1 + 1/log(d) [19, 11], a particular choice p = 1 + δ (δ is defined in Alg.",
      "startOffset" : 60,
      "endOffset" : 68
    }, {
      "referenceID" : 9,
      "context" : "For example, instead of the custom setting p = 1 + 1/log(d) [19, 11], a particular choice p = 1 + δ (δ is defined in Alg.",
      "startOffset" : 60,
      "endOffset" : 68
    }, {
      "referenceID" : 18,
      "context" : "In the first column, “Acc” and “Non-Acc” denote the corresponding algorithms are Nesterov’s accelerated or not respectively, “Primal” and “Dual” denote the corresponding algorithms solves the primal problem (1) and its regularized dual problem [20] respectively, `2-norm and `1-norm denote the theoretical guarantee is based on `2-norm and `1-norm respectively.",
      "startOffset" : 244,
      "endOffset" : 248
    }, {
      "referenceID" : 15,
      "context" : "When λ > 0, the generalized GS-r, GS-s and GS-q rules generally have worse theoretical guarantee than GCD [17].",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 7,
      "context" : "Meanwhile, because the bound depends on ‖x ‖1 rather than ‖x‖2 and on L1 rather than L2 (L1 and L2 are defined in (2)), for the `1-ERM problem, if the samples are high-dimensional, dense and the regularization parameter λ is relatively large, then it is possible that L1 L2 (in the extreme case, L2 = dL1 [9]) and ‖x‖1 ≈ ‖x‖2.",
      "startOffset" : 305,
      "endOffset" : 308
    }, {
      "referenceID" : 9,
      "context" : "Finally, whether the log d factor in the bound of ASGCD (which also appears in the COMID [11] analysis) is necessary deserves further research.",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 0,
      "context" : "In this case, we can use a better smooth constant T1 that satisfies ‖∇f(x)−∇f(y)‖∞ ≤ T1‖x− y‖1 rather than L1 [1].",
      "startOffset" : 110,
      "endOffset" : 113
    }, {
      "referenceID" : 15,
      "context" : "The necessity of computing the full gradient beforehand is the main bottleneck of GCD in applications [17].",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 7,
      "context" : "There exists some work [9] to avoid the computation of full gradient by performing some approximate greedy selection.",
      "startOffset" : 23,
      "endOffset" : 26
    }, {
      "referenceID" : 7,
      "context" : "While the method in [9] needs preprocessing, incoherence",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 6,
      "context" : "ALGORITHM TYPE PAPER CONVERGENCE RATE NON-ACC, PRIMAL, `2-NORM SAGA [8] O ( L2‖x‖(2)2 ) ACC, PRIMAL, `2-NORM KATYUSHA [1] O (√ L2‖x‖2 √ )",
      "startOffset" : 68,
      "endOffset" : 71
    }, {
      "referenceID" : 0,
      "context" : "ALGORITHM TYPE PAPER CONVERGENCE RATE NON-ACC, PRIMAL, `2-NORM SAGA [8] O ( L2‖x‖(2)2 ) ACC, PRIMAL, `2-NORM KATYUSHA [1] O (√ L2‖x‖2 √ )",
      "startOffset" : 118,
      "endOffset" : 121
    }, {
      "referenceID" : 22,
      "context" : "O (√ L2‖x‖2 √ log( 1 ) ) DUAL, SPDC [24] `2-NORM APCG [14] APPROX [12] NON-ACC, PRIMAL, `1-NORM GCD [2] O ( L1‖x‖(2)1 ) ACC, PRIMAL, `1-NORM ASGCD (THIS PAPER) O (√ L1‖x‖1 log d √ )",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 12,
      "context" : "O (√ L2‖x‖2 √ log( 1 ) ) DUAL, SPDC [24] `2-NORM APCG [14] APPROX [12] NON-ACC, PRIMAL, `1-NORM GCD [2] O ( L1‖x‖(2)1 ) ACC, PRIMAL, `1-NORM ASGCD (THIS PAPER) O (√ L1‖x‖1 log d √ )",
      "startOffset" : 54,
      "endOffset" : 58
    }, {
      "referenceID" : 10,
      "context" : "O (√ L2‖x‖2 √ log( 1 ) ) DUAL, SPDC [24] `2-NORM APCG [14] APPROX [12] NON-ACC, PRIMAL, `1-NORM GCD [2] O ( L1‖x‖(2)1 ) ACC, PRIMAL, `1-NORM ASGCD (THIS PAPER) O (√ L1‖x‖1 log d √ )",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 1,
      "context" : "O (√ L2‖x‖2 √ log( 1 ) ) DUAL, SPDC [24] `2-NORM APCG [14] APPROX [12] NON-ACC, PRIMAL, `1-NORM GCD [2] O ( L1‖x‖(2)1 ) ACC, PRIMAL, `1-NORM ASGCD (THIS PAPER) O (√ L1‖x‖1 log d √ )",
      "startOffset" : 100,
      "endOffset" : 103
    }, {
      "referenceID" : 7,
      "context" : "Contrary to [9], the proposed ASGCD algorithm reduces the complexity of greedy selection by a factor up to n in terms of the amortized cost by simply applying the existing stochastic variance reduction framework.",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 17,
      "context" : "In addition, following the claim to using data access rather than CPU time [19] and the recent SGD and RCD literature [13, 14, 1], we use the data access, i.",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 11,
      "context" : "In addition, following the claim to using data access rather than CPU time [19] and the recent SGD and RCD literature [13, 14, 1], we use the data access, i.",
      "startOffset" : 118,
      "endOffset" : 129
    }, {
      "referenceID" : 12,
      "context" : "In addition, following the claim to using data access rather than CPU time [19] and the recent SGD and RCD literature [13, 14, 1], we use the data access, i.",
      "startOffset" : 118,
      "endOffset" : 129
    }, {
      "referenceID" : 0,
      "context" : "In addition, following the claim to using data access rather than CPU time [19] and the recent SGD and RCD literature [13, 14, 1], we use the data access, i.",
      "startOffset" : 118,
      "endOffset" : 129
    }, {
      "referenceID" : 20,
      "context" : ", coordinate gradient descent (CGD) [22].",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 2,
      "context" : "To show the effect of the proposed new rule in Section 2, which is based on `1-norm square approximation, we compare ASGCD (b = n) with the `2-norm based proximal accelerated full gradient (AFG) implemented by the linear coupling framework [3].",
      "startOffset" : 240,
      "endOffset" : 243
    }, {
      "referenceID" : 21,
      "context" : "Meanwhile, as a benchmark of stochastic optimization for the problems with finite-sum structure, we also show the performance of proximal stochastic variance reduced gradient (SVRG) [23].",
      "startOffset" : 182,
      "endOffset" : 186
    }, {
      "referenceID" : 0,
      "context" : "In addition, based on [1] and our experiments, we find that “Katyusha” [1, Alg.",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 12,
      "context" : "Therefore other well-known state-of-art algorithms, such as APCG [14] and accelerated SDCA [21], are not included in the experiments.",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 19,
      "context" : "Therefore other well-known state-of-art algorithms, such as APCG [14] and accelerated SDCA [21], are not included in the experiments.",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 5,
      "context" : "The datasets are obtained from LIBSVM data [7] and summarized in Table 2.",
      "startOffset" : 43,
      "endOffset" : 46
    } ],
    "year" : 2018,
    "abstractText" : "In this paper we study the well-known greedy coordinate descent (GCD) algorithm to solve `1-regularized problems and improve GCD by the two popular strategies: Nesterov’s acceleration and stochastic optimization. Firstly, based on an `1-norm square approximation, we propose a new rule for greedy selection which is nontrivial to solve but convex; then an efficient algorithm called “SOft ThreshOlding PrOjection (SOTOPO)” is proposed to exactly solve an `1-regularized `1-norm square approximation problem, which is induced by the new rule. Based on the new rule and the SOTOPO algorithm, the Nesterov’s acceleration and stochastic optimization strategies are then successfully applied to the GCD algorithm. The resulted algorithm called accelerated stochastic greedy coordinate descent (ASGCD) has the optimal convergence rate O( √ 1/ ); meanwhile, it reduces the iteration complexity of greedy selection up to a factor of sample size. Both theoretically and empirically, we show that ASGCD has better performance for high-dimensional and dense problems with sparse solutions.",
    "creator" : "LaTeX with hyperref package"
  }
}