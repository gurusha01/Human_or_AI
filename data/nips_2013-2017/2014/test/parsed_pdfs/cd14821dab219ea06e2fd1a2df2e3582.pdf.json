{
  "name" : "cd14821dab219ea06e2fd1a2df2e3582.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Consistency of weighted majority votes",
    "authors" : [ "Daniel Berend", "Aryeh Kontorovich" ],
    "emails" : [ "berend@cs.bgu.ac.il", "karyeh@cs.bgu.ac.il" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Imagine independently consulting a small set of medical experts for the purpose of reaching a binary decision (e.g., whether to perform some operation). Each doctor has some “reputation”, which can be modeled as his probability of giving the right advice. The problem of weighting the input of several experts arises in many situations and is of considerable theoretical and practical importance. The rigorous study of majority vote has its roots in the work of Condorcet [1]. By the 70s, the field of decision theory was actively exploring various voting rules (see [2] and the references therein). A typical setting is as follows. An agent is tasked with predicting some random variable Y ∈ {±1} based on input Xi ∈ {±1} from each of n experts. Each expert Xi has a competence level pi ∈ (0, 1), which is the probability of making a correct prediction: P(Xi = Y ) = pi. Two simplifying assumptions are commonly made:\n(i) Independence: The random variables {Xi : i ∈ [n]} are mutually independent conditioned on the truth Y .\n(ii) Unbiased truth: P(Y = +1) = P(Y = −1) = 1/2.\nWe will discuss these assumptions below in greater detail; for now, let us just take them as given. (Since the bias of Y can be easily estimated from data, only the independence assumption is truly restrictive.) A decision rule is a mapping f : {±1}n → {±1} from the n expert inputs to the agent’s final decision. Our quantity of interest throughout the paper will be the agent’s probability of error,\nP(f(X) 6= Y ). (1) A decision rule f is optimal if it minimizes the quantity in (1) over all possible decision rules. It was shown in [2] that, when Assumptions (i)–(ii) hold and the true competences pi are known, the optimal decision rule is obtained by an appropriately weighted majority vote:\nfOPT(x) = sign ( n∑ i=1 wixi ) , (2)\nwhere the weights wi are given by\nwi = log pi\n1− pi , i ∈ [n]. (3)\nThus, wi is the log-odds of expert i being correct — and the voting rule in (2), also known as naive Bayes [3], may be seen as a simple consequence of the Neyman-Pearson lemma [4].\nMain results. The formula in (2) raises immediate questions, which apparently have not previously been addressed. The first one has to do with the consistency of the Nitzan-Paroush optimal rule: under what conditions does the probability of error decay to zero and at what rate? In Section 3, we show that the probability of error is controlled by the committee potential Φ, defined by\nΦ = n∑ i=1 (pi − 12 )wi = n∑ i=1 (pi − 12 ) log pi 1− pi . (4)\nMore precisely, we prove in Theorem 1 that log P(fOPT(X) 6= Y ) −Φ, where denotes equivalence up to universal multiplicative constants.\nAnother issue not addressed by the Nitzan-Paroush result is how to handle the case where the competences pi are not known exactly but rather estimated empirically by p̂i. We present two solutions to this problem: a frequentist and a Bayesian one. As we show in Section 4, the frequentist approach does not admit an optimal empirical decision rule. Instead, we analyze empirical decision rules in various settings: high-confidence (i.e., |p̂i − pi| 1) vs. low-confidence, adaptive vs. nonadaptive. The low-confidence regime requires no additional assumptions, but gives weaker guarantees (Theorem 5). In the high-confidence regime, the adaptive approach produces error estimates in terms of the empirical p̂is (Theorem 7), while the nonadaptive approach yields a bound in terms of the unknown pis, which still leads to useful asymptotics (Theorem 6). The Bayesian solution sidesteps the various cases above, as it admits a simple, provably optimal empirical decision rule (Section 5). Unfortunately, we are unable to compute (or even nontrivially estimate) the probability of error induced by this rule; this is posed as a challenging open problem."
    }, {
      "heading" : "2 Related work",
      "text" : "Machine learning theory typically clusters weighted majority [5, 6] within the framework of online algorithms; see [7] for a modern treatment. Since the online setting is considerably more adversarial than ours, we obtain very different weighted majority rules and consistency guarantees. The weights wi in (2) bear a striking similarity to the Adaboost update rule [8, 9]. However, the latter assumes weak learners with access to labeled examples, while in our setting the experts are “static”. Still, we do not rule out a possible deeper connection between the Nitzan-Paroush decision rule and boosting.\nIn what began as the influential Dawid-Skene model [10] and is now known as crowdsourcing, one attempts to extract accurate predictions by pooling a large number of experts, typically without the benefit of being able to test any given expert’s competence level. Still, under mild assumptions it is possible to efficiently recover the expert competences to a high accuracy and to aggregate them effectively [11]. Error bounds for the oracle MAP rule were obtained in this model by [12] and minimax rates were given in [13].\nIn a recent line of work [14, 15, 16] have developed a PAC-Bayesian theory for the majority vote of simple classifiers. This approach facilitates data-dependent bounds and is even flexible enough to capture some simple dependencies among the classifiers — though, again, the latter are learners as opposed to our experts. Even more recently, experts with adversarial noise have been considered [17], and efficient algorithms for computing optimal expert weights (without error analysis) were given [18]. More directly related to the present work are the papers of [19], which characterizes the consistency of the simple majority rule, and [20, 21, 22] which analyze various models of dependence among the experts."
    }, {
      "heading" : "3 Known competences",
      "text" : "In this section we assume that the expert competences pi are known and analyze the consistency of the Nitzan-Paroush optimal decision rule (2). Our main result here is that the probability of error P(fOPT(X) 6= Y ) is small if and only if the committee potential Φ is large. Theorem 1. Suppose that the experts X = (X1, . . . , Xn) satisfy Assumptions (i)-(ii) and fOPT : {±1}n → {±1} is the Nitzan-Paroush optimal decision rule. Then\n(i) P(fOPT(X) 6= Y ) ≤ exp ( − 12Φ ) .\n(ii) P(fOPT(X) 6= Y ) ≥ 3 8[1 + exp(2Φ + 4 √ Φ)] .\nAs we show in the full paper [27], the upper and lower bounds are both asymptotically tight. The remainder of this section is devoted to proving Theorem 1."
    }, {
      "heading" : "3.1 Proof of Theorem 1(i)",
      "text" : "Define the {0, 1}-indicator variables\nξi = 1{Xi=Y }, (5)\ncorresponding to the event that the ith expert is correct. A mistake fOPT(X) 6= Y occurs precisely when1 the sum of the correct experts’ weights fails to exceed half the total mass:\nP(fOPT(X) 6= Y ) = P ( n∑ i=1 wiξi ≤ 1 2 n∑ i=1 wi ) . (6)\nSince Eξi = pi, we may rewrite the probability in (6) as\nP (∑ i wiξi ≤ E [∑ i wiξi ] − ∑ i (pi − 12 )wi ) . (7)\nA standard tool for estimating such sum deviation probabilities is Hoeffding’s inequality. Applied to (7), it yields the bound\nP(fOPT(X) 6= Y ) ≤ exp ( − 2 [∑ i(pi − 1 2 )wi ]2∑ i w 2 i ) , (8)\nwhich is far too crude for our purposes. Indeed, consider a finite committee of highly competent experts with pi’s arbitrarily close to 1 and X1 the most competent of all. Raising X1’s competence sufficiently far above his peers will cause both the numerator and the denominator in the exponent to be dominated by w21 , making the right-hand-side of (8) bounded away from zero. The inability of Hoeffding’s inequality to guarantee consistency even in such a felicitous setting is an instance of its generally poor applicability to highly heterogeneous sums, a phenomenon explored in some depth in [23]. Bernstein’s and Bennett’s inequalities suffer from a similar weakness (see ibid.). Fortunately, an inequality of Kearns and Saul [24] is sufficiently sharp to yield the desired estimate: For all p ∈ [0, 1] and all t ∈ R,\n(1− p)e−tp + pet(1−p) ≤ exp (\n1− 2p 4 log((1− p)/p)\nt2 ) . (9)\nRemark. The Kearns-Saul inequality (9) may be seen as a distribution-dependent refinement of Hoeffding’s (which bounds the left-hand-side of (9) by et\n2/8), and is not nearly as straightforward to prove. An elementary rigorous proof is given in [25]. Following up, [26] gave a “soft” proof based on transportation and information-theoretic techniques.\n1 Without loss of generality, ties are considered to be errors.\nPut θi = ξi − pi, substitute into (6), and apply Markov’s inequality:\nP(fOPT(X) 6= Y ) = P ( − ∑ i wiθi ≥ Φ ) ≤ e−tΦEexp ( −t ∑ i wiθi ) . (10)\nNow\nEe−twiθi = pie−(1−pi)wit + (1− pi)epiwit ≤ exp (\n−1 + 2pi 4 log(pi/(1− pi)) w2i t 2\n) = exp [ 1 2 (pi − 1 2 )wit 2 ] , (11)\nwhere the inequality follows from (9). By independence,\nE exp ( −t ∑ i wiθi ) = ∏ i Ee−twiθi ≤ exp ( 1 2 ∑ i (pi − 12 )wit 2 ) = exp ( 1 2Φt 2 )\nand hence P(fOPT(X) 6= Y ) ≤ exp (\n1 2Φt\n2 − Φt ) .Choosing t = 1 yields the bound in Theorem 1(i)."
    }, {
      "heading" : "3.2 Proof of Theorem 1(ii)",
      "text" : "Define the {±1}-indicator variables ηi = 2 · 1{Xi=Y } − 1, (12) corresponding to the event that the ith expert is correct and put qi = 1− pi. The shorthand w · η =∑n i=1 wiηi will be convenient. We will need some simple lemmata, whose proofs are deferred to the journal version [27]. Lemma 2.\nP(fOPT(X) = Y ) = 12 ∑\nη∈{±1}n max {P (η), P (−η)}\nand\nP(fOPT(X) 6= Y ) = 12 ∑\nη∈{±1}n min {P (η), P (−η)} ,\nwhere P (η) = ∏ i:ηi=1 pi ∏ i:ηi=−1 qi.\nLemma 3. Suppose that s, s′ ∈ (0,∞)m satisfy ∑m i=1(si + s ′ i) ≥ a and R−1 ≤ si/s′i ≤ R,\ni ∈ [m], for some R <∞. Then ∑m i=1 min {si, s′i} ≥ a/(1 +R). Lemma 4. Define the function F : (0, 1)→ R by\nF (x) = x(1− x) log(x/(1− x))\n2x− 1 .\nThen sup0<x<1 F (x) = 1 2 .\nContinuing with the main proof, observe that\nE [w · η] = n∑ i=1 (pi − qi)wi = 2Φ (13)\nand Var [w · η] = 4 ∑n i=1 piqiw 2 i . By Lemma 4, piqiw 2 i ≤ 12 (pi − qi)wi, and hence\nVar [w · η] ≤ 4Φ. (14) Define the segment I ⊂ R by\nI = [ 2Φ− 4 √ Φ, 2Φ + 4 √ Φ ] . (15)\nChebyshev’s inequality together with (13) and (14) implies that\nP (w · η ∈ I) ≥ 3 4 . (16)\nConsider an atom η ∈ {±1}n for which w · η ∈ I . The proof of Lemma 2 shows that\nP (η) P (−η) = exp (w · η) ≤ exp(2Φ + 4 √ Φ), (17)\nwhere the inequality follows from (15). Lemma 2 further implies that\nP(fOPT(X) 6= Y ) ≥ 12 ∑\nη∈{±1}n:w·η∈I\nmin {P (η), P (−η)} ≥ 3/4 1 + exp(2Φ + 4 √ Φ) ,\nwhere the second inequality follows from Lemma 3, (16) and (17). This completes the proof."
    }, {
      "heading" : "4 Unknown competences: frequentist",
      "text" : "Our goal in this section is to obtain, insofar as possible, analogues of Theorem 1 for unknown expert competences. When the pis are unknown, they must be estimated empirically before any useful weighted majority vote can be applied. There are various ways to model partial knowledge of expert competences [28, 29]. Perhaps the simplest scenario for estimating the pis is to assume that the ith expert has been queried independently mi times, out of which he gave the correct prediction ki times. Taking the {mi} to be fixed, define the committee profile by k = (k1, . . . , kn); this is the aggregate of the agent’s empirical knowledge of the experts’ performance. An empirical decision rule f̂ : (x,k) 7→ {±1} makes a final decision based on the expert inputs x together with the committee profile. Analogously to (1), the probability of a mistake is\nP(f̂(X,K) 6= Y ). (18)\nNote that now the committee profile is an additional source of randomness. Here we run into our first difficulty: unlike the probability in (1), which is minimized by the Nitzan-Paroush rule, the agent cannot formulate an optimal decision rule f̂ in advance without knowing the pis. This is because no decision rule is optimal uniformly over the range of possible pis. Our approach will be to consider weighted majority decision rules of the form\nf̂(x,k) = sign ( n∑ i=1 ŵ(ki)xi ) (19)\nand to analyze their consistency properties under two different regimes: low-confidence and highconfidence. These refer to the confidence intervals of the frequentist estimate of pi, given by\np̂i = ki mi . (20)"
    }, {
      "heading" : "4.1 Low-confidence regime",
      "text" : "In the low-confidence regime, the sample sizes mi may be as small as 1, and we define2\nŵ(ki) = ŵLCi := p̂i − 12 , i ∈ [n], (21)\nwhich induces the empirical decision rule f̂LC. It remains to analyze f̂LC’s probability of error. Recall the definition of ξi from (5) and observe that\nE [ ŵLCi ξi ] = E[(p̂i − 12 )ξi] = (pi − 1 2 )pi, (22)\nsince p̂i and ξi are independent. As in (6), the probability of error (18) is\nP ( n∑ i=1 ŵLCi ξi ≤ 1 2 n∑ i=1 ŵLCi ) = P ( n∑ i=1 Zi ≤ 0 ) , (23)\n2 For mi min {pi, qi} 1, the estimated competences p̂i may well take values in {0, 1}, in which case log(p̂i/q̂i) = ±∞. The rule in (21) is essentially a first-order Taylor approximation to w(·) about p = 12 .\nwhere Zi = ŵLCi (ξi − 12 ). Now the {Zi} are independent random variables, EZi = (pi − 1 2 ) 2 (by (22)), and each Zi takes values in an interval of length 12 . Hence, the standard Hoeffding bound applies:\nP(f̂LC(X,K) 6= Y ) ≤ exp − 8 n ( n∑ i=1 (pi − 12 ) 2 )2 . (24) We summarize these calculations in\nTheorem 5. A sufficient condition for P(f̂LC(X,K) 6= Y )→ 0 is 1√ n ∑n i=1(pi − 1 2 ) 2 →∞.\nSeveral remarks are in order. First, notice that the error bound in (24) is stated in terms of the unknown {pi}, providing the agent with large-committee asymptotics but giving no finitary information; this limitation is inherent in the low-confidence regime. Secondly, the condition in Theorem 5 is considerably more restrictive than the consistency condition Φ → ∞ implicit in Theorem 1. Indeed, the empirical decision rule f̂LC is incapable of exploiting a single highly competent expert in the way that fOPT from (2) does. Our analysis could be sharpened somewhat for moderate sample sizes {mi} by using Bernstein’s inequality to take advantage of the low variance of the p̂is. For sufficiently large sample sizes, however, the high-confidence regime (discussed below) begins to take over. Finally, there is one sense in which this case is “easier” to analyze than that of known {pi}: since the summands in (23) are bounded, Hoeffding’s inequality gives nontrivial results and there is no need for more advanced tools such as the Kearns-Saul inequality (9) (which is actually inapplicable in this case)."
    }, {
      "heading" : "4.2 High-confidence regime",
      "text" : "In the high-confidence regime, each estimated competence p̂i is close to the true value pi with high probability. To formalize this, fix some 0 < δ < 1, 0 < ε ≤ 5, and put qi = 1 − pi, q̂i = 1 − p̂i. We will set the empirical weights according to the “plug-in” Nitzan-Paroush rule\nŵHCi := log p̂i q̂i , i ∈ [n], (25)\nwhich induces the empirical decision rule f̂HC and raises immediate concerns about ŵHCi = ±∞. We give two kinds of bounds on P(f̂HC 6= Y ): nonadaptive and adaptive. In the nonadaptive analysis, we show that for mi min {pi, qi} 1, with high probability |wi − ŵHCi | 1, and thus a “perturbed” version of Theorem 1(i) holds (and in particular, wHCi will be finite with high probability). In the adaptive analysis, we allow ŵHCi to take on infinite values\n3 and show (perhaps surprisingly) that this decision rule also asymptotically achieves the rate of Theorem 1(i).\nNonadaptive analysis. The following result captures our analysis of the nonadaptive agent:\nTheorem 6. Let 0 < δ < 1 and 0 < ε < min {5, 2Φ/n}. If\nmi min {pi, qi} ≥ 3 (√\n4ε+ 1− 1 4\n)−2 log\n4n δ , i ∈ [n], (26)\nthen\nP ( f̂HC(X,K) 6= Y ) ≤ δ + exp [ − (2Φ− εn) 2\n8Φ\n] . (27)\nRemark. For fixed {pi} and mini∈[n]mi → ∞, we may take δ and ε arbitrarily small — and in this limiting case, the bound of Theorem 1(i) is recovered.\n3 When the decision rule is faced with evaluating sums involving∞−∞, we automatically count this as an error.\nAdaptive analysis. Theorem 6 has the drawback of being nonadaptive, in that its assumptions (26) and conclusions (27) depend on the unknown {pi} and hence cannot be evaluated by the agent (the bound in (24) is also nonadaptive4). In the adaptive (fully empirical) approach, all results are stated in terms of empirically observed quantities: Theorem 7. Choose any5 δ ≥ ∑n i=1 1√ mi and let R be the event where\nexp ( − 12 ∑n i=1(p̂i − 1 2 )ŵ HC i ) ≤ δ2 . Then P ( R ∩ { f̂HC(X,K) 6= Y }) ≤ δ.\nRemark 1. Our interpretation for Theorem 7 is as follows. The agent observes the committee profile K, which determines the {p̂i, ŵHCi }, and then checks whether the event R has occurred. If not, the adaptive agent refrains from making a decision (and may choose to fall back on the low-confidence approach described previously). If R does hold, however, the agent predicts Y according to f̂HC. Observe that the eventR will only occur if the empirical committee potential Φ̂ = ∑n i=1(p̂i− 1 2 )ŵ HC i is sufficiently large — i.e., if enough of the experts’ competences are sufficiently far from 12 . But if this is not the case, little is lost by refraining from a high-confidence decision and defaulting to a low-confidence one, since near 12 , the two decision procedures are very similar.\nAs explained above, there does not exist a nontrivial a priori upper bound on P(f̂HC(X,K) 6= Y ) absent any knowledge of the pis. Instead, Theorem 7 bounds the probability of the agent being “fooled” by an unrepresentative committee profile.6 Note that we have done nothing to prevent ŵHCi = ±∞, and this may indeed happen. Intuitively, there are two reasons for infinite ŵHCi : (a) noisy p̂i due to mi being too small, or (b) the ith expert is actually highly (in)competent, which causes p̂i ∈ {0, 1} to be likely even for large mi. The 1/ √ mi term in the bound insures against case (a), while in case (b), choosing infinite ŵHCi causes no harm (as we show in the proof).\nProof of Theorem 7. We will write the probability and expectation operators with subscripts (such as K) to indicate the random variable(s) being summed over. Thus,\nPK,X,Y ( R ∩ { f̂HC(X,K) 6= Y }) = PK,η ( R ∩ { ŵHC · η ≤ 0 }) = EK [ 1R · Pη ( ŵHC · η ≤ 0 |K )] .\nRecall that the random variable η ∈ {±1}n, with probability mass function P (η) = ∏ i:ηi=1 pi ∏ i:ηi=−1 qi, is independent of K, and hence\nPη ( ŵHC · η ≤ 0 |K ) = Pη ( ŵHC · η ≤ 0 ) . (28)\nDefine the random variable η̂ ∈ {±1}n (conditioned on K) by the probability mass function P (η̂) = ∏ i:ηi=1 p̂i ∏ i:ηi=−1 q̂i, and the set A ⊆ {±1} n by A = { x : ŵHC · x ≤ 0 } . Now∣∣Pη (ŵHC · η ≤ 0)− Pη̂ (ŵHC · η̂ ≤ 0)∣∣ = |Pη (A)− Pη̂ (A)| ≤ max\nA⊆{±1}n |Pη (A)− Pη̂ (A)|\n= ‖Pη − Pη̂‖TV ≤ n∑ i=1 |pi − p̂i| =: M,\nwhere the last inequality follows from a standard tensorization property of the total variation norm ‖·‖TV, see e.g. [33, Lemma 2.2]. By Theorem 1(i), we have Pη̂ ( ŵHC · η̂ ≤ 0 ) ≤\nexp ( − 12 ∑n i=1(p̂i − 1 2 )ŵ HC i ) , and hence Pη ( ŵHC · η ≤ 0 ) ≤ M + exp ( − 12 ∑n i=1(p̂i − 1 2 )ŵ HC i ) . Invoking (28), we substitute the right-hand side above into (28) to obtain\nPK,X,Y ( R ∩ { f̂HC(X,K) 6= Y }) ≤ EK [ 1R · ( M + exp ( − 12 n∑ i=1 (p̂i − 12 )ŵ HC i ))]\n≤ EK[M ] + EK [ 1R exp ( − 12 n∑ i=1 (p̂i − 12 )ŵ HC i )] .\n4The term oracle was suggested by a referee for this setting. 5 Actually, as the proof will show, we may take δ to be a smaller value, but with a more complex dependence\non {mi}, which simplifies to 2[1− (1− (2 √ m)−1)n] for mi ≡ m.\n6These adaptive bounds are similar in spirit to empirical Bernstein methods, [30, 31, 32], where the agent’s confidence depends on the empirical variance.\nBy the definition of R, the second term on the last right-hand side is upper-bounded by δ/2. To estimate M , we invoke a simple mean absolute deviation bound (cf. [34]):\nEK |pi − p̂i| ≤\n√ pi(1− pi)\nmi ≤ 1 2 √ mi ,\nwhich finishes the proof.\nRemark. The improvement mentioned in Footnote 5 is achieved via a refinement of the bound ‖Pη − Pη̂‖TV ≤ ∑n i=1 |pi − p̂i| to ‖Pη − Pη̂‖TV ≤ α ({|pi − p̂i| : i ∈ [n]}), where α(·) is the function defined in [33, Lemma 4.2].\nOpen problem. As argued in Remark 1, Theorem 7 achieves the optimal asymptotic rate in {pi}. Can the dependence on {mi} be improved, perhaps through a better choice of ŵHC?"
    }, {
      "heading" : "5 Unknown competences: Bayesian",
      "text" : "A shortcoming of Theorem 7 is that when condition R fails, the agent is left with no estimate of the error probability. An alternative (and in some sense cleaner) approach to handling unknown expert competences pi is to assume a known prior distribution over the competence levels pi. The natural choice of prior for a Bernoulli parameter is the Beta distribution, namely pi ∼ Beta(αi, βi) with density p αi−1 i q βi−1 i\nB(αi,βi) , where αi, βi > 0, qi = 1 − pi and B(x, y) = Γ(x)Γ(y)/Γ(x + y). Our full\nprobabilistic model is as follows. Each of the n expert competences pi is drawn independently from a Beta distribution with known parameters αi, βi. Then the ith expert, i ∈ [n], is queried independentlymi times, with ki correct predictions andmi−ki incorrect ones. As before, K = (k1, . . . , kn) is the (random) committee profile. Absent direct knowledge of the pis, the agent relies on an empirical decision rule f̂ : (x,k) 7→ {±1} to produce a final decision based on the expert inputs x together with the committee profile k. A decision rule f̂Ba is Bayes-optimal if it minimizes P(f̂(X,K) 6= Y ), which is formally identical to (18) but semantically there is a difference: the former is over the pi in addition to (X, Y,K). Unlike the frequentist approach, where no optimal empirical decision rule was possible, the Bayesian approach readily admits one: f̂Ba(x,k) = sign ( ∑n i=1 ŵ Ba i xi), where\nŵBai = log αi + ki\nβi +mi − ki . (29)\nNotice that for 0 < pi < 1, we have ŵBai −→mi→∞ wi, almost surely, both in the frequentist and the Bayesian interpretations. Unfortunately, although P(f̂Ba(X,K) 6= Y ) = P(ŵBa · η ≤ 0) is a deterministic function of {αi, βi,mi}, we are unable to compute it at this point, or even give a non-trivial bound. The main source of difficulty is the coupling between ŵBa and η.\nOpen problem. Give a non-trivial estimate for P(f̂Ba(X,K) 6= Y )."
    }, {
      "heading" : "6 Discussion",
      "text" : "The classic and seemingly well-understood problem of the consistency of weighted majority votes continues to reveal untapped depth and suggest challenging unresolved questions. We hope that the results and open problems presented here will stimulate future research."
    } ],
    "references" : [ {
      "title" : "Optimal decision rules in uncertain dichotomous choice situations",
      "author" : [ "S. Nitzan", "J. Paroush" ],
      "venue" : "International Economic Review, 23(2):289–297,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 1982
    }, {
      "title" : "The Elements of Statistical Learning: Data Mining, Inference, and Prediction",
      "author" : [ "T. Hastie", "R. Tibshirani", "J. Friedman" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2009
    }, {
      "title" : "On the problem of the most efficient tests of statistical hypotheses",
      "author" : [ "J. Neyman", "E.S. Pearson" ],
      "venue" : "Phil. Trans. Royal Soc. A: Math., Physi. Eng. Sci., 231(694-706):289–337,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1933
    }, {
      "title" : "The weighted majority algorithm",
      "author" : [ "N. Littlestone", "M.K. Warmuth" ],
      "venue" : "FOCS,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 1989
    }, {
      "title" : "The weighted majority algorithm",
      "author" : [ "N. Littlestone", "M.K. Warmuth" ],
      "venue" : "Inf. Comput., 108(2):212–261,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "Prediction, learning, and games",
      "author" : [ "N. Cesa-Bianchi", "G. Lugosi" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2006
    }, {
      "title" : "A decision-theoretic generalization of on-line learning and an application to boosting",
      "author" : [ "Y. Freund", "R.E. Schapire" ],
      "venue" : "J. Comput. Syst. Sci., 55(1):119–139,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Boosting",
      "author" : [ "R.E. Schapire", "Y. Freund" ],
      "venue" : "Foundations and algorithms.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Maximum likelihood estimation of observer error-rates using the EM algorithm",
      "author" : [ "A.P. Dawid", "A.M. Skene" ],
      "venue" : "Applied Statistics, 28(1):20–28,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1979
    }, {
      "title" : "Ranking and combining multiple predictors without labeled data",
      "author" : [ "F. Parisi", "F. Strino", "B. Nadler", "Y. Kluger" ],
      "venue" : "Proc. Nat. Acad. Sci.,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2014
    }, {
      "title" : "Error rate bounds in crowdsourcing models",
      "author" : [ "H. Li", "B. Yu", "D. Zhou" ],
      "venue" : "CoRR, abs/1307.2674,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Minimax Optimal Convergence Rates for Estimating Ground Truth from Crowdsourced Labels",
      "author" : [ "C. Gao", "D. Zhou" ],
      "venue" : null,
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2014
    }, {
      "title" : "PAC-Bayes bounds for the risk of the majority vote and the variance of the gibbs classifier",
      "author" : [ "A. Lacasse", "F. Laviolette", "M. Marchand", "P. Germain", "N. Usunier" ],
      "venue" : "NIPS,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "PAC-Bayes risk bounds for stochastic averages and majority votes of samplecompressed classifiers",
      "author" : [ "F. Laviolette", "M. Marchand" ],
      "venue" : "JMLR, 8:1461–1487,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "From PAC-Bayes bounds to quadratic programs for majority votes",
      "author" : [ "J.-F. Roy", "F. Laviolette", "M. Marchand" ],
      "venue" : "ICML,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Robust aggregation of experts signals",
      "author" : [ "Y. Mansour", "A. Rubinstein", "M. Tennenholtz" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2013
    }, {
      "title" : "Discrete chebyshev classifiers",
      "author" : [ "E. Eban", "E. Mezuman", "A. Globerson" ],
      "venue" : "ICML (2),",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "When is Condorcet’s jury theorem valid? Soc",
      "author" : [ "D. Berend", "J. Paroush" ],
      "venue" : "Choice Welfare, 15(4):481–488,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Modelling dependence in simple and indirect majority systems",
      "author" : [ "P.J. Boland", "F. Proschan", "Y.L. Tong" ],
      "venue" : "J. Appl. Probab., 26(1):81–88,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 1989
    }, {
      "title" : "Monotonicity in Condorcet’s jury theorem with dependent voters",
      "author" : [ "D. Berend", "L. Sapir" ],
      "venue" : "Social Choice and Welfare, 28(3):507–528,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "On the necessity of irrelevant variables",
      "author" : [ "D.P. Helmbold", "P.M. Long" ],
      "venue" : "JMLR, 13:2145–2170,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Concentration inequalities for the missing mass and for histogram rule error",
      "author" : [ "D.A. McAllester", "L.E. Ortiz" ],
      "venue" : "JMLR, 4:895–911,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Large deviation methods for approximate probabilistic inference",
      "author" : [ "M.J. Kearns", "L.K. Saul" ],
      "venue" : "UAI,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "On the concentration of the missing mass",
      "author" : [ "D. Berend", "A. Kontorovich" ],
      "venue" : "Electron. Commun. Probab., 18(3), 1–7,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Concentration of measure inequalities in information theory, communications and coding",
      "author" : [ "M. Raginsky", "I. Sason" ],
      "venue" : "Foundations and Trends in Communications and Information Theory, 10(1-2):1–247,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "A finite-sample analysis of the naive Bayes classifier",
      "author" : [ "D. Berend", "A. Kontorovich" ],
      "venue" : "Preprint,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Distilling the wisdom of crowds: weighted aggregation of decisions on multiple issues",
      "author" : [ "E. Baharad", "J. Goldberger", "M. Koppel", "S. Nitzan" ],
      "venue" : "Autonomous Agents and Multi-Agent Systems, 22(1):31–42,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Beyond condorcet: optimal aggregation rules using voting records",
      "author" : [ "E. Baharad", "J. Goldberger", "M. Koppel", "S. Nitzan" ],
      "venue" : "Theory and Decision, 72(1):113–130,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Tuning bandit algorithms in stochastic environments",
      "author" : [ "J.-Y. Audibert", "R. Munos", "C. Szepesvári" ],
      "venue" : "ALT,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Empirical Bernstein stopping",
      "author" : [ "V. Mnih", "C. Szepesvári", "J.-Y. Audibert" ],
      "venue" : "ICML,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Empirical Bernstein bounds and sample-variance penalization",
      "author" : [ "A. Maurer", "M. Pontil" ],
      "venue" : "COLT,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Obtaining measure concentration from Markov contraction",
      "author" : [ "A. Kontorovich" ],
      "venue" : "Markov Proc. Rel. Fields, 4:613–638,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "A sharp estimate of the binomial mean absolute deviation with applications",
      "author" : [ "D. Berend", "A. Kontorovich" ],
      "venue" : "Statistics & Probability Letters, 83(4):1254–1259,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "By the 70s, the field of decision theory was actively exploring various voting rules (see [2] and the references therein).",
      "startOffset" : 90,
      "endOffset" : 93
    }, {
      "referenceID" : 0,
      "context" : "It was shown in [2] that, when Assumptions (i)–(ii) hold and the true competences pi are known, the optimal decision rule is obtained by an appropriately weighted majority vote:",
      "startOffset" : 16,
      "endOffset" : 19
    }, {
      "referenceID" : 1,
      "context" : "Thus, wi is the log-odds of expert i being correct — and the voting rule in (2), also known as naive Bayes [3], may be seen as a simple consequence of the Neyman-Pearson lemma [4].",
      "startOffset" : 107,
      "endOffset" : 110
    }, {
      "referenceID" : 2,
      "context" : "Thus, wi is the log-odds of expert i being correct — and the voting rule in (2), also known as naive Bayes [3], may be seen as a simple consequence of the Neyman-Pearson lemma [4].",
      "startOffset" : 176,
      "endOffset" : 179
    }, {
      "referenceID" : 3,
      "context" : "Machine learning theory typically clusters weighted majority [5, 6] within the framework of online algorithms; see [7] for a modern treatment.",
      "startOffset" : 61,
      "endOffset" : 67
    }, {
      "referenceID" : 4,
      "context" : "Machine learning theory typically clusters weighted majority [5, 6] within the framework of online algorithms; see [7] for a modern treatment.",
      "startOffset" : 61,
      "endOffset" : 67
    }, {
      "referenceID" : 5,
      "context" : "Machine learning theory typically clusters weighted majority [5, 6] within the framework of online algorithms; see [7] for a modern treatment.",
      "startOffset" : 115,
      "endOffset" : 118
    }, {
      "referenceID" : 6,
      "context" : "The weights wi in (2) bear a striking similarity to the Adaboost update rule [8, 9].",
      "startOffset" : 77,
      "endOffset" : 83
    }, {
      "referenceID" : 7,
      "context" : "The weights wi in (2) bear a striking similarity to the Adaboost update rule [8, 9].",
      "startOffset" : 77,
      "endOffset" : 83
    }, {
      "referenceID" : 8,
      "context" : "In what began as the influential Dawid-Skene model [10] and is now known as crowdsourcing, one attempts to extract accurate predictions by pooling a large number of experts, typically without the benefit of being able to test any given expert’s competence level.",
      "startOffset" : 51,
      "endOffset" : 55
    }, {
      "referenceID" : 9,
      "context" : "Still, under mild assumptions it is possible to efficiently recover the expert competences to a high accuracy and to aggregate them effectively [11].",
      "startOffset" : 144,
      "endOffset" : 148
    }, {
      "referenceID" : 10,
      "context" : "Error bounds for the oracle MAP rule were obtained in this model by [12] and minimax rates were given in [13].",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 11,
      "context" : "Error bounds for the oracle MAP rule were obtained in this model by [12] and minimax rates were given in [13].",
      "startOffset" : 105,
      "endOffset" : 109
    }, {
      "referenceID" : 12,
      "context" : "In a recent line of work [14, 15, 16] have developed a PAC-Bayesian theory for the majority vote of simple classifiers.",
      "startOffset" : 25,
      "endOffset" : 37
    }, {
      "referenceID" : 13,
      "context" : "In a recent line of work [14, 15, 16] have developed a PAC-Bayesian theory for the majority vote of simple classifiers.",
      "startOffset" : 25,
      "endOffset" : 37
    }, {
      "referenceID" : 14,
      "context" : "In a recent line of work [14, 15, 16] have developed a PAC-Bayesian theory for the majority vote of simple classifiers.",
      "startOffset" : 25,
      "endOffset" : 37
    }, {
      "referenceID" : 15,
      "context" : "Even more recently, experts with adversarial noise have been considered [17], and efficient algorithms for computing optimal expert weights (without error analysis) were given [18].",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 16,
      "context" : "Even more recently, experts with adversarial noise have been considered [17], and efficient algorithms for computing optimal expert weights (without error analysis) were given [18].",
      "startOffset" : 176,
      "endOffset" : 180
    }, {
      "referenceID" : 17,
      "context" : "More directly related to the present work are the papers of [19], which characterizes the consistency of the simple majority rule, and [20, 21, 22] which analyze various models of dependence among the experts.",
      "startOffset" : 60,
      "endOffset" : 64
    }, {
      "referenceID" : 18,
      "context" : "More directly related to the present work are the papers of [19], which characterizes the consistency of the simple majority rule, and [20, 21, 22] which analyze various models of dependence among the experts.",
      "startOffset" : 135,
      "endOffset" : 147
    }, {
      "referenceID" : 19,
      "context" : "More directly related to the present work are the papers of [19], which characterizes the consistency of the simple majority rule, and [20, 21, 22] which analyze various models of dependence among the experts.",
      "startOffset" : 135,
      "endOffset" : 147
    }, {
      "referenceID" : 20,
      "context" : "More directly related to the present work are the papers of [19], which characterizes the consistency of the simple majority rule, and [20, 21, 22] which analyze various models of dependence among the experts.",
      "startOffset" : 135,
      "endOffset" : 147
    }, {
      "referenceID" : 25,
      "context" : "As we show in the full paper [27], the upper and lower bounds are both asymptotically tight.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 21,
      "context" : "The inability of Hoeffding’s inequality to guarantee consistency even in such a felicitous setting is an instance of its generally poor applicability to highly heterogeneous sums, a phenomenon explored in some depth in [23].",
      "startOffset" : 219,
      "endOffset" : 223
    }, {
      "referenceID" : 22,
      "context" : "Fortunately, an inequality of Kearns and Saul [24] is sufficiently sharp to yield the desired estimate: For all p ∈ [0, 1] and all t ∈ R,",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 23,
      "context" : "An elementary rigorous proof is given in [25].",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 24,
      "context" : "Following up, [26] gave a “soft” proof based on transportation and information-theoretic techniques.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 25,
      "context" : "We will need some simple lemmata, whose proofs are deferred to the journal version [27].",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 26,
      "context" : "There are various ways to model partial knowledge of expert competences [28, 29].",
      "startOffset" : 72,
      "endOffset" : 80
    }, {
      "referenceID" : 27,
      "context" : "There are various ways to model partial knowledge of expert competences [28, 29].",
      "startOffset" : 72,
      "endOffset" : 80
    }, {
      "referenceID" : 28,
      "context" : "(6)These adaptive bounds are similar in spirit to empirical Bernstein methods, [30, 31, 32], where the agent’s confidence depends on the empirical variance.",
      "startOffset" : 79,
      "endOffset" : 91
    }, {
      "referenceID" : 29,
      "context" : "(6)These adaptive bounds are similar in spirit to empirical Bernstein methods, [30, 31, 32], where the agent’s confidence depends on the empirical variance.",
      "startOffset" : 79,
      "endOffset" : 91
    }, {
      "referenceID" : 30,
      "context" : "(6)These adaptive bounds are similar in spirit to empirical Bernstein methods, [30, 31, 32], where the agent’s confidence depends on the empirical variance.",
      "startOffset" : 79,
      "endOffset" : 91
    } ],
    "year" : 2014,
    "abstractText" : "We revisit from a statistical learning perspective the classical decision-theoretic problem of weighted expert voting. In particular, we examine the consistency (both asymptotic and finitary) of the optimal Nitzan-Paroush weighted majority and related rules. In the case of known expert competence levels, we give sharp error estimates for the optimal rule. When the competence levels are unknown, they must be empirically estimated. We provide frequentist and Bayesian analyses for this situation. Some of our proof techniques are non-standard and may be of independent interest. The bounds we derive are nearly optimal, and several challenging open problems are posed.",
    "creator" : null
  }
}