{"title": "Gaussian Process Volatility Model", "abstract": "The prediction of time-changing variances is an important task in the modeling of financial data. Standard econometric models are often limited as they assume rigid functional relationships for the evolution of the variance. Moreover, functional parameters are usually learned by maximum likelihood, which can lead to overfitting. To address these problems we introduce GP-Vol, a novel non-parametric model for time-changing variances based on Gaussian Processes. This new model can capture highly flexible functional relationships for the variances. Furthermore, we introduce a new online algorithm for fast inference in GP-Vol. This method is much faster than current offline inference procedures and it avoids overfitting problems by following a fully Bayesian approach. Experiments with financial data show that GP-Vol performs significantly better than current standard alternatives.", "id": "a733fa9b25f33689e2adbe72199f0e62", "authors": ["Yue Wu", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato", "Zoubin Ghahramani"], "conference": "NIPS2014", "accepted": true, "reviews": [{"comments": "The paper introduces a GP-Vol model to flexibly capture the time-dependent changes in variance, and develops a new online algorithm for fully Bayesian inference under the model. \n\nThe paper is clearly written, the developed inference method seems technically sound, and the presented results look promising. My opinion on the model itself, using a non-parametric approach such as using the GP prior on the transition function (as in the paper), seems, though, a bit an obvious way of extending the prior work developed in the finance area. So, I wouldn't put too high grade on the paper in terms of its originality. However, overall the paper is nicely presented and convincing. \n\nHere are a few questions to the authors:\n\n(1) the savings in computation time compared the other methods looks very impressive, and results all look very promising. Have authors also tested higher order dependency on variances and returns, i.e., higher p and q than just 1? How is it different from the order-1 dependency in terms of computation time and algorithmic efficiency? can authors learn the optimal values for p and q from the data, maybe by computing test likelihood? \n\n(2) authors mentions bias introduced from the sampling from artificial dynamics in kernel. Have the authors quantify the bias? It would be more convincing to know when/how RAPCF fails, rather than just saying \"the issues have limited impacts in practice\". \n\n(3) I am not sure how authors can choose the shrinkage parameter, lambda, in practice. \n\n In this paper, the evolution of the time-varying variance is modeled by GP and the associated fully Bayesian inference method is presented. Overall, it is a well-written and technically sound paper.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper proposes a new nonparametric volatility model.\n\nThe contribution of the paper relies on the application of Gaussian process prior to stochastic volatility models. The inference approach is based on SMC and is a straightforward application of the Liu and West's APF algorithm.\n\nThe literature review lacks of some important references and the empirical comparison is not complete. My major concerns are the following:\n\\begin{enumerate}\n\\item The authors proposed a new stochastic volatility (SV) model, but in the introduction and in the paper there is no reference (e.g., Taylor (1987), Jacquier, Polson, Rossi (1994, 2004) to this class of models.\n\\item A comparison is proposed between GP-Vol and GARCH models, but the increased flexibility of a SV over the GARCH family has already been proved in the literature by many parts. See e.g. Fridman and Harris (1998). Thus I would strongly suggest the inclusion of a comparison between a standard SV model and the proposed GP-Vol model.\n\\item The author proposed a new nonparametric model, but no references is give to the recent advances in Bayesian nonparametric which make use of flexible prior processes such as Dirichlet processes (e.g., see Bassetti, Casarin, Leisen (2014), Griffin (2011), Griffin and Steel (2011)). \n\\end{enumerate}\n\nReferences:\n\\begin{itemize}\n\\item Jacquier, E., Polson, N., Rossi, P., 1994. Bayesian analysis of stochastic volatility models (with discussion). Journal of Business and Economic Statistics 12 (4), 371-417.\n\n\\item Jacquier, E., Polson, N., Rossi, P., 1994. Bayesian analysis of stochastic volatility models with fat-tails and correlated errors. Journal of Econometrics 122, 185-212.\n\n\\item Fridman, M., Harris, L., 1998. A maximum likelihood approach for non-Gaussian stochastic volatility models.\nJournal of Business and Economics Statistics 16 (3), 284-291.\n\n\\item Bassetti, F., Casarin, R., Leisen, F. (2014), Pitman-Yor Process Prior for Bayesian Inference, Journal of Econometrics, 180, 49-72. \n\n\\item J. E. Griffin. Inference in infinite superpositions of non-Gaussian Ornstein-Uhlenbeck processes\nusing Bayesian nonparametic methods. Journal of Financial Econometrics, 1:1-31, 2011.\n\n\\item J. E. Griffin and M. F. J. Steel. Stick-breaking autoregressive processes. Journal of Econometrics, 162:383-396, 2011.\n\\end{itemize} I would expect the authors improve the presentation of their contribution and provide a comparison with a standard SV model. I would suggest to accept the paper after revision.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper provides an alternative based on Gaussian processes (GP) to standard GARCH-related methods for modeling the time-varying volatility of financial time series. The benefit of the GP approach is greater flexibility.\n\nThis submission is technically competent, but not of broad interest or great novelty. The mathematics and the Bayesian algorithm are specialized for this problem.\n\nThe experiments look rather unfair. The synthetic datasets are well-specified for GPs and mis-specified for GARCH variants, so it is not surprising that GPs do well. For real data \"We used GARCH(1,1), EGARCH(1,1) and GJR-GARCH(1,1,1) models since these variants have the least number of parameters and are consequently less affected by overfitting\" It seems there was no attempt to regularize GARCH variants, or to choose the best level of complexity for them. Even so, the authors method performs best on only 58% of datasets.\n\nThe author of this review is an experienced professor at a research university and \"data science\" director in industry. My advice to the author(s) is to apply their strong technical skills to a broader problem, and/or a less theoretical application.\n\nCOMMENTS ON THE AUTHORS' RESPONSE\n\nThe response seems valid technically to me, so I have upgraded my numerical evaluation of the paper. I still believe that the paper is not of broad interest in machine learning. This reviewer has served on the PhD committee of students in econometrics. If this paper is of interest to that community, it should be published there. \n\nThe authors say that higher-order GARCH models do no better than almost-trivial GARCH models. The GP method here does better, but not dramatically so. As a practitioner in applied finance, I say that all these models are better as mathematics than as descriptions of reality. The research area needs to go in a different direction, back from mathematical sophistication towards insight into facts. Too narrow a problem.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
