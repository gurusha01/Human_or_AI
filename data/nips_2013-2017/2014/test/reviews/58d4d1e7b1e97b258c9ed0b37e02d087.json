{"title": "A Framework for Testing Identifiability of Bayesian Models of Perception", "abstract": "Bayesian observer models are very effective in describing human performance in perceptual tasks, so much so that they are trusted to faithfully recover hidden mental representations of priors, likelihoods, or loss functions from the data. However, the intrinsic degeneracy of the Bayesian framework, as multiple combinations of elements can yield empirically indistinguishable results, prompts the question of model identifiability. We propose a novel framework for a systematic testing of the identifiability of a significant class of Bayesian observer models, with practical applications for improving experimental design. We examine the theoretical identifiability of the inferred internal representations in two case studies. First, we show which experimental designs work better to remove the underlying degeneracy in a time interval estimation task. Second, we find that the reconstructed representations in a speed perception task under a slow-speed prior are fairly robust.", "id": "58d4d1e7b1e97b258c9ed0b37e02d087", "authors": ["Luigi Acerbi", "Wei Ji Ma", "Sethu Vijayakumar"], "conference": "NIPS2014", "accepted": true, "reviews": [{"comments": "In this article, the authors propose a framework for performing model comparison of Bayesian models on behavioral data. To do so, they summarize the Bayesian Decision Theory framework, pinpoint areas of non-identifiability, and outline the types of constraints that can be used to make each term in the Bayesian framework identifiable. They then make assumptions to constrain each term in the Bayesian framework, explore how differentiable parameter values are in their model, and apply the technique to two studies that use Bayesian decision theory to explain behavioral responses: time interval estimation and motion perception. \n\nIssues of identifiability of internal representations and processes have been prominent issues within cognitive science and psychology for decades. For example, Anderson (1978) analyzed when representational formats can mimic each other, proving that they are indistinguishable without some constraints on processes (whenever the representations make equivalent distinctions of their inputs).\nIn recent years, it is one of the major drawbacks of the Bayesian framework that has hindered its widespread adoption (e.g., Jones & Love, 2011; Bowers & Davis, 2012 \u2013 the latter directly addresses speed perception as an example). \n\nAlthough the article touches on an issue of great theoretical importance, is well written, and generally does so in a reasonable and effective manner, I have two major reservations with it. First, it ignores the large previous literature on model comparison within cognitive science and psychology, which makes it difficult to evaluate its contribution appropriately. The general framework for model comparison proposed by the authors is not so different from some of this previous work (e.g., Pitt, Myung, & Zhang, 2002; Navarro, Pitt, & Myung, 2004). Second, the authors make assumptions that seem arbitrary at times and it is unclear how much of their framework depends on them. For example, why should $p_{meas}$ be defined by equation 3? Is defining the values of the parameters in Equation 12 really enough to define and capture all the characteristics of a cognitive or perceptual process? I understand that it is robust and can express a large class of sensory models. However, it is not clear that is a sufficient justification for the assumption and at the very least, the article should discuss and justify the assumptions used to constrain the Bayesian models so that they are identifiable. \n\nMinor comments:\nLine 53: \u201cIt is a trivial mathematical fact\u2026\u201d It might be more helpful to explain why it is true rather than declare it trivial. It might not be trivial for all readers.\n\nLine 73: I believe the second \u201cnor\u201d should be an \u201cor\u201d.\n\nFigure 2: What do the star and dashed lines denote? From the caption, it sounds like they both denote the true value. \n\nReferences\n\nAnderson, J. R. (1978). Arguments concerning representations for mental imagery. Psychological Review, 85, 249-277.\n\nBowers, J. S., & Davis, C. J. (2012). Bayesian Just-So Stories in Psychology and Neuroscience. Psychological Bulletin, 138(3), 389-414.\n\nJones, M., & Love, B. C. (2011). Bayesian fundamentalism or enlightenment? On the explanatory status and theoretical contributions of Bayesian models of cognition. Behavioral and Brain Sciences, 34, 169-188.\n\nNavarro, D. J., Pitt, M. A., & Myung, I. J. (2004). Assessing the distinguishability of models and the informativeness of data. Cognitive Psychology, 49, 47-84.\n\nPitt, M. A., Myung, I. J., & Zhang, S. (2002). Toward a Method of Selecting Among Computational Models of Cognition. Psychological Review, 109(3), 472-491. (also see Myung, Pitt, Zhang, & Balasubramanian, 2000 NIPS 13).\n\n A well-written article on an issue of great importance, but missing links to previous related work.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The manuscript tackles the important issue in cognitive modeling of\nmodel identifiability. The manuscript is nicely written and quite clear.\nHowever, the work is premised on a long list of assumptions that one\nmust buy into and make sense of, and this list is quite long relative\nto the impact of the key results presented. Because the methodology\nis interesting and innovative, I judge the work to be above threshold\nfor presentation at NIPS.\n\nInsofar as key results go: In section 4.1, the interchangeability of sensory\nand motor noise was little surprise (I questioned incorporating both into\nthe model as I was reading). It would help to indicate which condition\ndifferences were reliable. (Maybe I'm just too dumb to read box plots.)\nIn section 4.2, isn't it essential to show that if the reference\nobserve did not have a slow-speed prior, the model could recover this\nfact as well?\n\nSpecific comments:\n\nline 106: Why is the stimulus drawn from a discrete distribution when it in\nfact a continuous variable? I assume this is due to the typical\ndesign of experiments, where the stimulus level is the independent\nvariables. But the authors may wish to clarify this point.\n\nline 134: As the authors note, the log-stimulus transform (Equation 2) is\nmotivated by psychophysical laws. It seems that the success of their work\nmay be due in large part to the incorporation of this transform.\nThat is, the transform imposes a fairly strong constraint on inference\nand thus, this work is really saying that Bayesian models are identifiable\ngiven strong assumptions about representational transformations in the mind.\n\nline 143: Do the constraints in Eq 4 and the maximization of differential\nentropy ensure that Eqn 3 is fit to be a unimodal distribution? It seems like\nthe fit could yield in principle a bimodal distribution.\n\nline 158: Why should the observer's prior favor the lattice representation\nover a uniform representation? What does the user know about the true\nstimulus distribution that allows them to have a prior which is 50% wider\nthan the true range?\n\nFigure 1: Even after staring at the figure, I feel more confused by it\nthan enlightened. It seems like it would be clearer if Figure 1b were\nintegrated into Figure 1a, and p_est(s^*|x) were removed from the\nFigure, since it is a derived inference.\n\nline 252: Can the authors comment on the conditions on N that\nmake Equation 14 approximately correct, i.e., when Stirling's approximation\nof the factorial and the holds, and under what circumstances E[xlogx] ~=\nE[x]logE[x]. I have to say that by the point where the authors come up\nwith Equation 15---having abandoned priors on \\theta and made some\nquestionable approximations---I feel that Equation 15 is justified only\nby the fact that it yields an intuitive rule for assessing similarity\nof predictions.\n\nline 262, \"sample from this unnormalized density\": Which density? The dataset\ndistribution?\n\nline 365: Why does learning of priors not matter in 2AFC? Innovative approach, important problem, less than overwhelming results", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper describes a Bayesian model of perception (mathematical equations for sensory noise, likelihood function, prior probability distribution, loss function, response distribution). A significant strength of this model is that it combines both robustness and mathematical convenience. That is, the model can handle many different types of situations (e.g., stimulus-dependent noise) and still be computationally convenient (e.g., inference is tractable). The paper places emphasis on the fact that the model is identifiable (i.e., two parameter estimates can be easily evaluated and distinguished). \n\nI like this paper and would like to see it accepted to the NIPS conference. The proposed model provides a mathematically elegant framework for formalising perceptual estimation in many experiments. At the same time, I have some reservations. I believe that the proposed model is very much in the same spirit and style as other models that have recently appeared in the literature (often in the journal PLoS Computational Biology), and thus the novel contribution of this paper is incremental. For example, the reader may consider the following papers:\n\nAcerbi, L., Wolpert, D. M., & Vijayakumar, S. (2012). Internal representations of temporal statistics and feedback calibrate motor-sensory interval timing. PLoS Computational Biology, 8 (11), e1002771.\n\nAcerbi, L., Vijayakumar, S., & Wolpert, D. M. (2014). On the origins of suboptimality in human probabilistic inference. PLoS Computational Biology, 10 (6), e1003661.\n\nThe current submission is not identical to these (or other) earlier articles but it is similar enough (to these and other earlier articles) that I think that it is fair to state that the contribution of the current submission is \"incremental\".\n\nI suggest that the authors revise the manuscript by including a new section in which they review recently proposed Bayesian models of perception, and clearly state why the model proposed in the current submission is a significant advance over previously published models.\n\nOne more comment. The submission emphasizes the fact that the model is mathematically identifiable. That is true, but parameters are only identifiable due to the mathematical assumptions of the model. The term \"identifiable\" can be used in other ways. For example, the model could not be used to firmly distinguish whether an experimental subject's errors are due to sensory noise, decision noise, or response noise. As a result, it would be justified to say that the model does not help with the identifiability issue with which most perceptual scientists are concerned. Please comment on this in the revised manuscript.\n Mathematically elegant framework for formalising perceptual estimation. However, the novel contribution is incremental (closely related work already exists in the literature).", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
