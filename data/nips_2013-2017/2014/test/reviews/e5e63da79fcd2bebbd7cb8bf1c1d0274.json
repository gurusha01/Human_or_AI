{"title": "Deep Learning Face Representation by Joint Identification-Verification", "abstract": "The key challenge of face recognition is to develop effective feature representations for reducing intra-personal variations while enlarging inter-personal differences. In this paper, we show that it can be well solved with deep learning and using both face identification and verification signals as supervision. The Deep IDentification-verification features (DeepID2) are learned with carefully designed deep convolutional networks. The face identification task increases the inter-personal variations by drawing DeepID2 features extracted from different identities apart, while the face verification task reduces the intra-personal variations by pulling DeepID2 features extracted from the same identity together, both of which are essential to face recognition. The learned DeepID2 features can be well generalized to new identities unseen in the training data. On the challenging LFW dataset, 99.15% face verification accuracy is achieved. Compared with the best previous deep learning result on LFW, the error rate has been significantly reduced by 67%.", "id": "e5e63da79fcd2bebbd7cb8bf1c1d0274", "authors": ["Yi Sun", "Yuheng Chen", "Xiaogang Wang", "Xiaoou Tang"], "conference": "NIPS2014", "accepted": true, "reviews": [{"comments": "This paper's core finding is that combining an identity classification task as well as metric-learning-style verification task helps to learn better features for face classification/verification. The \"verification task\" here tries to decrease feature-space distance between instances of the same identity, and increase distance between those of different identities. This improvement is embedded in a state-of-the-art system for face verification, which uses convnets trained on many (400) different views to generate features, distilled into a small set of 25 using feature selection. Very good results are obtained and experiments performed using LFW as a test set.\n\nOverall, these are very good results obtained using a somewhat complex pipeline, and a good investigation into the contribution of each \"task\" in the loss for feature learning. Combining the tasks has been hinted at before (e.g. siamese network after classification pre-training for DeepFace), but this work brings this out specifically. Some of the writing could be a bit less dry (and edited for English), but this does not interfere with the understanding of the paper.\n\nFurther comments:\n\n* I don't understand how \"m\" in eqn 1 was selected. If it is learned as a parameter, it seems it would collapse to m=0, or at most the minimum ||fi-fj|| (even with the procedure indicated at l.152), since this would always give zero Verif error for negative pairs.\n\n* Is there a more concrete reason why including the identification task improves verification performance and/or learning (\"richer information\" is a bit vague)? E.g. the gradient from the verification task pushes apart just two points, while the softmax grad in the identification task pushes the correct identity away from the classification-layer templates for *all* other identities at the same time.\n\n* It would be nice to see individual performance of the best few selected network regions/views, or an evaluation using 1, 2, 4, ..., 25 views. The final combination achieves good performance, but it would be good to also see the individual contributions.\n\n* l.38 \"eternal topic\": this is an odd choice of word (it implies the topic will be debated forever, when in fact it seems to be making good progress); a \"central topic\" may be better here.\n This is a well-described state-of-the-art system, and explicitly explores the effect of using each of two tasks during feature learning. It seems a bit incremental in its contributions, putting together several existing ideas, but I don't see this as a major drawback.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper studies the face recognition problem by using a deep learning framework. The key idea is to learn features by using both face identification and verification signals as supervision. This will simultaneously enlarge inter-personal differences and reduce intra-personal variations. Such a motivation is simple and it has been widely studied before, e.g. LDA. Bringing such a technique into the deep learning framework is novel to me, and the obtained 99.15% verification accuracy on LFW is the best result compared with state-of-the-art. \n\nThis paper is also very well written. They also provides several experiments to verifiy their idea from different perspectives.\n A novel deep learning frmework by using both face identification and verification signals as supervision is proposed. The best 99.15% verification accuracy on LFW is achived. The idea is simple and the performance is very well.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "Summary\nThe paper proposes a face verification method using deep convolutional neural networks based on identification (e.g., softmax classifier) and verification objectives with landmark-based multi-scale approach. The approach in this paper is very closely related to the work of [18] except 1) the training objective is augmented with verification objectives and 2) the selection of patches (location and scale) proposed by facial landmarks. The model is trained on CelebFaces+ database and evaluated on LFW, achieving state-of-the-art performance on face verification.\n\nQuality\nThe paper introduces few neat ideas to extend the previous state-of-the-art system on face verification and the experiments are well executed.\n\nClarity\nThe paper is clearly written. Here are some comments:\n1) I think more head-to-head comparison to the work of [18] is necessary as both follow the almost identical verification pipeline except for details.\n2) Details about training m (margin, Equation (1)) is required (e.g., training/updating m doesn\u2019t appear in Table 1.\n3) The best verification accuracies in figures and tables (e.g., figure 3, 4, table 2, 3, and 4) do not match. Having more complete captions for tables and figures with details about experimental setting would be helpful.\n\nOriginality\nAlthough the techniques are all existing, it doesn\u2019t seem to hurt the paper as it combined the ingredients well and executed to show state-of-the-art performance.\n\nSignificance\nFace verification is an important problem and deep learning has shown recent success on this problem. This paper further pushes the bar and makes the paper significant. It could be more significant if authors can include the evaluation result on YouTube Face database, which is bit more challenging dataset.\n The paper extends the previous work by augmenting the CNN objective function with verification objectives and adopting better region selection algorithm. The paper demonstrates the state-of-the-art face verification performance on LFW database.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
