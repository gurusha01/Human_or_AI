{"title": "Causal Inference through a Witness Protection Program", "abstract": "One of the most fundamental problems in causal inference is the estimation of a causal effect when variables are confounded. This is difficult in an observational study because one has no direct evidence that all confounders have been adjusted for. We introduce a novel approach for estimating causal effects that exploits observational conditional independencies to suggest <code>weak'' paths in a unknown causal graph. The widely used faithfulness condition of Spirtes et al. is relaxed to allow for varying degrees of</code>path cancellations'' that will imply conditional independencies but do not rule out the existence of confounding causal paths. The outcome is a posterior distribution over bounds on the average causal effect via a linear programming approach and Bayesian inference. We claim this approach should be used in regular practice to complement other default tools in observational studies.", "id": "57aeee35c98205091e18d1140e9f38cf", "authors": ["Ricardo Silva", "Robin Evans"], "conference": "NIPS2014", "accepted": true, "reviews": [{"comments": "This paper is concerned with the problem of estimating the average causal effect (ACE) between two (binary) variables when the causal structure over the covariates is not fully given. It considers a rule proposed in Entner et al. (2013) that aims to select a set of observed covariates that is sufficient to block all back-door paths. For Entner et al.\u2019s purpose, however, the rule is justified only under the faithfulness assumption. This paper proposes to use the rule to provide bounds rather than point estimates of the ACE, and develops a method following Ramsahai (2012). \n\nI have to admit that I haven\u2019t digested all the technical details, but the main idea makes sense to me and seems interesting and useful. What puzzled me, however, was that I didn\u2019t really see the role of the conditions in Entner et al.\u2019s rule in this approach. Without the faithfulness assumption, those conditions do not have obvious implications for the causal structure. My best guess is that the conditions, if verified, are relevant to the choice of the relaxation parameters, but the paper explicitly puts that matter aside. It seems to me that the machinery does not crucially depend on the conditions in Entner et al.\u2019s rule, and I wonder if the apparent robustness of the method in the experiments has anything to do with this. I would appreciate a clarification on this issue.\n\nSome minor comments:\n\n1. First paragraph of Section 3, \u201c\u2026 express violations of faithfulness as bounded violations of local independence \u2026\u201d This sounds strange. Isn\u2019t unfaithfulness a matter of allowing extra independence rather than violating independence? It seems to me that the proposed framework is actually intended to allow/express \u201calmost violations\u201d of faithfulness by constraining the magnitude of dependence.\n\n2. In the experiments, it may be helpful to also report the performance of Entner et al.\u2019s method when their stringent thresholds are used, taking the answer of \u201cdon\u2019t know\u201d as reporting uninformative bounds. \n\n3. In the second paragraph on p. 8, if \u201cX=1 means the patient got a flu shot, Y=1 indicates the patient was *not* hospitalized\u201d, why does a negative ACE suggest a desirable vaccine?\n\n4. \u201cTable 1\u201d on top of p. 8 is cited as \u201cTable 5\u201d in the text. \n This is an interesting paper, though the details are not easy to follow.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper proposes a new approach to derive the bound of the average causal effect (ACE) from a variable X to another Y. Its main principles is the use of Entner's Rule 1 in its inverse direction, the relaxation of the faithfulness assumption to introduce possibility of the path-cancellation at some degree, and the introduction of assumptions represented by some inequality constraints. A computation scheme of the ACE bound are formulated by using linear programing under these principles. Though the authors have not optimized the algorithm to derive the bounds yet, the resulted bounds seem very narrow and accurate in comparison with the other approaches in state of the art.\n\nQuality\nThe authors tried to establish a novel method to derive more accurate bound of ACE than the state of the art. They combined several feasible principles and succeeded to provide the tighter bounds. In this regard, the content of the paper is very interesting. \nHowever, some criteria to define the bounds are not comprehensively explained. Particularly, the validity of the use of Entner's Rule 1 in the inverse direction is not clearly discussed. For its use in the inverse direction, the authors should explicitly assume the structure depicted in Fig.2. This should be clearly explained and discussed.\nIn addition, the generic criteria to choose appropriate parameters for relaxation are not provided. Since these affect the result of the bounds significantly, the principle to determine the parameters should be more investigated and included in the work.\n\nClarity\nThe explanation of the paper on the theoretical part seems basically comprehensive except the essential discussion I pointed out above. \nHowever, the demonstration of the experimental results are not well described. As I pointed out above, the actual implementation of the algorithm is not comprehensively explained. The definition of the parameters shown in Table 1 (Table 5?) are not clearly given.\nIn addition, I see some typos. For example;\n\"The full algorithm is shown in Table 1.\" on page 6=> I do not see any table of algorithm.\n\"Results are summarized in Table 5.\" on page 8=> I do not see Table 5 (maybe Table 1).\n\nOriginality\nThe problem setting of this paper has been addressed by some earlier work as the authors pointed out. In this regard, the scope of this paper does not have very string originality. \nThe idea to combine the three ideas in a unified shape contains some originality. But, as I pointed out above, the validity of the combination is not very clearly discussed.\n\nSignificance\nIn terms of deriving the tighter bounds of ACE, this method shows some significance. However, its performance has been check by quite limited experiments. It generality in both theory and wide experiments has not been strictly assessed. The paper addresses an important problem which is to evaluate the bound of the strength of causal relations. However, the validity of the presented idea should be more well described in both theory and experiments.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper describes the so-called Witness Protection Program (WPP) algorithm to compute bounds on an inferred average causal effect (ACE) that takes possible violations of the standard faithfulness assumption in causal inference into account. \nIt does so by introducing a set of relaxation parameters to constrain unfaithful interactions, and then uses a linear programming framework to solve for the resulting upper and lower bounds on the ACE for a given link by adjusting for an appropriate set of covariates, subject to these constraints.\n\nThis problem currently receives a fair amount of attention, so the paper is both timely and interesting. I like the approach and ideas introduced in the paper: it is a principled attempt to explicitly quantify the impact of (weak) unfaithful interaction patterns, in combination with well-known mathematical tools to solve the corresponding maximization/minimization problems.\n\nWhether or not they found the right method to capture this impact remains to be seen. The resulting output is hard to interpret from a conceptual point of view: a distribution over bounds which are a function of 'unfaithful relaxations' relative to a given model ... but how likely these unfaithful instances are, and with it how relevant/realistic these bounds themselves are remains unclear. Many relaxations lead to wide bounds to the point where they can become less than useful. The method does not commit to any preferred point estimate within the interval ... even though people are likely to interpret it that way. \n\nExperimental evaluation is poor: the 'bias' evaluation metric is meaningless in comparing the WPP method with its competitors as they literally measure two completely different things. As a result it is unclear if the WPP output is a valuable addition to practitioners or merely a complicated distraction. Also the practical performance on the influenza data set is worryingly weak: ACE in (-0.23,0.64) implies next to no possible relevant conclusion ... although that could be the fairest assessment of them all.\n\nQuality\nThe approach introduced in the paper is technically sound, with many details explicated in the supplementary file (I did not check any details in there). Ideas are well introduced, although the overall context is lost on occasion. Important aspects like choosing the relaxation parameters are relegated to a future article, which makes it difficult to get a feel for potential issues with this part of the method. Experimental evaluation is not balanced or robust enough. \n\nClarity\nDecently written (with exception of conclusion, see comments below). The algorithmic steps and subsequent modifications in terms of many subtly different parameters was quite hard to follow, in part due to lack of explanation of certain details of the method. (I think I understand what happens, but I am not sure I could fully implement it from just this description; supplement may just be sufficient).\n\nOriginality\nAs far as I can tell the method is a novel combination of familiar techniques. It is closely related to, but sufficiently different from recent work on the same problem. As such it may stimulate a fruitful cross-fertilization of several approaches on the subject.\n\nSignificance\nThe significance of the paper mainly lies in the ideas and direction it brings to the problem, showing how to incorporate other techniques in solving this highly challenging problem. In its current implementation it seems unlikely to represent the finished article for practitioners, although some of the ideas employed in the WPP algorithm could well end up playing an important role. \n\nSummary:\nRelevant and highly topical problem. Interesting method that will undoubtedly find an audience. Current application limited, but likely to extend to other, more general cases. Reasonably well written, though could be improved. Technically interesting solutions. Experimental evaluation is poor. Relevance and proper interpretation of output distribution over bounds remains unclear.\n\n----------------\nOther comments:\np1/5: 'Witness Protection Program' - > great name for an algorithm \np1/47: 'unstable' is not the right word (they are stable, but may not hold true) \np2/74: 'cartoon representation'?\np2/93-94: technically this also assumes causal sufficiency or knowledge W - > X\np3/127: explain that witness W is itself not needed in the computation of the ACE, only as a means to identify set Z\np3/143: typo 'an useful' \np3/144: 'gives greater control over violations of faithfulness' : too vague as I do not see the control aspect \np4/164: might - > can; \n idem: '(conditional)' - > remove or change to '(unconditional)' , as always W dep. U | X \np4/172-180: very sudden transition in level of abstraction; hard to interpret for readers less familiar with the subject - > explain / give some intuition on what these parameters represent,\np4/183: link to original introduction in (1),\np4/185-189: again interpret the constraint parameters; (easily misread as weak interactions)\np5/221: briefly describe the relation between the search part and the bounds computation,\nidem: explain how the identification of admissible sets Z for W depends on the relaxation parameters theta\np5/239: 'Background ... used here.' - > sentence/purpose unclear: used how? important for the paper?\np5/259: to be clear: you mean max. 10 free parameters to describe the entire set Z, not a set of 10 variables, right?\n\np6/304: 'We know of no previous analytical bounds' - > This seems closely related to recent papers such as 'Estimating Causal Eff ects by Bounding Confounding' (Geiger, Janzing, Sch olkopf, UAI2014)\np6/305: as a last-minute reviewer I have not checked the supplementary material in detail\np6/319-332; I like the method but I doubt the practical efficacy of the back-substitution process in refining bounds; seems rare to be able to exploit such constraint violations, (can you give some idea of how effective this step is in section 5?)\np7/350: 'more than one bound' - > this is due to different possible admissible sets for different witnesses right?\np7/357: 'comparison is not straightforward' - > no: the subsequent trivial optimal example shows that comparison based on the bias metric is meaningless.\np7/360: 'only about 30% of the interval (-1,1)' - > that still covers (0,0.6) which implies 'anywhere between a strong causal link and no causal link' ...\np7/369: '5000 points' - > typical (medical) trials often have a lot less data available: worried about the impact on the size of the bounds for say 500 records,\np8/384: it is completely impossible to gauge meaningful information from Table 1 on the benefit of using WPP over the standard point estimate using faithfulness.\np8/391: 'WPP is quite stable' - > seems like a nice way of saying that the bounds derived by WPP are so loose that they don't even depend on whether the problem is solvable or not \np8/406-8: 'This does not mean ... within the bounds.' - > this is a crucial statement for interpretation: many casual readers will read the bounds as a confidence interval around the best guess value. It also highlights the difficulty in using the WPP results in practice: what do the bounds we derive actually mean? \n\np8/421+: 'risky Bayesian approaches', 'WPP bounds keep inference more honest' - > emotive language that suggests a biased evaluation and/or erroneous interpretation of results\nidem: 'providing a compromise' - > WPP is not a compromise but focusses on an additional aspect of the overall inference problem,\nidem: 'and purely theory-driven analyses that refuse to look at competing models' - > I have no idea what you refer to in this statement, but it definitely sounds unduly dismissive\np9: typo ref 9: inuenza Relevant and highly topical problem. Technically and conceptuallyinteresting method that is likely to extend to more general cases.Reasonably well written, though could be improved. Experimentalevaluation is poor. Relevance and proper interpretation of outputdistribution over bounds remains unclear.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
