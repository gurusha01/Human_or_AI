{"title": "Multi-View Perceptron: a Deep Model for Learning Face Identity and View Representations", "abstract": "Various factors, such as identities, views (poses), and illuminations, are coupled in face images. Disentangling the identity and view representations is a major challenge in face recognition. Existing face recognition systems either use handcrafted features or learn features discriminatively to improve recognition accuracy. This is different from the behavior of human brain. Intriguingly, even without accessing 3D data, human not only can recognize face identity, but can also imagine face images of a person under different viewpoints given a single 2D image, making face perception in the brain robust to view changes. In this sense, human brain has learned and encoded 3D face models from 2D images. To take into account this instinct, this paper proposes a novel deep neural net, named multi-view perceptron (MVP), which can untangle the identity and view features, and infer a full spectrum of multi-view images in the meanwhile, given a single 2D face image. The identity features of MVP achieve superior performance on the MultiPIE dataset. MVP is also capable to interpolate and predict images under viewpoints that are unobserved in the training data.", "id": "140f6969d5213fd0ece03148e62e461e", "authors": ["Zhenyao Zhu", "Ping Luo", "Xiaogang Wang", "Xiaoou Tang"], "conference": "NIPS2014", "accepted": true, "reviews": [{"comments": "This paper presents a novel way to do multi-view representation of faces using a neural-net like model with deterministic and probabilistic units. The network is trained to recover the identity and view. It can be used to synthesize a new view as well. Generally, the paper does a good job at disentangling the contributing factors to the success of the method, and the results seem quite good.\n\nI wish the authors presented more evidence for why they chose to design their model they way they did. For one, it is not clear that a non-deterministic approach is really needed in this case -- could they have done a model that is fully feed-forward with deterministic neurons? It would have certainly avoided the need to variational/importance sampling inference.\n\nQuality: generally, a good paper with an interesting and well-grounded model, evaluated well on a competitive benchmark and \n\nClarity: The paper is well-written and easy to read, for most of the part.\n\nOriginality: in some sense, the approach is comparable to the work of Geoff Hinton and collaborators, who use stacks of Restricted Boltzmann Machines, where the top RBM can have the label as a side\n\nSignificance: this is likely to be of interest to the facial recognition community, but also to other researchers who work on problems where a hybrid deterministic and generative approach may be a good solution.\n\nComments and questions:\n\n- How did the authors come up with the structure in Figure 2? What are the insights behind the design choices made?\n- The authors should define q(h) at line 165\n- Is the MCEM method crucial to the model presented? More analysis on why this particular optimization method was used is in order since MCEM is not exactly a widely used method in the community.\n- For inference: how big is S at line 235? How expensive is inference generally? Some numbers and O() notation results would be good.\n- Is LDA necessary to get the best results? How do the results look like without LDA?\n- I don't think the authors should be using the tangent with how the brain works, except very sparsely. There is not much evidence that the presented method is particularly close to how humans do facial recognition or view point interpolation. \n- Did the authors try their approach on the Labeled Faces in the Wild benchmark? If yes, do they have results to report?\n An interesting novel approach to solving the face recognition problem using a graphical neural net-like model that is trained to recover the identity of the input face and its view. Competitive results on the MultiPIE benchmark and interesting solid experiments.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper proposes to use an Autoencoder with both deterministic and stochastic units to learn to reconstruct faces of the same person under different 3D viewpoints.\nIt is well written and the experiments are pretty solid.\n\nThe model in Fig. 2 have certain resemblance to the one in [25]. The main difference is that the v is added and it is predicted by both y and h3. This is useful to be able to use feedforward prediction of v instead of using Bayes rule. It is perhaps a good idea to discuss these differences in the text.\n\nminor:\nabstract: 'instinct' could be changed to 'intuition' or 'insight'\n\nin figures 1 and 6 are the examples test or training images?\n\nTo make the paper stronger, the authors can try to use the STOA Siamese CNN approach of [24] and see how it compares to the proposed methods. This paper proposes to use an autoencoder for pose representation learning on faces data. The problems are interesting and the experiments seems to suggest the usefulness of the approach.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper studies multi-view face recognition in constrained environments. The paper proposes a multi-layer multi-view perceptron (MVP) network to infer the identity and view angle representations by deterministic and random neurons from a single 2D image. The MVP is able to synthesize new view of faces from a single 2D face by a sequence of view representations. The paper derives the Monte Carlo Expectation Maximization (MCEM) procedure to learn the MVP from a pair of faces plus the view label, assuming the output face follows a conditional diagonal Gaussian distribution. The MVP is learned from 200 persons in the MultiPIE dataset and the identity features are employed to classify the reset 137 persons by LDA, which achieves comparable performance as the recent methods using convolutional neural networks.\n\nThe paper proposes a novel MVP network to disentangle the face identity and view angle representations, and employs the identity features in LDA for multi-view face recognition. Varying the view angle feature in MVP can synthesize new face views. Overall, the technical approach is sound with some limitations and the performance on the MultiPie is very competitive. Some technical concerns are as follows.\n\nThe approach seems to depend on well-aligned normalized 32X32 face images. The experiments on face recognition among 137 persons on MultiPIE leave the scalability of the proposed method in question. It is unclear if the method can benefit from more training samples and how to extend the approach for unconstrained face recognition in real applications.\n\nHow critical to assume the conditional diagonal Gaussian distribution for the output y? How many training pairs from 200 persons in MultiPIE are used to learn the MVP? Why the new face views have to be \"sequentially\" synthesized? \n\nThe claim that this new MVP \"simulates/mimics how human brain encodes view representations\" is quite weak. The paper presents no convincing evidence or discussion on how human brain encodes view representations and why the mechanism is similar to MVP. So I would not list this as one key contribution of the paper. \n This is a descent work on multi-view perceptron (MVP) learning for multi-view face recognition. The performance on the MultiPIE is competitive. Though I have the concerns on the scalability of this method and how to apply it to a face recognition system.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
