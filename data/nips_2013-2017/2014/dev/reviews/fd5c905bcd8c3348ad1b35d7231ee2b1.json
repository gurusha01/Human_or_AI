{"title": "Analysis of Brain States from Multi-Region LFP Time-Series", "abstract": "The local field potential (LFP) is a source of information about the broad patterns of brain activity, and the frequencies present in these time-series measurements are often highly correlated between regions. It is believed that these regions may jointly constitute a ``brain state,'' relating to cognition and behavior. An infinite hidden Markov model (iHMM) is proposed to model the evolution of brain states, based on electrophysiological LFP data measured at multiple brain regions. A brain state influences the spectral content of each region in the measured LFP. A new state-dependent tensor factorization is employed across brain regions, and the spectral properties of the LFPs are characterized in terms of Gaussian processes (GPs). The LFPs are modeled as a mixture of GPs, with state- and region-dependent mixture weights, and with the spectral content of the data encoded in GP spectral mixture covariance kernels. The model is able to estimate the number of brain states and the number of mixture components in the mixture of GPs. A new variational Bayesian split-merge algorithm is employed for inference. The model infers state changes as a function of external covariates in two novel electrophysiological datasets, using LFP data recorded simultaneously from multiple brain regions in mice; the results are validated and interpreted by subject-matter experts.", "id": "fd5c905bcd8c3348ad1b35d7231ee2b1", "authors": ["Kyle R. Ulrich", "David E. Carlson", "Wenzhao Lian", "Jana S. Borg", "Kafui Dzirasa", "Lawrence Carin"], "conference": "NIPS2014", "accepted": true, "reviews": [{"comments": "The manuscript describes a very interesting model for the analysis of brain states for multi-region LFP time-series. The time-series are separated in different time-windows. An infinite mixture of Gaussian Processes is considered to model the observations in each window. Brain states are assigned to each observation by means of an underlying HDP and brain regions are assigned to clusters by means of a HDP. The paper is original and overall clearly written, but the interpretation of the results needs some improvement. More specific comments are below:\n\na) Please clarify the algorithm used to separate the time-windows. That's very important and can affect considerably the results. \n\nLine 41: you should clearly distinguish between brain connectivity and brain states. \n\nLine 100: \"each window is considered a single observation\" Since you are not summarizing the observations in each window in a statistic, the statement has no clear meaning to me\n\nLine 098 and following: There's a bit of confusion in the notation, Are the windows different in each region, as suggested by \"For each region, the time-series is split...\", or the windows are common across regions as suggested by the model formulation?\n\nLine 107 What is L? How do you choose it? \n\nLine 113: In (1) \\lambda_g^{(a)} should be explicitly written down. Is it a vector across states or animals? That becomes clear only on line 124\n\nLine 183: Once (6) is established, the induced joint distribution over all windows is not block diagonal anymore. Worse, the joint distribution is not even well defined, since the joint covariance matrix is not semi-definite positive anymore. As a matter of fact, your infinite mixtures of Gaussian Processes is not a Process anymore, which is odd. This limitation should at least be acknowledged. \n\nSection 2.2 Gaussian Processes are probably not the best to describe brain connectivity in each given state. The covariance function depends on only a few parameters and cannot reproduce the pattern of sparsity of the brain (even when coupled across regions). This limitation, again, should be acknowledged. \n\nSection 2.3 I don't see the necessity of this section. Since you are decomposing a matrix of latent probabilities, way down in the hierarchy, the tensor characterization seems quite silly to me. \n\nLine 414 The statement is repeated (see line 410). In addition, the explanation is very weak. The results may depend on the choice of the clustering mechanism. It is well known that the DP shouldn't be used for cluster analysis in an absolute way (Antoniak, 1974; Miller and Harrison, 2013). Besides, you fix the parameters of the DPs (see line 333). Hence, your conclusions don't seem well supported. \n\nLine 418: What's the significance of this \"network\" with respect to the literature?  The paper is interesting, original, and overall clearly written, but the interpretation of the results needs some improvement.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "In this paper, the authors describe a HMM-based model for analysing local field potential data. The generative model assumes that for any particular window (short time period), the brain is in one of a set of discrete states. Conditioned on the state, the different brain regions are then assigned to particular LFP clusters and conditioned on the cluster, the observed data is generated from a GP. Variational Inference is performed using three data sets - toy data, mouse sleep data, and mouse novel environment data. Performance on the toy data is very good (to be expected as the data are generated from the model). Performance on the other datasets is harder to gauge, although this is due to the nature of the problem.\n\nQuality: this paper is of high quality. There is interesting technical development coupled with an interesting problem area. The model proposed is well presented and the performance appears (as far as it is possible to tell) to be good. I have no real criticism with the paper.\n\nClarity: very well written and very clear.\n\nOriginality and significance: the paper tackles an important problem. For me, the originality is predominately in the application of this class of algorithm to this problem - I don't feel that there is a huge amount of originality in the technical development itself. The authors propose a HMM-based model for analysing LFP data and assess it using real data from mice. The model is hierarchal, assuming that the observed data for each region comes from a region specific cluster which is itself conditioned on a global brain state. The performance on the datasets considered is good.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "SUMMARY\n\nThis paper reports a bespoke variational scheme for inverting state-space models of spectral density implicit in LFP time-series. In particular, its contribution is to provide a bespoke variational inversion using a hidden Markov model of discrete brain states that generate activity, where the form of spectral responses provides a Gaussian process model for the time-series. I thought that this was an interesting if colloquial application of variational Bayes that may need to be contextualized within the broader church of dynamical causal modelling \u2013 and its application to neurobiological time-series.\n\nCOMMENTS TO AUTHORS\n\nI enjoyed reading this interesting and detailed description of a variational state-space model inversion for time-series. Technically, this was an impressive piece of work. My main suggestions would be to contextualize this within the broader church of dynamic causal modelling and highlight the potential usefulness of your scheme. Perhaps you could consider the following:\n\n1)\tIn the neurosciences, the variational inversion of state-space models of electrophysiological time-series is usually described in terms of dynamic causal modelling. In fact, there is a literature on the dynamic causal modelling of cross spectral density that has been applied to multi region LFP time-series (and MEG). I think it would be scholarly to look at this work. You can find an overview of dynamic causal modelling at:\n\nhttp://www.scholarpedia.org/article/Dynamic_causal_modeling\n\nYour special contribution is a state-space model that is formulated in terms of a hidden Markov model. This contrasts with usual DCMs that are based upon differential equations. You might want to highlight this because it is particularly useful for things like steep staging or endogenous transitions among different brain states. \n\n2)\tYour description of the generative model is framed for a machine learning audience (with things like spectral mixture kernel and Gaussian processes). However, your rhetoric may confuse people in engineering and signal processing (and neurobiology). It would be useful to link your terminology to more standard concepts (perhaps in a glossary). For example, the Fourier transform of your spectral mixture is simply the auto-covariance function. Furthermore, your use of the word kernel is colloquial. In other fields, the kernel will be taken to mean the impulse response function or first order Volterra kernel whose Fourier transform is the transfer function (that corresponds to the spectral mixture). It might be useful to clarify terminology here?\n\n3)\tWhen you introduce the bound on model evidence or marginal likelihood, could you describe this as the variational free energy? This will enable people to see the connections between the use of variational free energy in dynamic causal modelling and in your application.\n\n4)\tTo illustrate the potential usefulness of your approach perhaps you could make more of the clusters implicit in the sleep data. Perhaps with something like:\n\n\u201cTo illustrate the potential importance of our (Bayes-optimal) states-space model inversion, we can now relate the clusters identified during sleep to classical sleep staging schemes (four distinct states). By examining the similarity between the clusters (spectral mixtures) we identified and the classic spectral profiles, we can see how stage four can be decomposed into three sub-stages\u2026\u2026\u201d\n\nI am not sure how you would do this but it would be very nice if you could provide a proof of principle that your approach can take us beyond what we already know.\n\nMINOR POINTS\n\n1)\tIn the abstract, I would say: \u201cThe model is able to estimate the number of brain states\u2026.\u201d\n\n2)\tOn page 2, it is not clear which of \u201cthe above two methods\u201d you are referring to. Can I suggest you say:\n\n\u201cMore recently new methods for tensor factorisation have been developed: in reference 7, tensor factorisation was applied to short-term FFT\u2026\u2026\u2026\u2026.\u201d\n\nThis will make it clear that the tensor factorisation does not refer to the current paper. \n\n3)\tBelow Equation 6, I would say the parameters describe the auto-correlation content associated with each y\u201d. I know what you mean but you are actually characterising data in the time domain not the spectral domain. In other words, you are using spectral mixtures to provide constraints on the Gaussian process.\n\n4)\tAt the top of page 8, it was not clear to me exactly what was being predicted by the results of Table 1. When you talk about a held out log predictive probability for different priors. What was this probability distribution over?\n\n5)\tFinally, I think you need to address a crucial issue in your generative model. Usually, state-space models of spectral density (or auto covariance functions) accommodate cross spectra or cross covariance functions. In other words, it is not just the spectral density at each node or region but the coupling between regions that is predicted on the basis of connectivity among regions. I think you need to make it clear that your generative model does not consider complex cross spectra (cross covariance functions) and that \u2013 in principle \u2013 you could extend the generative model in this direction.\n\n6)\tIn the supplementary material, when talking about the updates for global probability vectors, you might want to mention that the use of point estimates means you do not have to consider the entropy of the posterior distribution implicit in the variational free energy (and that you can use the log posterior directly). \n\nI hope these comments help should any revision be required.\n This was an interesting variational scheme for state-spaces models based on a HMM and a spectral mixture model of electrophysiological time-series. It Is not very biologically plausible but may have a role in sleep staging and classification of epileptic discharges.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
