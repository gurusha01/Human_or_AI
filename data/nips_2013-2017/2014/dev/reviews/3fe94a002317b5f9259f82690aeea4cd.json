{"title": "Learning Deep Features for Scene Recognition using Places Database", "abstract": "Scene recognition is one of the hallmark tasks of computer vision, allowing definition of a context for object recognition. Whereas the tremendous recent progress in object recognition tasks is due to the availability of large datasets like ImageNet and the rise of Convolutional Neural Networks (CNNs) for learning high-level features, performance at scene recognition has not attained the same level of success. This may be because current deep features trained from ImageNet are not competitive enough for such tasks. Here, we introduce a new scene-centric database called Places with over 7 million labeled pictures of scenes. We propose new methods to compare the density and diversity of image datasets and show that Places is as dense as other scene datasets and has more diversity. Using CNN, we learn deep features for scene recognition tasks, and establish new state-of-the-art results on several scene-centric datasets. A visualization of the CNN layers' responses allows us to show differences in the internal representations of object-centric and scene-centric networks.", "id": "3fe94a002317b5f9259f82690aeea4cd", "authors": ["Bolei Zhou", "Agata Lapedriza", "Jianxiong Xiao", "Antonio Torralba", "Aude Oliva"], "conference": "NIPS2014", "accepted": true, "reviews": [{"comments": "The authors propose a new large-scale scene image dataset which is 60 times bigger than the current\nstandard SUN dataset. They show that deep networks learned on object centric datasets like ImageNet\nare not optimal for scene recognition and training similar networks with large amounts of scene \nimages improves their performance substantially.\n\n- The diversity and density approach of analysis datasets relative to each other is quite \n interesting.\n \n- The dataset has substantially more number of images than existing scene image classification \n benchmark datasets and hence is surely a useful resource.\n \n- It is convincingly demonstrated that features from CNN trained on scene-centric images, i.e. on the\n proposed dataset, improves performance compared to those from CNN trained on object centric \n ImageNet dataset. The other way around is also demonstrated empirically i.e. the later features \n work better on object centric image classification tasks.\n \n- It is also demonstrated with visualizations that CNNs trained with scene images capture landscape\n and spatial structures in the higher layers of the network.\n \nOverall the paper is well written, addresses an important problem in computer vision. The analysis\nof dataset and cross-dataset performances presented are interesting and the proposed dataset is an \nimportant resource. I recommend acceptance of the paper. Computer vision is entering a new area in which data might have more values than algorithms. I see this paper as a pioneer work in this area.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper introduces a scene-centric database called PLACES with more than 6 million of labeled pictures for scene recognition. The purpose of building such a database is to complement to ImageNet which is an object-centric database, and improve the performance of scene recognition by learning deep features using PLACES. The database was built by scraping search engines with composite queries and utilizing Amazon Mechanical Turk (AMT) for validation. To compare the density and diversity of PLACES with existing databases such as SUN and ImageNet, the authors proposed two metrics and again utilized AMT to get the measures and show the advantages of PLACES. The authors also compared the features learned from PLACES and from ImageNet, and showed the two databases are complementary to each other. In particular, PLACES can result in to better performance for scene recognition and ImageNet better for object recognition.\n\nStrong points of this this work:\n1. A solid work on dataset building.\n2. Detailed and convincing better result than existing scene databases. Shows the power of data.\n\nMinor concerns and comments:\n1. Limited algorithm contribution.\n2. For density, nearest neighbors are obtained based on the GIST feature. Though this setting is the same for all the databases, I wonder if depending on a particular feature will lead to any bias for the density metric.\n3. For diversity, judgment can be quite difficult if judges are presented with two random images, as it doesn\u2019t make sense to judge the similarity between two unrelated random images. I wonder if the authors have similar observations in their AMT experiment.\n4. As PLACES and ImageNet are two complementary databases, how about to mix them together to train a model that is good for both object and scene recognition?\n This is a solid work on database building. The paper is clearly written and shows convincing result of the built database. The reviewer assumes that the database will be made publically available, and believes it will have a positive impact to scene image parsing and scene recognition.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The authors analyze why the recent success of CNN for visual recognition is less pronounced for scene recognition. They hypothesize that it is a lack of data and therefore collect the largest scene dataset to date with over 6 million images. Training the same convolutional architecture that has proven so successful for object recognition also improves on the state of the art in scene recognition given this new dataset.\n\nThe authors do a good job at providing further insights by comparing scene dataset by density and diversity measures. In this sense, the new dataset also compares favorably in quality. \n\nThe overall conclusion of the paper is that depending on the input data, one learns either a object-centric or scene-centric representation. They show that also either representation shows good performance on scene and object recognition task, state-of-the-art performance is only achieved with a very large dataset of the appropriate type (scene or object dataset). While this conclusion is not so surprising, up to now it was not possible to validate this hypothesis due to a lack of a large scene dataset.\n\nI am unclear in which way the proposed visualization is different from previous ones. this is not contrasted in the paper. Please detail this in your rebuttal.\n\nIt remains somewhat disappointing that the authors didn't try the obvious experiment of combining imagenet and their new scene database and train a joint network for objects and scenes. Their conclusion reads as if we have to decide if we either learn a good scene or a good object representation. It is not clear that we can both by training the network jointly. The authors show that the success of CNNs in object recognition can be carried over to scene recognition by their newly collected huge scene dataset that is about a factor 60x larger than any other scene database available to us today. The dataset and the results are of great value, but there is basically no technical novelty.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
