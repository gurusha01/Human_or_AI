{"title": "Tight Continuous Relaxation of the Balanced k-Cut Problem", "abstract": "Spectral Clustering as a relaxation of the normalized/ratio cut has become one of the standard graph-based clustering methods. Existing methods for the computation of multiple clusters, corresponding to a balanced k-cut of the graph, are either based on greedy techniques or heuristics which have weak connection to the original motivation of minimizing the normalized cut. In this paper we propose a new tight continuous relaxation for any balanced k-cut problem and show that a related recently proposed relaxation is in most cases loose leading to poor performance in practice. For the optimization of our tight continuous relaxation we propose a new algorithm for the hard sum-of-ratios minimization problem which achieves monotonic descent. Extensive comparisons show that our method beats all existing approaches for ratio cut and other balanced k-cut criteria.", "id": "f60bb6bb4c96d4df93c51bd69dcc15a0", "authors": ["Syama Sundar Rangapuram", "Pramod Kaushik Mudrakarta", "Matthias Hein"], "conference": "NIPS2014", "accepted": true, "reviews": [{"comments": "The paper presents a novel algorithm to solve the balanced k-cut problem. The k-cut criterion is defined by using the Lovasz extension of a set function. A relaxation of balanced k-cut functionals can be formulated using Lovasz extensions of cuts and of normalizing constraints. The appealing feature of this relaxation is the connection between convex Lovasz extensions and submodular set functions. The authors propose an algorithm that minimizes a sum of auxiliary variables that are lower-bounded by ratios. The minimization is further constraint by simplex and unique membership constraints. \n\nClarity: The paper is very well written and it appropriately refers to prior art. \n\nOriginality: There exists significant prior art and the novel idea modifies the optimization strategy. I consider the originality and in particular the novelty as limited but its significance due to the success in the experiments might justify publication of this paper at NIPS. \n\nSignificance: Due to the surprisingly clear superiority of the new method, this paper might show high impact in the future despite its high similarity with prior art. \n\n\nMinor comments:\n\nFigure 1 has five subfigures but only four are explained in the caption. What is the fifth subfigure about?\n\n A novel continuous relaxation for balanced k-cuts with a descent algorithm is presented andthe experimental evaluation looks very promising.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper proposes a new tight continuous relaxation approach to the k-cut problem which avoids the greedy recursive splitting technique required for other approaches.\n\nThe generality of the monotonic descent method make it of general interest. \n\nWhile the method shows clear promise in terms of finding the k vertices sets, the issue of estimating k itself is not really addressed.\n\nQuality: The conclusions of the paper seemed fair based on the detail written. A conclusions section with caveats and future work would have improved the quality however.\n\nClarity: The majority was well-written, if a little dense at times. Missing a conclusions/discussion section.\n\nOriginality: The idea seemed original but I find it difficult to comment on this due to my lack of expertise in this area.\n\nSignificance: Difficult to say.\n\nSmall issues:\n\nMove the \"Balanced k-Cut\" to the second line of the title\n\n\"Clustering\" on line 17 should not be capitalised.\n\nLine 42: \"frequently outperform\" rather than \"outperform frequently\"\n\nLine 57: change \"with small amount of label information\" to \"with a small amount of label information,\"\n\nAdd letters (a), (b), etc to graphs in Figure 1. An interesting theoretical idea but the paper is lacking in a conclusions section or discussion of caveats. The reframing of the cut problem in terms of the continuous relaxation proposed was of interest as was the monotonic descent method proposed for implementing its solution.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper proposes a new algorithm for the balanced k-cut objective function using continuous relaxation, for both the classical clustering setting with no labeled data, as well as the transductive setting. Thorough experimental results compare the new method against many other variation of spectral clustering, and demonstrate that the new method often outperforms previous ones. Particularly, the new algorithm consistently finds better balanced k-cuts, but also, somewhat surprisingly, it is able to find better partitions based on other related objective functions, even against algorithms that are designed for those functions. \n\nMinor comments:\n- Page 1, at end of the first paragraph of the introduction, switch the order of the words \u201coutperform\u201d and \u201cfrequently.\u201d \n- Please alphabetize the bibliography. \n\n A continuous relaxation of balanced k-cut is presented. Thorough experimental results show notable qualitative improved other previous related techniques.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
