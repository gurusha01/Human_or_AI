{"title": "Learning Multiple Tasks in Parallel with a Shared Annotator", "abstract": "", "id": "ca9c267dad0305d1a6308d2a0cf1c39c", "authors": ["Haim Cohen", "Koby Crammer"], "conference": "NIPS2014", "accepted": true, "reviews": [{"comments": "The paper presents a method for learning multiple tasks in parallel where at each round a sample is given per each task, but only a single task can have its sample annotated. The authors formulate their method using a trade-off between exploitation and exploration. Th1 provides an upper bound on the expected cumulative number of mistakes. The algorithm is compared to 2 different approaches for choosing the single sample/task to be annotated.\n\nI like the paper. It is well written and provides good theoretical as well as experimental results. \n\nI'm not sure the strict synchronic assumption on choice of annotation is really important. It seems more natural just to assume a total budget on annotation among all tasks in a learning system. It would be nice if the authors could add more real life motivation for this specific setting.\n\nI also feel the experimental results could be strengthen by adding two more comparisons:\na. The case were annotation is cheap and all samples can be annotated. Obviously the results could be better but this will show the trade-off between being cheap on annotation or regarding the annotation as cheap. \nb. An active learning approach applied to each task separately, while controlling the number of annotations among all tasks to be equal to the number of learning rounds. \nThis will provide a comparison to a method which \"pays\" the same on annotation but considers a weaker constraint among all tasks. Only the total number of annotation would have to be the same but each round several tasks could be annotated (or non).\n\n I liked the paper, it presents an interesting new problem while providing nice theoretical and experimental guarantees for the proposed solution. I would like to see more motivation into the specific choice of parallel task learning together with experimental evidence to its justification (see suggestions above).", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper introduced a novel multi-task framework where multiple online learners are sharing a single annotator. The proposed algorithm for the task is a perceptron like algorithm with an exploit and exploration strategy to decide the task to query for. The paper also includes an analysis of the proposed algorithm which bound the expected errors. The authors show that the algorithm can also be used to solve two different bandit problems. Empirical studies on standard machine learning dataset outperform weak baselines using naive query selection strategy under the same framework. The paper is well written. However, I found the proposed algorithm does not really leverage the relationship between different tasks to facilitate the learning, which in some senses are not as interesting as other multiple task learning algorithms. Moreover, the paper lacks an analysis on the sampling complexity of the proposed algorithm similar to the selective sampling literatures, which is very important for this kind of setup.\n\nDetailed comments and suggestions:\n1. The authors could include results for a full informative supervised learning baseline, it can help the reader learn the difficulty of the tasks. \n2. What is the advantage of learning the tasks together under the proposed framework compared to learning the tasks separately with K selective sampling algorithms? It will make the paper more interesting to discuss this matters in the paper, as well as show empirical results to prove the points. \n\n\n  The paper introduced a novel multi-task framework and proposed a perceptron like algorithm with theoretical guarantee to solve the task. A major drawback of the proposed algorithm is that it does not leverage the relationship between the tasks to facilitate the joint learning.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper studies the problem of online multi-task learning in which a single annotator with limited bandwidth is shared among tasks. An online algorithm is proposed and its performance is analyzed. \n\nMajor Strengths:\n\nOnline multitask learning is an important topic, and the field of multi-armed bandits has a rich history. Seeking to leverage ideas and results from the latter to apply to the former domain will likely yield improved techniques, especially since for the multi-task learning problem some labels might not be observed. Furthermore, this area is highly relevant to NIPS.\n\nMajor Weaknesses:\n\nAn important aspect to multi-task learning is that there is some dependency between the tasks so that there is utility between learning the tasks jointly. In the work under review, no dependency is assumed. This appears to be a significant departure from the main multitask learning literature with no apparent justification. Without the ability to transfer knowledge between the tasks, it appears more as the multi-armed bandit analog in multi-task learning. For instance, why can only one feature be annotated at a time though all features are allowed to be annotated? In using Mechanical Turk, as suggested, for some applications the workers might not annotate labels for all features equally well. Thus, only allowing a subset of features to be annotated while the rest cannot seems more relevant of a setting. The article mentions it is a new multi-task framework, so it need not follow traditional assumptions, though more motivation and justification is needed for why the differences are important.\n\nOne counter-example to the previous statement is Romera-Paredes et al. \u201cExploiting Unrelated Tasks in Multi-Task Learning\u201d in AISTATS 2012. There they use the knowledge that two tasks are unrelated to avoid overfitting by using the same features. However, the work under review does not exploit the lack of dependence.\n\nThis is less important, but to check the implication (lines 153-154) of Theorem 1, for the data analysis it would have been interesting to see how SHAMPO performs compared to the case when labels are available for all tasks.\n\nMinor notes:\n\n[25] \u201cboth allows\u201d\n[209] \u201coutputs multicalss\"\n[347] remove comma A new problem in multi-task learning is studied with detailed analysis.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
