{"title": "Generalized Unsupervised Manifold Alignment", "abstract": "In this paper, we propose a generalized Unsupervised Manifold Alignment (GUMA) method to build the connections between different but correlated datasets without any known correspondences. Based on the assumption that datasets of the same theme usually have similar manifold structures, GUMA is formulated into an explicit integer optimization problem considering the structure matching and preserving criteria, as well as the feature comparability of the corresponding points in the mutual embedding space. The main benefits of this model include: (1) simultaneous discovery and alignment of manifold structures; (2) fully unsupervised matching without any pre-specified correspondences; (3) efficient iterative alignment without computations in all permutation cases. Experimental results on dataset matching and real-world applications demonstrate the effectiveness and the practicability of our manifold alignment method.", "id": "b51a15f382ac914391a58850ab343b00", "authors": ["Zhen Cui", "Hong Chang", "Shiguang Shan", "Xilin Chen"], "conference": "NIPS2014", "accepted": true, "reviews": [{"comments": "This paper proposes an unsupervised method for aligning manifold structures of different datasets and finding correspondence between objects in different datasets. The proposed method is a combination of three objective functions: 1) geometry matching term, 2) feature matching term, and 3) geometry preserving term. In the learning procedures, matching objects and estimating projection matrices are alternately performed so as to maximize the objective function. In the experiments, the authors demonstrate the effectiveness of the proposed method comparing with unsupervised manifold alignment methods.\n\nThe proposed method is the combination of three related methods as described below. Therefore, the novelty of the proposed method is limited. However, it is interesting to combine related frameworks to solve unsupervised manifold alignment, which is a very difficult problem. The proposed method achieved the good performance in the experiments.\n\nThe geometry preserving term in the objective function is the same as that of unsupervised manifold alignment methods as described in the paper. The geometry matching term in the objective function is related to unsupervised object matching methods, such as kernelized sorting and least square object matching. Especially equation (3) is the same as that of convex kernelized sorting. Discussion on these unsupervised object matching methods should be added. The feature matching term is related to CCA (canonical correlation analysis) based unsupervised matching methods, such as matching CCA and many-to-many matching latent variable models. These methods find linear projection matrices and object correspondence.\n\n[kernelized sorting] Quadrianto, et al, Kernelized sorting, IEEE TPAMI, 2010\n[least square object matching] Yamada and Sugiyama, Cross-domain object matching with model selection, AISTATS, 2011\n[convex kernelized sorting] Djuric, et al, Convex kernelized sorting, AAAI, 2012\n[matching CCA] Haghighi, Learning bilingual lexicons from monolingual corpora, ACL, 2008\n[many-to-many latent variable model] Iwata et al, Unsupervised Cluster Matching via Probabilistic Latent Variable Models, AAAI, 2013\n\nIn the face pose experiments, it seems that the similarity between different datasets can be calculated. So, it might be able to solve this task with (supervised) manifold alignment methods. Please clarify it is a task for unsupervised methods.\n The proposed method is the combination of three related methods. But, it is interesting to combine related frameworks to solve unsupervised manifold alignment, which is a very difficult problem.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This work proposes a method for unsupervised manifold alignment---given two different but related datasets, find a common embedding space such that related data points are projected to similar locations (e.g., faces from 2 different subjects that share the same expression and pose). Manifold alignment could be potentially applied to map between datasets with drastically different appearances, as well as recognition tasks. \n\nWhile prior methods have treated the matching of structures (related data points should share similar local geometry) and alignment (identifying which data points are related) as a two-step process. The current work points out that this is sub-optimal for partial matching cases and proposes an approach for learning these steps simultaneously. \n\nI found the idea of jointly learning alignment and structure appealing and makes intuitive sense. Moreover, the paper conducted an extensive set of experiments and proposed an extension to the Frank-Wolfe integer programming algorithm to optimize for alignment. The paper is also very well written and organized. It was a nice touch to investigate effects of only using the structure matching term or the feature matching term. \n\nThere seems to be very little prior work on unsupervised manifold matching (compared to semi-supervised), only 2 were discussed in the introduction. One question I have is how much user labelling is required to achieve performances comparable to the proposed method using a semi-supervised method? This could have implications on the significance of the results achieved by the method and the importance of assuming no correspondences. I'm also wondering if the proposed approach could extended to handle cases where it doesn't make sense to have hard assignment, where modelling alignment using a mapping [19] makes more sense.  This paper proposes to simultaneously learn the structure and alignment for the unsupervised manifold learning problem, which improves upon prior methods that optimized the 2 steps separately. Additionally, an extension to the Frank-Wolfe integer programming algorithm was proposed and extension evaluations are performed.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The problem of aligning two manifolds is a well studied one in the literature. This paper proposes a method for aligning two datasets, under the crucial assumption that both data sets lie on a single manifold, given no correspondences. This problem was studied by Wang and Mahadevan (IJCAI 2009), and subsequently by several others. This paper proposes a more sophisticated loss function than previous work, based on minimizing a sum of three terms: a geometry matching term, a feature matching term, and a geometry preserving term. This results in a difficult non-convex optimization problem, but the author(s) propose a sophisticated convex relaxation based on an alternating projection like idea of assuming the projections are known, and solving the resulting quadratic integer programming problem using the Frank-Wolfe algorithm. \n\nThe paper contains a detailed set of experiments comparing the new method to the previous work of Wang and Mahadevan and others, showing significantly improved performance on several synthetic and moderately complex real datasets. The results appear to show a significant improvement over previous work. \n\nThe major limitation of this work, however, is the crucial assumption that the datasets lie on a single underlying manifold. This is unfortunately unlikely to be the case with the majority of real-world data sets, which lie on some complex mixture of manifolds. Techniques for dealing with alignment in this case are beginning to be proposed, but appear to be beyond the scope of this paper. It would be interesting to see if the proposed approach could be extended to this more realistic setting.  Proposes a novel method for aligning two datasets that lie on a single underlying manifold based on no correspondence information, and shows improved performance over previous unsupervised alignment methods. Results show significant improvement, but the assumption of a single underlying manifold remains restrictive.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
