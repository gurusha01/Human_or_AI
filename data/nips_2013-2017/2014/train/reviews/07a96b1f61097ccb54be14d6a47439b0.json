{"title": "Recovery of Coherent Data via Low-Rank Dictionary Pursuit", "abstract": "The recently established RPCA method provides a convenient way to restore low-rank matrices from grossly corrupted observations. While elegant in theory and powerful in reality, RPCA is not an ultimate solution to the low-rank matrix recovery problem. Indeed, its performance may not be perfect even when data are strictly low-rank. This is because RPCA ignores clustering structures of the data which are ubiquitous in applications. As the number of cluster grows, the coherence of data keeps increasing, and accordingly, the recovery performance of RPCA degrades. We show that the challenges raised by coherent data (i.e., data with high coherence) could be alleviated by Low-Rank Representation (LRR)~\\cite{tpami<em>2013</em>lrr}, provided that the dictionary in LRR is configured appropriately. More precisely, we mathematically prove that if the dictionary itself is low-rank then LRR is immune to the coherence parameter which increases with the underlying cluster number. This provides an elementary principle for dealing with coherent data and naturally leads to a practical algorithm for obtaining proper dictionaries in unsupervised environments. Experiments on randomly generated matrices and real motion sequences verify our claims. See the full paper at arXiv:1404.4032.", "id": "07a96b1f61097ccb54be14d6a47439b0", "authors": ["Guangcan Liu", "Ping Li"], "conference": "NIPS2014", "accepted": true, "reviews": [{"comments": "This paper addresses the problem of robustly estimating the low-dimensional subspace of contaminated observations when the observations are inherently coherent. Performance goes worse with increasing data coherence is a standard theoretical bottleneck of previous RPCA methods. This paper, however, circumvents this problem in a clever manner. Considering that such cluster structure is rather common in realistic data, solving this issue is certainly significantly meaningful. The proposed method is both theoretically sound and well demonstrated to perform well in practice.\n\nI just have a curious comment on the submission:\n\nCan the proposed method also be applied for solving subspace clustering/segmentation problem? Could the authors provide some comments on this point?\n\n This paper solves an important problem in robust PCA works. The quality of the paper is very good and should be accepted.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper combines two recent techniques, robust PCA and\ndictionary-based structure-preserving projection, in the task of\nrestoring corrupted observartion matrices. The key insight is that\nfor structured (for instance clustered) data, the guarantees of robust\nPCA are not strong enough, and by representing the structure with\nby a dictionary, stronger bounds can be given. Theorems are given to\nsupport these claims. The remaining problem is how to learn the\ndictionary. For that an algorithm justified by empirical results is\ngiven: First compute robust PCA, then represent the result by a\ndictionary. \n\nQuality:\n\nThe paper is technically sound, up to a reasonable level of\nchecking. The two theorems elaborate conditions under which\nreconstruction is possible, given a dictionary. For the learning of\nthe dictionary, the justification is empirical.\n\nClarity:\n\nClarity is the main problem of the paper. While the structure is clear,\nthe main contributions and impact of the paper have not been explained\nclearly enough to be accessible beyond a very narrow specialist audience.\nThe claims would need to be more well-defined, and the impact of the\nresults explicated. For instance, the concept coherence is hard to understand,\nand means of interpreting it are very indirect (and given in the appendix).\nOne of the potential impacts of the paper may be that by using\ndictionaries many earlier problems can be sidestepped.\n\nAlso the language needs checking.\n\nIt would be important to get a comment from the authors about what can be\ndone about these issues.\n\nOriginality:\n\nThe paper is based on a combination of recent techniques, but includes\nnew theorems and empirical results supporting the usefulness of the\ncombination. \n\nSignificance:\n\nThe paper does advance the state-of-the art with rigorous\nresults. Even though the proposed algorithm for finding the dictionary\nis heuristic, clear improvements over alternative algorithmns\ndemonstrate that the insights given this paper are useful. \n\n---\nComment after the author rebuttal and reviewer discussion:\n\nThere is clearly publishable content and interesting contributions. The only remaining concern I have is that it will be hard work to re-write the paper to make it accessible to very specialists. If there was an option for a \"major revision\" I would vote for it.\n\n The paper combines two recent ideas, and gives both theoreticalresults and a heuristic but empirically well-performing algorithm.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper proposes to use Low Rank Representation (LRR) with some learned dictionary A to improve the effectiveness of RPCA. In particular, the authors show that the incoherence parameter \\mu which often thought of as a bottleneck in the recovery guarantee in RPCA can in fact correspond to some additional clustering structure in the data. Under some condition on the dictionary A, the authors show that one can exploit such structure using LRR and partially remove the dependence on \\mu and get a theoretically stronger guarantee in both exact low-rank and sparse decomposition and its noisy extension.\nThe method is novel and significant to the field. It is closely related to the union-of-subspace structure assumed in previous subspace clustering papers such as \u201cWang and Xu: Noisy Sparse Subspace Clustering & Provable subspace clustering: When LRR meets SSC\u201d, and \u201cSoltanolkotabi and Candes: A geometric analysis of subspace clustering with outliers\u201d \u201cSoltanolkotabi et al: Robust subspace clustering\u201d but are less explicit about the assumption on \u201cclustering\u201d, which is reasonable and more probably more general. The simulation and real data experiments verify the theoretical analysis and I think the new structure can be found in many other real applications too (such as text data as remarked in the paper).\nIn summary, the paper contains a substantial contribution to the field of compressed sensing and I think it should be accepted by NIPS.\nThat said, I do have a number of discussions and stylistic suggestions which are summarized in the detailed comments below. \n\n1.\tLine 80-82: Need some re-writing to make the description clearer. What do you mean by \u201cour data\u201d? Also even if the problem captures all the structures in the problem, there is still yet another condition to qualify to have \u201cperfect recovery\u201d.\n2.\tLine 88: \u2026 is no longer a method of perfect (WHAT?).\n3.\tPlease proof-read the papers more carefully for problems like the above two. Be specific and precise about what to claim and what you are referring to in the text. In general, please work on clarity of the language in the paper.\n4.\tWang and Xu also have written in their paper \u201cNoisy Sparse Subspace Clustering\u201d how higher coherence parameter is actually good for subspace clustering (unlike in RPCA and matrix completion). The key difference from here is that the data need not be low-rank in overall, only every cluster has to be low-rank. The structure exploited here in this paper can be thought of as a combination of low-rank structure and union-of-subspace cluster structure.\n5.\tIt will be interesting to compare the proposed algorithm against first solving noisy subspace clustering with \\ell_1 penalty then do PCA for each subspace. No provable guarantee exists to date for the later version though.\n6.\tSection 4.2 essentially proposes a new method for solving subspace clustering problem with sparse corruption in the data. The method leads to significant improvements over the standard RPCA+SSC on Hopkins155 dataset which I think is a hidden contribution here in this paper and the authors should point it out. This paper should be accepted because it contains at least three important contributions to the field including: 1. descriptions of a clustering structure that leads to high coherence, 2. example that one can implicitly exploit such structure by using a dictionary in LRR, 3. partially solve the sparse corruptions problem in subspace clustering problem.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
