{"title": "Learning to Discover Efficient Mathematical Identities", "abstract": "In this paper we explore how machine learning techniques can be applied to the discovery of efficient mathematical identities. We introduce an attribute grammar framework for representing symbolic expressions. Given a grammar of math operators, we build trees that combine them in different ways, looking for compositions that are analytically equivalent to a target expression but of lower computational complexity. However, as the space of trees grows exponentially with the complexity of the target expression, brute force search is impractical for all but the simplest of expressions. Consequently, we introduce two novel learning approaches that are able to learn from simpler expressions to guide the tree search. The first of these is a simple n-gram model, the other being a recursive neural-network. We show how these approaches enable us to derive complex identities, beyond reach of brute-force search, or human derivation.", "id": "08419be897405321542838d77f855226", "authors": ["Wojciech Zaremba", "Karol Kurach", "Rob Fergus"], "conference": "NIPS2014", "accepted": true, "reviews": [{"comments": "First, apologies for the brevity of this review- I had written a version with more detailed comments and had found a few typos, but can't find it now.\n\nThis paper is an application of DNNs to a novel area (finding mathematical identities) and my feeling is that while the ideas are novel, this seems like preliminary work that maybe doesn't quite rise to the level of a NIPS publication. Specifically, your method doesn't seem to show particularly impressive performance in discovering identities, even though you only gave it a very limited set of inputs. The expressions that you were finding identities on were from such a limited set that it would probably have been easier to just work out some mathematical rule to discover them rather than applying DNNs; it seems like using a sledgehammer to crack a nut. Of course you might argue that your approach could be extended to a much more general range of expressions, but it's not clear to me that your existing approach would very easily scale out in that way, or that doing so would even make sense given your so-so initial results.\n\n I do think this is an interesting paper, but I think it's maybe a little but below the threshold for publication.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper describes two methods for searching for simpler symbolic expression trees. One of these is based on the use of ngrams computed over sequences of sub-expressions. The other uses a recursive neural network to create continuous space representations of symbolic expression trees. These representations are then used to predict what rule is likely to be used to combine subtrees. The use of ngrams appears from Figure 3 to be better than the RNN on two of the three tasks. \n\nComments wrt specific review criteria:\nQuality - High.\nClarity - The paper is somewhat hard to follow, especially Section 7.2.\nOriginality - High.\nSignificance - Low. It is unlikely that anyone seeking to perform efficient computations would ever do this. The problem seems contrived. This paper describes ways of searching for more computationally efficient symbolic expression trees. The significance of the methods is unclear.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper introduces an interesting solution to finding more efficient algebraic identities. It is very interesting to see that distributed, recursive neural representations can successfully classify these identities.\n\n\nThe problem definition seems quite restricted.\n\nThis is not well explained:\n\"weight tensorW3 (of size lxlxl, so that the output is also size l),\"\nDoes this mean you use a neural tensor network instead of a simple linear network?\nBowman showed that the tensor network works a lot better in these than the RNN.\n\n\n7.2 Efficient Identity Discovery\nIt is unclear if you're still using the RNN here for classification but you are evaluation different search strategies.\nI didn't quite follow how you generate proposals in your search. This could be explained better.\n\n\ntypos:\nhas contains a single matrix\nlisted in table Table 1.\nvector is the presented to the next operation\nThe final vector is pass to a softmax classifier\nas to how explore space of possible\nThe scheduler is is fixed\nThe difficulty of the task by be appreciated by looking\nwhich can easily captured with\nShould be RNN, not TNN in figure 3. This paper introduces an interesting solution to finding more efficient algebraic identities. It is very interesting to see that distributed, recursive neural representations can successfully classify these identities.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper introduces a novel use case for neural nets, which is learning a representation for symbolic expressions and finding their mathematical identities.\nEven though the expressions studied are very limited and there is no proof that they can be extended to more complicated expressions, I find the paper interesting. And I believe it could have good impact for symbolic software libraries. \n\n-The problem statement states that we're looking for expressions with lower computational complexity. But nowhere in the algorithm such a constraint is enforced. I understand that this is not trivial, but have authors taught about possible solutions to limit the search space to such solutions?\n\n-About the restrictions mentioned in section 2, is the scheduler the only limiting factor for more complicated mathematical expression? I would have liked to see more formal or mention of empirical experiments for setting these restrictions.\n\n-Also the structure of the paper is a not easy to follow. It would be better if stages were explained more clearly. \n\n-Is there a constraint for size of the vector/matrix? e.g. for k=1,n=1 the expression for RBM-1 in the supplementary material doesn't seems to be valid.\n\nSome typos:\n332: show for\n148: has contains\n289: is is\n338: by be The paper introduced a novel approach for representing symbolic expressions and finding their mathematical identities. Even though it is a limited in the expressions it can handle, it is an interesting and novel approach.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
