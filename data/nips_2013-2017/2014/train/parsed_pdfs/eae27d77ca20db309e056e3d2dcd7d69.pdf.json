{
  "name" : "eae27d77ca20db309e056e3d2dcd7d69.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "A Unified Semantic Embedding: Relating Taxonomies and Attributes",
    "authors" : [ "Sung Ju Hwang", "Leonid Sigal" ],
    "emails" : [ "sungju.hwang@disneyresearch.com", "lsigal@disneyresearch.com" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Object categorization is a challenging problem that requires drawing boundaries between groups of objects in a seemingly continuous space. Semantic approaches have gained a lot of attention recently as object categorization became more focused on large-scale and fine-grained recognition tasks and datasets. Attributes [1, 2, 3, 4] and semantic taxonomies [5, 6, 7, 8] are two popular semantic sources which impose certain relations between the category models, including a more recently introduced analogies [9] that induce even higher-order relations between them. While many techniques have been introduced to utilize each of the individual semantic sources for object categorization, no unified model has been proposed to relate them.\nWe propose a unified semantic model where we can learn to place categories, supercategories, and attributes as points (or vectors) in a hypothetical common semantic space, and taxonomies provide specific topological relationships between these semantic entities. Further, we propose a discriminative learning framework, based on dictionary learning and large margin embedding, to learn each of these semantic entities to be well separated and pseudo-orthogonal, such that we can use them to improve visual recognition tasks such as category or attribute recognition.\nHowever, having semantic entities embedded into a common space is not enough to utilize the vast number of relations that exist between the semantic entities. Thus, we impose a graph-based regularization between the semantic embeddings, such that each semantic embedding is regularized by sparse combination of auxiliary semantic embeddings. This additional requirement imposed on the discriminative learning model would guide the learning such that we obtain not just the optimal model for class discrimination, but to learn a semantically plausible model which has a potential to be more robust and human-interpretable; we call this model Unified Semantic Embedding (USE).\n∗Now at Ulsan National Institute of Science and Technology in Ulsan, South Korea\nThe observation we make to draw the relation between the categories and attributes, is that a category can be represented as the sum of its supercategory + the category-specific modifier, which in many cases can be represented by a combination of attributes. Further, we want the representation to be compact. Instead of describing a dalmatian as a domestic animal with a lean body, four legs, a long tail, and spots, it is more efficient to say it is a spotted dog (Figure 1). It is also more exact since the higher-level category dog contains all general properties of different dog breeds, including indescribable dog-specific properties, such as the shape of the head, and its posture.\nThis exemplifies how a human would describe an object, to efficiently communicate and understand the concept. Such decomposition of a category into attributes+supercategory can hold for categories at any level. For example, supercategory feline can be described as a stalking carnivore.\nWith the addition of this new generative objective, our goal is to learn a discriminative model that can be compactly represented as a combination of semantic entities, which helps learn a model that is semantically more reasonable. We want to balance between these two discriminative and generative objectives when learning a model for each object category. For object categories that have scarce training examples, we can put more weight on the generative part of the model.\nContributions: Our contributions are threefold: (1) We show a multitask learning formulation for object categorization that learns a unified semantic space for supercategories and attributes, while drawing relations between them. (2) We propose a novel sparse-coding based regularization that enforces the object category representation to be reconstructed as the sum of a supercategory and a sparse combination of attributes. (3) We show from the experiments that the generative learning with the sparse-coding based regularization helps improve object categorization performance, especially in the one or few-shot learning case, by generating semantically plausible predictions."
    }, {
      "heading" : "2 Related Work",
      "text" : "Semantic methods for object recognition. For many years, vision researchers have sought to exploit external semantic knowledge about the object to incorporate semantics into learning of the model. Taxonomies, or class hierarchies were the first to be explored by vision researchers [5, 6], and were mostly used to efficiently rule out irrelevant category hypotheses leveraging class hierarchical structure [8, 10]. Attributes are visual or semantic properties of an object that are common across multiple categories, mostly regarded as describable mid-level representations. They have been used to directly infer categories [1, 2], or as additional supervision to aid the main categorization problem in the multitask learning framework [3]. While many methods have been proposed to leverage either of these two popular types of semantic knowledge, little work has been done to relate the two, which our paper aims to address.\nDiscriminative embedding for object categorization. Since the conventional kernel-based multiclass SVM does not scale due to its memory and computational requirements for today’s large-scale classification tasks, embedding-based methods have gained recent popularity. Embedding-based methods perform classification on a low dimensional shared space optimized for class discrimination. Most methods learn two linear projections, for data instances and class labels, to a common lower-dimensional space optimized by ranking loss. Bengio et al. [10] solves the problem using stochastic gradient, and also provides a way to learn a tree structure which enables one to efficiently predict the class label at the test time. Mensink et al. [11] eliminated the need of class embedding by replacing them with the class mean, which enabled generalization to new classes at near zero cost.\nThere are also efforts in incorporating semantic information into the learned embedding space. Weinberger et al. [7] used the taxonomies to preserve the inter-class similarities in the learned space,\nin terms of distance. Akata et al. [4] used attributes and taxonomy information as labels, replacing the conventional unit-vector based class representation with more structured labels to improve on zero-shot performance. One most recent work in this direction is DEVISE [12], which learns embeddings that maximize the ranking loss, as an additional layer on top of the deep network for both images and labels. However, these models impose structure only on the output space, and structure on the learned space is not explicitly enforced, which is our goal.\nRecently, Hwang et al. [9] introduced one such model, which regularizes the category quadruplets, that form an analogy, to form a parallelogram. Our goal is similar, but we explore a more general compositional relationship, which we learn without any manual supervision.\nMultitask learning. Our work can be viewed as a multitask learning method, since we relate each model for different semantic entities by learning both the joint semantic space and enforcing geometric constraints between them. Perhaps the most similar work is [13], where the parameter of each model is regularized while fixing the parameter for its parent-level models. We use similar strategy but instead of enforcing sharing between the models, we simply learn each model to be close to its approximation obtained using higher-level (more abstract) concepts.\nSparse coding. Our method to approximate each category embedding as a sum of its direct supercategory plus a sparse combination of attributes, is similar to the objective of sparse coding. One work that is specifically relevant to ours is Mairal et al. [14], where the learning objective is to reduce both the classification and reconstruction error, given class labels. In our model, however, the dictionary atoms are also discriminatively learned with supervision, and are assembled to be a semantically meaningful combination of a supercategory + attributes, while [14] learns the dictionary atoms in an unsupervised way."
    }, {
      "heading" : "3 Approach",
      "text" : "We now explain our unified semantic embedding model, which learns a discriminative common low-dimensional space to embed both the images and semantic concepts including object categories, while enforcing relationships between them using semantic reconstruction.\nSuppose that we have a d-dimensional image descriptor andm-dimensional vector describing labels associated with the instances, including category labels at different semantic granularities and attributes. Our goal then is to embed both images and the labels onto a single unified semantic space, where the images are associated with their corresponding semantic labels.\nTo formally state the problem, given a training set D that has N labeled examples, i.e. D = {xi, yi}Ni=1, where xi ∈ Rd denotes image descriptors and yi ∈ {1, . . . ,m} are their labels associated with m unique concepts, we want to embed each xi as zi, and each label yi as uyi in the de-dimensional space, such that the similarity between zi and uyi , S(zi,uyi) is maximized.\nOne way to solve the above problem is to use regression, using S(zi,uyi) = −‖zi−uyi‖22. That is, we estimate the data embedding zi as zi =Wxi, and minimize their distances to the correct label embeddings uyi ∈ Rm where the dimension for yi is set to 1 and every other dimension is set to 0:\nmin W m∑ c=1 N∑ i=1 ‖Wxi − uyi‖22 + λ‖W ‖2F . (1)\nThe above ridge regression will project each instance close to its correct embedding. However, it does not guarantee that the resulting embeddings are well separated. Therefore, most embedding methods for categorization add in discriminative constraints which ensure that the projected instances have higher similarity to their own category embedding than to others. One way to enforce this is to use large-margin constraints on distance: ‖Wxi−uyi‖22+1 ≤ ‖Wxi−uc‖22+ξic, yi 6= c which can be translated into to the following discriminative loss:\nLC(W ,U ,xi, yi) = ∑ c [1 + ‖Wxi − uyi‖22 − ‖Wxi − uc‖22]+,∀c 6= yi, (2)\nwhere U is the columwise concatenation of each label embedding vector, such that uj denotes jth column of U . After replacing the generative loss in the ridge regression formula with the discriminative loss, we get the following discriminative learning problem:\nmin W ,U N∑ i LC(W ,U ,xi, yi) + λ‖W ‖2F + λ‖U‖2F , yi ∈ {1, . . . ,m}, (3)\nwhere λ regularizes W and U from shooting to infinity. This is one of the most common objective used for learning discriminative category embeddings for multi-class classification [10, 7], while ranking loss-based [15] models have been also explored for LC . Bilinear model on a single variable W has been also used in Akata et al. [4], which uses structured labels (attributes) as uyi ."
    }, {
      "heading" : "3.1 Embedding auxiliary semantic entities.",
      "text" : "Now we describe how we embed the supercategories and attributes onto the learned shared space.\nSupercategories. While our objective is to better categorize entry level categories, categories in general can appear at different semantic granularities. For example, a zebra could be both an equus, and an odd-toed ungulate. To learn the embeddings for the supercategories, we map each data instance to be closer to its correct supercategory embedding than to its siblings: ‖Wxi−us‖22+1 ≤ ‖Wxi − uc‖22 + ξsc,∀s ∈ Pyi and c ∈ Ss where Pyi denotes the set of superclasses at all levels for class s, and Ss is the set of its siblings. The constraints can be translated into the following loss term:\nLS(W ,U ,xi, yi) = ∑ s∈Pyi ∑ c∈Ss [1 + ‖Wxi − us‖22 − ‖Wxi − uc‖22]+. (4)\nAttributes. Attributes can be considered normalized basis vectors for the semantic space, whose combination represents a category. Basically, we want to maximize the correlation between the projected instance that possess the attribute, and its correct attribute embedding, as follows:\nLA(W ,U ,xi, yi) = 1− ∑ a (Wxi) Tyai ua, ‖ua‖2 ≤ 1, yai ∈ {0, 1},∀a ∈ Ayi , (5)\nwhere Ac is the set of all attributes for class c and ua is an embedding vector for an attribute a."
    }, {
      "heading" : "3.2 Relationship between the categories, supercategories, and attributes",
      "text" : "Simply summing up all previously defined loss functions while adding {us} and {ua} as additional columns of U will result in a multi-task formulation that implicitly associate the semantic entities, through the shared data embedding W . However, we want to further utilize the relationships between the semantic entities, to explicitly impose structural regularization on the semantic embeddings U . One simple and intuitive relation is that an object class can be represented as the combination of its parent level category plus a sparse combination of attributes, which translates into the following constraint:\nuc = up +U Aβc, c ∈ Cp, ‖βc‖0 γ1,βc 0,∀c ∈ {1, . . . ,C}, (6)\nwhere UA is the aggregation of all attribute embeddings {ua}, Cp is the set of children classes for class p, γ1 is the sparsity parameter, and C is the number of categories. We require β to be nonnegative, since it makes more sense and more efficient to describe an object with attributes that it might have, rather than describing it by attributes that it might not have.\nWe rewrite Eq. 7 into a regularization term as follows, replacing the `0-norm constraints with `1- norm regularizations for tractable optimization:\nR(U ,B) = C∑ c ‖uc − up −UAβc‖22 + γ2‖βc + βo‖22,\nc ∈ Cp, o ∈ Pc ∪ Sc, 0 βc γ1,∀c ∈ {1, . . . ,C}, (7)\nwhereB is the matrix whose jth column vector βj is the reconstruction weight for class j, Sc is the set of all sibling classes for class c, and γ2 is the parameters to enforce exclusivity.\nThe exclusive regularization term is used to prevent the semantic reconstruction βc for class c from fitting to the same attributes fitted by its parents and siblings. This is because attributes common across parent and child, and between siblings, are less discriminative. This regularization is especially useful for discrimination between siblings, which belong to the same superclass and only differ by the category-specific modifier. By generating unique semantic decomposition for each class, we can better discriminate between any two categories using a semantic combination of discriminatively learned auxiliary entities.\nWith the sparsity regularization enforced by γ1, the simple sum of the two weights will prevent the two (super)categories from having high weight for a single attribute, which will let each category embedding to fit to exclusive attribute set. This, in fact, is the exclusive lasso regularizer introduced in [16], except for the nonnegativity constraint on βc, which makes the problem easier to solve."
    }, {
      "heading" : "3.3 Unified semantic embeddings for object categorization",
      "text" : "After augmenting the categorization objective in Eq. 3 with the superclass and attributes loss and the sparse-coding based regularization in Eq. 7, we obtain the following multitask learning formulation that jointly learns all the semantic entities along with the sparse-coding based regularization:\nmin W ,U,B N∑ i=1 LC(W ,U ,xi, yi) + µ1 (LS(W ,U ,xi, yi) + LA(W ,U ,xi, yi)) + µ2R(U ,B);\n‖wj‖22 ≤ λ, ‖uk‖22 ≤ λ, 0 βc γ1∀j ∈ {1, . . . , d}, ∀k ∈ {1, . . . ,m}, ∀c ∈ {1, . . . ,C+ S},\n(8)\nwhere S is the number of supercategories, wj is W ’s jth column, and µ1 and µ2 are parameters to balance between the main and auxiliary tasks, and discriminative and generative objective.\nEq. 8 could be also used for knowledge transfer when learning a model for a novel set of categories, by replacing UA inR(U ,B) with US , learned on class set S to transfer the knowledge from."
    }, {
      "heading" : "3.4 Numerical optimization",
      "text" : "Eq. 8 is not jointly convex in all variables, and has both discriminative and generative terms. This problem is similar to the problem in [14], where the objective is to learn the dictionary, sparse coefficients, and classifier parameters together, and can be optimized using a similar alternating optimization, while each subproblem differs. We first describe how we optimize for each variable.\nLearning of W and U . The optimization of both embedding models are similar, except for the reconstructive regularization onU . and the main bottleneck lies in the minimization of the O(Nm) large-margin losses. Since the losses are non-differentiable, we solve the problems using stochastic subgradient method. Specifically, we implement the proximal gradient algorithm in [17], handling the `-2 norm constraints with proximal operators.\nLearning B. This is similar to the sparse coding problem, but simpler. We use projected gradient method, where at each iteration t, we project the solution of the objective βt+ 1 2\nc for category c to `-1 norm ball and nonnegative orthant, to obtain βtc that satisfies the constraints.\nAlternating optimization. We decompose Eq. 8 to two convex problems: 1) Optimization of the data embeddingW and approximation parameterB (Since the two variable do not have direct link between them) , and 2) Optimization of the category embedding U . We alternate the process of optimizing each of the convex problems while fixing the remaining variables, until the convergence criterion 1 is met, or the maximum number of iteration is reached.\nRun-time complexity. Training: Optimization of W and U using proximal stochastic gradient [17], have time complexities of O(ded(k+1)) and O(de(dk+C)) respectively. Both terms are dominated by the gradient computation for k(k N) sampled constraints, that is O(dedk). Outer loop for alternation converges within 5-10 iterations depending on . Test: Test time complexity is exactly the same as in LME, which is O(de(C + d))."
    }, {
      "heading" : "4 Results",
      "text" : "We validate our method for multiclass categorization performance on two different datasets generated from a public image collection, and also test for knowledge transfer on few-shot learning."
    }, {
      "heading" : "4.1 Datasets",
      "text" : "We use Animals with Attributes dataset [1], which consists of 30, 475 images of 50 animal classes, with 85 class-level attributes 2. We use the Wordnet hierarchy to generate supercategories. Since\n1‖W t+1 −W t‖2 + ‖U t+1 −U t‖2 + ‖Bt+1 −Bt‖2 < 2Attributes are defined on color (black, orange), texture (stripes, spots), parts (longneck, hooves), and other\nhigh-level behavioral properties (slow, hibernate, domestic) of the animals\nthere is no fixed training/test split, we use {30,30,30} random split for training/validation/test. We generate the following two datasets using the provided features. 1) AWA-PCA: We compose a 300- dimensional feature vectors by performing PCA on each of 6 types of features provided, including SIFT, rgSIFT, SURF, HoG, LSS, and CQ to have 50 dimensions per each feature type, and concatenating them. 2) AWA-DeCAF: For the second dataset, we use the provided 4096-D DeCAF features [18] obtained from the layer just before the output layer of a deep convolutional neural network."
    }, {
      "heading" : "4.2 Baselines",
      "text" : "We compare our proposed method against multiple existing embedding-based categorization approaches, that either do not use any semantic information, or use semantic information but do not explicitly embed semantic entities. For non-semantics baselines, we use the following: 1)Ridge Regression: A linear regression with `-2 norm (Eq. 1). 2) NCM: Nearest mean classifier from [11], which uses the class mean as category embeddings (uc = xµc ). We use the code provided by the authors3. 3) LME: A base large-margin embedding (Eq. 3) solved using alternating optimization.\nFor implicit semantic baselines, we consider two different methods. 4) LMTE: Our implementation of the Weinberger et al. [7], which enforces the semantic similarity between class embeddings as distance constraints [7], where U is regularized to preserve the pairwise class similarities from a given taxonomy. 5-7) ALE, HLE, AHLE: Our implementation of the attribute label embedding in Akata et al. [4], which encodes the semantic information by representing each class with structured labels that indicate the class’ association with superclasses and attributes. We implement variants that use attributes (ALE), leaf level + superclass labels (HLE), and both (AHLE) labels.\nFor our models, we implement multiple variants to analyze the impact of each semantic entity and the proposed regularization. 1) LME-MTL-S: The multitask semantic embedding model learned with supercategories. 2) LME-MTL-A: The multitask embedding model learned with attributes. 3) USE-No Reg.: The unified semantic embedding model learned using both attributes and supercategories, without semantic regularization. 4) USE-Reg: USE with the sparse coding regularization.\nFor parameters, the projection dimension de = 50 for all our models. 4 For other parameters, we find the optimal value by cross-validation on the validation set. We set µ1 = 1 that balances the main and auxiliary task equally, and search for µ2 for discriminative/generative tradeoff, in the range of {0.01, 0.1, 0.2 . . . , 1, 10}, and set `-2 norm regularization parameter λ = 1. For sparsity parameter γ1, we set it to select on average several (3 or 4) attributes per class, and for disjoint parameter γ2, we use 10γ1, without tuning for performance."
    }, {
      "heading" : "4.3 Multiclass categorization",
      "text" : "We first evaluate the suggested multitask learning framework for categorization performance. We report the average classification performance and standard error over 5 random training/test splits in Table 1 and 2, using both flat hit@k, which is the accuracy for the top-k predictions made, and hierarchical precision@k from [12], which is a precision the given label is correct at k, at all levels.\nNon-semantic baselines, ridge regression and NCM, were outperformed by our most basic LME model. For implicit semantic baselines, ALE-variants underperformed even the ridge regression\n3http://staff.science.uva.nl/˜tmensink/code.php 4Except for ALE variants where de=m, the number of semantic entities.\nbaseline with regard to the top-1 classification accuracy 5, while they improve upon the top-2 recognition accuracy and hierarchical precision. This shows that hard-encoding structures in the label space do not necessarily improve the discrimination performance, while it helps to learn a more semantic space. LMTE makes substantial improvement on 300-D features, but not on DeCAF features.\nExplicit embedding of semantic entities using our method improved both the top-1 accuracy and the hierarchical precision, with USE variants achieving the best performance in both. Specifically, adding superclass embeddings as auxiliary entities improves the hierarchical precision, while using attributes improves the flat top-k classification accuracy. USE-Reg, especially, made substantial improvements on flat hit and hierarchical precision @ 5, which shows the proposed regularization’s effectiveness in learning a semantic space that also discriminates well."
    }, {
      "heading" : "4.3.1 Qualitative analysis",
      "text" : "Besides learning a space that is both discriminative and generalizes well, our method’s main advantage, over existing methods, is its ability to generate compact, semantic descriptions for each category it has learned. This is a great caveat, since in most models, including the state-of-the art deep convolutional networks, humans cannot understand what has been learned; by generating human-understandable explanation, our model can communicate with the human, allowing understanding of the rationale behind the categorization decisions, and to possibly allow feedback for correction.\nTo show the effectiveness of using supercategory+attributes in the description, we report the learned reconstruction for our model, compared against the description generated by its ground-truth attributes in Table 3. The results show that our method generates compact description of each category, focusing on its discriminative attributes. For example, our method select attributes such as flippers for otter, and stripes for skunk, instead of attributes common and nondescriminative such as tail. Note that some attributes that are ranked less relevant by humans were selected for their discriminativity, e.g., yellow for dear and black for moose, both of which human annotators regarded\n5We did extensive parameter search for the ALE variants.\nantelope: lean agility active grizzly bear: cave big m ountains k. w hale: m eatteeth m eat lean beaver: sw im s pads stripes dalm atian: spots longleg hairless Persian cat: dom estic pads claw\ns\nhorse: toughskin brow n plains G . shepherd: longleg gray stalker blue w hale: inactive Siam ese: inactive stalker m eatteeth skunk: horns slow hooves m ole: plankton tunnels tiger: group orange hippopotam us: strainteeth fish sw\nim s\nleopard: spots fish\nm oose: inactive spider m onkey: horns grazer hum pback: tail elephant: plankton tusks bush gorilla: bipedal bulbous ox: bush bulbous hairless fox: horns orange fish sheep: fish dom estic pads seal: m ountains sm all w alks chim\npanzee: toughskin insects hands\nham ster: patches w alks inactive squirrel: pads stalker bipedal rhinoceros: jungle tusks rabbit: plankton bush bat: plankton flys hairless giraffe: yellow orange longneck w olf: arctic m uscle C hihuahua: w eak dom estic gray rat: fierce fields m eatteeth w easel: longneck grazer otter: tusks group coastal buffalo: slow toughskin zebra: stripes longneck bush giant panda: tusks plankton slow deer: spots lean hooves bobcat: strong yellow spots pig: w eak tunnels w hite lion: desert bulbous sm elly m ouse: forest group dom estic polar bear: ocean sm elly arctic collie: dom estic m eatteeth w alrus: tusks grazer buckteeth raccoon: stripes spots fast cow : horns c. dolphin: active dom estic sw im s\nbear plankton longneck strainteeth dolphin plankton longneck rodent plankton\ndomestic plankton longneck toughskin equine hunter meatteeth small sheperdbaleen musteln strainteeth longneck plankton big cat toughskin longneck big\ndeer muscle g.ape bovine small meatteeth pinnpd walks ground stalker procyonid longneck toughskin strainteeth\nbovid hooves horns grazer whale longleg plains fields dog strainteeth toughskin longneck cat strainteeth toughskin hairless odd−toed ungulate plankton meatteeth hunter primate plankton hands bipedal\nruminant plankton meatteeth hunter aquatic plankton ocean swims canine longneck feline plankton yellow orange\neven−toed hunter carnivore pads stalker paws\nungulate horns hooves longneck\nplacental\nFigure 2: Learned discriminative attributes association on the AWA-PCA dataset. Incorrect attributes are colored in red.\n0 2 4 6 8 10 15\n20\n25\n30\n35\n40\n45\nNumber of training examples\nA c c u\nra c y (\n% )\nAWA−PCA\nNo transfer AHLE USE USE−Reg.\n0 2 4 6 8 10 20\n30\n40\n50\n60\n70\nNumber of training examples\nA c c u\nra c y (\n% )\nAWA−DeCAF\nNo transfer AHLE USE USE−Reg.\nClass Learned decomposition Humpback whale A baleen whale, with plankton, flippers, blue, skimmer, arctic Leopard A big cat that is orange, claws, black Hippopotamus An even-toed ungulate, that is gray,bulbous, water, smelly, hands Chimpanzee A primate, that is mountains, strong,stalker, black Persian Cat A domestic cat, that is arctic, nestspot,fish, bush\nFigure 3: Few-shot experiment result on the AWA dataset, and generated semantic decompositions.\nas brown. Further, our method selects discriminative attributes for each supercategory, while there is no provided attribute label for supercategories.\nFigure 2 shows the discriminative attributes disjointly selected at each node on the class hierarchy. We observe that coarser grained categories fit to attributes that are common throughout all its children (e.g. pads, stalker and paws for carnivore), while the finer grained categories fit to attributes that help for finer-grained distinctions (e.g. orange for tiger, spots for leopard, and desert for lion)."
    }, {
      "heading" : "4.4 One-shot/Few-shot learning",
      "text" : "Our method is expected to be especially useful for few-shot learning, by generating a richer description than existing methods, that approximate the new input category using either trained categories or attributes. For this experiment, we divide the 50 categories into predefined 40/10 training/test split, and compare with the knowledge transfer using AHLE. We assume that no attribute label is provided for test set. For AHLE, and USE, we regularize the learning of W with W S learned on training class set S by adding λ2‖W −W S‖22, to LME (Eq. 3). For USE-Reg we use the reconstructive regularizer to regularize the model to generate semantic decomposition using US .\nFigure 3 shows the result, and the learned semantic decomposition of each novel category. While all methods make improvements over the no-transfer baseline, USE-Reg achieves the most improvement, improving two-shot result on AWA-DeCAF from 38.93% to 49.87%, where USE comes in second with 44.87%. Most learned reconstructions look reasonable, and fit to discriminative traits that help to discriminate between the test classes, which in this case are colors; orange for leopard, gray for hippopotamus, blue for humpback whale, and arctic (white) for Persian cat."
    }, {
      "heading" : "5 Conclusion",
      "text" : "We propose a unified semantic space model that learns a discriminative space for object categorization, with the help of auxiliary semantic entities such as supercategories and attributes. The auxiliary entities aid object categorization both indirectly, by sharing a common data embedding, and directly, by a sparse-coding based regularizer that enforces the category to be generated by its supercategory + a sparse combination of attributes. Our USE model improves both the flat-hit accuracy and hierarchical precision on the AWA dataset, and also generates semantically meaningful decomposition of categories, that provides human-interpretable rationale."
    } ],
    "references" : [ {
      "title" : "Learning to Detect Unseen Object Classes by Between-Class Attribute Transfer",
      "author" : [ "Christoph Lampert", "Hannes Nickisch", "Stefan Harmeling" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2009
    }, {
      "title" : "Describing Objects by their Attributes",
      "author" : [ "Ali Farhadi", "Ian Endres", "Derek Hoiem", "David Forsyth" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2009
    }, {
      "title" : "Sharing features between objects and their attributes",
      "author" : [ "Sung Ju Hwang", "Fei Sha", "Kristen Grauman" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2011
    }, {
      "title" : "Label-Embedding for Attribute-Based Classification",
      "author" : [ "Zeynep Akata", "Florent Perronnin", "Zaid Harchaoui", "Cordelia Schmid" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2013
    }, {
      "title" : "Constructing category hierarchies for visual recognition",
      "author" : [ "Marcin Marszalek", "Cordelia Schmid" ],
      "venue" : "In European Conference on Computer Vision (ECCV),",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2008
    }, {
      "title" : "Learning and using taxonomies for fast visual categorization",
      "author" : [ "Gregory Griffin", "Pietro Perona" ],
      "venue" : "In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2008
    }, {
      "title" : "Large margin taxonomy embedding for document categorization",
      "author" : [ "Kilian Q. Weinberger", "Olivier Chapelle" ],
      "venue" : "In Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2009
    }, {
      "title" : "Discriminative learning of relaxed hierarchy for large-scale visual recognition",
      "author" : [ "Tianshi Gao", "Daphne Koller" ],
      "venue" : "International Conference on Computer Vision (ICCV),",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2011
    }, {
      "title" : "Analogy-preserving semantic embedding for visual object categorization",
      "author" : [ "Sung Ju Hwang", "Kristen Grauman", "Fei Sha" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2013
    }, {
      "title" : "Label Embedding Trees for Large Multi- Class Task",
      "author" : [ "Samy Bengio", "Jason Weston", "David Grangier" ],
      "venue" : "In Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2010
    }, {
      "title" : "Distance-based image classification: Generalizing to new classes at near zero cost",
      "author" : [ "Thomas Mensink", "Jakov Verbeek", "Florent Perronnin", "Gabriela Csurka" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI),",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2013
    }, {
      "title" : "Devise: A deep visual-semantic embedding model",
      "author" : [ "Andrea Frome", "Greg Corrado", "Jon Shlens", "Samy Bengio", "Jeffrey Dean", "Marc’Aurelio Ranzato", "Tomas Mikolov" ],
      "venue" : "In Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2013
    }, {
      "title" : "Hierarchical regularization cascade for joint learning",
      "author" : [ "Alon Zweig", "Daphna Weinshall" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2013
    }, {
      "title" : "Supervised dictionary learning",
      "author" : [ "Julien Mairal", "Francis Bach", "Jean Ponce", "Guillermo Sapiro", "Andrew Zisserman" ],
      "venue" : "In Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2008
    }, {
      "title" : "Wsabie: Scaling up to large vocabulary image annotation",
      "author" : [ "Jason Weston", "Samy Bengio", "Nicolas Usunier" ],
      "venue" : "In International Joint Conferences on Artificial Intelligence (IJCAI),",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2011
    }, {
      "title" : "Exclusive lasso for multi-task feature selection",
      "author" : [ "Yang Zhou", "Rong Jin", "Steven C.H. Hoi" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2010
    }, {
      "title" : "Efficient online and batch learning using forward backward splitting",
      "author" : [ "John Duchi", "Yoram Singer" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2009
    }, {
      "title" : "DeCAF: A deep convolutional activation feature for generic visual recognition",
      "author" : [ "Jeff Donahue", "Yangqing Jia", "Oriol Vinyals", "Judy Hoffman", "Ning Zhang", "Eric Tzeng", "Trevor Darrell" ],
      "venue" : "In International Conference on Machine Learning (ICML),",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Attributes [1, 2, 3, 4] and semantic taxonomies [5, 6, 7, 8] are two popular semantic sources which impose certain relations between the category models, including a more recently introduced analogies [9] that induce even higher-order relations between them.",
      "startOffset" : 11,
      "endOffset" : 23
    }, {
      "referenceID" : 1,
      "context" : "Attributes [1, 2, 3, 4] and semantic taxonomies [5, 6, 7, 8] are two popular semantic sources which impose certain relations between the category models, including a more recently introduced analogies [9] that induce even higher-order relations between them.",
      "startOffset" : 11,
      "endOffset" : 23
    }, {
      "referenceID" : 2,
      "context" : "Attributes [1, 2, 3, 4] and semantic taxonomies [5, 6, 7, 8] are two popular semantic sources which impose certain relations between the category models, including a more recently introduced analogies [9] that induce even higher-order relations between them.",
      "startOffset" : 11,
      "endOffset" : 23
    }, {
      "referenceID" : 3,
      "context" : "Attributes [1, 2, 3, 4] and semantic taxonomies [5, 6, 7, 8] are two popular semantic sources which impose certain relations between the category models, including a more recently introduced analogies [9] that induce even higher-order relations between them.",
      "startOffset" : 11,
      "endOffset" : 23
    }, {
      "referenceID" : 4,
      "context" : "Attributes [1, 2, 3, 4] and semantic taxonomies [5, 6, 7, 8] are two popular semantic sources which impose certain relations between the category models, including a more recently introduced analogies [9] that induce even higher-order relations between them.",
      "startOffset" : 48,
      "endOffset" : 60
    }, {
      "referenceID" : 5,
      "context" : "Attributes [1, 2, 3, 4] and semantic taxonomies [5, 6, 7, 8] are two popular semantic sources which impose certain relations between the category models, including a more recently introduced analogies [9] that induce even higher-order relations between them.",
      "startOffset" : 48,
      "endOffset" : 60
    }, {
      "referenceID" : 6,
      "context" : "Attributes [1, 2, 3, 4] and semantic taxonomies [5, 6, 7, 8] are two popular semantic sources which impose certain relations between the category models, including a more recently introduced analogies [9] that induce even higher-order relations between them.",
      "startOffset" : 48,
      "endOffset" : 60
    }, {
      "referenceID" : 7,
      "context" : "Attributes [1, 2, 3, 4] and semantic taxonomies [5, 6, 7, 8] are two popular semantic sources which impose certain relations between the category models, including a more recently introduced analogies [9] that induce even higher-order relations between them.",
      "startOffset" : 48,
      "endOffset" : 60
    }, {
      "referenceID" : 8,
      "context" : "Attributes [1, 2, 3, 4] and semantic taxonomies [5, 6, 7, 8] are two popular semantic sources which impose certain relations between the category models, including a more recently introduced analogies [9] that induce even higher-order relations between them.",
      "startOffset" : 201,
      "endOffset" : 204
    }, {
      "referenceID" : 4,
      "context" : "Taxonomies, or class hierarchies were the first to be explored by vision researchers [5, 6], and were mostly used to efficiently rule out irrelevant category hypotheses leveraging class hierarchical structure [8, 10].",
      "startOffset" : 85,
      "endOffset" : 91
    }, {
      "referenceID" : 5,
      "context" : "Taxonomies, or class hierarchies were the first to be explored by vision researchers [5, 6], and were mostly used to efficiently rule out irrelevant category hypotheses leveraging class hierarchical structure [8, 10].",
      "startOffset" : 85,
      "endOffset" : 91
    }, {
      "referenceID" : 7,
      "context" : "Taxonomies, or class hierarchies were the first to be explored by vision researchers [5, 6], and were mostly used to efficiently rule out irrelevant category hypotheses leveraging class hierarchical structure [8, 10].",
      "startOffset" : 209,
      "endOffset" : 216
    }, {
      "referenceID" : 9,
      "context" : "Taxonomies, or class hierarchies were the first to be explored by vision researchers [5, 6], and were mostly used to efficiently rule out irrelevant category hypotheses leveraging class hierarchical structure [8, 10].",
      "startOffset" : 209,
      "endOffset" : 216
    }, {
      "referenceID" : 0,
      "context" : "They have been used to directly infer categories [1, 2], or as additional supervision to aid the main categorization problem in the multitask learning framework [3].",
      "startOffset" : 49,
      "endOffset" : 55
    }, {
      "referenceID" : 1,
      "context" : "They have been used to directly infer categories [1, 2], or as additional supervision to aid the main categorization problem in the multitask learning framework [3].",
      "startOffset" : 49,
      "endOffset" : 55
    }, {
      "referenceID" : 2,
      "context" : "They have been used to directly infer categories [1, 2], or as additional supervision to aid the main categorization problem in the multitask learning framework [3].",
      "startOffset" : 161,
      "endOffset" : 164
    }, {
      "referenceID" : 9,
      "context" : "[10] solves the problem using stochastic gradient, and also provides a way to learn a tree structure which enables one to efficiently predict the class label at the test time.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[11] eliminated the need of class embedding by replacing them with the class mean, which enabled generalization to new classes at near zero cost.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 6,
      "context" : "[7] used the taxonomies to preserve the inter-class similarities in the learned space,",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[4] used attributes and taxonomy information as labels, replacing the conventional unit-vector based class representation with more structured labels to improve on zero-shot performance.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 11,
      "context" : "One most recent work in this direction is DEVISE [12], which learns embeddings that maximize the ranking loss, as an additional layer on top of the deep network for both images and labels.",
      "startOffset" : 49,
      "endOffset" : 53
    }, {
      "referenceID" : 8,
      "context" : "[9] introduced one such model, which regularizes the category quadruplets, that form an analogy, to form a parallelogram.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 12,
      "context" : "Perhaps the most similar work is [13], where the parameter of each model is regularized while fixing the parameter for its parent-level models.",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 13,
      "context" : "[14], where the learning objective is to reduce both the classification and reconstruction error, given class labels.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 13,
      "context" : "In our model, however, the dictionary atoms are also discriminatively learned with supervision, and are assembled to be a semantically meaningful combination of a supercategory + attributes, while [14] learns the dictionary atoms in an unsupervised way.",
      "startOffset" : 197,
      "endOffset" : 201
    }, {
      "referenceID" : 9,
      "context" : "This is one of the most common objective used for learning discriminative category embeddings for multi-class classification [10, 7], while ranking loss-based [15] models have been also explored for LC .",
      "startOffset" : 125,
      "endOffset" : 132
    }, {
      "referenceID" : 6,
      "context" : "This is one of the most common objective used for learning discriminative category embeddings for multi-class classification [10, 7], while ranking loss-based [15] models have been also explored for LC .",
      "startOffset" : 125,
      "endOffset" : 132
    }, {
      "referenceID" : 14,
      "context" : "This is one of the most common objective used for learning discriminative category embeddings for multi-class classification [10, 7], while ranking loss-based [15] models have been also explored for LC .",
      "startOffset" : 159,
      "endOffset" : 163
    }, {
      "referenceID" : 3,
      "context" : "[4], which uses structured labels (attributes) as uyi .",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 15,
      "context" : "This, in fact, is the exclusive lasso regularizer introduced in [16], except for the nonnegativity constraint on βc, which makes the problem easier to solve.",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 13,
      "context" : "This problem is similar to the problem in [14], where the objective is to learn the dictionary, sparse coefficients, and classifier parameters together, and can be optimized using a similar alternating optimization, while each subproblem differs.",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 16,
      "context" : "Specifically, we implement the proximal gradient algorithm in [17], handling the `-2 norm constraints with proximal operators.",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 16,
      "context" : "Training: Optimization of W and U using proximal stochastic gradient [17], have time complexities of O(dd(k+1)) and O(d(dk+C)) respectively.",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 0,
      "context" : "We use Animals with Attributes dataset [1], which consists of 30, 475 images of 50 animal classes, with 85 class-level attributes 2.",
      "startOffset" : 39,
      "endOffset" : 42
    }, {
      "referenceID" : 17,
      "context" : "2) AWA-DeCAF: For the second dataset, we use the provided 4096-D DeCAF features [18] obtained from the layer just before the output layer of a deep convolutional neural network.",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 10,
      "context" : "2) NCM: Nearest mean classifier from [11], which uses the class mean as category embeddings (uc = xc ).",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 6,
      "context" : "[7], which enforces the semantic similarity between class embeddings as distance constraints [7], where U is regularized to preserve the pairwise class similarities from a given taxonomy.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "[7], which enforces the semantic similarity between class embeddings as distance constraints [7], where U is regularized to preserve the pairwise class similarities from a given taxonomy.",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 3,
      "context" : "[4], which encodes the semantic information by representing each class with structured labels that indicate the class’ association with superclasses and attributes.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 11,
      "context" : "We report the average classification performance and standard error over 5 random training/test splits in Table 1 and 2, using both flat hit@k, which is the accuracy for the top-k predictions made, and hierarchical precision@k from [12], which is a precision the given label is correct at k, at all levels.",
      "startOffset" : 232,
      "endOffset" : 236
    } ],
    "year" : 2014,
    "abstractText" : "We propose a method that learns a discriminative yet semantic space for object categorization, where we also embed auxiliary semantic entities such as supercategories and attributes. Contrary to prior work, which only utilized them as side information, we explicitly embed these semantic entities into the same space where we embed categories, which enables us to represent a category as their linear combination. By exploiting such a unified model for semantics, we enforce each category to be generated as a supercategory + a sparse combination of attributes, with an additional exclusive regularization to learn discriminative composition. The proposed reconstructive regularization guides the discriminative learning process to learn a model with better generalization. This model also generates compact semantic description of each category, which enhances interoperability and enables humans to analyze what has been learned.",
    "creator" : null
  }
}