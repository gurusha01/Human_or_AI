{
  "name" : "c06d06da9666a219db15cf575aff2824.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Inferring sparse representations of continuous signals with continuous orthogonal matching pursuit",
    "authors" : [ "Karin C. Knudson", "Jacob L. Yates", "Jonathan W. Pillow" ],
    "emails" : [ "kknudson@math.utexas.edu", "jlyates@utexas.edu", "huk@utexas.edu", "pillow@princeton.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "It is often the case that an observed signal is a linear combination of some other target signals that one wishes to resolve from each other and from background noise. For example, the voltage trace from an electrode (or array of electrodes) used to measure neural activity in vivo may be recording from a population of neurons, each of which produces many instances of its own stereotyped action potential waveform. One would like to decompose an analog voltage trace into a list of the timings and amplitudes of action potentials (spikes) for each neuron.\nMotivated in part by the spike-sorting problem, we consider the case where we are given a signal that is the sum of known waveforms whose timing and amplitude we seek to recover. Specifically, we suppose our signal can be modeled as:\ny(t) = Nf∑ n=1 J∑ j=1 an,jfn(t− τn,j), (1)\nwhere the waveforms fn are known, and we seek to estimate positive amplitudes an,j and event times τn,j . Signals of this form have been studied extensively [12, 9, 4, 3].\nThis a difficult problem in part because of the nonlinear dependence of y on τ . Moreover, in most applications we do not have access to y(t) for arbitrary t, but rather have a vector of sampled (noisy) measurements on a grid of discrete time points. One way to simplify the problem is to discretize τ , considering only a finite set of possible time shift τn,j ∈ {∆, 2∆..., N∆∆} and approximating the signal as\ny ≈ Nf∑ n=1 J∑ j=1 an,jfn(t− in,j∆), in,j ∈ 1, ..., N∆ (2)\nOnce discretized in this way, the problem is one of sparse recovery: we seek to represent the observed signal with a sparse linear combination of elements of a finite dictionary {fn,j(t) := fn(t − j∆), n ∈ 1, ..., Nf , j ∈ 1, ..., N∆}. Framing the problem as sparse recovery, one can bring tools from compressed sensing to bear. However, the discretization introduces several new difficulties. First, we can only approximate the translation τ by values on a discrete grid. Secondly, choosing small ∆ allows us to more closely approximate τ , but demands more computation, and such finely spaced dictionary elements yield a highly coherent dictionary, while sparse recovery algorithms generally have guarantees for low-coherence dictionaries.\nA previously introduced algorithm that uses techniques of sparse recovery and returns accurate and continuous valued estimates of a and τ is Continuous Basis Pursuit (CBP) [4], which we describe below. CBP proceeds (roughly speaking) by augmenting the discrete dictionary fn,j(t) with other carefully chosen basis elements, and then solving a convex optimization problem inspired by basis pursuit denoising. We extend ideas introduced in CBP to present a new method for recovering the desired time shifts τ and amplitudes a that leverage the speed and tractability of solving the discretized problem while still ultimately producing continuous valued estimates of τ , and partially circumventing the problem of too much coherence.\nBasis pursuit denoising and other convex optimization or `1-minimization based methods have been effective in the realm of sparse recovery and compressed sensing. However, greedy methods have also been used with great success. Our approach begins with the augmented bases used in CBP, but adds basis vectors greedily, drawing on the well known Orthogonal Matching Pursuit algorithm [11]. In the regimes considered, our greedy approach is faster and more accurate than CBP.\nBroadly speaking, our approach has three parts. First, we augment the discretized basis in one of several ways. We draw on [4] for two of these choices, but also present another choice of basis that is in some sense optimal. Second, we greedily select candidate time bins of size ∆ in which we suspect an event has occurred. Finally, we move from this rough, discrete-valued estimate of timing τ to continuous-valued estimates of τ and a. We iterate the second and third steps, greedily adding candidate time bins and updating our estimates of τ and a until a stopping criterion is reached.\nThe structure of the paper is as follows. In Section 2 we describe the method of Continuous Basis Pursuit (CBP), which our method builds upon. In Section 3 we develop our method, which we call Continuous Orthogonal Matching Pursuit (COMP). In Section 4 we present the performance of our method on simulated and neural data."
    }, {
      "heading" : "2 Continuous basis pursuit",
      "text" : "Continuous Basis Pursuit (CBP) [4, 3, 5] is a method for recovering the time shifts and amplitudes of waveforms present in a signal of the form (1). A key element of CBP is augmenting or replacing the set {fn,j(t)} with certain additional dictionary elements that are chosen to smoothly interpolate the one dimensional manifold traced out by fn,j(t− τ) as τ varies in (−∆/2,∆/2). The benefit of a dictionary that is expanded in this way is twofold. First, it increases the ability of the dictionary to represent shifted copies of the waveform fn(t − τ) without introducing as much correlation as would be introduced by simply using a finer discretization (decreasing ∆), which is an advantage because dictionaries with smaller coherence are generally better suited for sparse recovery techniques. Second, one can move from recovered coefficients in this augmented dictionary to estimates an,j and continuous-valued estimates of τn,j .\nIn general, there are three ingredients for CBP: basis elements, an interpolator with corresponding mapping function Φ, and a convex constraint set, C. There are K basis elements {gn,j,k(t) = gn,k(t−j∆)}k=Kk=1 , for each waveform and width-∆ time bin, which together can be used to linearly interpolate fn,j(t − τ), |τ | < ∆/2. The function Φ maps from amplitude a and time shift τ to Ktuples of coefficients Φ(a, τ) = (c(1)n,j , ..., c (K) n,j ), so afn,j(t− τ) ≈ ∑K k=1 c (k) n,jgn,j,k(t). The convex constraint set C is for K-tuples of coefficients of {gn,j,k}k=Kk=1 and corresponds to the requirement that a > 0 and |τ | < ∆/2. If the constraint region corresponding to these requirements is not convex (e.g. in the polar basis discussed below), its convex relaxation is used.\nAs a concrete example, let us first consider (as discussed in [4]) the dictionary augmented with shifted copies of each waveform’s derivative : {f ′n,j(t) := f ′n(t−j∆)}. Assuming fn is sufficiently smooth, we have from the Taylor expansion that for small τ , afn,j(t−τ) ≈ afn,j(t)−aτf ′n,j(t). If we recover a representation of y as c1fn,j(t)+c2f ′n,j(t), then we can estimate the amplitude a of the waveform present in y as c1, the time shift τ as−c2/c1. Hence, we estimate y ≈ c1fn,j(t+c2/c1) = c1fn(t − j∆ + c2/c1). Note that the estimate of the time shift τ varies continuously with c1, c2. In contrast, using shifted copies of the waveforms only as a basis would not allow for a time shift estimate off of the grid {j∆}j=N∆j=1 . Once a suitable dictionary is chosen, one must still recover coefficients (i.e. c1, c2 above). Motivated by the assumed sparsity of the signal (i.e. y is the sum of relatively few shifted copies of waveforms, so the coefficients of most dictionary elements will be zero), CBP draws on the basis pursuit denoising, which has been effective in the compressive sensing setting and elsewhere [10],[1]. Specifically, CBP (with a Taylor basis) recovers coefficients using:\nargminc ∥∥∥∥∥∥ Nf∑ n=1 (Fnc (1) n + F ′ nc (2) n )− y ∥∥∥∥∥∥ 2\n2\n+ λ Nf∑ n=1 ∥∥∥c(1)n ∥∥∥ 1 s.t. c(1)n,i ≥ 0 , |c (2) n,i| ≤ ∆ 2 c (1) i,n ∀n, i (3)\nHere we denote by F the matrix with columns {fn,j(t)} and F′ the matrix with columns {f ′n,j(t)}. The `1 penalty encourages sparsity, pushing most of the estimated amplitudes to zero, with higher λ encouraging greater sparsity. Then, for each (n, j) such that c(1)n,j 6= 0, one estimates that there is a waveform in the shape of fn with amplitude â = c (1) n,j and time shift j∆ − τ̂ = j∆ − c (2) n,j/c (1) n,j present in the signal. The inequality constraints in the optimization problem ensure first that we only recover positive amplitudes â, and second that estimates τ̂ satisfy |τ̂ | < ∆/2. Requiring τ̂ to fall in this range keeps the estimated τ in the time bin represented by fn,j and also in the regime where they Taylor approximation to fn,j(t−τ) is accurate. Note that (3) is a convex optimization problem. Better results in [4] are obtained for a second order Taylor interpolation and the best results come from a polar interpolator, which represents each manifold of time-shifted waveforms fn,j(t − τ), |τ | ≤ ∆/2 as an arc of the circle that is uniquely defined to pass through fn,j(t), fn,j(t−∆/2), and fn,j(t+∆/2). Letting the radius of the arc be r, and its angle be 2θ one represents points on this arc by linear combinations of functions w, u, v: f(t−τ) ≈ w(t)+r cos( 2τ∆ θ)u(t)+r sin( 2τ ∆ θ)v(t).\nThe Taylor and polar bases consist of shifted copies of elements chosen in order to linearly interpolate the curve in function space defined by fn(t − τ) as τ varies from −∆/2 to ∆/2. Let Gn,k be the matrix whose columns are gn,j,k(t) for j ∈ 1, ..., N∆. With choices of basis elements, interpolator, and corresponding convex constraint set C in place, one proceeds to estimate coefficients in the chosen basis by solving:\nargminc ∥∥∥∥∥∥y − Nf∑ n=1 K∑ k=1 Gn,kc (k) n ∥∥∥∥∥∥ 2\n2\n+ λ‖ Nf∑ n=1 c(1)n ‖1 subject to (c (1) n,j , ..., c (K) n,j ) ∈ C ∀(n, j) (4)\nOne then maps back from each nonzero K-tuple of recovered coefficients c(1)n,j , ..., c (K) n,j to corresponding ân,j , τ̂n,j that represent the amplitude and timing of the nth waveform present in the jth time bin. This can be done by inverting Φ, if possible, or estimating (ân,j , τ̂n,j) = argmina,τ‖Φ(a, τ)− (c (1) n,j , ..., c (K) n,j )‖22."
    }, {
      "heading" : "3 Continuous Orthogonal Matching Pursuit",
      "text" : "We now present our method for recovery, which makes use of the idea of augmented bases presented above, but differs from CBP in several important ways. First, we introduce a different choice of basis that we find enables more accurate estimates. Second, we make use of a greedy method that iterates between choosing basis vectors and estimating time shifts and amplitudes, rather than proceeding via a single convex optimization problem as CBP does. Lastly, we introduce an alternative to the step of mapping back from recovered coefficients via Φ that notably improves the accuracy of the recovered time estimates.\nGreedy methods such as Orthogonal Matching Pursuit (OMP) [11], Subspace Pursuit [2], and Compressive Sampling Matching Pursuit (CoSaMP) [8] have proven to be fast and effective in the realm of compressed sensing. Since the number of iterations of these greedy methods tend to go as the sparsity (when the algorithms succeed), they tend to be extremely fast when for very sparse signals. Moreover, our the greedy method eliminates the need to choose a regularization constant λ, a choice that can vastly alter the effectiveness of CBP. (We still need to choose K and ∆.) Our method is most closely analogous to OMP, but recovers continuous time estimates, so we call it Continuous Orthogonal Matching Pursuit (COMP). However, the steps below could be adapted in a straightforward way to create analogs of other greedy methods."
    }, {
      "heading" : "3.1 Choice of finite basis",
      "text" : "We build upon [4], choosing as our basis N∆ shifted copies of a set of K basis vectors for each waveform in such away that these K basis vectors can effectively linearly interpolate fn(t − τ) for |τ | < ∆/2. In our method, as in Continuous Basis Pursuit, these basis vectors allow us to represent continuous time shifts instead of discrete time shifts, and expand the descriptive power of our dictionary without introducing undue amounts of coherence. While previous work introduced Taylor and polar bases, we obtain the best recovery from a different basis, which we describe now.\nThe basis comes from a singular value decomposition of a matrix whose columns correspond to discrete points on the curve in function space traced out by fn,j(t− τ) as we vary τ for |τ | < ∆/2. Within one time bin of size ∆, consider discretizing further intoNδ = ∆/δ time bins of size δ ∆. Let Fδ be the matrix with columns that are these (slightly) shifted copies of the waveform, so that the ith column of Fδ is fn,j(t − iδ + ∆/2) for a discrete vector of time points t. Each column of this matrix is a discrete point on the curve traced out by fn,j(t− τ) as τ varies. In choosing a basis, we seek the best choice ofK vectors to use to linearly interpolate this curve. We might instead seek to solve the related problem of finding the bestK vectors to represent these finely spaced points on the curve, in which case a clear choice for theseK vectors is the firstK left singular vectors of Fδ . This choice is optimal in the sense that the singular value decomposition yields the best rank-K approximation to a matrix. If Fδ = UΣVT is the singular value decomposition, and uk,vk are the columns of U and V respectively, then ‖Fδ − ∑K k=1 u kΣk,k(v k)T ‖ ≤ ‖F−A‖ for any rank-K matrix A and any unitarily invariant norm ‖ · ‖.\nIn order to use this SVD basis with CBP or COMP, one must specify a convex constraint set for the coefficients of this basis. Since afn,j(t− iδ) = ∑K k=1 au kΣk,kv k i a reasonable and simply enforced constraint set would be to assume that the recovered coefficients c(k) corresponding to each basis vector uk, when divided by c(1) to account for scaling, be between mini Σk,kvki and maxi Σk,kv k i . A\nsimple way to recover a and τ would to choose τ = iδ and a, i to minimize ∑K k=1(c\n(k)−aΣk,kvki )2. In figure 3.1, we compare the error between shifted copies of a sample waveform f(t − τ) for |τ | < 0.5 and the best (least-squares) approximation of that waveform as a linear combination of K = 3 vectors from the Taylor, polar, and SVD bases. The structure of the error as a function of the time shift τ reflects the structure of these bases. The Taylor approximation is chosen to be exactly accurate at τ = 0 while the polar basis is chosen to be precisely accurate at τ = 0,∆/2,−∆/2. The SVD basis gives the lowest mean error across time shifts.\nTaylor: Polar: SVD: 0.027 0.027 0.014"
    }, {
      "heading" : "3.2 Greedy recovery",
      "text" : "Having chosen our basis, we then greedily recover the time bins in which an occurrence of each waveform appears to be present. We would like to build up a set of pairs (n, j) corresponding to an instance of the nth waveform in the jth time bin. (In our third step, we will refine the estimate within the chosen bins.)\nOur greedy method is motivated by Orthogonal Matching Pursuit (OMP), which is used to recover a sparse solution x from measurements y = Ax. In OMP [11], one greedily adds a single dictionary element to an estimated support set S at each iteration, and then projects orthogonally to adjust the coefficients of all chosen dictionary elements. After initializing with S = ∅,x = 0, one iterates the following until a stopping criterion is met:\nr = y −Ax j = argmaxj{|〈aj , r〉| s.t. j ∈ {1, ...J}\\S} S = S ∪ {j} x = argminz{||y −Az||2 s.t. zi = 0 ∀ i /∈ S}\nIf we knew the sparsity of the signal, we could use that as our stopping condition. Normally we do not know the sparsity a priori; we stop when changes in the residual become sufficiently small.\nWe adjust this method to choose at each step not a single additional element but rather a set of K associated basis vectors. S is again initialized to be empty, but at each step we add a timebin/waveform pair (n, j), which is associated with K basis vectors. In this way, we are adding K vectors at each step, instead of one as in OMP. We greedily add the next index (n, j) according to:\n(n, j) = argminm,i { min cm,i {‖ k∑ i=1 c (k) m,ig (k) m,i − r‖ 2 2 s.t. cm,i ∈ C} , (m, i) ∈ Sc } (5)\nHere {g(k)m,i} are the chosen basis vectors (Taylor, polar, or SVD), and C is the corresponding constraint set, as in Section 2.\nIn comparison with the greedy step in OMP, choosing j as in (5) is more costly, because we need to perform a constrained optimization over a K dimensional space for each n, j. Fortunately, it is not necessary to repeat the optimization for each of the Nf ·N∆ possible indices each time we add an index. Assuming waves are localized in time, we need only update the results of the constrained optimization locally. When we update the residual r by subtracting the newly identified waveform n in the jth bin, the residual only changes in the bins at or near the jth bin, so we need only update the quantity mincn,j′{‖ ∑k i=1 c (k) n,j′g (k) n,j′ − r‖22 s.t. cn,j′ ∈ C } for j′ neighboring j."
    }, {
      "heading" : "3.3 Estimating time shifts",
      "text" : "Having greedily added a new waveform/timebin index pair (n, j), we next define our update step, which will correspond to the orthogonal projection in OMP. We present two alternatives, one of which most closely mirrors the corresponding step in OMP, the other of which works within the Fourier domain to obtain more accurate recovery.\nTo most closely follow the steps of OMP, at each iteration after updating S we update coefficients c according to:\nargminc ∥∥∥∥∥∥ ∑\n(n,j)∈S K∑ k=1 c (k) n,jg (k) n,j − y ∥∥∥∥∥∥ 2\n2\nsubject to cn,j ∈ C ∀ (n, j) ∈ S (6)\nWe alternate between the greedily updating S via (5), and updating c as in (6), at each iteration finding the new residual r = ∑ (n,j)∈S ∑K k=1 c (k) n,jg (k) n,j−y ) until the `2 stopping criterion is reached. Then, one maps back from {cn,j}(n,j)∈S to {a(n,j), τ(n,j)}(n,j)∈S as described in Section 2. Alternatively we may replace the orthogonal projection step with a more accurate recovery of spike timings that involves working in the Fourier domain. We use the property of the Fourier transform with respect to translation that: (f(t− τ))∧ = e2πiτ f̂ . This allows us to estimate a, τ directly via:\nargmina,τ‖( ∑ n,j∈S an,je 2πiωτn,j f̂n,j(ω))− ŷ(ω)‖2 subject to |τn,j | < ∆/2 ∀ (n, j) ∈ S (7)\nThis is a nonlinear and non-convex constrained optimization problem. However, it can be solved reasonably quickly using, for example, trust region methods. The search space is dramatically reduced because τ has only |S| entries, each constrained to be small in absolute value. By searching directly for a, τ as in (7) we sacrifice convexity, but with the benefit of eliminating from this step error of interpolation introduced as we map back from c to a, τ using Φ−1 or a least squares estimation.\nIt is easy and often helpful to add inequality constraints to a as well, for example requiring a to be in some interval around 1, and we do impose this in our spike-sorting simulations and analysis in Section 4. Such a requirement effectively imposes a uniform prior on a over the chosen interval. It would be an interesting future project to explore imposing other priors on a."
    }, {
      "heading" : "4 Results",
      "text" : "We test COMP and CBP for each choice of basis on simulated and neural data. Here, COMP denotes the greedy method that includes direct estimation of a and τ during the update set as in (7). The convex optimization for CBP is implemented using the cvx package for MATLAB [7], [6]."
    }, {
      "heading" : "4.1 Simulated data",
      "text" : "We simulate a signal y as the sum of time-shifted copies of two sample waveforms f1(t) ∝ t exp(−t2) and f2(t) ∝ e−t\n4/16 − e−t2 (Figure 2a). There are s1 = s2 = 5 shifted copies of f1 and f2, respectively. The time shifts are independently generated for each of the two waveforms using a Poisson process (truncated after 5 spikes), and independent Gaussian noise of variance σ2 is\n5 0 5 0.5\n0\n0.5\nt 5 0 5 0.5\n0\n0.5\nt\nCBP-SVD\nCOMP-SVD\n0 .05 .1 .2 .4 0\n0.5\n1\n1.5\n2\n2.5\nNoise ( )\n(M iss\nes +\nF al\nse P\nos itiv\nes )/s\nCBP Taylor CBP Polar CBP SVD COMP Taylor COMP Polar COMP SVD\n0 .05 .1 .2 .4 0\n0.1\n0.2\n0.3\n0.4\n0.5\nAv er\nag e\nHi t E\nrro r\nNoise ( ) 0 20 40 60 80 100\n1\n0.5\n0\n0.5\n1 0 20 40 60 80 100\n1\n0.5\n0\n0.5\n1\n0 20 40 60 80 100 0\n0.5\n1\n1.5\n0 20 40 60 80 100 0\n0.5\n1\n1.5\nTrue COMP SVD\n0 20 40 60 80 100 0\n0.5\n1\n1.5\n0 20 40 60 80 100 0\n0.5\n1\n1.5\nTrue CBP SVD\nwaveform 1\nt\nt t\nwaveform 2\nw av\nef or\nm 1\nw av\nef or\nm 1\nw av\nef or\nm 2\nw av\nef or\nm 2\n(a)\n(b)\n(c)\n(d)\n(e)\n(f )\nFigure 2: (a) Waveforms present in the signal. (b) A noiseless (top) and noisy (bottom) signal with σ = .2. (c) Recovery using CBP. (d) Recovery using COMP (with a, τ updated as in (7)). (e) For each recovery method over different values of the standard deviation of the noise σ, misses plus false positives, divided by the total number of events present, s = s1 + s2. (f) Average distance between the true and estimated spike for each hit.\nadded at each time point. Figures 2b,c show an example noise-free signal (σ = 0), and noisy signal (σ = .2) on which each recovery method will be run.\nWe run CBP with the Taylor and polar bases, but also with our SVD basis, and COMP with all three bases. Since COMP here imposes a lower bound on a, we also impose a thresholding step after recovery with CBP, discarding any recovered waveforms with amplitude less than .3. We find the thresholding generally improved the performance of the CBP algorithm by pruning false positives. Throughout, we use K = 3, since the polar basis requires 3 basis vectors per bin.\nWe categorize hits, false positive and misses based on whether a time shift estimate is within a threshold of = 1 of the true value. The “average hit error” of Figure 2h, 3b is the average distance between the true and estimated event time for each estimate that is categorized as a hit. Results are averaged over 20 trials.\nWe compare CBP and COMP over different parameter regimes, varying the noise (σ) and the bin size (∆). Figures 2g and 3a show misses plus false positives for each method, normalized by the total number of events present. Figures 2f and 3b show average distance between the true and estimated spike for each estimate categorized as a hit. The best performance by both measures across nearly all parameter regimes considered is achieved by COMP using the SVD basis. COMP is more robust to noise (Figure 2g), and also to increases in bin width ∆. Since both algorithms are faster for higher ∆, robustness with respect to ∆ is an advantage. We also note a significant increase in CBP’s robustness to noise when we implement it with our SVD basis rather than with the Taylor or polar basis (Figure 2e).\nA significant advantage of COMP over CBP is its speed. In Figure 3c we compare the speed of COMP (solid) and CBP (dashed) algorithms for each basis. COMP yields vast gains in speed. The comparison is especially dramatic for small ∆, where results are most accurate across methods."
    }, {
      "heading" : "4.2 Neural data",
      "text" : "We now present recovery of spike times and identities from neural data. Recordings were made using glass-coated tungsten electrodes in the lateral intraparietal sulcus (LIP) of a macaque monkey performing a motion discrimination task. In addition to demonstrating the applicability of COMP to sorting spikes in neural data, this section also shows the resistance of COMP to a certain kind of error that recovery via CBP can systematically commit, and which is relevant to neural data.\nIn the data, the waveform of one neuron resembles a scaled copy of another (Figure 4a).The similarity causes problems for CBP or any other `1 minimization based method that penalizes large amplitudes. When the second waveform is present with an amplitude of one, CBP is likely to incorrectly add a low-amplitude copy of the first waveform (to reduce the amplitude penalty), instead of correctly choosing the larger copy of the second waveform; the amplitude penalty for choosing the correct waveform can outweigh the higher `2 error caused by including the incorrect waveform.\nThis misassignment is exactly what we observe (Figure 4b). We see that CBP tends to report smallamplitude copies of waveform one where COMP reports large-amplitude copies of waveform two. Although we lack ground truth, the closer match of the recovered signal to data (Figure 4c) indicates that the waveform identities and amplitudes identified via COMP better explain the observed signal."
    }, {
      "heading" : "5 Discussion",
      "text" : "We have presented a new greedy method called Continuous Orthogonal Matching Pursuit (COMP) for identifying the timings and amplitudes for waveforms from a signal that has the form of a (noisy) sum of shifted and scaled copies of several known waveforms. We draw upon the method of Continuous Basis Pursuit, and extend it in several ways. We leverage the success of Orthogonal Matching Pursuit in the realm of sparse recovery, use a different basis derived from a singular value decomposition, and also introduce a move to the Fourier domain to fine-tune the recovered time shifts. Our SVD basis can also be used with CBP and in our simulations it increased performance of CBP as compared to previously used bases. In our simulations COMP obtains increased accuracy as well as greatly increased speed over CBP across nearly all regimes tested. Our results suggest that greedy methods of the type introduced here may be quite promising for, among other applications, spike-sorting during the processing of neural data."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was supported by the McKnight Foundation (JP), NSF CAREER Award IIS-1150186 (JP), and grants from the NIH (NEI grant EY017366 and NIMH grant MH099611 to AH & JP)."
    } ],
    "references" : [ {
      "title" : "Atomic decomposition by basis pursuit",
      "author" : [ "Scott Shaobing Chen", "David L Donoho", "Michael A Saunders" ],
      "venue" : "SIAM journal on scientific computing,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1998
    }, {
      "title" : "Subspace pursuit for compressive sensing signal reconstruction",
      "author" : [ "Wei Dai", "Olgica Milenkovic" ],
      "venue" : "Information Theory, IEEE Transactions on,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2009
    }, {
      "title" : "A blind deconvolution method for neural spike identification",
      "author" : [ "Chaitanya Ekanadham", "Daniel Tranchina", "Eero P Simoncelli" ],
      "venue" : "In Proceedings of the 25th Annual Conference on Neural Information Processing Systems (NIPS11),",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2011
    }, {
      "title" : "Recovery of sparse translation-invariant signals with continuous basis pursuit",
      "author" : [ "Chaitanya Ekanadham", "Daniel Tranchina", "Eero P Simoncelli" ],
      "venue" : "Signal Processing, IEEE Transactions on,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2011
    }, {
      "title" : "A unified framework and method for automatic neural spike identification",
      "author" : [ "D. Ekanadham", "C.vand Tranchina", "E.P. Simoncelli" ],
      "venue" : "Journal of Neuroscience Methods,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2014
    }, {
      "title" : "Graph implementations for nonsmooth convex programs",
      "author" : [ "M. Grant", "S. Boyd" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2008
    }, {
      "title" : "Cosamp: Iterative signal recovery from incomplete and inaccurate samples",
      "author" : [ "Deanna Needell", "Joel A Tropp" ],
      "venue" : "Applied and Computational Harmonic Analysis,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2009
    }, {
      "title" : "A model-based spike sorting algorithm for removing correlation artifacts in multi-neuron recordings",
      "author" : [ "Jonathan W Pillow", "Jonathon Shlens", "EJ Chichilnisky", "Eero P Simoncelli" ],
      "venue" : "PloS one,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2013
    }, {
      "title" : "Regression shrinkage and selection via the lasso",
      "author" : [ "Robert Tibshirani" ],
      "venue" : "Journal of the Royal Statistical Society. Series B (Methodological),",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1996
    }, {
      "title" : "Signal recovery from random measurements via orthogonal matching pursuit",
      "author" : [ "Joel A Tropp", "Anna C Gilbert" ],
      "venue" : "Information Theory, IEEE Transactions on,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2007
    }, {
      "title" : "Sampling signals with finite rate of innovation",
      "author" : [ "Martin Vetterli", "Pina Marziliano", "Thierry Blu" ],
      "venue" : "Signal Processing, IEEE Transactions on,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2002
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "The method involves greedily selecting component waveforms and then refining estimates of their amplitudes and translations, moving iteratively between these steps in a process analogous to the well-known Orthogonal Matching Pursuit (OMP) algorithm [11].",
      "startOffset" : 249,
      "endOffset" : 253
    }, {
      "referenceID" : 3,
      "context" : "Our approach for modeling translations borrows from Continuous Basis Pursuit (CBP) [4], which we extend in several ways: by selecting a subspace that optimally captures translated copies of the waveforms, replacing the convex optimization problem with a greedy approach, and moving to the Fourier domain to more precisely estimate time shifts.",
      "startOffset" : 83,
      "endOffset" : 86
    }, {
      "referenceID" : 10,
      "context" : "Signals of this form have been studied extensively [12, 9, 4, 3].",
      "startOffset" : 51,
      "endOffset" : 64
    }, {
      "referenceID" : 7,
      "context" : "Signals of this form have been studied extensively [12, 9, 4, 3].",
      "startOffset" : 51,
      "endOffset" : 64
    }, {
      "referenceID" : 3,
      "context" : "Signals of this form have been studied extensively [12, 9, 4, 3].",
      "startOffset" : 51,
      "endOffset" : 64
    }, {
      "referenceID" : 2,
      "context" : "Signals of this form have been studied extensively [12, 9, 4, 3].",
      "startOffset" : 51,
      "endOffset" : 64
    }, {
      "referenceID" : 3,
      "context" : "A previously introduced algorithm that uses techniques of sparse recovery and returns accurate and continuous valued estimates of a and τ is Continuous Basis Pursuit (CBP) [4], which we describe below.",
      "startOffset" : 172,
      "endOffset" : 175
    }, {
      "referenceID" : 9,
      "context" : "Our approach begins with the augmented bases used in CBP, but adds basis vectors greedily, drawing on the well known Orthogonal Matching Pursuit algorithm [11].",
      "startOffset" : 155,
      "endOffset" : 159
    }, {
      "referenceID" : 3,
      "context" : "We draw on [4] for two of these choices, but also present another choice of basis that is in some sense optimal.",
      "startOffset" : 11,
      "endOffset" : 14
    }, {
      "referenceID" : 3,
      "context" : "Continuous Basis Pursuit (CBP) [4, 3, 5] is a method for recovering the time shifts and amplitudes of waveforms present in a signal of the form (1).",
      "startOffset" : 31,
      "endOffset" : 40
    }, {
      "referenceID" : 2,
      "context" : "Continuous Basis Pursuit (CBP) [4, 3, 5] is a method for recovering the time shifts and amplitudes of waveforms present in a signal of the form (1).",
      "startOffset" : 31,
      "endOffset" : 40
    }, {
      "referenceID" : 4,
      "context" : "Continuous Basis Pursuit (CBP) [4, 3, 5] is a method for recovering the time shifts and amplitudes of waveforms present in a signal of the form (1).",
      "startOffset" : 31,
      "endOffset" : 40
    }, {
      "referenceID" : 3,
      "context" : "As a concrete example, let us first consider (as discussed in [4]) the dictionary augmented with shifted copies of each waveform’s derivative : {f ′ n,j(t) := f ′ n(t−j∆)}.",
      "startOffset" : 62,
      "endOffset" : 65
    }, {
      "referenceID" : 8,
      "context" : "y is the sum of relatively few shifted copies of waveforms, so the coefficients of most dictionary elements will be zero), CBP draws on the basis pursuit denoising, which has been effective in the compressive sensing setting and elsewhere [10],[1].",
      "startOffset" : 239,
      "endOffset" : 243
    }, {
      "referenceID" : 0,
      "context" : "y is the sum of relatively few shifted copies of waveforms, so the coefficients of most dictionary elements will be zero), CBP draws on the basis pursuit denoising, which has been effective in the compressive sensing setting and elsewhere [10],[1].",
      "startOffset" : 244,
      "endOffset" : 247
    }, {
      "referenceID" : 3,
      "context" : "Better results in [4] are obtained for a second order Taylor interpolation and the best results come from a polar interpolator, which represents each manifold of time-shifted waveforms fn,j(t − τ), |τ | ≤ ∆/2 as an arc of the circle that is uniquely defined to pass through fn,j(t), fn,j(t−∆/2), and fn,j(t+∆/2).",
      "startOffset" : 18,
      "endOffset" : 21
    }, {
      "referenceID" : 3,
      "context" : "Table 1: Basis choices (see also [4], Table 1.",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 9,
      "context" : "Greedy methods such as Orthogonal Matching Pursuit (OMP) [11], Subspace Pursuit [2], and Compressive Sampling Matching Pursuit (CoSaMP) [8] have proven to be fast and effective in the realm of compressed sensing.",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 1,
      "context" : "Greedy methods such as Orthogonal Matching Pursuit (OMP) [11], Subspace Pursuit [2], and Compressive Sampling Matching Pursuit (CoSaMP) [8] have proven to be fast and effective in the realm of compressed sensing.",
      "startOffset" : 80,
      "endOffset" : 83
    }, {
      "referenceID" : 6,
      "context" : "Greedy methods such as Orthogonal Matching Pursuit (OMP) [11], Subspace Pursuit [2], and Compressive Sampling Matching Pursuit (CoSaMP) [8] have proven to be fast and effective in the realm of compressed sensing.",
      "startOffset" : 136,
      "endOffset" : 139
    }, {
      "referenceID" : 3,
      "context" : "1 Choice of finite basis We build upon [4], choosing as our basis N∆ shifted copies of a set of K basis vectors for each waveform in such away that these K basis vectors can effectively linearly interpolate fn(t − τ) for |τ | < ∆/2.",
      "startOffset" : 39,
      "endOffset" : 42
    }, {
      "referenceID" : 9,
      "context" : "In OMP [11], one greedily adds a single dictionary element to an estimated support set S at each iteration, and then projects orthogonally to adjust the coefficients of all chosen dictionary elements.",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 5,
      "context" : "The convex optimization for CBP is implemented using the cvx package for MATLAB [7], [6].",
      "startOffset" : 85,
      "endOffset" : 88
    } ],
    "year" : 2014,
    "abstractText" : "Many signals, such as spike trains recorded in multi-channel electrophysiological recordings, may be represented as the sparse sum of translated and scaled copies of waveforms whose timing and amplitudes are of interest. From the aggregate signal, one may seek to estimate the identities, amplitudes, and translations of the waveforms that compose the signal. Here we present a fast method for recovering these identities, amplitudes, and translations. The method involves greedily selecting component waveforms and then refining estimates of their amplitudes and translations, moving iteratively between these steps in a process analogous to the well-known Orthogonal Matching Pursuit (OMP) algorithm [11]. Our approach for modeling translations borrows from Continuous Basis Pursuit (CBP) [4], which we extend in several ways: by selecting a subspace that optimally captures translated copies of the waveforms, replacing the convex optimization problem with a greedy approach, and moving to the Fourier domain to more precisely estimate time shifts. We test the resulting method, which we call Continuous Orthogonal Matching Pursuit (COMP), on simulated and neural data, where it shows gains over CBP in both speed and accuracy.",
    "creator" : null
  }
}