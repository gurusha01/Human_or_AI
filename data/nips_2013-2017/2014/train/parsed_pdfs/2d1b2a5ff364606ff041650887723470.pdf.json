{
  "name" : "2d1b2a5ff364606ff041650887723470.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Signal Aggregate Constraints in Additive Factorial HMMs, with Application to Energy Disaggregation",
    "authors" : [ "Mingjun Zhong", "Nigel Goddard", "Charles Sutton" ],
    "emails" : [ "mzhong@inf.ed.ac.uk", "nigel.goddard@inf.ed.ac.uk", "csutton@inf.ed.ac.uk" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Many learning tasks require separating a time series into a linear combination of a larger number of “source” signals. This general problem of blind source separation (BSS) arises in many application domains, including audio processing [17, 2], computational biology [1], and modelling electricity usage [8, 12]. This problem is difficult because it is inherently underdetermined and unidentifiable, as there are many more sources than dimensions in the original time series. The unidentifiability problem is especially serious because often the main goal of interest is for people to interpret the resulting source signals.\nFor example, consider the application of energy disaggregation. In this application, the goal is to help people understand what appliances in their home use the most energy; the time at which the appliance is used is of less importance. To place an electricity monitor on every appliance in a household is expensive and intrusive, so instead researchers have proposed performing BSS on the total household electricity usage [8, 22, 15]. If this is to be effective, we must deal with the issue of identifiability: it will not engender confidence to show the householder a “franken-appliance” whose electricity usage looks like a toaster from 8am to 10am, a hot water heater until 12pm, and a television until midnight.\nTo address this problem, we need to incorporate domain knowledge regarding what sorts of sources we are hoping to find. Recently a number of general frameworks have been proposed for incorporating prior constraints into general-purpose probabilistic models. These include posterior regularization [4], the generalized expectation criterion [14], and measurement-based learning [13]. However, all of these approaches leave open the question of what types of domain knowledge we should include. This paper considers precisely that research issue, namely, how to identify classes\nof constraints for which we often have prior knowledge, which are general across a wide variety of domains, and for which we can perform efficient computation.\nIn this paper we observe that in many applications of BSS, the total signal often varies widely across the different unknown sources, and we often have a good idea of what total values to expect. We introduce signal aggregate constraints (SACs) that encourage the aggregate values, such as the sums, of the source signals to be close to some specified values. For example, in the energy disaggregation problem, we know in advance that a toaster might use 50 Wh in a day and will be most unlikely to use as much as 1000 Wh. We incorporate these constraints into an additive factorial hidden Markov model (AFHMM), a commonly used model for BSS [17].\nSACs raise difficult inference issues, because each constraint is a function of the entire state sequence of one chain of the AFHMM, and does not decompose according to the Markov structure of the model. We instead solve a relaxed problem and transform the optimization problem into a convex quadratic program which is computationally efficient.\nOn real-world data from the electricity disaggregation domain (Section 7.2.2), we show that the use of SACs significantly improves performance, resulting in a 45% decrease in normalized disaggregation error compared to the original AFHMM, and a significant improvement (29%) in performance compared to a recent state-of-the-art approach to the disaggregation problem [12].\nTo summarize, the contributions of this paper are: (a) introducing signal aggregate constraints for blind source separation problems (Section 4), (b) a convex quadratic program for the relaxed AFHMM with SACs (Section 5), and (c) an evaluation (Section 7) of the use of SACs on a realworld problem in energy disaggregation."
    }, {
      "heading" : "2 Related Work",
      "text" : "The problem of energy disaggregation, also called non-intrusive load monitoring, was introduced by [8] and has since been the subject of intense research interest. Reviews on energy disaggregation can be found in [22] and [24].\nVarious approaches have been proposed to improve the basic AFHMM by constraining the states of the HMMs. The additive factorial approximate maximum a posteriori (AFAMAP) algorithm in [12] introduces the constraint that at most one chain can change state at any one time point. Another approach [21] proposed non-homogeneous HMMs combining with the constraint of changing at most one chain at a time. Alternately, semi-Markov models represent duration distributions on the hidden states and are another approach to constrain the hidden states. These have been applied to the disaggregation problems by [11] and [10]. Both [12] and [16] employ other kinds of additional information to improve the AFHMM. Other approaches could also be applicable for constraining the AFHMM, e.g., the k-segment constraints introduced for HMMs [19]. Some work in probabilistic databases has considered aggregate constraints [20], but that work considers only models with very simple graphical structure, namely, independent discrete variables."
    }, {
      "heading" : "3 Problem Setting",
      "text" : "Suppose we have observed a time series of sensor readings, for example the energy measured in watt hours by an electricity meter, denoted by Y = (Y1, Y2, · · · , YT ) where Yt ∈ R+. It is assumed that this signal was aggregated from some component signals, for example the energy consumption of individual appliances used by the household. Suppose there were I components, and for each component, the signal is represented as Xi = (xi1, xi2, · · · , xiT ) where xit ∈ R+. Therefore, the observation signal could be represented as the summation of the component signals as follows\nYt = I∑ i=1 xit + t (1)\nwhere t is assumed Gaussian noise with zero mean and variance σ2t . The disaggregation problem is then to recover the unknown time series Xi given only the observed data Y . This is essentially the BSS problem [3] where only one mixture signal was observed. As discussed earlier, there is no\nunique solution for this model, due to the identifiability problem: component signals are exchangeable."
    }, {
      "heading" : "4 Models",
      "text" : "Our models in this paper will assume that the component signals Xi can be modelled by a hidden Markov chain, in common with much work in BSS. For simplicity, each Markov chain is assumed to have a finite set of states such that for the chain i, xit ≈ µit for some µit ∈ {µi1, · · · , µiKi} where Ki denotes the number of the states in chain i. The idea of the SAC is fairly general, however, and could be easily incorporated into other models of the hidden sources."
    }, {
      "heading" : "4.1 The Additive Factorial HMM",
      "text" : "Our baseline model will be the AFHMM. The AFHMM is a natural model for generation of an aggregated signal Y where the component signalsXi are assumed each to be a hidden Markov chain with states Zit ∈ {1, 2, · · · ,Ki} over time t. In the AFHMM, and variants such as AFAMAP, the model parameters, denoted by θ, are unknown. These parameters are the µik; the initial probabilities πi = (πi1, · · · , πiKi)T for each chain where πik = P (Zi1 = k); and the transition probabilities p (i) jk = P (Zit = j|Zi,t−1 = k). Those parameters can be estimated by using approximation methods such as the structured variational approximation [5].\nIn this paper we focus on inferring the sequence over time of hidden states Zit for each hidden Markov chain; θ are assumed known. We are interested in maximum a posteriori (MAP) inference, and the posterior distribution has the following form\nP (Z|Y ) ∝ I∏ i=1 P (Zi1) T∏ t=1 p(Yt|Zt) T∏ t=2 I∏ i=1 P (Zit|Zi,t−1) (2)\nwhere p(Yt|Zt) = N( ∑I i=1 µi,zit , σ 2 t ) is a Gaussian distribution. An alternative way to represent the posterior distibution would use a binary vector Sit = (Sit1, Sit2, · · · , SitKi)T to represent the discrete variable Zit such that Sitk = 1 when Zit = k and for all Sitj = 0 when j 6= k. The logarithm of posterior distribution over S then has the following form\nlogP (S|Y ) ∝ I∑ i=1 STi1 log πi + T∑ t=2 I∑ i=1 STit ( logP (i) ) Si,t−1− 1 2 T∑ t=1 1 σ2t ( Yt − I∑ i=1 STitµi )2 (3)\nwhere P (i) = (p(i)jk ) is the transition probability matrix and µi = (µi1, µi2, · · · , µiKi)T . Exact inference is not tractable as the numbers of chains and states increase. A MAP value can be conveniently found by using the chainwise Viterbi algorithm [18], which optimizes jointly over each chain Si1 . . . SiT in sequence, holding the other chains constant. However, the chainwise Viterbi algorithm can get stuck in local optima. Instead, in this paper we solve a convex quadratic program for a relaxed version of the MAP problem (see Section 5). However, this solution is not guaranteed optimal due to the identifiability problem. Many efforts have been made to provide tractable solutions to this problem by constraining the states of the hidden Markov chains. In the next section we introduce signal aggregate constraints, which will help to address this problem."
    }, {
      "heading" : "4.2 The Additive Factorial HMM with Signal Aggregate Constraints",
      "text" : "Now we add Signal Aggregate Constraints to the AFHMM, yielding a new model AFHMM+SAC. The AFHMM+SAC assumes that the aggregate value of each component signal i over the entire sequence is expected to be a certain value µi0, which is known in advance. In other words, the SAC assumes ∑T t=1 xit ≈ µi0. The constraint values µi0 (i = 1, 2, · · · , I) could be obtained from expert knowledge or by experiments. For example, in the energy disaggregation domain, extensive research has been undertaken to estimate the average national consumption of different appliances [23].\nIncorporating this constraint into the AFHMM, using the formulation from (3), results in the following optimization problem for MAP inference\nmaximize S logP (S|Y )\nsubject to ( T∑ t=1 µTi Sit − µi0 )2 ≤ δi, i = 1, 2, · · · , I,\n(4)\nwhere µi0 (i = 1, 2, · · · , I) are assumed known, and δi ≥ 0 is a tuning parameter which has the similar role as the ones used in ridge regression and LASSO [9]. Instead of solving this optimization problem directly, we equivalently solve the penalized objective function\nmaximize S L(S) = logP (S|Y )− I∑ i=1 λi ( T∑ t=1 µTi Sit − µi0 )2 , (5)\nwhere λi ≥ 0 is a complexity parameter which has a one-to-one correspondence with the tuning parameter δi. In the Bayesian point of view, the constraint terms could be viewed as the logarithm of the prior distributions over the states S. Therefore, the objective can be viewed as a log posterior distribution over S. Now the Viterbi algorithm is not applicable directly since at any time t, the state Sit depends on all the states at all time steps, because of the regularization terms which are non-Markovian inherently. Therefore, in the following section we transform the optimization problem (5) into a convex quadratic program which can be efficiently solved.\nNote that the constraints in equation (4) could be generalised. Rather than making only one constraint on each chain in the time period [0, T ] (as described above), a series of constraints could be made. We could define J constraints such that, for j = 1, 2, · · · , J , the jth constraint for chain i is:(∑tbij\nτ (i) j =t a ij µTi Si,τ(i)j − µji0\n)2 ≤ δij where [taij , tbij ] denotes the time period for the constraint. This\ncould be reasonable particularly in household energy data to represent the fact that some appliances are commonly used during the daytime and are unlikely to be used between 2am and 5am. This is a straightforward extension that does not complicate the algorithms, so for presentational simplicity, we only use a single constraint per chain, as shown in (4), in the rest of this paper."
    }, {
      "heading" : "5 Convex Quadratic Programming for AFHMM+SAC",
      "text" : "In this section we derive a convex quadratic program (CQP) for the relaxed problem for (5). The problem (5) is not convex even if the constraint Sitk ∈ {0, 1} is relaxed, because logP (S|Y ) is not convex. By adding an additional set of variables, we obtain a convex problem.\nSimilar to [12], we define a new Ki × Ki variable matrix Hit = (hitjk) such that hitjk = 1 when Si,t−1,k = 1 and Sitj = 1, and otherwise hitjk = 0. In order to present a CQP problem, we define the following notation. Denote 1T as a column vector of size T × 1 with all the elements being 1. Denote µ∗i = 1T ⊗ µi with size TKi × 1, where ⊗ is Kronecker product, then Λi = λiµ∗iµ∗Ti and µ̃i = 2λiµi0µ∗i . Denote eT as a T × 1 vector with the first element being 1 and all the others being zero. Denote π̃i = eT ⊗ log πi with size TKi×1. We represent−→µ = (µT1 , µT2 , · · · , µTI )T with size∑ iKi × 1, and denote Vt = σ −2 t −→µ−→µ T and ut = σ−2t Yt−→µ . We also denote Si = (STi1, · · · , STiT )T\nwith size TKi × 1 and St = (ST1t, · · · , STIt)T with size ∑ iKi × 1. Denote Hit.l and Hitl. as the column and row vectors of the matrix Hit, respectively.\nThe objective function in equation (5) can then be equivalently represented as L(S,H) = IX\ni=1\nSTi π̃i + X\ni,t,k,j\nhitjk log p (i) jk − IX i=1 “ STi ΛiSi − STi µ̃i ” − 1 2 TX t=1 “ STt VtSt − 2uTt St ” + C\n= X\ni,t,k,j\nhitjk log p (i) jk − IX i=1 “ STi ΛiSi − STi (µ̃i + π̃i) ” − 1 2 TX t=1 “ STt VtSt − 2uTt St ” + C\nwhere C is constant. Our aim is to optimize the problem\nmaximize S,H L(S,H) subject to Ki∑ k=1 Sitk = 1, Sitk ∈ {0, 1}, i = 1, 2, · · · , I; t = 1, 2, · · · , T,\nKi∑ l=1 Hitl. = S T i,t−1, Ki∑ l=1 Hit.l = Sit, h it jk ∈ {0, 1}.\n(6)\nThis problem is equavalent to the problem in equation (5). It should be noted that the matrices Λi and Vt are positive semidefinite (PSD). Therefore, the problem is an integer quadratic program (IQP) which is hard to solve. Instead we solve the relaxed problem where Sitk ∈ [0, 1] and hitjk ∈ [0, 1]. The problem is thus a CQP. To solve this problem we used CVX, a package for specifying and solving convex programs [7, 6]. Note that a relaxed problem for AFHMM could also be obtained by setting λi = 0, which is also a CQP. Concerning the computational complexity, the CQP for AFHMM+SAC has polynomial time in the number of time steps times the total number of states of the HMMs. In practice, our implementations of AFHMM, AFAMAP, and AFHMM+SAC scale similarly (see Section 7.2)."
    }, {
      "heading" : "6 Relation to Posterior Regularization",
      "text" : "In this section we show that the objective function in (5) can also be derived from the posterior regularization framework [4]. The posterior regularization framework guides the model to approach desired behavior by constraining the space of the model posteriors. The distribution defined in (3) is the model posterior distribution for the AFHMM. However, the desired distribution P̃ we are interested in is defined in the constrained space { P̃ |E eP (ϕi(S, Y )) ≤ δi\n} where ϕi(S, Y ) =(∑T\nt=1 µ T i Sit − µi0\n)2 . To ensure P̃ is a valid distribution, it is required to optimize\nminimizeeP KL(P̃ (S)|P (S|Y )) subject to E eP (ϕi(S, Y )) ≤ δi, i = 1, 2, · · · , I,\n(7)\nwhere KL(·|·) denotes the KL-divergence. According to [4], the unique optimal solution for the desired distribution is P̃ ∗(S) = 1ZP (S|Y ) exp { − ∑I i=1 λiϕi(S, Y ) } . This is exactly the distribution in equation (5)."
    }, {
      "heading" : "7 Results",
      "text" : "In this section, the AFHMM+SAC is evaluated by applying it to the disaggregation problems of a toy data set and energy data, and comparing with AFHMM and AFAMAP performance."
    }, {
      "heading" : "7.1 Toy Data",
      "text" : "In this section the AFHMM+SAC was applied to a toy data set to evaluate the robustness of the method. Two chains were generated with state values µ1 = (0, 24, 280)T and µ2 = (0, 300, 500)T . The initial and transition probabilities were randomly generated. Suppose the generated chains were xi = xi1, xi2, · · · , xiT (i = 1, 2), with T = 100. The aggregated data were generated by the equation Yt = x1t + x2t + t where t follows a Gaussian distribution with zero mean and variance σ2 = 0.01. The AFHMM+SAC was applied to this data to disaggregate Y into component signals. Note that we simply set λi = 1 for all the experiments including the energy data, though in practice these hyper-parameters could be tuned using cross validation. Denote x̂i as the estimated signal for xi. The disaggregation performance was evaluated by the normalized disaggregation error (NDE)\nNDE = ∑ i,t(x̂it − xit)2∑\ni,t x 2 it\n. (8)\nFor the energy data we are also particularly interested in recovering the total energy used by each appliance [16, 10]. Therefore, another objective of the disaggregation is to estimate the total energy consumed by each appliance over a period of time. To measure this, we employ the following signal aggregate error (SAE)\nSAE = 1 I I∑ i=1 | ∑T t=1 x̂it − ∑T t′=1 xit′ |∑T t=1 Yt . (9)\nIn order to assess how the SAC regularizer affects the results, various values for µ0 = (µ10, µ20)T were used for the AFHMM+SAC algorithm. Figure 1 shows the NDE and SAE results. It shows that as the Euclidean distance between the input vector µ0 and the true signal aggregate vector(∑T\nt=1 x1t, ∑T t=1 x2t ) increases, both the NDE and SAE increase. This shows how the SACs\naffect the performance of AFHMM+SAC.\n(µ10, µ20)T and the true signal aggregate vector\n(∑T\nt=1 x1t,\n∑T\nt=1 x2t\n)T\n."
    }, {
      "heading" : "7.2 Energy Disaggregation",
      "text" : "In this section, the AFHMM, AFAMAP, and AFHMM+SAC were applied to electrical energy disaggregation problems. We use the Household Electricity Survey (HES) data. HES was a recent study commissioned by the UK Department of Food and Rural Affairs, which monitored a total of 251 owner-occupied households across England from May 2010 to July 2011 [23]. The study monitored 26 households for an entire year, while the remaining 225 were monitored for one month during the year with periods selected to be representative of the different seasons. Individual appliances as well as the overall electricity consumption were monitored. The households were carefully selected to be representative of the overall population. The data were recorded every 2 or 10 minutes, depending on the household. This ultra-low frequency data presents a challenge for disaggregation techniques; typically studies rely on much higher data rates, e.g., the REDD data [12]. Both the data measured without and with a mains reading were used to compare those models. The model parameters θ defined in AFHMM, AFAMAP and AFHMM+SAC for every appliance were estimated by using 15-30 days’ data for each household. We simply assume 3 states for all the appliances, though we could assume more states which requires more computational costs. The µi was estimated by using k-means clustering on each appliance’s signals in the training data."
    }, {
      "heading" : "7.2.1 Energy Data without Mains Readings",
      "text" : "In the first experiment, we generated the aggregate data by adding up the appliance signals, since no mains reading had been measured for most of the households. One-hundred households were studied, and one day’s usage was used as test data for each household. The model parameters were\nestimated by using 15-26 days’ data as the training data. In future work, it would be straightforward to incorporate the SAC into unsupervised disaggregation approaches [11], by using prior information such as national surveys to estimate µ0. The AFHMM, AFAMAP and AFHMM+SAC were applied to the aggregated signal to recover the component appliances. For the AFHMM+SAC, two kinds of total consumption vectors were used as the vector µ0. The first, the national total consumption (NTC), was the average consumption of each appliance over the training days across all households in the data set. The second, for comparison, was the true total consumption (TTC) for each appliance for that day and household. Obviously, TTC is the optimal value for the regularizer in AFHMM+SAC, so this gives us an oracle result which indicates the largest possible benefit from including this kind of SAC.\nTable 1 shows the NDE and SAE when the three methods were applied to one day’s data for 100 households. We see that AFHMM+SAC outperformed the AFHMM in terms of both NDE and SAE. The AFAMAP outperformed the AFHMM in terms of SAE, and otherwise they performed similar in terms of NDE. Unsurprisingly, the AFHMM+SAC using TTC performs the best among these methods. This shows the difference the constraints made, even though we would never be able to obtain the TTC in reality. By looking at the mean values in the Table 1, we also conclude that AFHMM+SAC using NTC had improved 33% and 16% over state-of-the-art AFAMAP in terms of NDE and SAE, respectively. This was also verified by computing the paired t-test to show that the mean NDE and SAE obtained by AFHMM+SAC and AFAMAP were different at the 5% significance level. To demonstrate the computational efficiency, the computing time is also shown in the Table 1. It indicates that AFHMM, AFAMAP and AFHMM+SAC consumed similar time for inference."
    }, {
      "heading" : "7.2.2 Energy Data with Mains Readings",
      "text" : "We studied 9 houses in which the mains as well as the appliances were measured. In this experiment we applied the models directly to the measured mains signal. This scenario is more difficult than that of the previous section, because the mains power will also include the demand of some appliances which are not included in the training data, but it is also the most realistic. The summary of the 9 houses is shown in Table 2. The training data were used to estimate the model parameters. The number of appliances corresponds to the number of the HMMs in the model. The mains measured in the test days are inputted into the models to recover the consumption of those appliances. We computed the NTC by using the training data for the AFHMM+SAC. The NDE and SAE were computed for every house and each method. The results are shown in Figure 2. For each house we also computed the paired t-test for the NDE and SAE computed by AFAMAP and AFHMM+SAC(NTC), which shows that the mean errors are different at the 5% significance level. This indicates that across all the houses AFHMM+SAC has improved over AFAMAP. The overall results for all the test days are shown in Table 3, which shows that AFHMM+SAC has improved over both AFHMM and AFAMAP. In terms of computing time, however, AFHMM+SAC is similar to AFHMM and AFAMAP. It should be noted that, by looking at Tables 1 and 3, all the three methods require more time for the data with mains than those without mains. This is because the algorithms take more time to converge for realistic data. These results indicate the value of signal aggregate constraints for this problem."
    }, {
      "heading" : "8 Conclusions",
      "text" : "In this paper, we have proposed an additive factorial HMM with signal aggregate constraints. The regularizer was derived from a prior distribution over the chain states. We also showed that the objective function can be derived in the framework of posterior regularization. We focused on finding the MAP configuration for the posterior distribution with the constraints. Since dynamic programming is not directly applicable, we pose the optimization problem as a convex quadratic program and solve the relaxed problem. On simulated data, we showed that the AFHMM+SAC is robust to errors in specification of the constraint value. On real world data from the energy disaggregation problem, we showed that the AFHMM+SAC performed better both than a simple AFHMM and than previously published research."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work is supported by the Engineering and Physical Sciences Research Council (grant number EP/K002732/1)."
    } ],
    "references" : [ {
      "title" : "Large-scale learning of combinatorial transcriptional dynamics from gene expression",
      "author" : [ "H.M.S. Asif", "G. Sanguinetti" ],
      "venue" : "Bioinformatics, 27(9):1277–1283",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Blind one-microphone speech separation: A spectral learning approach",
      "author" : [ "F. Bach", "M.I. Jordan" ],
      "venue" : "Neural Information Processing Systems, pages 65–72",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "editors",
      "author" : [ "P. Comon", "C. Jutten" ],
      "venue" : "Handbook of Blind Source Separation: Independent Component Analysis and Applications. Academic Press, First Edition",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Posterior regularization for structured latent variable models",
      "author" : [ "K. Ganchev", "J. Graça", "J. Gillenwater", "B. Taskar" ],
      "venue" : "Journal of Machine Learning Research, 11:2001–2049",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Factorial hidden Markov models",
      "author" : [ "Z. Ghahramani", "M.I. Jordan" ],
      "venue" : "Machine Learning, 27:245–273",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Graph implementations for nonsmooth convex programs",
      "author" : [ "M. Grant", "S. Boyd" ],
      "venue" : "V. Blondel, S. Boyd, and H. Kimura, editors, Recent Advances in Learning and Control, Lecture Notes in Control and Information Sciences, pages 95–110. Springer-Verlag Limited",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "CVX: Matlab software for disciplined convex programming, version",
      "author" : [ "M. Grant", "S. Boyd" ],
      "venue" : "//cvxr.com/cvx,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2014
    }, {
      "title" : "Nonintrusive appliance load monitoring",
      "author" : [ "G.W. Hart" ],
      "venue" : "Proceedings of the IEEE,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1992
    }, {
      "title" : "editors",
      "author" : [ "T. Hastie", "R. Tibshirani", "J. Friedman" ],
      "venue" : "The Elements of Statistical Learning, Second Edition. Springer",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Bayesian nonparametric hidden semi-Markov models",
      "author" : [ "M.J. Johnson", "A.S. Willsky" ],
      "venue" : "Journal of Machine Learning Research, 14:673–701",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Unsupervised disaggregation of low frequency power measurements",
      "author" : [ "H. Kim", "M. Marwah", "M. Arlitt", "G. Lyon", "J. Han" ],
      "venue" : "Proceedings of the SIAM Conference on Data Mining, pages 747–758",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Approximate inference in additive factorial HMMs with application to energy disaggregation",
      "author" : [ "J.Z. Kolter", "T. Jaakkola" ],
      "venue" : "Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS-12), volume 22, pages 1472–1482",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Learning from measurements in exponential families",
      "author" : [ "P. Liang", "M.I. Jordan", "D. Klein" ],
      "venue" : "The 26th Annual International Conference on Machine Learning, pages 641–648",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Generalized expectation criteria for semi-supervised learning of conditional random fields",
      "author" : [ "G. Mann", "A. McCallum" ],
      "venue" : "In Proceedings of Association for Computational Linguistics",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2008
    }, {
      "title" : "Unsupervised Training Methods for Non-intrusive Appliance Load Monitoring from Smart Meter Data",
      "author" : [ "O. Parson" ],
      "venue" : "PhD thesis,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2014
    }, {
      "title" : "Non-intrusive load monitoring using prior models of general appliance types",
      "author" : [ "O. Parson", "S. Ghosh", "M. Weal", "A. Rogers" ],
      "venue" : "In Proceedings of the Twenty-Sixth Conference on Artificial Intelligence (AAAI-",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2012
    }, {
      "title" : "One microphone source separation",
      "author" : [ "S.T. Roweis" ],
      "venue" : "Advances in Neural Information Processing, pages 793–799",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Mixed memory Markov chains: Decomposing complex stochastic processes as mixtures of simpler ones",
      "author" : [ "L.K. Saul", "M.I. Jordan" ],
      "venue" : "Machine Learning, 37:75–87",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Statistical inference in hidden Markov models using k-segment constraints",
      "author" : [ "M.K. Titsias", "C. Yau", "C.C. Holmes" ],
      "venue" : "Eprint arXiv:1311.1189",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Querying uncertain data with aggregate constraints",
      "author" : [ "M. Yang", "H. Wang", "H. Chen", "W. Ku" ],
      "venue" : "Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data, SIGMOD ’11, pages 817–828, New York, NY, USA",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Interleaved factorial non-homogeneous hidden Markov models for energy disaggregation",
      "author" : [ "M. Zhong", "N. Goddard", "C. Sutton" ],
      "venue" : "Neural Information Processing Systems, Workshop on Machine Learning for Sustainability, Lake Tahoe, Nevada, USA",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Nonintrusive appliance load monitoring: review and outlook",
      "author" : [ "M. Ziefman", "K. Roth" ],
      "venue" : "IEEE transactions on Consumer Electronics, 57:76–84",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "and C",
      "author" : [ "J.-P. Zimmermann", "M. Evans", "J. Griggs", "N. King", "L. Harding", "P. Roberts" ],
      "venue" : "Evans. Household electricity survey",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Non-intrusive load monitoring approaches for disaggregated energy sensing: a survey",
      "author" : [ "A. Zoha", "A. Gluhak", "M.A. Imran", "S. Rajasegarar" ],
      "venue" : "Sensors, 12:16838–16866",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 16,
      "context" : "This general problem of blind source separation (BSS) arises in many application domains, including audio processing [17, 2], computational biology [1], and modelling electricity usage [8, 12].",
      "startOffset" : 117,
      "endOffset" : 124
    }, {
      "referenceID" : 1,
      "context" : "This general problem of blind source separation (BSS) arises in many application domains, including audio processing [17, 2], computational biology [1], and modelling electricity usage [8, 12].",
      "startOffset" : 117,
      "endOffset" : 124
    }, {
      "referenceID" : 0,
      "context" : "This general problem of blind source separation (BSS) arises in many application domains, including audio processing [17, 2], computational biology [1], and modelling electricity usage [8, 12].",
      "startOffset" : 148,
      "endOffset" : 151
    }, {
      "referenceID" : 7,
      "context" : "This general problem of blind source separation (BSS) arises in many application domains, including audio processing [17, 2], computational biology [1], and modelling electricity usage [8, 12].",
      "startOffset" : 185,
      "endOffset" : 192
    }, {
      "referenceID" : 11,
      "context" : "This general problem of blind source separation (BSS) arises in many application domains, including audio processing [17, 2], computational biology [1], and modelling electricity usage [8, 12].",
      "startOffset" : 185,
      "endOffset" : 192
    }, {
      "referenceID" : 7,
      "context" : "To place an electricity monitor on every appliance in a household is expensive and intrusive, so instead researchers have proposed performing BSS on the total household electricity usage [8, 22, 15].",
      "startOffset" : 187,
      "endOffset" : 198
    }, {
      "referenceID" : 21,
      "context" : "To place an electricity monitor on every appliance in a household is expensive and intrusive, so instead researchers have proposed performing BSS on the total household electricity usage [8, 22, 15].",
      "startOffset" : 187,
      "endOffset" : 198
    }, {
      "referenceID" : 14,
      "context" : "To place an electricity monitor on every appliance in a household is expensive and intrusive, so instead researchers have proposed performing BSS on the total household electricity usage [8, 22, 15].",
      "startOffset" : 187,
      "endOffset" : 198
    }, {
      "referenceID" : 3,
      "context" : "These include posterior regularization [4], the generalized expectation criterion [14], and measurement-based learning [13].",
      "startOffset" : 39,
      "endOffset" : 42
    }, {
      "referenceID" : 13,
      "context" : "These include posterior regularization [4], the generalized expectation criterion [14], and measurement-based learning [13].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 12,
      "context" : "These include posterior regularization [4], the generalized expectation criterion [14], and measurement-based learning [13].",
      "startOffset" : 119,
      "endOffset" : 123
    }, {
      "referenceID" : 16,
      "context" : "We incorporate these constraints into an additive factorial hidden Markov model (AFHMM), a commonly used model for BSS [17].",
      "startOffset" : 119,
      "endOffset" : 123
    }, {
      "referenceID" : 11,
      "context" : "2), we show that the use of SACs significantly improves performance, resulting in a 45% decrease in normalized disaggregation error compared to the original AFHMM, and a significant improvement (29%) in performance compared to a recent state-of-the-art approach to the disaggregation problem [12].",
      "startOffset" : 292,
      "endOffset" : 296
    }, {
      "referenceID" : 7,
      "context" : "The problem of energy disaggregation, also called non-intrusive load monitoring, was introduced by [8] and has since been the subject of intense research interest.",
      "startOffset" : 99,
      "endOffset" : 102
    }, {
      "referenceID" : 21,
      "context" : "Reviews on energy disaggregation can be found in [22] and [24].",
      "startOffset" : 49,
      "endOffset" : 53
    }, {
      "referenceID" : 23,
      "context" : "Reviews on energy disaggregation can be found in [22] and [24].",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 11,
      "context" : "The additive factorial approximate maximum a posteriori (AFAMAP) algorithm in [12] introduces the constraint that at most one chain can change state at any one time point.",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 20,
      "context" : "Another approach [21] proposed non-homogeneous HMMs combining with the constraint of changing at most one chain at a time.",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 10,
      "context" : "These have been applied to the disaggregation problems by [11] and [10].",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 9,
      "context" : "These have been applied to the disaggregation problems by [11] and [10].",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 11,
      "context" : "Both [12] and [16] employ other kinds of additional information to improve the AFHMM.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 15,
      "context" : "Both [12] and [16] employ other kinds of additional information to improve the AFHMM.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 18,
      "context" : ", the k-segment constraints introduced for HMMs [19].",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 19,
      "context" : "Some work in probabilistic databases has considered aggregate constraints [20], but that work considers only models with very simple graphical structure, namely, independent discrete variables.",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 2,
      "context" : "This is essentially the BSS problem [3] where only one mixture signal was observed.",
      "startOffset" : 36,
      "endOffset" : 39
    }, {
      "referenceID" : 4,
      "context" : "Those parameters can be estimated by using approximation methods such as the structured variational approximation [5].",
      "startOffset" : 114,
      "endOffset" : 117
    }, {
      "referenceID" : 17,
      "context" : "A MAP value can be conveniently found by using the chainwise Viterbi algorithm [18], which optimizes jointly over each chain Si1 .",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 22,
      "context" : "For example, in the energy disaggregation domain, extensive research has been undertaken to estimate the average national consumption of different appliances [23].",
      "startOffset" : 158,
      "endOffset" : 162
    }, {
      "referenceID" : 8,
      "context" : "where μi0 (i = 1, 2, · · · , I) are assumed known, and δi ≥ 0 is a tuning parameter which has the similar role as the ones used in ridge regression and LASSO [9].",
      "startOffset" : 158,
      "endOffset" : 161
    }, {
      "referenceID" : 11,
      "context" : "Similar to [12], we define a new Ki × Ki variable matrix H = (h jk) such that h jk = 1 when Si,t−1,k = 1 and Sitj = 1, and otherwise h jk = 0.",
      "startOffset" : 11,
      "endOffset" : 15
    }, {
      "referenceID" : 6,
      "context" : "To solve this problem we used CVX, a package for specifying and solving convex programs [7, 6].",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 5,
      "context" : "To solve this problem we used CVX, a package for specifying and solving convex programs [7, 6].",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 3,
      "context" : "In this section we show that the objective function in (5) can also be derived from the posterior regularization framework [4].",
      "startOffset" : 123,
      "endOffset" : 126
    }, {
      "referenceID" : 3,
      "context" : "According to [4], the unique optimal solution for the desired distribution is P̃ ∗(S) = 1 ZP (S|Y ) exp { − ∑I i=1 λiφi(S, Y ) } .",
      "startOffset" : 13,
      "endOffset" : 16
    }, {
      "referenceID" : 15,
      "context" : "For the energy data we are also particularly interested in recovering the total energy used by each appliance [16, 10].",
      "startOffset" : 110,
      "endOffset" : 118
    }, {
      "referenceID" : 9,
      "context" : "For the energy data we are also particularly interested in recovering the total energy used by each appliance [16, 10].",
      "startOffset" : 110,
      "endOffset" : 118
    }, {
      "referenceID" : 22,
      "context" : "HES was a recent study commissioned by the UK Department of Food and Rural Affairs, which monitored a total of 251 owner-occupied households across England from May 2010 to July 2011 [23].",
      "startOffset" : 183,
      "endOffset" : 187
    }, {
      "referenceID" : 10,
      "context" : "In future work, it would be straightforward to incorporate the SAC into unsupervised disaggregation approaches [11], by using prior information such as national surveys to estimate μ0.",
      "startOffset" : 111,
      "endOffset" : 115
    } ],
    "year" : 2014,
    "abstractText" : "Blind source separation problems are difficult because they are inherently unidentifiable, yet the entire goal is to identify meaningful sources. We introduce a way of incorporating domain knowledge into this problem, called signal aggregate constraints (SACs). SACs encourage the total signal for each of the unknown sources to be close to a specified value. This is based on the observation that the total signal often varies widely across the unknown sources, and we often have a good idea of what total values to expect. We incorporate SACs into an additive factorial hidden Markov model (AFHMM) to formulate the energy disaggregation problems where only one mixture signal is assumed to be observed. A convex quadratic program for approximate inference is employed for recovering those source signals. On a real-world energy disaggregation data set, we show that the use of SACs dramatically improves the original AFHMM, and significantly improves over a recent state-of-the-art approach.",
    "creator" : null
  }
}