{
  "name" : "6883966fd8f918a4aa29be29d2c386fb.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Active Regression by Stratification",
    "authors" : [ "Sivan Sabato", "Remi Munos" ],
    "emails" : [ "sabatos@cs.bgu.ac.il", "remi.munos@inria.fr" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "In linear regression, the goal is to predict the real-valued labels of data points in Euclidean space using a linear function. The quality of the predictor is measured by the expected squared error of its predictions. In the standard regression setting with random design, the input is a labeled sample drawn i.i.d. from the joint distribution of data points and labels, and the cost of data is measured by the size of the sample. This model, which we refer to here as passive learning, is useful when both data and labels are costly to obtain. However, in domains where raw data is very cheap to obtain, a more suitable model is that of active learning (see, e.g., Cohn et al., 1994). In this model we assume that random data points are essentially free to obtain, and the learner can choose, for any observed data point, whether to ask also for its label. The cost of data here is the total number of requested labels.\nIn this work we propose a new active learning algorithm for linear regression. We provide finite sample convergence guarantees for general distributions, under a possibly misspecified model. For parametric linear regression, the sample complexity of passive learning as a function of the excess error is of the order O(1/ ). This rate cannot in general be improved by active learning, unlike in the case of classification (Balcan et al., 2009). Nonetheless, the so-called ‘constant’ in this rate of convergence depends on the distribution, and this is where the potential improvement by active learning lies.\nFinite sample convergence of parametric linear regression in the passive setting has been studied by several (see, e.g., Györfi et al., 2002; Hsu et al., 2012). The standard approach is Ordinary Least Squares (OLS), where the output predictor is simply the minimizer of the mean squared error on the sample. Recently, a new algorithm for linear regression has been proposed (Hsu and Sabato, 2014). This algorithm obtains an improved convergence guarantee under less restrictive assumptions. An appealing property of this guarantee is that it provides a direct and tight relationship between the point-wise error of the optimal predictor and the convergence rate of the predictor. We exploit this to\n∗Current Affiliation: Google DeepMind.\nallow our active learner to adapt to the underlying distribution. Our approach employs a stratification technique, common in Monte-Carlo function integration (see, e.g., Glasserman, 2004). For any finite partition of the data domain, an optimal oracle risk can be defined, and the convergence rate of our active learner approaches the rate defined by this risk. By constructing an infinite sequence of partitions that become increasingly refined, one can approach the globally optimal oracle risk.\nActive learning for parametric regression has been investigated in several works, some of them in the context of statistical experimental design. One of the earliest works is Cohn et al. (1996), which proposes an active learning algorithm for locally weighted regression, assuming a well-specified model and an unbiased learning function. Wiens (1998, 2000) calculates a minimax optimal design for regression given the marginal data distribution, assuming that the model is approximately well-specified. Kanamori (2002) and Kanamori and Shimodaira (2003) propose an active learning algorithm that first calculates a maximum likelihood estimator and then uses this estimator to come up with an optimal design. Asymptotic convergence rates are provided under asymptotic normality assumptions. Sugiyama (2006) assumes an approximately well-specified model and i.i.d. label noise, and selects a design from a finite set of possibilities. The approach is adapted to pool-based active learning by Sugiyama and Nakajima (2009). Burbidge et al. (2007) propose an adaptation of Query By Committee. Cai et al. (2013) propose guessing the potential of an example to change the current model. Ganti and Gray (2012) propose a consistent pool-based active learner for the squared loss. A different line of research, which we do not discuss here, focuses on active learning for non-parameteric regression, e.g. Efromovich (2007).\nOutline In Section 2 the formal setting and preliminaries are introduced. In Section 3 the notion of an oracle risk for a given distribution is presented. The stratification technique is detailed in Section 4. The new active learner algorithm and its analysis are provided in Section 5, with the main result stated in Theorem 5.1. In Section 6 we show via a simple example that in some cases the active learner approaches the maximal possible improvement over passive learning."
    }, {
      "heading" : "2 Setting and Preliminaries",
      "text" : "We assume a data space in Rd and labels in R. For a distribution P over Rd × R, denote by suppX(P ) the support of the marginal of P over Rd. Denote the strictly positive reals by R∗+. We assume that labeled examples are distributed according to a distribution D. A random labeled example is (X, Y ) ∼ D, where X ∈ Rd is the example and Y ∈ R is the label. Throughout this work, whenever P[·] or E[·] appear without a subscript, they are taken with respect to D. DX is the marginal distribution of X in pairs draws from D. The conditional distribution of Y when the example is X = x is denoted DY |x. The function x 7→ DY |x is denoted DY |X .\nA predictor is a function from Rd to R that predicts a label for every possible example. Linear predictors are functions of the form x 7→ x>w for some w ∈ Rd. The squared loss of w ∈ Rd for an example x ∈ Rd with a true label y ∈ R is `((x, y),w) = (x>w − y)2. The expected squared loss of w with respect to D is L(w, D) = E(X,Y )∼D[(X>w − Y )2]. The goal of the learner is to find a w such that L(w) is small. The optimal loss achievable by a linear predictor is L?(D) = minw∈Rd L(w, D). We denote by w?(D) a minimizer of L(w, D) such that L?(D) = L(w?(D), D). In all these notations the parameter D is dropped when clear from context.\nIn the passive learning setting, the learner draws random i.i.d. pairs (X, Y ) ∼ D. The sample complexity of the learner is the number of drawn pairs. In the active learning setting, the learner draws i.i.d. examples X ∼ DX . For any drawn example, the learner may draw a label according to the distribution DY |X. The label complexity of the learner is the number of drawn labels. In this setting it is easy to approximate various properties ofDX to any accuracy, with zero label cost. Thus we assume for simplicity direct access to some properties of DX , such as the covariance matrix of DX , denoted ΣD = EX∼DX [XX>], and expectations of some other functions of X. We assume w.l.o.g. that ΣD is not singular. For a matrix A ∈ Rd×d, and x ∈ Rd, denote ‖x‖A = √ x>Ax. Let R2D = maxx∈suppX(D) ‖x‖ 2 Σ−1D\n. This is the condition number of the marginal distribution DX . We have\nE[‖X‖2 Σ−1D ] = E[tr(X>Σ−1D X)] = tr(Σ −1 D E[XX >]) = d. (1)\nHsu and Sabato (2014) provide a passive learning algorithm for least squares linear regression with a minimax optimal sample complexity (up to logarithmic factors). The algorithm is based on splitting the labeled sample into several subsamples, performing OLS on each of the subsamples, and then choosing one of the resulting predictors via a generalized median procedure. We give here a useful version of the result.1\nTheorem 2.1 (Hsu and Sabato, 2014). There are universal constants C, c, c′, c′′ > 0 such that the following holds. LetD be a distribution over Rd×R. There exists an efficient algorithm that accepts as input a confidence δ ∈ (0, 1) and a labeled sample of size n drawn i.i.d. from D, and returns ŵ ∈ Rd, such that if n ≥ cR2D log(c′n) log(c′′/δ), with probability 1− δ,\nL(ŵ, D)− L?(D) = ‖w?(D)− ŵ‖2ΣD ≤ C log(1/δ)\nn · ED[‖X‖2Σ−1D (Y −X >w?(D)) 2]. (2)\nThis result is particularly useful in the context of active learning, since it provides an explicit dependence on the point-wise errors of the labels, including in heteroscedastic settings, where this error is not uniform. As we see below, in such cases active learning can potentially gain over passive learning. We denote an execution of the algorithm on a labeled sample S by ŵ← REG(S, δ). The algorithm is used a black box, thus any other algorithm with similar guarantees could be used instead. For instance, similar guarantees might hold for OLS for a more restricted class of distributions.\nThroughout the analysis we omit for readability details of integer rounding, whenever the effects are negligible. We use the notation O(exp), where exp is a mathematical expression, as a short hand for c̄ · exp + C̄ for some universal constants c̄, C̄ ≥ 0, whose values can vary between statements."
    }, {
      "heading" : "3 An Oracle Bound for Active Regression",
      "text" : "The bound in Theorem 2.1 crucially depends on the input distribution D. In an active learning framework, rejection sampling (Von Neumann, 1951) can be used to simulate random draws of labeled examples according to a different distribution, without additional label costs. By selecting a suitable distribution, it might be possible to improve over Eq. (2). Rejection sampling for regression has been explored in Kanamori (2002); Kanamori and Shimodaira (2003); Sugiyama (2006) and others, mostly in an asymptotic regime. Here we use the explicit bound in Eq. (2) to obtain new finite sample guarantees that hold for general distributions.\nLet φ : Rd → R∗+ be a strictly positive weight function such that E[φ(X)] = 1. We define the distribution Pφ over Rd×R as follows: For x ∈ Rd, y ∈ R, let Γφ(x, y) = {(x̃, ỹ) ∈ Rd×R | x = x̃√ φ(x̃) , y = ỹ√ φ(x̃) }, and define Pφ by\n∀(X, Y ) ∈ Rd × R, Pφ(X, Y ) = ∫\n(X̃,Ỹ )∈Γφ(X,Y ) φ(X̃)dD(X̃, Ỹ ).\nA labeled i.i.d. sample drawn according to Pφ can be simulated using rejection sampling without additional label costs (see Alg. 2 in Appendix B). We denote drawing m random labeled examples according to P by S ← SAMPLE(P,m). For the squared loss on Pφ we have\nL(w, Pφ) = ∫ (X,Y )∈Rd `((X, Y ),w) dPφ(X, Y )\n(∗) = ∫ (X,Y )∈Rd `((X, Y ),w) ∫ (X̃,Ỹ )∈Γφ(X,Y ) φ(X̃) dD(X̃, Ỹ )\n= ∫ (X̃,Ỹ )∈Rd `(( X̃√ φ(X̃) , Ỹ√ φ(X̃) ),w)φ(X̃) dD(X̃, Ỹ )\n= ∫ (X,Y )∈Rd `((X, Y ),w) dD(X, Y ) = L(w, D).\nThe equality (∗) can be rigorously derived from the definition of Lebesgue integration. It follows that also L?(D) = L?(Pφ) and that w?(D) = w?(Pφ). We thus denote these by L? and w?. In\n1This is a slight variation of the original result of Hsu and Sabato (2014), see Appendix A.\na similar manner, we have ΣPφ = ∫ XX> dPφ(X, Y ) = ∫ XX> dD(X, Y ) = ΣD. From now on we denote this matrix simply Σ. We denote ‖ · ‖Σ by ‖ · ‖, and ‖ · ‖Σ−1 by ‖ · ‖∗. The condition number of Pφ is R2Pφ = maxx∈suppX(D) ‖x‖2∗ φ(x) .\nIf the regression algorithm is applied to n labeled examples drawn from the simulated Pφ, then by Eq. (2) and the equalities above, with probability 1− δ, if n ≥ cR2Pφ log(c ′n) log(c′′/δ)),\nL(ŵ)− L? ≤ C · log(1/δ)\nn · EPφ [‖X‖2∗(X>w? − Y )2]\n= C · log(1/δ)\nn · ED[‖X‖2∗(X>w? − Y )2/φ(X)].\nDenote ψ2(x) := ‖x‖2∗ · ED[(X>w? − Y )2 | X = x]. Further denote ρ(φ) := ED[ψ2(X)/φ(X)], which we term the risk of φ. Then, if n ≥ cR2Pφ log(c ′n) log(c′′/δ), with probability 1− δ,\nL(ŵ)− L? ≤ C · ρ(φ) log(1/δ)\nn . (3)\nA passive learner essentially uses the default φ, which is constantly 1, for a risk of ρ(1) = E[ψ2(X)]. But the φ that minimizes the bound is the solution to the following minimization problem:\nMinimizeφ E[ψ2(X)/φ(X)] subject to E[φ(X)] = 1, (4)\nφ(x) ≥ c log(c ′n) log(c′′/δ)\nn ‖x‖2∗, ∀x ∈ suppX(D).\nThe second constraint is due to the requirement n ≥ cR2Pφ log(c ′n) log(c′′/δ). The following lemma bounds the risk of the optimal φ. Its proof is provided in Appendix C.\nLemma 3.1. Let φ? be the solution to the minimization problem in Eq. (4). Then for n ≥ O(d log(d) log(1/δ)), E2[ψ(X)] ≤ ρ(φ?) ≤ E2[ψ(X)](1 +O(d log(n) log(1/δ)/n)).\nThe ratio between the risk of φ? and the risk of the default φ thus approaches E[ψ2(X)]/E2[ψ(X)], and this is also the optimal factor of label complexity reduction. The ratio is 1 for highly symmetric distributions, where the support of DX is on a sphere and all the noise variances are identical. In these cases, active learning is not helpful, even asymptotically. However, in the general case, this ratio is unbounded, and so is the potential for improvement from using active learning. The crucial challenge is that without access to the conditional distribution DY |X , Eq. (4) cannot be solved directly. We consider the oracle risk ρ? = E2[ψ(X)], which can be approached if an oracle divulges the optimal φ and n→∞. The goal of the active learner is to approach the oracle guarantee without prior knowledge of DY |X ."
    }, {
      "heading" : "4 Approaching the Oracle Bound with Strata",
      "text" : "To approximate the oracle guarantee, we borrow the stratification approach used in Monte-Carlo function integration (e.g., Glasserman, 2004). Partition suppX(D) into K disjoint subsets A = {A1, . . . , AK}, and consider for φ only functions that are constant on each Ai and such that E[φ(X)] = 1. Each of the functions in this class can be described by a vector a = (a1, . . . , aK) ∈ (R∗+)K . The value of the function on x ∈ Ai is ai∑\nj∈[K] pjaj , where pj := P[X ∈ Aj ]. Let φa denote\na function defined by a, leaving the dependence on the partition A implicit. To calculate the risk of φa, denote µi := E[‖X‖2∗(X>w? − Y )2 | X ∈ Ai]. From the definition of ρ(φ),\nρ(φa) = ∑ j∈[K] pjaj ∑ i∈[K] pi ai µi. (5)\nIt is easy to verify that a? such that a?i = √ µi minimizes ρ(φa), and\nρ?A := inf a∈RK+ ρ(φa) = ρ(φa?) = ( ∑ i∈[K] pi √ µi) 2. (6)\nρ?A is the oracle risk for the fixed partition A. In comparison, the standard passive learner has risk ρ(φ1) = ∑ i∈[K] piµi. Thus, the ratio between the optimal risk and the default risk can be as large as 1/mini pi. Note that here, as in the definition of ρ? above, ρ?A might not be achievable for samples up to a certain size, because of the additional requirement that φ not be too small (see Eq. (4)). Nonetheless, this optimistic value is useful as a comparison.\nConsider an infinite sequence of partitions: for j ∈ N, Aj = {Aj1, . . . , A j Kj }, with Kj → ∞. Similarly to Carpentier and Munos (2012), under mild regularity assumptions, if the partitions have diameters and probabilities that approach zero, then ρ?Aj → ρ(φ\n?), achieving the optimal upper bound for Eq. (3). For a fixed partition A, the challenge is then to approach ρ∗A without prior knowledge of the true µi’s, using relatively few extra labeled examples. In the next section we describe our active learning algorithm that does just that."
    }, {
      "heading" : "5 Active Learning for Regression",
      "text" : "To approach the optimal risk ρ∗A, we need a good estimate of µi for i ∈ [K]. Note that µi depends on the optimal predictor w?, therefore its value depends on the entire distribution. We assume that the error of the label relative to the optimal predictor is bounded as follows: There exists a b ≥ 0 such that (x>w?− y)2 ≤ b2‖x‖2∗ for all (x, y) in the support of D. This boundedness assumption can be replaced by an assumption on sub-Gaussian tails with similar results. Our assumption implies also L? = E[(x>w? − y)2] ≤ b2E[‖X‖2∗] = b2d, where the last equality follows from Eq. (1).\nAlgorithm 1 Active Regression input Confidence δ ∈ (0, 1), label budget m, partition A. output ŵ ∈ Rd\n1: m1 ← m4/5/2, m2 ← m4/5/2, m3 ← m− (m1 +m2). 2: δ1 ← δ/4, δ2 ← δ/4, δ3 ← δ/2. 3: S1 ← SAMPLE(Pφ[Σ],m1) 4: v̂← REG(S1, δ1) 5: ∆← √ Cd2b2 log(1/δ1)\nm1 ; γ ← (b+ 2∆)2\n√ K log(2K/δ2)/m2; t← m2/K.\n6: for i = 1 to K do 7: Ti ← SAMPLE(Qi, t). 8: µ̃i ← Θi · ( 1 t ∑ (x,y)∈Ti(|x >v̂ − y|+ ∆)2 + γ ) . 9: âi ← √ µ̃i.\n10: end for 11: ξ ← c log(c ′m3) log(c ′′/δ3)\nm3 12: Set φ̂ such that for x ∈ Ai, φ̂(x) := ‖x‖2∗ · ξ + (1− dξ) âi∑ j pj âj . 13: S3 ← SAMPLE(Pφ̂,m3). 14: ŵ← REG(S3, δ3).\nOur active regression algorithm, listed in Alg. 1, operates in three stages. In the first stage, the goal is to find a crude loss optimizer v̂, so as to later estimate µi. To find this optimizer, the algorithm draws a labeled sample of size m1 from the distribution Pφ[Σ], where φ[Σ](x) := 1dx >Σ−1x = 1d‖x‖ 2 ∗. Note that ρ(φ[Σ]) = d ·E[(Xw?− Y )2] = dL?. In addition, R2Pφ[Σ] = d. Consequently, by Eq. (3), applying REG tom1 ≥ O(d log(d) log(1/δ1)) random draws from Pφ[Σ] gets, with probability 1−δ1\nL(v̂)− L? = ‖v̂ −w?‖2 ≤ CdL? log(1/δ1) m1 ≤ Cd\n2b2 log(1/δ1)\nm1 . (7)\nIn Needell et al. (2013) a similar distribution is used to speed up gradient descent for convex losses. Here, we make use of φ[Σ] as a stepping stone in order to approach the optimal φ at a rate that does not depend on the condition number of D. Denote by E the event that Eq. (7) holds. In the second stage, estimates for µi, denoted µ̃i, are calculated from labeled samples that are drawn from another set of probability distributions, Qi for i ∈ [K]. These distributions are defined as follows. Denote Θi = E[‖X‖4∗ | X ∈ Ai]. For x ∈ Rd, y ∈ R, let Γi(x, y) = {(x̃, ỹ) ∈ Ai ×\nR | x = x̃‖x̃‖∗ , y = ỹ ‖x̃‖∗ }, and define Qi by dQi(X, Y ) = 1 Θi ∫ (X̃,Ỹ )∈Γi(X,Y ) ‖X̃‖ 4 ∗ dD(X̃, Ỹ ). Clearly, for all x ∈ suppX(Qi), ‖x‖∗ = 1. Drawing labeled examples from Qi can be done using rejection sampling, similarly to Pφ. The use of the Qi distributions in the second stage again helps avoid a dependence on the condition number of D in the convergence rates.\nIn the last stage, a weight function φ̂ is determined based on the estimated µ̃i. A labeled sample is drawn from Pφ̂, and the algorithm returns the predictor resulting from running REG on this sample. The following theorem gives our main result, a finite sample convergence rate guarantee. Theorem 5.1. Let b ≥ 0 such that (x>w? − y)2 ≤ b2‖x‖2∗ for all (x, y) in the support of D. Let ΛD = E[‖X‖4∗]. If Alg. 1 is executed with δ and m such that m ≥ O(d log(d) log(1/δ))5/4, then it draws m labels, and with probability 1− δ,\nL(ŵ)− L? ≤ Cρ?A log(3/δ)\nm +\nO\n( log(1/δ)\nm6/5 ρ?A +\nd1/2Λ 1/4 D log 5/4(1/δ)\nm6/5 b1/2ρ?A\n3/4 + dΛ\n1/2 D K 1/4 log1/4(K/δ) log(1/δ)\nm6/5 bρ?A\n1/2 ) .\nThe theorem shows that the learning rate of the active learner approaches the oracle rate for the given partition. With an infinite sequence of partitions with K an increasing function of m, the optimal oracle risk can also be approached. The rate of convergence to the oracle rate does not depend on the condition number of D, unlike the passive learning rate. In addition, m = O(d log(d) log(1/δ))5/4 suffices to approach the optimal rate, whereas m = Ω(d) is obviously necessary for any learner. It is interesting that also in active learning for classification, it has been observed that active learning in a non-realizable setting requires a super-linear dependence on d (See, e.g., Dasgupta et al., 2008). Whether this dependence is unavoidable for active regression is an open question. Theorem 5.1 is be proved via a series of lemmas. First, we show that if µ̃i is a good approximation of µi then ρA(φ̂) can be bounded as a function of the oracle risk for A. Lemma 5.2. Suppose m3 ≥ O(d log(d) log(1/δ3)), and let φ̂ as in Alg. 1. If, for some α, β ≥ 0,\nµi ≤ µ̃i ≤ µi + αi √ µi + βi, (8)\nthen ρA(φ̂) ≤ (1 +O(d log(m3) log(1/δ3)/m3))(ρ?A + ( ∑ i piαi) 1/2ρ?A 3/4 + ( ∑ i piβi) 1/2ρ?A 1/2).\nProof. We have ∀x ∈ Ai, φ̂(x) ≥ (1− dξ) âi∑ j pj âj , where ξ = c log(c ′m3) log(c ′′/δ) m3 . Therefore\nρ(φ̂) ≡ E[ψ2(X)/φ̂(X)] ≤ 1 1− dξ ∑ j pj âj ∑ i pi · E[ψ2(X)/âi | X ∈ Ai]\n= 1 1− dξ ∑ j pj âj ∑ i piµi/âi = (1 + dξ 1− dξ )ρ(φâ).\nFor m3 ≥ O(d log(d) log(1/δ3)), dξ ≤ 12 , 2 therefore dξ1−dξ ≤ 2dξ. It follows\nρ(φ̂) ≤ (1 +O(d log(m3) log(1/δ3)/m3))ρ(φâ). (9) By Eq. (8),\nρA(φâ) = ∑ j pj √ µ̃j ∑ i piµi/ √ µ̃i\n≤ ∑ j pj( √ µj + √ αjµ 1/4 j + √ βj) ∑ i pi √ µi\n= ( ∑ i pi √ µi) 2 + ( ∑ j pj √ αjµ 1/4 j )( ∑ i pi √ µi) + ( ∑ j pj √ βj)( ∑ i pi √ µi).\n= ρ?A + ( ∑ j pj √ αjµ 1/4 j )ρ ? A 1/2 + ( ∑ j pj √ βj)ρ ? A 1/2.\n2Using the fact that m ≥ O(d log(d) log(1/δ3)) implies m ≥ O(d log(m) log(1/δ3)).\nThe last equality is since ρ?A = ( ∑ i pi √ µi) 2. By Cauchy-Schwartz, ( ∑ j pj √ αjµ 1/4 j ) ≤\n( ∑ i piαi) 1/2ρ?A 3/4. By Jensen’s inequality, ∑ j pj √ βj ≤ ( ∑ j pjβj)\n1/2. Combined with Eq. (6) and Eq. (9), the lemma directly follows.\nWe now show that Eq. (8) holds and provide explicit values for α and β. Define\nνi := Θi · EQi [(|X>ŵ − Y |+ ∆)2], and ν̂i := Θi t ∑ (x,y)∈Ti (|x>ŵ − y|+ ∆)2.\nNote that µ̃i = ν̂i + Θiγ. We will relate ν̂i to νi, and then νi to µi, to conclude a bound of the form in Eq. (8) for µ̃i. First, note that if m1 ≥ O(d log(d) log(1/δ1) and E holds, then for any x ∈ ∪i∈[K]suppX(Qi),\n|x>v̂ − x>w?| ≤ ‖x‖∗‖v̂ −w?‖ ≤\n√ Cd2b2 log(1/δ1)\nm1 ≡ ∆. (10)\nThe second inequality stems from ‖x‖∗ = 1 for x ∈ ∪i∈[K]suppX(Qi), and Eq. (7). This is useful in the following lemma, which relates ν̂i with νi. Lemma 5.3. Suppose that m1 ≥ O(d log(d) log(1/δ1)) and E holds. Then with probability 1− δ2 over the draw of T1, . . . , TK , for all i ∈ [K], |ν̂i−νi| ≤ Θi(b+2∆)2 √ K log(2K/δ2)/m2 ≡ Θiγ.\nProof. For a fixed v̂, ν̂i/Θi is the empirical average of i.i.d. samples of the random variable Z = (|X>v̂ − Y | + ∆)2, where (X, Y ) is drawn according to Qi. We now give an upper bound for Z with probability 1. Let (X̃, Ỹ ) in the support of D such that X = X̃/‖X̃‖∗ and Y = Ỹ /‖X̃‖∗. Then |X>w? − Y | = |X̃>w? − Ỹ |/‖X̃‖∗ ≤ b. If E holds and m1 ≥ O(d log(d) log(1/δ1)),\nZ ≤ (|X>v̂ −X>w?|+ |X>w? − Y |+ ∆)2 ≤ (b+ 2∆)2, where the last inequality follows from Eq. (10). By Hoeffding’s inequality, for every i, with probability 1 − δ2, |ν̂i − νi| ≤ Θi(b + 2∆)2 √ log(2/δ2)/t. The statement of the lemma follows from a union bound over i ∈ [K] and t = m2/K.\nThe following lemma, proved in Appendix D, provides the desired relationship between νi and µi. Lemma 5.4. Ifm1 ≥ O(d log(d) log(1/δ1)) and E holds, then µi ≤ νi ≤ µi+4∆ √ Θiµi+4∆ 2Θi.\nWe are now ready to prove Theorem 5.1.\nProof of Theorem 5.1. From the condition on m and the definition of m1,m3 in Alg. 1 we have m1 ≥ O(d log(d/δ1)) andm3 ≥ O(d log(d/δ3)). Therefore the inequalities in Lemma 5.4, Lemma 5.3 and Eq. (3) (with n, δ, φ substituted with m3, δ3, φ̂) hold simultaneously with probability 1 − δ1 − δ2 − δ3. For Eq. (3), note that ‖x‖∗φ̂(x) ≥ ξ, thus m3 ≥ cR 2 Pφ̂ log(c′n) log(c′′/δ3) as required.\nCombining Lemma 5.4 and Lemma 5.3, and noting that µ̃i = ν̂i + Θiγ, we conclude that µi ≤ µ̃i ≤ µi + 4∆ √ Θiµi + Θi(4∆ 2 + 2γ).\nBy Lemma 5.2, it follows that\nρA(φ̂) ≤ ρ?A + 2 √ ∆( ∑ i∈[K] pi √ Θi) 1/2ρ?A 3/4 + √ 4∆2 + 2γ · ( ∑ i∈[K] piΘi) 1/2ρ?A 1/2 + Ō( log(m3) m3 )\n≤ ρ?A + 2∆1/2Λ 1/4 D ρ ? A\n3/4 + √\n4∆2 + 2γ · Λ1/2D ρ ? A 1/2 + Ō(log(m3)/m3). The last inequality follows since ∑ i∈[K] piΘi = ΛD. We use Ō to absorb parameters that already appear in the other terms of the bound. Combining this with Eq. (3),\nL(ŵ)− L? ≤ Cρ?A log(1/δ3)\nm3 +\nC log(1/δ3)\nm3\n( 2∆1/2Λ\n1/4 D ρ ? A\n3/4 + (2∆ + √\n2γ) · Λ1/2D ρ ? A\n1/2 )\n+ Ō( log(m3)\nm23 ).\nWe have γ = (b+2∆)2 √ K log(2K/δ2)/m2, and ∆ = √ Cd2b2 log(1/δ1)\nm1 . Form1 ≥ Cd log(1/δ1),\n∆ ≤ b √ d, thus γ ≤ b2(2 √ d+ 1)2 √ K log(2K/δ2)/m2. Substituting for ∆ and γ, we have\nL(ŵ)− L? ≤ Cρ?A log(1/δ3) m3 + C log(1/δ3) m3\n( 16Cd2b2 log(1/δ1)\nm1\n)1/4 Λ\n1/4 D ρ ? A 3/4\n+ C log(1/δ3)\nm3\n(( 4Cd2b2 log(1/δ1)\nm1 )1/2 + √ 2b(2 √ d+ 1) ( K log(2K/δ2)\nm2\n)1/4) · Λ1/2D ρ ? A 1/2 + Ō( log(m3)\nm23 ).\nTo get the theorem, set m3 = m−m4/5, m2 = m1 = m4/5/2, δ1 = δ2 = δ/4, and δ3 = δ/2."
    }, {
      "heading" : "6 Improvement over Passive Learning",
      "text" : "Theorem 5.1 shows that our active learner approaches the oracle rate, which can be strictly faster than the rate implied by Theorem 2.1 for passive learning. To complete the picture, observe that this better rate cannot be achieved by any passive learner. This can be seen by the following 1-dimensional example. Let σ > 0, α > 1√\n2 , p = 12α2 , and η ∈ R such that |η| ≤ σ α . Let Dη over R × R such\nthat with probability p, X = α and Y = αη + , where ∼ N(0, σ2), and with probability 1 − p, X = β := √ 1−pα2\n1−p and Y = 0. Then E[X 2] = 1 and w? = pα2η. Consider a partition of R such\nthat α ∈ A1 and β ∈ A2. Then p1 = p, µ1 = E [α2( +αη−αw?)2] = α2(σ2 +α2η2(1−pα2)) ≤ 3 2α 2σ2. In addition, p2 = 1− p and µ2 = β4w2? = ( 1−pα2 1−p ) 2p2α4η2 ≤ p 2α2σ2 4(1−p)2 . The oracle risk is\nρ?A = (p1 √ µ1 + p2 √ µ2) 2 ≤ (p √ 3\n2 ασ + (1− p) pασ 2(1− p) )2 = p2α2σ2(\n√ 3\n2 +\n1 2 )2 ≤ 2pσ2.\nTherefore, for the active learner, with probability 1− δ,\nL(ŵ)− L? ≤ 2Cpσ2 log(1/δ)\nm + o(\n1 m ). (11)\nIn contrast, consider any passive learner that receives m labeled examples and outputs a predictor ŵ. Consider the estimator for η defined by η̂ = ŵpα2 . η̂ estimates the mean of a Gaussian distribution with variance σ2/α2. The minimax optimal rate for such an estimator is σ 2\nα2n , where n is the number of examples with X = α.3 With probability at least 1/2, n ≤ 2mp. Therefore, EDm [(η̂ − η)2] ≥ σ2\n4α2mp . It follows that EDm [L(ŵ)− L?] = EDm [(ŵ −w) 2] = p2α4 ·E[(η̂ − η)2] ≥ pα\n2σ2 4m = σ2 4m .\nComparing this to Eq. (11), one can see that the ratio between the rate of the best passive learner and the rate of the active learner approaches O(1/p) for large m."
    }, {
      "heading" : "7 Discussion",
      "text" : "Many questions remain open for active regression. For instance, it is of particular interest whether the convergence rates provided here are the best possible for this model. Second, we consider here only the plain vanilla finite-dimensional regression, however we believe that the approach can be extended to ridge regression in a general Hilbert space. Lastly, the algorithm uses static allocation of samples to stages and to partitions. In Monte-Carlo estimation Carpentier and Munos (2012), dynamic allocation has been used to provide convergence to a pseudo-risk with better constants. It is an open question whether this type of approach can be useful in the case of active regression."
    } ],
    "references" : [ {
      "title" : "Agnostic active learning",
      "author" : [ "M.F. Balcan", "A. Beygelzimer", "J. Langford" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "Balcan et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Balcan et al\\.",
      "year" : 2009
    }, {
      "title" : "Active learning for regression based on query by committee",
      "author" : [ "R. Burbidge", "J.J. Rowland", "R.D. King" ],
      "venue" : "In Intelligent Data Engineering and Automated Learning-IDEAL",
      "citeRegEx" : "Burbidge et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Burbidge et al\\.",
      "year" : 2007
    }, {
      "title" : "Maximizing expected model change for active learning in regression",
      "author" : [ "W. Cai", "Y. Zhang", "J. Zhou" ],
      "venue" : "In Data Mining (ICDM),",
      "citeRegEx" : "Cai et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Cai et al\\.",
      "year" : 2013
    }, {
      "title" : "Minimax number of strata for online stratified sampling given noisy samples",
      "author" : [ "A. Carpentier", "R. Munos" ],
      "venue" : "Algorithmic Learning Theory,",
      "citeRegEx" : "Carpentier and Munos.,? \\Q2012\\E",
      "shortCiteRegEx" : "Carpentier and Munos.",
      "year" : 2012
    }, {
      "title" : "Estimating a bounded normal mean",
      "author" : [ "G. Casella", "W.E. Strawderman" ],
      "venue" : "The Annals of Statistics,",
      "citeRegEx" : "Casella and Strawderman.,? \\Q1981\\E",
      "shortCiteRegEx" : "Casella and Strawderman.",
      "year" : 1981
    }, {
      "title" : "Improving generalization with active learning",
      "author" : [ "D. Cohn", "L. Atlas", "R. Ladner" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Cohn et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Cohn et al\\.",
      "year" : 1994
    }, {
      "title" : "Active learning with statistical models",
      "author" : [ "D.A. Cohn", "Z. Ghahramani", "M.I. Jordan" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Cohn et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Cohn et al\\.",
      "year" : 1996
    }, {
      "title" : "A general agnostic active learning algorithm",
      "author" : [ "S. Dasgupta", "D. Hsu", "C. Monteleoni" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "Dasgupta et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Dasgupta et al\\.",
      "year" : 2008
    }, {
      "title" : "Sequential design and estimation in heteroscedastic nonparametric regression",
      "author" : [ "S. Efromovich" ],
      "venue" : "Sequential Analysis,",
      "citeRegEx" : "Efromovich.,? \\Q2007\\E",
      "shortCiteRegEx" : "Efromovich.",
      "year" : 2007
    }, {
      "title" : "Upal: Unbiased pool based active learning",
      "author" : [ "R. Ganti", "A.G. Gray" ],
      "venue" : "In International Conference on Artificial Intelligence and Statistics,",
      "citeRegEx" : "Ganti and Gray.,? \\Q2012\\E",
      "shortCiteRegEx" : "Ganti and Gray.",
      "year" : 2012
    }, {
      "title" : "Monte Carlo methods in financial engineering, volume 53",
      "author" : [ "P. Glasserman" ],
      "venue" : null,
      "citeRegEx" : "Glasserman.,? \\Q2004\\E",
      "shortCiteRegEx" : "Glasserman.",
      "year" : 2004
    }, {
      "title" : "A distribution-free theory of nonparametric regression",
      "author" : [ "L. Györfi", "M. Kohler", "A. Krzyzak", "H. Walk" ],
      "venue" : null,
      "citeRegEx" : "Györfi et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Györfi et al\\.",
      "year" : 2002
    }, {
      "title" : "Heavy-tailed regression with a generalized median-of-means",
      "author" : [ "D. Hsu", "S. Sabato" ],
      "venue" : "In Proceedings of the 31st International Conference on Machine Learning,",
      "citeRegEx" : "Hsu and Sabato.,? \\Q2014\\E",
      "shortCiteRegEx" : "Hsu and Sabato.",
      "year" : 2014
    }, {
      "title" : "Random design analysis of ridge regression",
      "author" : [ "D. Hsu", "S.M. Kakade", "T. Zhang" ],
      "venue" : "In Twenty-Fifth Conference on Learning Theory,",
      "citeRegEx" : "Hsu et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Hsu et al\\.",
      "year" : 2012
    }, {
      "title" : "Statistical asymptotic theory of active learning",
      "author" : [ "T. Kanamori" ],
      "venue" : "Annals of the Institute of Statistical Mathematics,",
      "citeRegEx" : "Kanamori.,? \\Q2002\\E",
      "shortCiteRegEx" : "Kanamori.",
      "year" : 2002
    }, {
      "title" : "Active learning algorithm using the maximum weighted loglikelihood estimator",
      "author" : [ "T. Kanamori", "H. Shimodaira" ],
      "venue" : "Journal of Statistical Planning and Inference,",
      "citeRegEx" : "Kanamori and Shimodaira.,? \\Q2003\\E",
      "shortCiteRegEx" : "Kanamori and Shimodaira.",
      "year" : 2003
    }, {
      "title" : "Stochastic gradient descent and the randomized kaczmarz algorithm",
      "author" : [ "D. Needell", "N. Srebro", "R. Ward" ],
      "venue" : "arXiv preprint arXiv:1310.5715,",
      "citeRegEx" : "Needell et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Needell et al\\.",
      "year" : 2013
    }, {
      "title" : "Active learning in approximately linear regression based on conditional expectation of generalization error",
      "author" : [ "M. Sugiyama" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Sugiyama.,? \\Q2006\\E",
      "shortCiteRegEx" : "Sugiyama.",
      "year" : 2006
    }, {
      "title" : "Pool-based active learning in approximate linear regression",
      "author" : [ "M. Sugiyama", "S. Nakajima" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Sugiyama and Nakajima.,? \\Q2009\\E",
      "shortCiteRegEx" : "Sugiyama and Nakajima.",
      "year" : 2009
    }, {
      "title" : "Various techniques used in connection with random digits",
      "author" : [ "J. Von Neumann" ],
      "venue" : "Applied Math Series,",
      "citeRegEx" : "Neumann.,? \\Q1951\\E",
      "shortCiteRegEx" : "Neumann.",
      "year" : 1951
    }, {
      "title" : "Minimax robust designs and weights for approximately specified regression models with heteroscedastic errors",
      "author" : [ "D.P. Wiens" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "Wiens.,? \\Q1998\\E",
      "shortCiteRegEx" : "Wiens.",
      "year" : 1998
    }, {
      "title" : "Robust weights and designs for biased regression models: Least squares and generalized m-estimation",
      "author" : [ "D.P. Wiens" ],
      "venue" : "Journal of Statistical Planning and Inference,",
      "citeRegEx" : "Wiens.,? \\Q2000\\E",
      "shortCiteRegEx" : "Wiens.",
      "year" : 2000
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "This rate cannot in general be improved by active learning, unlike in the case of classification (Balcan et al., 2009).",
      "startOffset" : 97,
      "endOffset" : 118
    }, {
      "referenceID" : 13,
      "context" : "Finite sample convergence of parametric linear regression in the passive setting has been studied by several (see, e.g., Györfi et al., 2002; Hsu et al., 2012).",
      "startOffset" : 109,
      "endOffset" : 159
    }, {
      "referenceID" : 12,
      "context" : "Recently, a new algorithm for linear regression has been proposed (Hsu and Sabato, 2014).",
      "startOffset" : 66,
      "endOffset" : 88
    }, {
      "referenceID" : 3,
      "context" : "One of the earliest works is Cohn et al. (1996), which proposes an active learning algorithm for locally weighted regression, assuming a well-specified model and an unbiased learning function.",
      "startOffset" : 29,
      "endOffset" : 48
    }, {
      "referenceID" : 3,
      "context" : "One of the earliest works is Cohn et al. (1996), which proposes an active learning algorithm for locally weighted regression, assuming a well-specified model and an unbiased learning function. Wiens (1998, 2000) calculates a minimax optimal design for regression given the marginal data distribution, assuming that the model is approximately well-specified. Kanamori (2002) and Kanamori and Shimodaira (2003) propose an active learning algorithm that first calculates a maximum likelihood estimator and then uses this estimator to come up with an optimal design.",
      "startOffset" : 29,
      "endOffset" : 374
    }, {
      "referenceID" : 3,
      "context" : "One of the earliest works is Cohn et al. (1996), which proposes an active learning algorithm for locally weighted regression, assuming a well-specified model and an unbiased learning function. Wiens (1998, 2000) calculates a minimax optimal design for regression given the marginal data distribution, assuming that the model is approximately well-specified. Kanamori (2002) and Kanamori and Shimodaira (2003) propose an active learning algorithm that first calculates a maximum likelihood estimator and then uses this estimator to come up with an optimal design.",
      "startOffset" : 29,
      "endOffset" : 409
    }, {
      "referenceID" : 3,
      "context" : "One of the earliest works is Cohn et al. (1996), which proposes an active learning algorithm for locally weighted regression, assuming a well-specified model and an unbiased learning function. Wiens (1998, 2000) calculates a minimax optimal design for regression given the marginal data distribution, assuming that the model is approximately well-specified. Kanamori (2002) and Kanamori and Shimodaira (2003) propose an active learning algorithm that first calculates a maximum likelihood estimator and then uses this estimator to come up with an optimal design. Asymptotic convergence rates are provided under asymptotic normality assumptions. Sugiyama (2006) assumes an approximately well-specified model and i.",
      "startOffset" : 29,
      "endOffset" : 661
    }, {
      "referenceID" : 3,
      "context" : "One of the earliest works is Cohn et al. (1996), which proposes an active learning algorithm for locally weighted regression, assuming a well-specified model and an unbiased learning function. Wiens (1998, 2000) calculates a minimax optimal design for regression given the marginal data distribution, assuming that the model is approximately well-specified. Kanamori (2002) and Kanamori and Shimodaira (2003) propose an active learning algorithm that first calculates a maximum likelihood estimator and then uses this estimator to come up with an optimal design. Asymptotic convergence rates are provided under asymptotic normality assumptions. Sugiyama (2006) assumes an approximately well-specified model and i.i.d. label noise, and selects a design from a finite set of possibilities. The approach is adapted to pool-based active learning by Sugiyama and Nakajima (2009). Burbidge et al.",
      "startOffset" : 29,
      "endOffset" : 874
    }, {
      "referenceID" : 1,
      "context" : "Burbidge et al. (2007) propose an adaptation of Query By Committee.",
      "startOffset" : 0,
      "endOffset" : 23
    }, {
      "referenceID" : 1,
      "context" : "Burbidge et al. (2007) propose an adaptation of Query By Committee. Cai et al. (2013) propose guessing the potential of an example to change the current model.",
      "startOffset" : 0,
      "endOffset" : 86
    }, {
      "referenceID" : 1,
      "context" : "Burbidge et al. (2007) propose an adaptation of Query By Committee. Cai et al. (2013) propose guessing the potential of an example to change the current model. Ganti and Gray (2012) propose a consistent pool-based active learner for the squared loss.",
      "startOffset" : 0,
      "endOffset" : 182
    }, {
      "referenceID" : 14,
      "context" : "Rejection sampling for regression has been explored in Kanamori (2002); Kanamori and Shimodaira (2003); Sugiyama (2006) and others, mostly in an asymptotic regime.",
      "startOffset" : 55,
      "endOffset" : 71
    }, {
      "referenceID" : 14,
      "context" : "Rejection sampling for regression has been explored in Kanamori (2002); Kanamori and Shimodaira (2003); Sugiyama (2006) and others, mostly in an asymptotic regime.",
      "startOffset" : 55,
      "endOffset" : 103
    }, {
      "referenceID" : 14,
      "context" : "Rejection sampling for regression has been explored in Kanamori (2002); Kanamori and Shimodaira (2003); Sugiyama (2006) and others, mostly in an asymptotic regime.",
      "startOffset" : 55,
      "endOffset" : 120
    }, {
      "referenceID" : 12,
      "context" : "In (1)This is a slight variation of the original result of Hsu and Sabato (2014), see Appendix A.",
      "startOffset" : 59,
      "endOffset" : 81
    }, {
      "referenceID" : 3,
      "context" : "Similarly to Carpentier and Munos (2012), under mild regularity assumptions, if the partitions have diameters and probabilities that approach zero, then ρAj → ρ(φ ), achieving the optimal upper bound for Eq.",
      "startOffset" : 13,
      "endOffset" : 41
    }, {
      "referenceID" : 16,
      "context" : "In Needell et al. (2013) a similar distribution is used to speed up gradient descent for convex losses.",
      "startOffset" : 3,
      "endOffset" : 25
    }, {
      "referenceID" : 3,
      "context" : "In Monte-Carlo estimation Carpentier and Munos (2012), dynamic allocation has been used to provide convergence to a pseudo-risk with better constants.",
      "startOffset" : 26,
      "endOffset" : 54
    } ],
    "year" : 2014,
    "abstractText" : "We propose a new active learning algorithm for parametric linear regression with random design. We provide finite sample convergence guarantees for general distributions in the misspecified model. This is the first active learner for this setting that provably can improve over passive learning. Unlike other learning settings (such as classification), in regression the passive learning rate of O(1/ ) cannot in general be improved upon. Nonetheless, the so-called ‘constant’ in the rate of convergence, which is characterized by a distribution-dependent risk, can be improved in many cases. For a given distribution, achieving the optimal risk requires prior knowledge of the distribution. Following the stratification technique advocated in Monte-Carlo function integration, our active learner approaches the optimal risk using piecewise constant approximations.",
    "creator" : "pdftk 2.02 - www.pdftk.com"
  }
}