{
  "name" : "535ab76633d94208236a2e829ea6d888.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Reputation-based Worker Filtering in Crowdsourcing",
    "authors" : [ "Srikanth Jagabathula", "Lakshminarayanan Subramanian", "Ashwin Venkataraman" ],
    "emails" : [ "sjagabat@stern.nyu.edu", "lakshmi@cs.nyu.edu", "ashwin@cs.nyu.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The growing popularity of online crowdsourcing services (e.g. Amazon Mechanical Turk, CrowdFlower etc.) has made it easy to collect low-cost labels from the crowd to generate training datasets for machine learning applications. However, these applications remain vulnerable to noisy labels introduced either unintentionally by unreliable workers or intentionally by spammers and malicious workers [10, 11]. Recovering the underlying true labels in the face of noisy input in online crowdsourcing environments is challenging due to three key reasons: (a) Workers are often anonymous and transient and can provide random or even malicious labels (b) The reliabilities or reputations of the workers are often unknown (c) Each task may receive labels from only a (small) subset of the workers.\nSeveral existing approaches aim to address the above challenges under the following standard setup. There is a set T of binary tasks, each with a true label in { 1, 1}. A set of workers W are asked to label the tasks, and the assignment of the tasks to the workers can be represented by a bipartite graph with the workers on one side, tasks on the other side, and an edge connecting each worker to the set of tasks she is assigned. We term this the worker-task assignment graph. Workers are assumed to generate labels according to a probabilistic model - given a task t, a worker w provides the true label with probability pw. Note that every worker is assumed to label each task independent of other tasks. The goal then is to infer the underlying true labels of the tasks by aggregating the labels provided by the workers. Prior works based on the above model can be broadly classified into two categories: machine-learning based and linear-algebra based. The machine-learning approaches are typically based on variants of the EM algorithm [3, 16, 24, 14]. These algorithms perform well in most scenarios, but they lack any theoretical guarantees. More recently, linear-algebra based algorithms [9, 6, 2] have been proposed, which provide guarantees on the error in estimating the true labels of the tasks (under appropriate assumptions), and have also been shown to perform well on various real-world datasets. While existing work focuses on workers making random errors, recent work and anecdotal evidence have shown that worker labeling strategies that are common in practice do not fit the standard random model [19]. Specific examples include vote pollution attacks\non Digg [18], malicious behavior in social media [22, 12] and low-precision worker populations in crowdsourcing experiments [4].\nIn this paper, we aim to go beyond the standard random model and study the problem of inferring the true labels of tasks under a much broader class of adversarial worker strategies with no specific assumptions on their labeling pattern. For instance, deterministic labeling, where the workers always give the same label, cannot be captured by the standard random model. Also, malicious workers can employ arbitrary labeling patterns to degrade the accuracy of the inferred labels. Our goal is to accurately infer the true labels of the tasks without restricting workers’ strategies.\nMain results. Our main contribution is the design of a reputation algorithm to identify and filter out adversarial workers in online crowdsourcing systems. Specifically, we propose 2 computationally efficient algorithms to compute worker reputations using only the labels provided by the workers (see Algorithms 1 and 2), which are robust to manipulation by adversaries. We compute worker reputations by assigning penalties to a worker for each task she is assigned. The assigned penalty is higher for tasks on which there is “a lot” of disagreement with the other workers. The penalties are then aggregated in a “load-balanced” manner using the concept of optimal semi-matchings [7]. The reputation algorithm is designed to be used in conjunction with any of the existing label aggregation algorithms that are designed for the standard random worker model: workers with low reputations1 are filtered out and the aggregation algorithm is used on the remaining labels. As a result, our algorithm can be used to boost the performance of existing label aggregation algorithms.\nWe demonstrate the effectiveness of our algorithm using a combination of strong theoretical guarantees and empirical results on real-world datasets. Our analysis considers three scenarios. First, we consider the standard setting in which workers are not adversarial and provide labels according to the random model. In this setting, we show that when the worker-task assignment graph is (l, r)regular, the reputation scores are proportional to the reliabilities of the workers (see Theorem 1), so that only unreliable workers are filtered out. As a result, our reputation scores are consistent with worker reliabilities in the absence of adversarial workers. The analysis becomes significantly complicated for more general graphs (a fact observed in prior works; see [2]); hence, we demonstrate improvements using simulations and experiments on real world datasets. Second, we evaluate the performance of our algorithm in the presence of workers who use deterministic labeling strategies (always label 1 or 1). For these strategies, when the worker-task assignment graph is (l, r)-regular, we show (see Theorem 2) that the adversarial workers receive lower reputations than their “honest” counterparts, provided honest workers have “high enough” reliabilities – the exact bound depends on the prevalence of tasks with true label 1, the fraction of adversarial workers and the average reliability of the honest workers.\nThird, we consider the case of sophisticated adversaries, i.e. worst-case adversarial workers whose goal is to maximize the number of tasks they affect (i.e. cause to get incorrect labels). Under this assumption, we provide bounds on the “damage” they can do: We prove that irrespective of the label aggregation algorithm (as long as it is agnostic to worker/task identities), there is a nontrivial minimum fraction of tasks whose true label is incorrectly inferred. This bound depends on the graph structure of the honest worker labeling pattern (see Theorem 3 for details). Our result is valid across different labeling patterns and a large class of label aggregation algorithms, and hence provides fundamental limits on the damage achievable by adversaries. Further, we propose a label aggregation algorithm utilizing the worker reputations computed in Algorithm 2 and prove the existence of an upper bound on the worst-case accuracy in inferring the true labels (see Theorem 4). Finally, using several publicly available crowdsourcing datasets (see Section 4), we show that our reputation algorithm: (a) can help in enhancing the accuracy of state-of-the-art label aggregation algorithms (b) is able to detect workers in these datasets who exhibit certain ‘non-random’ strategies.\nAdditional Related Work: In addition to the references cited above, there have been works which use gold standard tasks, i.e. tasks whose true label is already known [17, 5, 11] to correct for worker bias. [8] proposed a way of quantifying worker quality by transforming the observed labels into soft posterior labels based on the estimated confusion matrix [3]. The authors in [13] propose an empirical Bayesian algorithm to eliminate workers who label randomly without looking at the particular task (called spammers), and estimate the consensus labels from the remaining workers. Both these\n1As will become evident later, reputations are measures of how adversarial a worker is and are different from reliabilities of workers.\nworks use the estimated parameters to define “good workers” whereas we compute the reputation scores using only the labels provided by the workers. The authors in [20] focus on detecting specific kinds of spammers and then replace their labels with new workers. We consider all types of adversarial workers, not just spammers and don’t assume access to a pool of workers who can be asked to label the tasks."
    }, {
      "heading" : "2 Model and reputation algorithms",
      "text" : "Notation. Consider a set of tasks T having true labels in {1, 1}. Let yj denotes the true label of a task tj 2 T and suppose that the tasks are sampled from a population in which the prevalence of the positive tasks is 2 [0, 1], so that there is a fraction of tasks with true label 1. A set of workers W provide binary labels to the tasks in T . We let G denote the bipartite worker-task assignment graph where an edge between worker wi and task tj indicates that wi has labeled tj . Further, let wi(tj) denote the label provided by worker wi to task tj , where we set wi(tj) = 0 if worker wi did not label task tj . For a task tj , let Wj ⇢ W denote the set of workers who labeled tj and likewise, for a worker wi, let Ti denote the set of tasks the worker has labeled. Denote by d+j (resp. d j ) the number of workers labeling task tj as 1 (resp. 1). Finally, let L 2 {1, 0, 1}|W |⇥|T | denote the matrix representing the labels assigned by the workers to the tasks, i.e. Lij = wi(tj). Given L, the goal is to infer the true labels yj of the tasks.\nWorker model. We consider the setting in which workers may be honest or adversarial. That is, W = H [ A with H \\ A = ;. Honest workers are assumed to provide labels according to a probabilistic model: for task tj with true label yj , worker wi provides label yj with probability pi and yj with probability 1 pi. Note that the parameter pi doesn’t depend on the particular task that the worker is labeling, so an honest worker labels each task independently. It is standard to define the reliability of an honest worker as µi = 2pi 1, so that we have µi 2 [ 1, 1]. Further, we assume that the honest workers are sampled from a population with average reliability µ > 0. Adversaries, on the other hand, may adopt any arbitrary (deterministic or randomized) labeling strategy that cannot be described using the above probabilistic process. For instance, the adversary could always label all tasks as 1, irrespective of the true label. Another example is when the adversary decides her labels based on existing labels cast by other workers (assuming the adversary has access to such information). Note however, that adversarial workers need not always provide the incorrect labels. Essentially, the presence of such workers breaks the assumptions of the model and can adversely impact the performance of aggregation algorithms. Hence, our focus in this paper is on designing algorithms to identify and filter out such adversarial workers. Once this is achieved, we can use existing state-of-the-art label aggregation algorithms on the remaining labels to infer the true labels of the tasks.\nTo identify these adversarial workers, we propose an algorithm for computing “reputation” or “trust” scores for each worker. More concretely, we assign penalties (in a suitable way) to every worker and higher the penalty, worse the reputation of the worker. First note that any task that has all 1 labels (or 1 labels) does not provide us with any information about the reliabilities of the workers who labeled the task. Hence, we focus on the tasks that have both 1 and 1 labels and we call this set the conflict set Tcs. Further, since we have no “side” information on the identities of workers, any reputation score computation must be based solely on the labels provided by the workers.\nWe start with the following basic idea to compute reputation scores: a worker is penalized for every ‘conflict’ s/he is involved in (a task in the conflict set the worker has labeled on). This idea is motivated by the fact that in an ideal scenario, where all honest workers have a reliability µi = 1, a conflict indicates the presence of an adversary and the reputation score aims to capture a measure of the number of conflicts each worker is involved in: the higher the number of conflicts, the worse the reputation score. However, a straightforward aggregation of penalties for each worker may overpenalize (honest) workers who label several tasks.\nIn order to overcome the issue of over-penalizing (honest) workers, we propose two techniques: (a) soft and (b) hard assignment of penalties. In the soft assignment of penalties (Algorithm 1), we assign a penalty of 1/d+j to all workers who label 1 on task tj and 1/d j to all workers who label 1 on task tj . Then, for each worker, we aggregate the penalties across all assigned tasks by taking the average. The above assignment of penalties implicitly rewards agreements by making the penalty inversely proportional to the number of other workers that agree with a worker. Further, taking the average normalizes for the number of tasks labeled by the worker. Since we expect the\nhonest workers to agree with the majority more often than not, we expect this technique to assign lower penalties to honest workers when compared to adversaries. The soft assignment of penalties can be shown to perform quite well in identifying low reliability and adversarial workers (refer to Theorems 1 and 2). However, it may still be subject to manipulation by more “sophisticated” adversaries who can adapt and modify their labeling strategy to target certain tasks and to inflate the penalty of specific honest workers. In fact for such worst-case adversaries, we can show that (Theorem 3) given any honest worker labeling pattern, there exists a lower bound on the number of tasks whose true label cannot be inferred correctly, by any label aggregation algorithm.\nTo address the case of these sophisticated adversaries, we propose a hard penalty assignment scheme (Algorithm 2) where the key idea is not to distribute the penalty evenly across all workers; but to only choose two workers to penalize per conflict task: one “representative” worker among those who labeled 1 and another “representative” worker among those who labeled 1. While choosing such workers, the goal is to pick these representative workers in a load-balanced manner to “spread” the penalty across all workers, so that it is not concentrated on one/few workers. The final penalty of each worker is the sum of the accrued penalties across all the (conflict) tasks assigned to the worker. Intuitively, such hard assignment of penalties will penalize workers with higher degrees and many conflicts (who are potential ‘worst-case’ adversaries), limiting their impact.\nWe use the concept of optimal semi-matchings [7] on bipartite graphs to distribute penalties in a load balanced manner, which we briefly discuss here. For a bipartite graph B = (U, V,E), a semimatching in B is a set of edges M ✓ E such that each vertex in V is incident to exactly one edge in M (note that vertices in U could be incident to multiple edges in M ). A semi-matching generalizes the notion of matchings on bipartite graphs. To define an optimal semi-matching, we introduce a cost function for a semi-matching - for each u 2 U , let degM (u) denote the number of edges in M that are incident to u and let costM (u) be defined as costM (u) = PdegM (u) i=1 i = degM (u)(degM (u)+1) 2 . An optimal semi-matching then, is one which minimizes P\nu2U costM (u). This notion of cost is motivated by the load balancing problem for scheduling tasks on machines (refer to [7] for further details). Intuitively, an optimal semi-matching fairly matches the V -vertices across the U -vertices so that the maximum “load” on any U -vertex is minimized.\nAlgorithm 1 SOFT PENALTY 1: Input: W , T and L 2: For every task tj 2 Tcs, assign penalty sij\nto each worker wi 2 Wj as follows: sij =\n1 d+j if Lij = 1\nsij = 1 d j if Lij = 1 3: Output: Penalty of worker wi\npen(wi) =\nP\ntj2Ti\\ Tcs sij |Ti \\ Tcs|\nAlgorithm 2 HARD PENALTY 1: Input: W , T and L 2: Create a bipartite graph Bcs as follows:\n(i) Each worker wi 2 W is represented by a node on the left (ii) Each task tj 2 Tcs is represented by two nodes on the right t+j and t j (iii) Add the edge (wi, t + j ) if Lij = 1 or\nedge (wi, t j ) if Lij = 1. 3: Compute an optimal semi-matching OSM on\nBcs and let di ( degree of worker wi in OSM 4: Output: Penalty of worker wi pen(wi) = di"
    }, {
      "heading" : "3 Theoretical Results",
      "text" : "Soft penalty. We focus on (l, r)-regular worker-task assignment graphs in which every worker is assigned l tasks and every object is labeled by r workers. The performance of our reputation algorithms depend on the reliabilities of the workers as well as the true labels of the tasks. Hence, we consider the following probabilistic model: for a given (l, r)-regular worker-task assignment graph G, the reliabilities of the workers and the true labels of tasks are sampled independently (from distributions described in Section 2). We then analyze the performance of our algorithms as the task degree r (and hence number of workers |W |) goes to infinity. Specifically, we establish the following results (the proofs of all theorems are in the supplementary material).\nTheorem 1. Suppose there are no adversarial workers, i.e A = ; and that the worker-task assignment graph G is (l, r)-regular. Then, with high probability as r ! 1, for any pair of workers wi and wi0 , µi < µi0 =) pen(wi) > pen(wi0), i.e. higher reliability workers are assigned lower penalties by Algorithm 1.\nThe probability in the above theorem is according to the model described above. Note that the theorem justifies our definition of the reputation scores by establishing their consistency with worker reliabilities in the absence of adversarial workers. Next, consider the setting in which adversarial workers adopt the following uniform strategy: label 1 on all assigned tasks (the 1 case is symmetric). Theorem 2. Suppose that the worker-task assignment graph G is (l, r)-regular. Let the probability of an arbitrary worker being honest be q and suppose each adversary adopts the uniform strategy in which she labels 1 on all the tasks assigned to her. Denote an arbitrary honest worker as hi and any adversary as a. Then, with high probability as r ! 1, we have\n1. If = 12 and µi = 1, then pen(hi) < pen(a) if and only if q > 1 1+µ\n2. If = 12 and q > 1 1+µ , then pen(hi) < pen(a) if and only if\nµi (2 q)(1 q q2µ2) q2µ2\n(2 q)q + q2µ2\nThe above theorem establishes that when adversaries adopt the uniform strategy, the soft-penalty algorithm assigns lower penalties to honest workers whose reliability excess a threshold, as long as the fraction of honest workers is “large enough”. Although not stated, the result above immediately extends (with a modified lower bound for µi) to the case when > 1/2, which corresponds to adversaries adopting smart strategies by labeling based on the prevalence of positive tasks.\nSophisticated adversaries. Numerous real-world incidents show evidence of malicious worker behavior in online systems [18, 22, 12]. Moreover, attacks on the training process of ML models have also been studied [15, 1]. Recent work [21] has also shown the impact of powerful adversarial attacks by administrators of crowdturfing (malicious crowdsourcing) sites. Motivated by these examples, we consider sophisticated adversaries: Definition 1. Sophisticated adversaries are computationally unbounded and colluding. Further, they have knowledge of the labels provided by the honest workers and their goal is to maximize the number of tasks whose true label is incorrectly identified.\nWe now raise the following question: In the presence of sophisticated adversaries, does there exist a fundamental limit on the number of tasks whose true label can be correctly identified, irrespective of the aggregation algorithm employed to aggregate the worker labels?\nIn order to answer the above question precisely, we introduce some notation. Let n = |W | and m = |T |. Then, we represent any label aggregation algorithm as a decision rule R : L ! {1, 1}m, which maps the observed labeling matrix L to a set of output labels for each task. Because of the absence of any auxiliary information about the workers or the tasks, the class of decision rules, say C, is invariant to permutations of the identities of workers and/or tasks. More precisely, C denotes the class of decision rules that satisfy R(PLQ) = R(L)Q, for any n⇥ n permutation matrix P and m⇥m permutation matrix Q. We say that a task is affected if the decision rule outputs the incorrect label for the task. We define the quality of a decision rule R(·) as the worst-case number of affected tasks over all possible true labelings and adversary strategies with a fixed honest worker labeling pattern. Fixing the honest worker labeling pattern allows isolation of the effect of the adversary strategy on the accuracy of the decision rule. Considering the worst-case over all possible true labels makes the metric robust to ground-truth assignments, which are typically application specific.\nNext to formally define the quality, let BH denote the honest worker-task assignment graph and y = (y1, y2, . . . , ym) denote the vector of true labels for the tasks. Note that since the number of affected tasks also depends on the actual honest worker labels, we further assume that all honest workers have reliability µi = 1, i.e they always label correctly. This assumption allows us to attribute any mis-identification of true labels to the presence of adversaries because, otherwise, in the absence of any adversaries, the true labels of all the tasks can be trivially identified. Finally, let Sk denote the strategy space of k adversaries, where each strategy 2 Sk specifies the k ⇥m label matrix provided by the adversaries. Since we do not restrict the adversary strategy in any way, it follows that Sk = { 1, 0, 1}k⇥m. The quality of a decision rule is then defined as\nA↵(R,BH , k) = max 2Sk,y2{1, 1}m\nn tj 2 T : Ry, tj 6= yj) o ,\nwhere Ry, t 2 {1, 1} is the label output by the decision rule R for task t when the true label vector is y and the adversary strategy is . Note that our notation A↵(R,BH , k) makes the dependence of the quality measure on the honest worker-task assignment graph BH and the number of adversaries k explicit. We answer the question raised above in the affirmative, i.e. there does exist a fundamental limit on identification. In the theorem below, PreIm(T 0) is the set of honest workers who label atleast one task in T 0. Theorem 3. Suppose that k = |A| and µh = 1 for all honest workers h 2 H . Then, given any honest worker-task assignment graph BH , there exists an adversary strategy ⇤ 2 Sk that is independent of any decision rule R 2 C such that\nL  max y2{ 1,1}m\nA↵(R, ⇤,y) 8R 2 C, where\nL = 1\n2\nmax T 0✓T : |PreIm(T 0)|k |T 0| ,\nand A↵(R, ⇤,y) denotes the number of affected tasks under adversary strategy ⇤, decision rule R, and true label vector y (with the assumption that max over an empty set is zero).\nWe describe the main idea of the proof which proceeds in two steps: (i) we provide an explicit construction of an adversary strategy ⇤ that depends on BH and y, and (ii) we show the existence of another true labeling ŷ such that R outputs exactly the same labels in both scenarios. The adversary labeling strategy we construct uses the idea of indistinguishability, which captures the fact that by carefully choosing their labels, the adversaries can render themselves indistinguishable from honest workers. Specifically, in the simple case when there is only one honest worker, the adversary simply labels the opposite of the honest worker on all assigned tasks, so that each task has two labels of opposite parity. It can be argued that since there is no other information, it is impossible for any decision rule R 2 C to distinguish the honest worker from the adversary and hence identify the true label of any task (better than a random guess). We extend this to the general case, where the adversary “targets” atmost k honest workers and derives a strategy based on the subgraph of BH restricted to the targeted workers. The resultant strategy can be shown to result in incorrect labels for atleast L tasks for some true labeling of the tasks.\nHard penalty. We now analyze the performance of the hard penalty-based reputation algorithm in the presence of sophisticated adversarial workers. For the purposes of the theorem, we consider a natural extension of our reputation algorithm to also perform label aggregation (see figure 1). Theorem 4. Suppose that k = |A| and µi = 1 for each honest worker, i.e an honest worker always provides the correct label. Further, let d1 d2 · · · d|H| denote the degrees of the honest workers in the optimal semi-matching on BH . For any true labeling of the tasks and under the penalty-based label aggregation algorithm (with the convention that di = 0 for i > |H|) :\n1. There exists an adversary strategy ⇤ such that the number of tasks affected Pk 1\ni=1 di. 2. No adversary strategy can affect more than U tasks where\n(a) U = Pk\ni=1 di , when atmost one adversary provides correct labels (b) U =\nP2k i=1 di , in the general case\nA few remarks are in order. First, it can be shown [7] that for optimal semi-matchings, the degree sequence is unique and therefore, the bounds in the theorem above are uniquely defined given BH . Also, the assumption that µi = 1 is required for analytical tractability, proving theoretical guarantees in crowd-sourced settings (even without adversaries) for general graph structures is notoriously hard [2]. Note that the result of Theorem 4 provides both a lower and upper bound for the number of tasks that can be affected by k adversaries when using the penalty-based aggregation algorithm. The characterization we obtain is reasonably tight for the case when atmost 1 adversary provides correct labels; in this case the gap between the upper and lower bounds is dk, which can be “small” for k large enough. However, our characterization is loose in the general case when adversaries can label arbitrarily; here the gap is\nP2k i=k di which we attribute to our proof technique and conjecture\nthat the upper bound of Pk\ni=1 di also applies in the more general case."
    }, {
      "heading" : "4 Experiments",
      "text" : "In this section, we evaluate the performance of our reputation algorithms on both synthetic and real datasets. We consider the following popular label aggregation algorithms: (a) simple majority vot-\ning MV (b) the EM algorithm [3] (c) the BP-based KOS algorithm [9] and (d) KOS+, a normalized version of KOS that is amenable for arbitrary graphs (KOS is designed for random regular graphs), and compare their accuracy in inferring the true labels of the tasks, when implemented in conjunction with our reputation algorithms. We implemented iterative versions of Algorithms 1(SOFT) and 2(HARD), where in each iteration we filtered out the worker with the highest penalty and recomputed penalties for the remaining workers.\nSynthetic Dataset. We analyzed the performance of our soft penalty-based reputation algorithm on (l, r)-regular graphs in section 3. In many practical scenarios, however, the worker-task assignment graph forms organically where the workers decide which tasks to label on. To consider this case, we simulated a setup of 100 workers with a power-law distribution for worker degrees to generate the bipartite worker-task assignment graph. We assume that an honest worker always labels correctly (the results are qualitatively similar when honest workers make errors with small probability) and consider three notions of adversaries: (a) random - who label each task 1 or 1 with prob. 1/2 (b) malicious - who always label incorrectly and (c) uniform - who label 1 on all tasks. Also, we consider both cases - one where the adversaries are biased to have high degrees and the other where they have low degrees. Further, we arbitrarily decided to remove 15% of the workers with the highest penalties and we define precision as the percentage of workers filtered who were adversarial. Figure 1 shows the performance improvement of the different benchmarks in the presence of our reputation algorithm.\nWe make a few observations. First, we are successful in identifying random adversaries as well as low-degree malicious and uniform adversaries (precision > 80%). This shows that our reputation algorithms also perform well when worker-task assignment graphs are non-regular, complementing the theoretical results (Theorems 1 and 2) for regular graphs. Second, our filtering algorithm can result in significant reduction (upto 26%) in the fraction of incorrect tasks. In fact, in 5 out of 6 cases, the best performing algorithm incorporates our reputation algorithm. Note that since 15 workers are filtered out, labels from fewer workers are used to infer the true labels of the tasks. Despite using fewer labels, we improve performance because the high precision of our algorithms results in mostly adversaries being filtered out. Third, we note that when the adversaries are malicious and have high degrees, the removal of 15 workers degrades the performance of the KOS (and KOS+) and EM algorithms. We attribute this to the fact that while KOS and EM are able to automatically invert the malicious labels, we discard these labels which hurts performance, since the adversaries have high degrees. Finally, note that the SOFT (HARD) penalty algorithm tends to perform better when adversaries are biased towards low (high) degrees, and this insight can be used to aid the choice of the reputation algorithm to be employed in different scenarios.\nReal Datasets. Next, we evaluated our algorithm on some standard datasets: (a) TREC2: a collection of topic-document pairs labeled as relevant or non-relevant by workers on AMT. We consider two versions: stage2 and task2. (b) NLP [17]: consists of annotations by AMT workers for different NLP tasks (1) rte - which provides binary judgments for textual entailment, i.e. whether one\n2 http://sites.google.com/site/treccrowd/home\nsentence can be inferred from another (2) temp - which provides binary judgments for temporal ordering of events. (c) bluebird [23] contains judgments differentiating two kinds of birds in an image. Table 1 reports the best accuracy achieved when upto 10 workers are filtered using our iterative reputation algorithms.\nThe main conclusion we draw is that our reputation algorithms are able to boost the performance of state-of-the-art aggregation algorithms by a significant amount across the datasets: the average improvement for MV and KOS+ is 2.5%, EM is 3% and for KOS is almost 18%, when using the hard penalty-based reputation algorithm. Second, we can elevate the performance of simpler algorithms such as KOS and MV to the levels of the more general (and in some cases, complicated) EM algorithm. The KOS algorithm for instance, is not only easier to implement, but also has tight theoretical guarantees when the underlying assignment graph is sparse random regular and further is robust to different initializations [9]. The modified version KOS+ can be used in graphs where worker degrees are skewed, but we are still able to enhance its accuracy. Our results provide evidence for the fact that existing random models are inadequate in capturing the behavior of workers in real-world datasets, necessitating the need for a more general approach. Third, note that the hard penalty-based algorithm outperforms the soft version across the datasets. Since the hard penalty algorithm works well when adversaries have higher degrees (a fact noticed in the simulation results above), this suggests the presence of high-degree adversarial workers in theses datasets. Finally, our algorithm was successful in identifying the following types of “adversaries”: (1) uniform workers who always label 1 or 1 (in temp, task2, stage2), (2) malicious workers who mostly label incorrectly (in bluebird, stage2) and (3) random workers who label each task independent of its true label (such workers were identified as “spammers” in [13]). Therefore, our algorithm is able to identify a broad set of adversary strategies in addition to those detected by existing techniques."
    }, {
      "heading" : "5 Conclusions",
      "text" : "This paper analyzes the problem of inferring true labels of tasks in crowdsourcing systems against a broad class of adversarial labeling strategies. The main contribution is the design of a reputationbased worker filtering algorithm that uses a combination of disagreement-based penalties and optimal semi-matchings to identify adversarial workers. We show that our reputation scores are consistent with the existing notion of worker reliabilities and further can identify adversaries that employ deterministic labeling strategies. Empirically, we show that our algorithm can be applied in real crowd-sourced datasets to enhance the accuracy of existing label aggregation algorithms. Further, we analyze the scenario of worst-case adversaries and establish lower bounds on the minimum “damage” achievable by the adversaries."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank the anonymous reviewers for their valuable feedback. Ashwin Venkataraman was supported by the Center for Technology and Economic Development (CTED)."
    } ],
    "references" : [ {
      "title" : "Poisoning attacks against support vector machines",
      "author" : [ "B. Biggio", "B. Nelson", "P. Laskov" ],
      "venue" : "arXiv preprint arXiv:1206.6389,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2012
    }, {
      "title" : "Aggregating crowdsourced binary ratings",
      "author" : [ "N. Dalvi", "A. Dasgupta", "R. Kumar", "V. Rastogi" ],
      "venue" : "In Proceedings of the 22nd international conference on World Wide Web,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2013
    }, {
      "title" : "Maximum likelihood estimation of observer error-rates using the em algorithm",
      "author" : [ "A.P. Dawid", "A.M. Skene" ],
      "venue" : "Applied Statistics,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1979
    }, {
      "title" : "Zencrowd: leveraging probabilistic reasoning and crowdsourcing techniques for large-scale entity linking",
      "author" : [ "G. Demartini", "D.E. Difallah", "P. Cudré-Mauroux" ],
      "venue" : "In Proceedings of the 21st international conference on World Wide Web,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2012
    }, {
      "title" : "Are your participants gaming the system?: screening mechanical turk workers",
      "author" : [ "J.S. Downs", "M.B. Holbrook", "S. Sheng", "L.F. Cranor" ],
      "venue" : "In Proceedings of the 28th international conference on Human factors in computing systems,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2010
    }, {
      "title" : "Who moderates the moderators?: crowdsourcing abuse detection in user-generated content",
      "author" : [ "A. Ghosh", "S. Kale", "P. McAfee" ],
      "venue" : "In Proceedings of the 12th ACM conference on Electronic commerce,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2011
    }, {
      "title" : "Semi-matchings for bipartite graphs and load balancing",
      "author" : [ "N.J. Harvey", "R.E. Ladner", "L. Lovász", "T. Tamir" ],
      "venue" : "In Algorithms and data structures,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2003
    }, {
      "title" : "Quality management on amazon mechanical turk",
      "author" : [ "P.G. Ipeirotis", "F. Provost", "J. Wang" ],
      "venue" : "In Proceedings of the ACM SIGKDD workshop on human computation,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2010
    }, {
      "title" : "Iterative learning for reliable crowdsourcing systems",
      "author" : [ "D.R. Karger", "S. Oh", "D. Shah" ],
      "venue" : "Neural Information Processing Systems,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2011
    }, {
      "title" : "Crowdsourcing user studies with mechanical turk",
      "author" : [ "A. Kittur", "E.H. Chi", "B. Suh" ],
      "venue" : "In Proceedings of the SIGCHI conference on human factors in computing systems,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2008
    }, {
      "title" : "Crowdturfers, campaigns, and social media: tracking and revealing crowdsourced manipulation of social media",
      "author" : [ "K. Lee", "P. Tamilarasan", "J. Caverlee" ],
      "venue" : "In 7th international AAAI conference on weblogs and social media (ICWSM),",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2013
    }, {
      "title" : "Eliminating spammers and ranking annotators for crowdsourced labeling tasks",
      "author" : [ "V.C. Raykar", "S. Yu" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2012
    }, {
      "title" : "Learning from crowds",
      "author" : [ "V.C. Raykar", "S. Yu", "L.H. Zhao", "G.H. Valadez", "C. Florin", "L. Bogoni", "L. Moy" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2010
    }, {
      "title" : "Antidote: understanding and defending against poisoning of anomaly detectors",
      "author" : [ "B.I. Rubinstein", "B. Nelson", "L. Huang", "A.D. Joseph", "S.-h. Lau", "S. Rao", "N. Taft", "J. Tygar" ],
      "venue" : "In Proceedings of the 9th ACM SIGCOMM conference on Internet measurement conference,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2009
    }, {
      "title" : "Inferring ground truth from subjective labelling of venus images. Advances in neural information processing",
      "author" : [ "P. Smyth", "U. Fayyad", "M. Burl", "P. Perona", "P. Baldi" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1995
    }, {
      "title" : "Cheap and fast—but is it good?: evaluating non-expert annotations for natural language tasks. In Proceedings of the conference on empirical methods in natural language processing, pages 254–263",
      "author" : [ "R. Snow", "B. O’Connor", "D. Jurafsky", "A.Y. Ng" ],
      "venue" : "Association for Computational Linguistics,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2008
    }, {
      "title" : "Sybil-resilient online content voting",
      "author" : [ "N. Tran", "B. Min", "J. Li", "L. Subramanian" ],
      "venue" : "In Proceedings of the 6th USENIX symposium on Networked systems design and implementation,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2009
    }, {
      "title" : "How much spam can you take? an analysis of crowdsourcing results to increase accuracy",
      "author" : [ "J. Vuurens", "A.P. de Vries", "C. Eickhoff" ],
      "venue" : "In Proc. ACM SIGIR Workshop on Crowdsourcing for Information Retrieval",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2011
    }, {
      "title" : "Obtaining high-quality relevance judgments using crowdsourcing",
      "author" : [ "J.B. Vuurens", "A.P. de Vries" ],
      "venue" : "Internet Computing, IEEE,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2012
    }, {
      "title" : "Man vs. machine: Practical adversarial detection of malicious crowdsourcing workers",
      "author" : [ "G. Wang", "T. Wang", "H. Zheng", "B.Y. Zhao" ],
      "venue" : "In 23rd USENIX Security Symposium,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2014
    }, {
      "title" : "Serf and turf: crowdturfing for fun and profit",
      "author" : [ "G. Wang", "C. Wilson", "X. Zhao", "Y. Zhu", "M. Mohanlal", "H. Zheng", "B.Y. Zhao" ],
      "venue" : "In Proceedings of the 21st international conference on World Wide Web,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2012
    }, {
      "title" : "The multidimensional wisdom of crowds",
      "author" : [ "P. Welinder", "S. Branson", "S. Belongie", "P. Perona" ],
      "venue" : "Advances in Neural Information Processing Systems,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2010
    }, {
      "title" : "Whose vote should count more: Optimal integration of labels from labelers of unknown expertise",
      "author" : [ "J. Whitehill", "P. Ruvolo", "T. Wu", "J. Bergsma", "J. Movellan" ],
      "venue" : "Advances in Neural Information Processing Systems,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "However, these applications remain vulnerable to noisy labels introduced either unintentionally by unreliable workers or intentionally by spammers and malicious workers [10, 11].",
      "startOffset" : 169,
      "endOffset" : 177
    }, {
      "referenceID" : 2,
      "context" : "The machine-learning approaches are typically based on variants of the EM algorithm [3, 16, 24, 14].",
      "startOffset" : 84,
      "endOffset" : 99
    }, {
      "referenceID" : 14,
      "context" : "The machine-learning approaches are typically based on variants of the EM algorithm [3, 16, 24, 14].",
      "startOffset" : 84,
      "endOffset" : 99
    }, {
      "referenceID" : 22,
      "context" : "The machine-learning approaches are typically based on variants of the EM algorithm [3, 16, 24, 14].",
      "startOffset" : 84,
      "endOffset" : 99
    }, {
      "referenceID" : 12,
      "context" : "The machine-learning approaches are typically based on variants of the EM algorithm [3, 16, 24, 14].",
      "startOffset" : 84,
      "endOffset" : 99
    }, {
      "referenceID" : 8,
      "context" : "More recently, linear-algebra based algorithms [9, 6, 2] have been proposed, which provide guarantees on the error in estimating the true labels of the tasks (under appropriate assumptions), and have also been shown to perform well on various real-world datasets.",
      "startOffset" : 47,
      "endOffset" : 56
    }, {
      "referenceID" : 5,
      "context" : "More recently, linear-algebra based algorithms [9, 6, 2] have been proposed, which provide guarantees on the error in estimating the true labels of the tasks (under appropriate assumptions), and have also been shown to perform well on various real-world datasets.",
      "startOffset" : 47,
      "endOffset" : 56
    }, {
      "referenceID" : 1,
      "context" : "More recently, linear-algebra based algorithms [9, 6, 2] have been proposed, which provide guarantees on the error in estimating the true labels of the tasks (under appropriate assumptions), and have also been shown to perform well on various real-world datasets.",
      "startOffset" : 47,
      "endOffset" : 56
    }, {
      "referenceID" : 17,
      "context" : "While existing work focuses on workers making random errors, recent work and anecdotal evidence have shown that worker labeling strategies that are common in practice do not fit the standard random model [19].",
      "startOffset" : 204,
      "endOffset" : 208
    }, {
      "referenceID" : 16,
      "context" : "on Digg [18], malicious behavior in social media [22, 12] and low-precision worker populations in crowdsourcing experiments [4].",
      "startOffset" : 8,
      "endOffset" : 12
    }, {
      "referenceID" : 20,
      "context" : "on Digg [18], malicious behavior in social media [22, 12] and low-precision worker populations in crowdsourcing experiments [4].",
      "startOffset" : 49,
      "endOffset" : 57
    }, {
      "referenceID" : 10,
      "context" : "on Digg [18], malicious behavior in social media [22, 12] and low-precision worker populations in crowdsourcing experiments [4].",
      "startOffset" : 49,
      "endOffset" : 57
    }, {
      "referenceID" : 3,
      "context" : "on Digg [18], malicious behavior in social media [22, 12] and low-precision worker populations in crowdsourcing experiments [4].",
      "startOffset" : 124,
      "endOffset" : 127
    }, {
      "referenceID" : 6,
      "context" : "The penalties are then aggregated in a “load-balanced” manner using the concept of optimal semi-matchings [7].",
      "startOffset" : 106,
      "endOffset" : 109
    }, {
      "referenceID" : 1,
      "context" : "The analysis becomes significantly complicated for more general graphs (a fact observed in prior works; see [2]); hence, we demonstrate improvements using simulations and experiments on real world datasets.",
      "startOffset" : 108,
      "endOffset" : 111
    }, {
      "referenceID" : 15,
      "context" : "tasks whose true label is already known [17, 5, 11] to correct for worker bias.",
      "startOffset" : 40,
      "endOffset" : 51
    }, {
      "referenceID" : 4,
      "context" : "tasks whose true label is already known [17, 5, 11] to correct for worker bias.",
      "startOffset" : 40,
      "endOffset" : 51
    }, {
      "referenceID" : 7,
      "context" : "[8] proposed a way of quantifying worker quality by transforming the observed labels into soft posterior labels based on the estimated confusion matrix [3].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[8] proposed a way of quantifying worker quality by transforming the observed labels into soft posterior labels based on the estimated confusion matrix [3].",
      "startOffset" : 152,
      "endOffset" : 155
    }, {
      "referenceID" : 11,
      "context" : "The authors in [13] propose an empirical Bayesian algorithm to eliminate workers who label randomly without looking at the particular task (called spammers), and estimate the consensus labels from the remaining workers.",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 18,
      "context" : "The authors in [20] focus on detecting specific kinds of spammers and then replace their labels with new workers.",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 6,
      "context" : "We use the concept of optimal semi-matchings [7] on bipartite graphs to distribute penalties in a load balanced manner, which we briefly discuss here.",
      "startOffset" : 45,
      "endOffset" : 48
    }, {
      "referenceID" : 6,
      "context" : "This notion of cost is motivated by the load balancing problem for scheduling tasks on machines (refer to [7] for further details).",
      "startOffset" : 106,
      "endOffset" : 109
    }, {
      "referenceID" : 16,
      "context" : "Numerous real-world incidents show evidence of malicious worker behavior in online systems [18, 22, 12].",
      "startOffset" : 91,
      "endOffset" : 103
    }, {
      "referenceID" : 20,
      "context" : "Numerous real-world incidents show evidence of malicious worker behavior in online systems [18, 22, 12].",
      "startOffset" : 91,
      "endOffset" : 103
    }, {
      "referenceID" : 10,
      "context" : "Numerous real-world incidents show evidence of malicious worker behavior in online systems [18, 22, 12].",
      "startOffset" : 91,
      "endOffset" : 103
    }, {
      "referenceID" : 13,
      "context" : "Moreover, attacks on the training process of ML models have also been studied [15, 1].",
      "startOffset" : 78,
      "endOffset" : 85
    }, {
      "referenceID" : 0,
      "context" : "Moreover, attacks on the training process of ML models have also been studied [15, 1].",
      "startOffset" : 78,
      "endOffset" : 85
    }, {
      "referenceID" : 19,
      "context" : "Recent work [21] has also shown the impact of powerful adversarial attacks by administrators of crowdturfing (malicious crowdsourcing) sites.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 6,
      "context" : "First, it can be shown [7] that for optimal semi-matchings, the degree sequence is unique and therefore, the bounds in the theorem above are uniquely defined given BH .",
      "startOffset" : 23,
      "endOffset" : 26
    }, {
      "referenceID" : 1,
      "context" : "Also, the assumption that μi = 1 is required for analytical tractability, proving theoretical guarantees in crowd-sourced settings (even without adversaries) for general graph structures is notoriously hard [2].",
      "startOffset" : 207,
      "endOffset" : 210
    }, {
      "referenceID" : 2,
      "context" : "ing MV (b) the EM algorithm [3] (c) the BP-based KOS algorithm [9] and (d) KOS+, a normalized version of KOS that is amenable for arbitrary graphs (KOS is designed for random regular graphs), and compare their accuracy in inferring the true labels of the tasks, when implemented in conjunction with our reputation algorithms.",
      "startOffset" : 28,
      "endOffset" : 31
    }, {
      "referenceID" : 8,
      "context" : "ing MV (b) the EM algorithm [3] (c) the BP-based KOS algorithm [9] and (d) KOS+, a normalized version of KOS that is amenable for arbitrary graphs (KOS is designed for random regular graphs), and compare their accuracy in inferring the true labels of the tasks, when implemented in conjunction with our reputation algorithms.",
      "startOffset" : 63,
      "endOffset" : 66
    }, {
      "referenceID" : 15,
      "context" : "(b) NLP [17]: consists of annotations by AMT workers for different NLP tasks (1) rte - which provides binary judgments for textual entailment, i.",
      "startOffset" : 8,
      "endOffset" : 12
    }, {
      "referenceID" : 21,
      "context" : "(c) bluebird [23] contains judgments differentiating two kinds of birds in an image.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 8,
      "context" : "The KOS algorithm for instance, is not only easier to implement, but also has tight theoretical guarantees when the underlying assignment graph is sparse random regular and further is robust to different initializations [9].",
      "startOffset" : 220,
      "endOffset" : 223
    }, {
      "referenceID" : 11,
      "context" : "Finally, our algorithm was successful in identifying the following types of “adversaries”: (1) uniform workers who always label 1 or 1 (in temp, task2, stage2), (2) malicious workers who mostly label incorrectly (in bluebird, stage2) and (3) random workers who label each task independent of its true label (such workers were identified as “spammers” in [13]).",
      "startOffset" : 354,
      "endOffset" : 358
    } ],
    "year" : 2014,
    "abstractText" : "In this paper, we study the problem of aggregating noisy labels from crowd workers to infer the underlying true labels of binary tasks. Unlike most prior work which has examined this problem under the random worker paradigm, we consider a much broader class of adversarial workers with no specific assumptions on their labeling strategy. Our key contribution is the design of a computationally efficient reputation algorithm to identify and filter out these adversarial workers in crowdsourcing systems. Our algorithm uses the concept of optimal semi-matchings in conjunction with worker penalties based on label disagreements, to assign a reputation score for every worker. We provide strong theoretical guarantees for deterministic adversarial strategies as well as the extreme case of sophisticated adversaries where we analyze the worst-case behavior of our algorithm. Finally, we show that our reputation algorithm can significantly improve the accuracy of existing label aggregation algorithms in real-world crowdsourcing datasets.",
    "creator" : null
  }
}