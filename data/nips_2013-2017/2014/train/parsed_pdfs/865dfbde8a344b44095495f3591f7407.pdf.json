{
  "name" : "865dfbde8a344b44095495f3591f7407.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Stochastic Variational Inference for Hidden Markov Models",
    "authors" : [ "Nicholas J. Foti", "Jason Xu" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Modern data analysis has seen an explosion in the size of the datasets available to analyze. Significant progress has been made scaling machine learning algorithms to these massive datasets based on optimization procedures [1, 2, 3]. For example, stochastic gradient descent employs noisy estimates of the gradient based on minibatches of data, avoiding a costly gradient computation using the full dataset [4]. There is considerable interest in leveraging these methods for Bayesian inference since traditional algorithms such as Markov chain Monte Carlo (MCMC) scale poorly to large datasets, though subset-based MCMC methods have been recently proposed as well [5, 6, 7, 8].\nVariational Bayes (VB) casts posterior inference as a tractable optimization problem by minimizing the Kullback-Leibler divergence between the target posterior and a family of simpler variational distributions. Thus, VB provides a natural framework to incorporate ideas from stochastic optimization to perform scalable Bayesian inference. Indeed, a scalable modification to VB harnessing stochastic gradients—stochastic variational inference (SVI)—has recently been applied to a variety of Bayesian latent variable models [9, 10]. Minibatch-based VB methods have also proven effective in a streaming setting where data arrives sequentially [11].\nHowever, these algorithms have been developed assuming independent or exchangeable data. One exception is the SVI algorithm for the mixed-membership stochastic block model [12], but independence at the level of the generative model must be exploited. SVI for Bayesian time series including HMMs was recently considered in settings where each minibatch is a set of independent series [13], though in this setting again dependencies do not need to be broken.\nIn contrast, we are interested in applying SVI to very long time series. As a motivating example, consider the application in Sec. 4 of a genomics dataset consisting of T = 250 million observations in 12 dimensions modeled via an HMM to learn human chromatin structure. An analysis of the entire sequence is computationally prohibitive using standard Bayesian inference techniques for\n† Co-first authors contributed equally to this work.\nHMMs due to a per-iteration complexity linear in T . Unfortunately, despite the simple chain-based dependence structure, applying a minibatch-based method is not obvious. In particular, there are two potential issues immediately arising in sampling subchains as minibatches: (1) the subsequences are not mutually independent, and (2) updating the latent variables in the subchain ignores the data outside of the subchain introducing error. We show that for (1), appropriately scaling the noisy subchain gradients preserves unbiased gradient estimates. To address (2), we propose an approximate message-passing scheme that adaptively bounds error by accounting for memory decay of the chain.\nWe prove that our proposed SVIHMM algorithm converges to a local mode of the batch objective, and empirically demonstrate similar performance to batch VB in significantly less time on synthetic datasets. We then consider our genomics application and show that SVIHMM allows efficient Bayesian inference on this massive dataset where batch inference is computationally infeasible."
    }, {
      "heading" : "2 Background",
      "text" : ""
    }, {
      "heading" : "2.1 Hidden Markov models",
      "text" : "Hidden Markov models (HMMs) [14] are a class of discrete-time doubly stochastic processes consisting of observations yt and latent states xt ∈ {1, . . . ,K} generated by a discrete-valued Markov chain. Specifically, for y = (y1, . . . , yT ) and x = (x1, . . . , xT ), the joint distribution factorizes as\np(x,y) = π0(x1)p(y1|x1) T∏ t=2 p(xt|xt−1, A)p(yt|xt, φ) (1)\nwhere A = [Aij ] K i,j=1 is the transition matrix with Aij = Pr(xt = j|xt−1 = i), φ = {φk} K k=1 the emission parameters, and π0 the initial distribution. We denote the set of HMM parameters as θ = (π0, A, φ). We assume that the underlying chain is irreducible and aperiodic so that a stationary distribution π exists and is unique. Furthermore, we assume that we observe the sequence at stationarity so that π0 = π, where π is given by the leading left-eigenvector of A. As such, we do not seek to learn π0 in the setting of observing a single realization of a long chain.\nWe specify conjugate Dirichlet priors on the rows of the transition matrix as\np(A) = K∏ j=1 Dir(Ai: | αAj ). (2)\nHere, Dir(π | α) denotes a K-dimensional Dirichlet distribution with concentration parameters α. Although our methods are more broadly applicable, we focus on HMMs with multivariate Gaussian emissions where φk = {µk,Σk}, with conjugate normal-inverse-Wishart (NIW) prior\nyt | xt ∼ N(yt | µxt ,Σxt), φk = (µk,Σk) ∼ NIW(µ0, κ0,Σ0, ν0). (3)\nFor simplicity, we suppress dependence on θ and write π(x0), p(xt|xt−1), and p(yt|xt) throughout."
    }, {
      "heading" : "2.2 Structured mean-field VB for HMMs",
      "text" : "We are interested in the posterior distribution of the state sequence and parameters given an observation sequence, denoted p(x, θ|y). While evaluating marginal likelihoods, p(y|θ), and most probable state sequences, arg maxx p(x|y, θ), are tractable via the forward-backward (FB) algorithm when parameter values θ are fixed [14], exact computation of the posterior is intractable for HMMs. Markov chain Monte Carlo (MCMC) provides a widely used sampling-based approach to posterior inference in HMMs [15, 16]. We instead focus on variational Bayes (VB), an optimization-based approach that approximates p(x, θ|y) by a variational distribution q(θ,x) within a simpler family. Typically, for HMMs a structured mean field approximation is considered:\nq(θ,x) = q(A)q(φ)q(x), (4)\nbreaking dependencies only between the parameters θ = {A, φ} and latent state sequence x [17]. Note that making a full mean field assumption in which q(x) = ∏T i=1 q(xi) loses crucial information about the latent chain needed for accurate inference.\nEach factor in Eq. (4) is endowed with its own variational parameter and is set to be in the same exponential family distribution as its respective complete conditional. The variational parameters are optimized to maximize the evidence lower bound (ELBO) L:\nln p(y) ≥ Eq [ln p(θ)]− Eq [ln q(θ)] + Eq [ln p(y,x|θ)]− Eq [ln q(x)] := L(q(θ), q(x)). (5)\nMaximizing L is equivalent to minimizing the KL divergence KL(q(x, θ)||p(x, θ|y)) [18]. In practice, we alternate updating the global parameters θ—those coupled to the entire set of observations—and the local variables {xt}—a variable corresponding to each observation, yt. Details on computing the terms in the equations and algorithms that follow are in the Supplement.\nThe global update is derived by differentiating L with respect to the global variational parameters [17]. Assuming a conjugate exponential family leads to a simple coordinate ascent update [9]:\nw = u + Eq(x) [t(x,y)] . (6)\nHere, t(x,y) denotes the vector of sufficient statistics, and w = (wA,wφ) and u = (uA,uφ) the variational parameters and model hyperparameters, respectively, in natural parameter form.\nThe local update is derived analogously, yielding the optimal variational distribution over the latent sequence:\nq∗(x) ∝ exp ( Eq(A) [lnπ(x1)] +\nT∑ t=2 Eq(A) [ lnAxt−1,xt ] + T∑ t=1 Eq(φ) [ln p(yt|xt)]\n) . (7)\nCompare with Eq. (1). Here, we have replaced probabilities by exponentiated expected log probabilities under the current variational distribution. To determine the optimal q∗(x) in Eq. (7), define:\nÃj,k := exp [ Eq(A) ln(Aj,k) ] p̃(yt|xt = k) := exp [ Eq(φ) ln p(yt|xt = k) ] . (8)\nWe estimate π with π̂ being the leading eigenvector of Eq(A)[A]. We then use π̂, Ã = (Ãj,k), and p̃ = {p̃(yt|xt = k), k = 1, . . . ,K, t = 1, . . . , T} to run a forward-backward algorithm, producing forward messages α and backward messages β which allow us to compute q∗(xt = k) and q∗(xt−1 = j, xt = k). [19, 17]. See the Supplement."
    }, {
      "heading" : "2.3 Stochastic variational inference for non-sequential models",
      "text" : "Even in non-sequential models, the batch VB algorithm requires an entire pass through the dataset for each update of the global parameters. This can be costly in large datasets, and wasteful when local-variable passes are based on uninformed initializations of the global parameters or when many data points contain redundant information.\nTo cope with this computational challenge, stochastic variational inference (SVI) [9] leverages a Robbins-Monro algorithm [1] to optimize the ELBO via stochastic gradient ascent. When the data are independent, the ELBO in Eq. (5) can be expressed as\nL = Eq(θ) [ln p(θ)]− Eq(θ) [ln q(θ)] + T∑ i=1 Eq(xi) [ln p(yi, xi|θ)]− Eq(x) [ln q(x)] . (9)\nIf a single observation index s is sampled uniformly s ∼ Unif(1, . . . , T ), the ELBO corresponding to (xs, ys) as if it were replicated T times is given by\nLs = Eq(θ) [ln p(θ)]− Eq(θ) [ln q(θ)] + T · ( Eq(xs) [ln p(ys, xs|θ)]− Eq(xs) [ln q(xs)] ) , (10)\nand it is clear that Es[Ls] = L. At each iteration n of the SVI algorithm, a data point ys is sampled and its local q∗(xs) is computed given the current estimate of global variational parameters wn. Next, the global update is performed via a noisy, unbiased gradient step (Es[∇̂wLs] = ∇wL). When all pairs of distributions in the model are conditionally conjugate, it is cheaper to compute the stochastic natural gradient, ∇̃wLs, which additionally accounts for the information geometry of the distribution [9]. The resulting stochastic natural gradient step with step-size ρn is:\nwn+1 = wn + ρn∇̃wLs(wn). (11)\nWe show the form of ∇̃wLs in Sec. 3.2, specifically in Eq. (13) with details in the Supplement."
    }, {
      "heading" : "3 Stochastic variational inference for HMMs",
      "text" : "The batch VB algorithm of Sec. 2.2 becomes prohibitively expensive as the length of the chain T becomes large. In particular, the forward-backward algorithm in the local step takes O(K2T ) time. Instead, we turn to a subsampling approach, but naively applying SVI from Sec. 2.3 fails in the HMM setting: decomposing the sum over local variables into a sum of independent terms as in Eq. (9) ignores crucial transition counts, equivalent to making a full mean-field approximation.\nExtending SVI to HMMs requires additional considerations due to the dependencies between the observations. It is clear that subchains of consecutive observations rather than individual observations are necessary to capture the transition structure (see Sec. 3.1). We show that if the local variables of each subchain can be exactly optimized, then stochastic gradients computed on subchains can be scaled to preserve unbiased estimates of the full gradient (see Sec. 3.2).\nUnfortunately, as we show in Sec. 3.3, the local step becomes approximate due to edge effects: local variables are incognizant of nodes outside of the subchain during the forward-backward pass. Although an exact scheme requires message passing along the entire chain, we harness the memory decay of the latent Markov chain to guarantee that local state beliefs in each subchain form an - approximation q (x) to the full-data beliefs q∗(x). We achieve these approximations by adaptively buffering the subchains with extra observations based on current global parameter estimates. We then prove that for sufficiently small, the noisy gradient computed using q (x) corresponds to an ascent direction in L, guaranteeing convergence of our algorithm to a local optimum. We refer to our algorithm, which is outlined in Alg. 1, as SVIHMM.\nAlgorithm 1 Stochastic Variational Inference for HMMs (SVIHMM) 1: Initialize variational parameters (wA0 ,w φ 0 ) and choose stepsize schedule ρn, n = 1, 2, . . .\n2: while (convergence criterion is not met) do 3: Sample a subchain yS ⊂ {y1, . . . , yT } with S ∼ p(S) 4: Local step: Compute π̂, Ã, p̃S and run q(xS) = ForwardBackward(yS , π̂, Ã, p̃S). 5: Global update: wn+1 = wn(1− ρn) + ρn(u + cTEq(xS)[t(xS ,yS)]) 6: end while"
    }, {
      "heading" : "3.1 ELBO for subsets of data",
      "text" : "Unlike the independent data case (Eq. (9)), the local term in the HMM setting decomposes as\nln p(y,x|θ) = lnπ(x1) + T∑ t=2 lnAxt−1,xt + T∑ i=1 ln p(yt|xt). (12)\nBecause of the paired terms in the first sum, it is necessary to consider consecutive observations to learn transition structure. For the SVIHMM algorithm, we define our basic sampling unit as subchains yS = (yS1 , . . . , y S L), where S refers to the associated indices. We denote the ELBO restricted to yS as LS , and associated natural gradient as ∇̃wLS ."
    }, {
      "heading" : "3.2 Global update",
      "text" : "We detail the global update assuming we have optimized q∗(x) exactly (i.e., as in the batch setting), although this assumption will be relaxed as discussed in Sec 3.3. Paralleling Sec. 2.3, the global SVIHMM step involves updating the global variational parameters w via stochastic (natural) gradient ascent based on q∗(xS), the beliefs corresponding to our current subchain S.\nRecall from Eq. (10) that the original SVI algorithm maintains Es[∇̃wLs] = ∇̃wL by scaling the gradient based on an individual observation s by the total number of observations T . In the HMM case, we analogously derive a batch factor vector c = (cA, cφ) such that\nES [∇̃wLS ] = ∇̃wL with ∇̃wLS = u + cTEq∗(xS) [ t(xS ,yS) ] −w. (13)\nThe specific form of Eq. (13) for Gaussian emissions is in the Supplement. Now, the Robbins-Monro average in Eq. (11) can be written as\nwn+1 = wn(1− ρn) + ρn(u + cTEq∗(xS)[t(xS ,yS)]). (14)\nWhen the noisy natural gradients ∇̃wLS are independent and unbiased estimates of the true natural gradient, the iterates in Eq. (14) converge to a local maximum of L under mild regularity conditions as long as step-sizes ρn satisfy ∑ n ρ 2 n <∞, and ∑ n ρn =∞ [2, 9]. In our case, the noisy gradients are necessarily correlated even for independently sampled subchains due to dependence between observations (y1, . . . , yT ). However, as detailed in [20], unbiasedness suffices for convergence of Eq. (14) to a local mode.\nBatch factor Recalling our assumption of being at stationarity, Eq(π) lnπ(x1) = Eq(π) lnπ(xi) for all i. If we sample subchains from the uniform distribution over subchains of length L, denoted p(S), then we can write\nES [ Eq ln p(y S ,xS |θ) ] ≈ p(S)Eq [ T−L+1∑ t=1 lnπ(xt) + (L− 1) T∑ t=2 lnAxt−1,xt + L T∑ t=1 p(yt|xt) ] , (15) where the expectation is with respect to (π,A, φ); this is detailed in the Supplement. The approximate equality in Eq. (15) arises because while most transitions appear in L − 1 subchains, those near the endpoints of the full chain do not, e.g., x1 and xT appear in only one subchain. This error becomes negligible as the length of the HMM increases. Since p(S) is uniform over all lengthL subchains, by linearity of expectation the batch factor c = (cA, cφ) is given by cA = (T−L+1)/(L−1), cφ = (T − L+ 1)/L. Other choices of p(S) can be used by considering the appropriate version of Eq. (15) analogously to [12], generally with a batch factor cS varying with each subset yS ."
    }, {
      "heading" : "3.3 Local update",
      "text" : "The optimal SVIHMM local variational distribution arises just as in the batch case of Eq. (7), but with time indices restricted to the length L subchain yS :\nq∗(xS) ∝ exp ( Eq(A) [ lnπ(xS1 ) ] + L∑ `=2 Eq(A) [ lnAxS`−1,xS` ] + L∑ `=1 Eq(φ) [ ln p(yS` |xS` ) ]) . (16)\nTo compute these local beliefs, we use our current q(A), q(φ)—which have been informed by all previous subchains—to form π̂, Ã, p̃S = {p̃(yS` |xS` = k),∀k, ` = 1, . . . , L}, with these parameters defined as in the batch case. We then use these parameters in a forward-backward algorithm detailed in the Supplement. However, this message passing produces only an approximate optimization due to loss of information incurred at the ends of the subchain. Specifically, for yS = (yt, . . . , yt+L), the forward messages coming from y1, . . . , yt−1 are not available to yt, and similarly the backwards messages from yt+L+1, . . . , yT are not available to yt+L.\nRecall our assumption in the global update step that q∗(xS) corresponds to a subchain of the fulldata optimal beliefs q∗(x). Here, we see that this assumption is assuredly false; instead, we analyze the implications of using approximate local subchain beliefs and aim to ameliorate the edge effects.\nBuffering subchains To cope with the subchain edge effects, we augment the subchain S with enough extra observations on each end so that the local state beliefs, q(xi), i ∈ S, are within an -ball of q∗(xi) — those had we considered the entire chain. The practicality of this approach arises from the approximate finite memory of the process. In particular, consider performing a forwardbackward pass on (xS1−τ , . . . , x S L+τ ) leading to approximate beliefs q̃\nτ (xi). Given > 0, define τ as the smallest buffer length τ such that\nmax i∈S ||q̃τ (xi)− q∗(xi)||1 ≤ . (17)\nThe τ that satisfies Eq. (17) determines the number of observations used to buffer the subchain. After improving subchain beliefs, we discard q̃τ (xi), i ∈ buffer, prior to the global update. As will be seen in Sec. 4, in practice the necessary τ is typically very small relative to the lengthy observation sequences of interest.\nBuffering subchains is related to splash belief propagation (BP) for parallel inference in undirected graphical models, where the belief at any given node is monitored based on locally-aware message passing in order to maintain a good approximation to the true belief [21]. Unlike splash BP, we\nembed the buffering scheme inside an iterative procedure for updating both the local latent structure and the global parameters, which affects the -approximation in future iterations. Likewise, we wish to maintain the approximation on an entire subchain, not just at a single node.\nEven in settings where parameters θ are known, as in splash BP, analytically choosing τ is generally infeasible. As such, we follow the approach of splash BP to select an approximate τ . We then go further by showing that SVIHMM still converges using approximate messages within an uncertain parameter setting where θ is learned simultaneously with the state sequence x.\nSpecifically, we approximate τ by monitoring the change in belief residuals with a sub-routine GrowBuf, outlined in Alg. 2, that iteratively expands a buffer qold → qnew around a given subchain yS . Growbuf terminates when all belief residuals satisfy\nmax i∈S ||q(xi)new − q(xi)old||1 ≤ . (18)\nThe GrowBuf sub-routine can be computed efficiently due to (1) monotonicity of the forward and backward messages so that only residuals at endpoints, q(xS1 ) and q(x S L), need be considered, and (2) the reuse of computations. Specifically, the forward-backward pass can be rooted at the midpoint of yS so that messages to the endpoints can be efficiently propagated, and vice versa [22].\nFurthermore, choosing sufficiently small guarantees that the noisy natural gradient lies in the same half-plane as the true natural gradient, a sufficient condition for maintaining convergence when using approximate gradients [23]; the proof is presented in the Supplement.\nAlgorithm 2 GrowBuf procedure. 1: Input: subchain S, min buffer length u ∈ Z+, error tolerance > 0. 2: Initialize qold(xS) = ForwardBackward(yS , π̂, Ã, p̃S) and set Sold = S. 3: while true do 4: Grow buffer Snew by extending Sold by u observations in each direction. 5: qnew(xS new ) = ForwardBackward(yS new\n, π̂, Ã, p̃Snew), reusing messages from Sold. 6: if ∣∣∣∣qnew(xS)− qold(xS)∣∣∣∣ < then 7: return q∗(xS) = qnew(xS) 8: end if 9: Set Sold = Snew and qold = qnew.\n10: end while"
    }, {
      "heading" : "3.4 Minibatches for variance mitigation and their effect on computational complexity",
      "text" : "Stochastic gradient algorithms often benefit from sampling multiple observations in order to reduce the variance of the gradient estimates at each iteration. We use a similar idea in SVIHMM by sampling a minibatch B = (yS1 , . . . ,ySM ) consisting of M subchains. If the latent Markov chain tends to dwell in one component for extended periods, sampling one subchain may only contain information about a select number of states observed in that component. Increasing the length of this subchain may only lead to redundant information from this component. In contrast, using a minibatch of many smaller subchains may discover disparate components of the chain at comparable computational cost, accelerating learning and leading to a better local optimum. However, subchains must be sufficiently long to be informative of transition dynamics. In this setting, the local step on each subchain is identical; summing over subchains in the minibatch yields the gradient update:\nŵB = ∑ S∈B cTEq(xS) [ t(xS ,yS) ] , wn+1 = wn(1− ρn) + ρn ( u+ ŵB |B| ) .\nWe see that the computational complexity of SVIHMM isO(K2(L+2τ )M), leading to significant efficiency gains compared to O(K2T ) in batch inference when (L+ 2τ )M << T ."
    }, {
      "heading" : "4 Experiments",
      "text" : "We evaluate the performance of SVIHMM compared to batch VB on synthetic experiments designed to illustrate the trade off between the choice of subchain length L and the number of subchains per\nminibatch M . We also demonstrate the utility of GrowBuf. We then apply our algorithm to gene segmentation in a large human chromatin data set.\nSynthetic data We create two synthetic datasets with T = 10, 000 observations and K = 8 latent states. The first, called diagonally dominant (DD), illustrates the potential benefit of large M , the number of sampled subchains per minibatch. The Markov chain heavily self-transitions so that most subchains contain redundant information with observations generated from the same latent state. Although transitions are rarely observed, the emission means are set to be distinct so that this example is likelihood-dominated and highly identifiable. Thus, fixing a computational budget, we expect large M to be preferable to large L, covering more of the observation sequence and avoiding poor local modes arising from redundant information.\nThe second dataset we consider contains two reversed cycles (RC): the Markov chain strongly transitions from states 1 → 2 → 3 → 1 and 5 → 7 → 6 → 5 with a small probability of transitioning between cycles via bridge states 4 and 8. The emission means for the two cycles are very similar but occur in reverse order with respect to the transitions. Transition information in observing long enough dynamics is thus crucial to identify between states 1, 2, 3 and 5, 6, 7, and a large enough L is imperative. The Supplement contains details for generating both synthetic datasets.\nWe compare SVIHMM to batch VB on these two synthetic examples. For each per parameter setting, we ran 20 random restarts of SVIHMM for 100 iterations and batch VB until convergence of the ELBO. A forgetting rate κ parametrizes step sizes ρn = (1 + n)−κ. We fix the total number of observations L ×M used per iteration of SVIHMM such that increasing M implies decreasing L (and vice versa).\nIn Fig. 1(a) we compare ||Â−A||F , whereA is the true transition matrix and Â its learned variational mean. We see trends one would expect: the small L, large M settings achieve better performance for the DD example, but the opposite holds for RC, with bL/2c = 1 significantly underperforming. (Of course, allowing large L and M is always preferable, except computationally.) Under appropriate settings in both cases, we achieve comparable performance to batch VB. In Fig. 1(b), we see similar trends in terms of predictive log-probability holding out 10% of the observations as a test set and using 5-fold cross validation. Here, we actually notice that SVIHMM often achieves higher predictive log-probability than batch VB, which is attributed to the fact that stochastic algorithms can find better local modes than their non-random counterparts.\nA timing comparison of SVIHMM to batch VB with T = 3 million is presented in Table 4. All settings of SVIHMM run faster than even a single iteration of batch, with only a negligible change in predictive log-likelihood. Further discussion on these timing results is in the Supplement.\nMotivated by the demonstrated importance of choice of L, we now turn to examine the impact of the GrowBuf routine via predictive log-probability. In Fig. 1(b), we see a noticeable improvement for small L settings when GrowBuf is incorporated (the dashed lines in Fig. 1(b)). In particular, the RC example is now learning dynamics of the chain even with bL/2c = 1, which was not possible without buffering. GrowBuf thus provides robustness by guarding against poor choice of L. We note that the buffer routine does not overextend subchains, on average growing by only ≈ 8 observations with = 1×10−6. Since the number of observations added is usually small, GrowBuf does not significantly add to per-iteration computational cost (see the Supplement).\nHuman chromatin segmentation We apply the SVIHMM algorithm to a massive human chromatin dataset provided by the ENCODE project [24]. This data was studied in [25] with the goal of unsupervised pattern discovery via segmentation of the genome. Regions sharing the same labels have certain common properties in the observed data, and because the labeling at each position is unknown but influenced by the label at the previous position, an HMM is a natural model [26].\nWe were provided with 250 million observations consisting of twelve assays carried out in the chronic myeloid leukemia cell line K562. We analyzed the data using SVIHMM on an HMM with 25 states and 12 dimensional Gaussian emissions. We compare our performance to the corresponding segmentation learned by an expectation maximization (EM) algorithm applied to a more flexible dynamic Bayesian network model (DBN) [27]. Due to the size of the dataset, the analysis of [27] requires breaking the chain into several blocks, severing long range dependencies.\nWe assess performance by comparing the false discovery rate (FDR) of predicting active promoter elements in the sequence. The lowest (best) FDR achieved with SVIHMM over 20 random restarts trials was .999026 using bL/2c = 2000,M = 50, κ = .51, comparable and slightly lower than the .999038 FDR obtained using DBN-EM on the severed data [27]. We emphasize that even when restricted to a simpler HMM model, learning on the full data via SVIHMM attains similar results to that of [27] with significant gains in efficiency. In particular, our SVIHMM runs require only under an hour for a fixed 100 iterations, the maximum iteration limit specified in the DBN-EM approach. In contrast, even with a parallelized implementation over the broken chain, the DBN-EM algorithm can take days. In conclusion, SVIHMM enables scaling to the entire dataset, allowing for a more principled approach by utilizing the data jointly."
    }, {
      "heading" : "5 Discussion",
      "text" : "We have presented stochastic variational inference for HMMs, extending such algorithms from independent data settings to handle time dependence. We elucidated the complications that arise when sub-sampling dependent observations and proposed a scheme to mitigate the error introduced from breaking dependencies. Our approach provides an adaptive technique with provable guarantees for convergence to a local mode. Further extensions of the algorithm in the HMM setting include adaptively selecting the length of meta-observations and parallelizing the local step when the number of meta-observations is large. Importantly, these ideas generalize to other settings and can be applied to Bayesian nonparametric time series models, general state space models, and other graph structures with spatial dependencies."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This work was supported in part by the TerraSwarm Research Center sponsored by MARCO and DARPA, DARPA Grant FA9550-12-1-0406 negotiated by AFOSR, and NSF CAREER Award IIS-1350133. JX was supported by an NDSEG fellowship. We also appreciate the data, discussions, and guidance on the ENCODE project provided by Max Libbrecht and William Noble.\n1Other parameter settings were explored."
    } ],
    "references" : [ {
      "title" : "A Stochastic Approximation Method",
      "author" : [ "H. Robbins", "S. Monro" ],
      "venue" : "The Annals of Mathematical Statistics, 22(3):400–407,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 1951
    }, {
      "title" : "Online algorithms and stochastic approximations",
      "author" : [ "L. Bottou" ],
      "venue" : "Online Learning and Neural Networks. Cambridge University Press,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Large-Scale Machine Learning with Stochastic Gradient Descent",
      "author" : [ "L. Bottou" ],
      "venue" : "International Conference on Computational Statistics, pages 177–187, August",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Robust stochastic approximation approach to stochastic programming",
      "author" : [ "A. Nemirovski", "A. Juditsky", "G. Lan", "A. Shapiro" ],
      "venue" : "SIAM J. on Optimization, 19(4):1574–1609, January",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Bayesian learning via stochastic gradient Langevin dynamics",
      "author" : [ "M. Welling", "Y.W. Teh" ],
      "venue" : "International Conference on Machine Learning, pages 681–688,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Firefly Monte Carlo: Exact MCMC with subsets of data",
      "author" : [ "D. Maclaurin", "R.P. Adams" ],
      "venue" : "CoRR, abs/1403.5693,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Parallelizing MCMC via Weierstrass sampler",
      "author" : [ "X. Wang", "D.B. Dunson" ],
      "venue" : "CoRR, abs/1312.4605,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Asymptotically exact, embarrassingly parllel MCMC",
      "author" : [ "W. Neiswanger", "C. Wang", "E. Xing" ],
      "venue" : "CoRR, abs/1311.4780,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Stochastic variational inference",
      "author" : [ "M.D. Hoffman", "D.M. Blei", "C. Wang", "J. Paisley" ],
      "venue" : "Journal of Machine Learning Research, 14(1):1303–1347, May",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Truly nonparametric online variational inference for hierarchical Dirichlet processes",
      "author" : [ "M. Bryant", "E.B. Sudderth" ],
      "venue" : "Advances in Neural Information Processing Systems, pages 2708–2716,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Streaming variational Bayes",
      "author" : [ "T. Broderick", "N. Boyd", "A. Wibisono", "A.C. Wilson", "M.I. Jordan" ],
      "venue" : "Advances in Neural Information Processing Systems, pages 1727–1735,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Scalable inference of overlapping communities",
      "author" : [ "P. Gopalan", "D.M. Mimno", "S. Gerrish", "M.J. Freedman", "D.M. Blei" ],
      "venue" : "Advances in Neural Information Processing Systems, pages 2258–2266,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Stochastic variational inference for Bayesian time series models",
      "author" : [ "M.J. Johnson", "A.S. Willsky" ],
      "venue" : "International Conference on Machine Learning,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "A tutorial on hidden Markov models and selected applications in speech recognition",
      "author" : [ "L.R. Rabiner" ],
      "venue" : "Proceedings of the IEEE, 77(2):257–286,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 1989
    }, {
      "title" : "Finite mixture and Markov switching models",
      "author" : [ "S. Frühwirth-Schnatter" ],
      "venue" : "Springer Verlag,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Bayesian methods for hidden Markov models: Recursive computing in the 21st century",
      "author" : [ "S.L. Scott" ],
      "venue" : "Journal of the American Statistical Association, 97(457):337–351, March",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Variational Algorithms for Approximate Bayesian Inference",
      "author" : [ "M.J. Beale" ],
      "venue" : "Ph.D. thesis, University College London,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "An introduction to variational methods for graphical models",
      "author" : [ "M.I. Jordan", "Z. Ghahramani", "T.S. Jaakkola", "L.K. Saul" ],
      "venue" : "Machine Learning, 37(2):183–233, November",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Pattern Recognition and Machine Learning",
      "author" : [ "C.M. Bishop" ],
      "venue" : "Springer Verlag,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Pseudo-gradient adaptation and learning algorithms",
      "author" : [ "B.T. Polyak", "Y. Tsypkin" ],
      "venue" : "Automatics and Telemechanics, 3:45–68,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 1973
    }, {
      "title" : "Residual splash for optimally parallelizing belief propagation",
      "author" : [ "J. Gonzalez", "Y. Low", "C. Guestrin" ],
      "venue" : "International Conference on Artificial Intelligence and Statistics,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Artificial Intelligence: A Modern Approach",
      "author" : [ "S.J. Russell", "P. Norvig" ],
      "venue" : "Pearson Education,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Numerical Optimization",
      "author" : [ "J. Nocedal", "S. Wright" ],
      "venue" : "Springer Series in Operations Research and Financial Engineering. Springer,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "An integrated encyclopedia of DNA elements in the human genome",
      "author" : [ "ENCODE Project Consortium" ],
      "venue" : "Nature, 489(7414):57–74, September",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Unsupervised pattern discovery in human chromatin structure through genomic segmentation",
      "author" : [ "M.M. Hoffman", "O.J. Buske", "J. Wang", "Z. Weng", "J.A. Bilmes", "W.S. Noble" ],
      "venue" : "Nature Methods, 9:473–476,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Unsupervised segmentation of continuous genomic data",
      "author" : [ "N. Day", "A. Hemmaplardh", "R.E. Thurman", "J.A. Stamatoyannopoulos", "W.S. Noble" ],
      "venue" : "Bioinformatics, 23(11):1424–1426,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Integrative annotation of chromatin elements from encode data",
      "author" : [ "M.M. Hoffman", "J. Ernst", "S.P. Wilder", "A. Kundaje", "R.S. Harris", "M. Libbrecht", "B. Giardine", "P.M. Ellenbogen", "J.A. Bilmes", "E. Birney", "R.C. Hardison", "M. Dunham", "I. Kellis", "W.S. Noble" ],
      "venue" : "Nucleic Acids Research, 41(2):827–841,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Significant progress has been made scaling machine learning algorithms to these massive datasets based on optimization procedures [1, 2, 3].",
      "startOffset" : 130,
      "endOffset" : 139
    }, {
      "referenceID" : 1,
      "context" : "Significant progress has been made scaling machine learning algorithms to these massive datasets based on optimization procedures [1, 2, 3].",
      "startOffset" : 130,
      "endOffset" : 139
    }, {
      "referenceID" : 2,
      "context" : "Significant progress has been made scaling machine learning algorithms to these massive datasets based on optimization procedures [1, 2, 3].",
      "startOffset" : 130,
      "endOffset" : 139
    }, {
      "referenceID" : 3,
      "context" : "For example, stochastic gradient descent employs noisy estimates of the gradient based on minibatches of data, avoiding a costly gradient computation using the full dataset [4].",
      "startOffset" : 173,
      "endOffset" : 176
    }, {
      "referenceID" : 4,
      "context" : "There is considerable interest in leveraging these methods for Bayesian inference since traditional algorithms such as Markov chain Monte Carlo (MCMC) scale poorly to large datasets, though subset-based MCMC methods have been recently proposed as well [5, 6, 7, 8].",
      "startOffset" : 252,
      "endOffset" : 264
    }, {
      "referenceID" : 5,
      "context" : "There is considerable interest in leveraging these methods for Bayesian inference since traditional algorithms such as Markov chain Monte Carlo (MCMC) scale poorly to large datasets, though subset-based MCMC methods have been recently proposed as well [5, 6, 7, 8].",
      "startOffset" : 252,
      "endOffset" : 264
    }, {
      "referenceID" : 6,
      "context" : "There is considerable interest in leveraging these methods for Bayesian inference since traditional algorithms such as Markov chain Monte Carlo (MCMC) scale poorly to large datasets, though subset-based MCMC methods have been recently proposed as well [5, 6, 7, 8].",
      "startOffset" : 252,
      "endOffset" : 264
    }, {
      "referenceID" : 7,
      "context" : "There is considerable interest in leveraging these methods for Bayesian inference since traditional algorithms such as Markov chain Monte Carlo (MCMC) scale poorly to large datasets, though subset-based MCMC methods have been recently proposed as well [5, 6, 7, 8].",
      "startOffset" : 252,
      "endOffset" : 264
    }, {
      "referenceID" : 8,
      "context" : "Indeed, a scalable modification to VB harnessing stochastic gradients—stochastic variational inference (SVI)—has recently been applied to a variety of Bayesian latent variable models [9, 10].",
      "startOffset" : 183,
      "endOffset" : 190
    }, {
      "referenceID" : 9,
      "context" : "Indeed, a scalable modification to VB harnessing stochastic gradients—stochastic variational inference (SVI)—has recently been applied to a variety of Bayesian latent variable models [9, 10].",
      "startOffset" : 183,
      "endOffset" : 190
    }, {
      "referenceID" : 10,
      "context" : "Minibatch-based VB methods have also proven effective in a streaming setting where data arrives sequentially [11].",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 11,
      "context" : "One exception is the SVI algorithm for the mixed-membership stochastic block model [12], but independence at the level of the generative model must be exploited.",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 12,
      "context" : "SVI for Bayesian time series including HMMs was recently considered in settings where each minibatch is a set of independent series [13], though in this setting again dependencies do not need to be broken.",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 13,
      "context" : "Hidden Markov models (HMMs) [14] are a class of discrete-time doubly stochastic processes consisting of observations yt and latent states xt ∈ {1, .",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 13,
      "context" : "While evaluating marginal likelihoods, p(y|θ), and most probable state sequences, arg maxx p(x|y, θ), are tractable via the forward-backward (FB) algorithm when parameter values θ are fixed [14], exact computation of the posterior is intractable for HMMs.",
      "startOffset" : 190,
      "endOffset" : 194
    }, {
      "referenceID" : 14,
      "context" : "Markov chain Monte Carlo (MCMC) provides a widely used sampling-based approach to posterior inference in HMMs [15, 16].",
      "startOffset" : 110,
      "endOffset" : 118
    }, {
      "referenceID" : 15,
      "context" : "Markov chain Monte Carlo (MCMC) provides a widely used sampling-based approach to posterior inference in HMMs [15, 16].",
      "startOffset" : 110,
      "endOffset" : 118
    }, {
      "referenceID" : 16,
      "context" : "q(θ,x) = q(A)q(φ)q(x), (4) breaking dependencies only between the parameters θ = {A, φ} and latent state sequence x [17].",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 17,
      "context" : "Maximizing L is equivalent to minimizing the KL divergence KL(q(x, θ)||p(x, θ|y)) [18].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 16,
      "context" : "The global update is derived by differentiating L with respect to the global variational parameters [17].",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 8,
      "context" : "Assuming a conjugate exponential family leads to a simple coordinate ascent update [9]: w = u + Eq(x) [t(x,y)] .",
      "startOffset" : 83,
      "endOffset" : 86
    }, {
      "referenceID" : 8,
      "context" : "To cope with this computational challenge, stochastic variational inference (SVI) [9] leverages a Robbins-Monro algorithm [1] to optimize the ELBO via stochastic gradient ascent.",
      "startOffset" : 82,
      "endOffset" : 85
    }, {
      "referenceID" : 0,
      "context" : "To cope with this computational challenge, stochastic variational inference (SVI) [9] leverages a Robbins-Monro algorithm [1] to optimize the ELBO via stochastic gradient ascent.",
      "startOffset" : 122,
      "endOffset" : 125
    }, {
      "referenceID" : 8,
      "context" : "When all pairs of distributions in the model are conditionally conjugate, it is cheaper to compute the stochastic natural gradient, ∇̃wL, which additionally accounts for the information geometry of the distribution [9].",
      "startOffset" : 215,
      "endOffset" : 218
    }, {
      "referenceID" : 1,
      "context" : "(14) converge to a local maximum of L under mild regularity conditions as long as step-sizes ρn satisfy ∑ n ρ 2 n <∞, and ∑ n ρn =∞ [2, 9].",
      "startOffset" : 132,
      "endOffset" : 138
    }, {
      "referenceID" : 8,
      "context" : "(14) converge to a local maximum of L under mild regularity conditions as long as step-sizes ρn satisfy ∑ n ρ 2 n <∞, and ∑ n ρn =∞ [2, 9].",
      "startOffset" : 132,
      "endOffset" : 138
    }, {
      "referenceID" : 19,
      "context" : "However, as detailed in [20], unbiasedness suffices for convergence of Eq.",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 11,
      "context" : "(15) analogously to [12], generally with a batch factor c varying with each subset y .",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 20,
      "context" : "Buffering subchains is related to splash belief propagation (BP) for parallel inference in undirected graphical models, where the belief at any given node is monitored based on locally-aware message passing in order to maintain a good approximation to the true belief [21].",
      "startOffset" : 268,
      "endOffset" : 272
    }, {
      "referenceID" : 21,
      "context" : "Specifically, the forward-backward pass can be rooted at the midpoint of y so that messages to the endpoints can be efficiently propagated, and vice versa [22].",
      "startOffset" : 155,
      "endOffset" : 159
    }, {
      "referenceID" : 22,
      "context" : "Furthermore, choosing sufficiently small guarantees that the noisy natural gradient lies in the same half-plane as the true natural gradient, a sufficient condition for maintaining convergence when using approximate gradients [23]; the proof is presented in the Supplement.",
      "startOffset" : 226,
      "endOffset" : 230
    }, {
      "referenceID" : 23,
      "context" : "Human chromatin segmentation We apply the SVIHMM algorithm to a massive human chromatin dataset provided by the ENCODE project [24].",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 24,
      "context" : "This data was studied in [25] with the goal of unsupervised pattern discovery via segmentation of the genome.",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 25,
      "context" : "Regions sharing the same labels have certain common properties in the observed data, and because the labeling at each position is unknown but influenced by the label at the previous position, an HMM is a natural model [26].",
      "startOffset" : 218,
      "endOffset" : 222
    }, {
      "referenceID" : 26,
      "context" : "We compare our performance to the corresponding segmentation learned by an expectation maximization (EM) algorithm applied to a more flexible dynamic Bayesian network model (DBN) [27].",
      "startOffset" : 179,
      "endOffset" : 183
    }, {
      "referenceID" : 26,
      "context" : "Due to the size of the dataset, the analysis of [27] requires breaking the chain into several blocks, severing long range dependencies.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 26,
      "context" : "999038 FDR obtained using DBN-EM on the severed data [27].",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 26,
      "context" : "We emphasize that even when restricted to a simpler HMM model, learning on the full data via SVIHMM attains similar results to that of [27] with significant gains in efficiency.",
      "startOffset" : 135,
      "endOffset" : 139
    } ],
    "year" : 2014,
    "abstractText" : "Variational inference algorithms have proven successful for Bayesian analysis in large data settings, with recent advances using stochastic variational inference (SVI). However, such methods have largely been studied in independent or exchangeable data settings. We develop an SVI algorithm to learn the parameters of hidden Markov models (HMMs) in a time-dependent data setting. The challenge in applying stochastic optimization in this setting arises from dependencies in the chain, which must be broken to consider minibatches of observations. We propose an algorithm that harnesses the memory decay of the chain to adaptively bound errors arising from edge effects. We demonstrate the effectiveness of our algorithm on synthetic experiments and a large genomics dataset where a batch algorithm is computationally infeasible.",
    "creator" : null
  }
}