{
  "name" : "670e8a43b246801ca1eaca97b3e19189.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Top Rank Optimization in Linear Time",
    "authors" : [ "Nan Li", "Rong Jin", "Zhi-Hua Zhou" ],
    "emails" : [ "lin@lamda.nju.edu.cn", "zhouzh@lamda.nju.edu.cn", "rongjin@cse.msu.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Bipartite ranking aims to learn a real-valued ranking function that places positive instances above negative instances. It has attracted much attention because of its applications in several areas such as information retrieval and recommender systems [32, 25]. Many ranking methods have been developed for bipartite ranking, and most of them are essentially based on pairwise ranking. These algorithms reduce the ranking problem into a binary classification problem by treating each positivenegative instance pair as a single object to be classified [16, 12, 5, 39, 38, 33, 1, 3]. Since the number of instance pairs can grow quadratically in the number of training instances, one limitation of these methods is their high computational costs, making them not scalable to large datasets.\nConsidering that for applications such as document retrieval and recommender systems, only the top ranked instances will be examined by users, there has been a growing interest in learning ranking functions that perform especially well at the top of the ranked list [7, 39, 38, 33, 1, 3, 27, 40]. Most of these approaches can be categorized into two groups. The first group maximizes the ranking accuracy at the top of the ranked list by optimizing task specific metrics [17, 21, 23, 40], such as average precision (AP) [42], NDCG [39] and partial AUC [27, 28]. The main limitation of these methods is that they often result in non-convex optimization problems that are difficult to solve efficiently. Structural SVM [37] addresses this issue by translating the non-convexity into an exponential number of constraints. It can still be computationally challenging because it usually requires to search for the most violated constraint at each iteration of optimization. In addition, these methods are statistically inconsistent [36, 21], leading to suboptimal solutions. The second group of methods are based on pairwise ranking. They design special convex loss functions that place more penalties on the ranking errors related to the top ranked instances [38, 33, 1]. Since these methods are based on pairwise ranking, their computational costs are usually proportional to the number of positive-negative instance pairs, making them unattractive for large datasets.\nIn this paper, we address the computational challenge of bipartite ranking by designing a ranking algorithm, named TopPush, that can efficiently optimize the ranking accuracy at the top. The key feature of the proposed TopPush algorithm is that its time complexity is only linear in the number of training instances. This is in contrast to most existing methods for bipartite ranking whose computational costs depend on the number of instance pairs. Moreover, we develop novel analysis for bipartite ranking. One deficiency of the existing theoretical studies [33, 1] on bipartite ranking is that they try to bound the probability for a positive instance to be ranked before any negative instance, leading to relatively pessimistic bounds. We overcome this limitation by bounding the probability of ranking a positive instance before most negative instances, and show that TopPush is effective in placing positive instances at the top of a ranked list. Extensive empirical study shows that TopPush is computationally more efficient than most ranking algorithms, and yields comparable performance as the state-of-the-art approaches that maximize the ranking accuracy at the top.\nThe rest of this paper is organized as follows. Section 2 introduces the preliminaries of bipartite ranking, and addresses the difference between AUC optimization and maximizing accuracy at the top. Section 3 presents the proposed TopPush algorithm and its key theoretical properties. Section 4 summarizes the empirical study, and Section 5 concludes this work with future directions."
    }, {
      "heading" : "2 Bipartite Ranking: AUC vs. Accuracy at the Top",
      "text" : "Let X = {x ∈ Rd : ‖x‖ ≤ 1} be the instance space. Let S = S+ ∪ S− be a set of training instances, where S+ = {x+i ∈ X}mi=1 and S− = {x − i ∈ X}ni=1 include m positive instances and n negative instances independently sampled from distributions P+ and P−, respectively. The goal of bipartite ranking is to learn a ranking function f : X 7→ R that is likely to place a positive instance before most negative ones. In the literature, bipartite ranking has found applications in many domains [32, 25], and its theoretical properties have been examined by several studies [2, 6, 20, 26].\nAUC is a commonly used evaluation metric for bipartite ranking [15, 9]. By exploring its equivalence to Wilcoxon-Mann-Whitney statistic [15], many ranking algorithms have been developed to optimize AUC by minimizing the ranking loss defined as\nLrank(f ;S) = 1\nmn ∑m i=1 ∑n j=1 I ( f(x+i ) ≤ f(x − j ) ) , (1)\nwhere I(·) is the indicator function. Other than a few special loss functions (e.g., exponential and logistic loss) [33, 20], most of these methods need to enumerate all the positive-negative instance pairs, making them unattractive for large datasets. Various methods have been developed to address this computational challenge [43, 13].\nRecently, there is a growing interest on optimizing ranking accuracy at the top [7, 3]. Maximizing AUC is not suitable for this goal as indicated by the analysis in [7]. To address this challenge, we propose to maximize the number of positive instances that are ranked before the first negative instance, which is known as positives at the top [33, 1, 3]. We can translate this objective into the minimization of the following loss\nL(f ;S) = 1 m ∑m i=1 I ( f(x+i ) ≤ max 1≤j≤n f(x−j ) ) . (2)\nwhich computes the fraction of positive instances ranked below the top-ranked negative instance. By minimizing the loss in (2), we essentially push negative instances away from the top of the ranked list, leading to more positive ones placed at the top. We note that (2) is fundamentally different from AUC optimization as AUC does not focus on the ranking accuracy at the top. More discussion about the relationship between (1) and (2) can be found in the longer version of the paper [22].\nTo design practical learning algorithms, we replace the indicator function in (2) with its convex surrogate, leading to the following loss function\nL`(f ;S) = 1 m ∑m i=1 ` ( max 1≤j≤n f(x−j )− f(x + i ) ) , (3)\nwhere `(·) is a convex loss function that is non-decreasing1 and differentiable. Examples of such loss functions include truncated quadratic loss `(z) = [1 + z]2+, exponential loss `(z) = e z , or\n1In this paper, we let `(z) to be non-decreasing for the simplicity of formulating dual problem.\nlogistic loss `(z) = log(1 + ez). In the discussion below, we restrict ourselves to the truncated quadratic loss, though most of our analysis applies to others.\nIt is easy to verify that the loss L`(f ;S) in (3) is equivalent to the loss used in InfinitePush [1] (a special case of P -norm Push [33]), i.e.,\nL`∞(f ;S) = max 1≤j≤n\n1\nm ∑m i=1 ` ( f(x−j )− f(x + i ) ) . (4)\nThe apparent advantage of employing L`(f ;S) instead of L`∞(f ;S) is that it only needs to evaluate on m positive-negative instance pairs, whereas the later needs to enumerate all the mn instance pairs. As a result, the number of dual variables induced by L`(f ;S) is n+m, linear in the number of training instances, which is significantly smaller than mn, the number of dual variables induced by L`∞(f ;S) [1, 31]. It is this difference that makes the proposed algorithm achieve a computational complexity linear in the number of training instances and therefore be more efficiently than the existing algorithms for most state-of-the-art algorithms for bipartite ranking."
    }, {
      "heading" : "3 TopPush for Optimizing Top Accuracy",
      "text" : "We first present a learning algorithm to minimize the loss function in (3), and then the computational complexity and performance guarantee for the proposed algorithm."
    }, {
      "heading" : "3.1 Dual Formulation",
      "text" : "We consider linear ranking function2, i.e., f(x) = w>x, where w ∈ Rd is the weight vector to be learned. As a result, the learning problem is given by the following optimization problem\nmin w\nλ 2 ‖w‖2 + 1 m ∑m i=1 ` ( max 1≤j≤n w>x−j −w >x+i ) , (5)\nwhere λ > 0 is a regularization parameter. Directly minimizing the objective in (5) can be challenging because of the max operator in the loss function. We address this challenge by developing a dual formulation for (5). Specifically, given a convex and differentiable function `(z), we can rewrite it in its convex conjugate form as `(z) = maxα∈Ω αz − `∗(α) , where `∗(α) is the convex conjugate of `(z) and Ω is the domain of dual variable [4]. For example, the convex conjugate of truncated quadratic loss is `∗(α) = −α + α2/4 with Ω = R+. We note that dual form has been widely used to improve computational efficiency [35] and connect different styles of learning algorithms [19]. Here we exploit it to overcome the difficulty caused by max operator. The dual form of (5) is given in the following theorem, whose detailed proof can be found in the longer version [22]. Theorem 1. Define X+ = (x+1 , . . . ,x+m)> and X− = (x − 1 , . . . ,x − n ) >, the dual problem of (5) is\nmin (α,β)∈Ξ\ng(α,β) = 1\n2λm ‖α>X+ − β>X−‖2 + ∑m i=1 `∗(αi) (6)\nwhere α and β are dual variables, and the domain Ξ is defined as Ξ = { α ∈ Rm+ , β ∈ Rn+ : 1>mα = 1>nβ } . Let α∗ and β∗ be the optimal solution to the dual problem (6). Then, the optimal solution w∗ to the primal problem in (5) is given by\nw∗ = 1\nλm\n( a∗>X+ − β∗>X− ) . (7)\nRemark The key feature of the dual problem in (6) is that the number of dual variables is m + n, leading to a linear time ranking algorithm. This is in contrast to the InfinitPush algorithm in [1] that introduces mn dual variables and a higher computational cost. In addition, the objective function in (6) is smooth if the convex conjugate `∗(·) is smooth, which is true for many common loss functions (e.g., truncated quadratic loss and logistic loss). It is well known in the literature of optimization [4] that an O(1/T 2) convergence rate can be achieved if the objective function is smooth, where T is the number of iterations; this also helps in designing efficient learning algorithm.\n2Nonlinear function can be trained by kernel methods, and Nyström method and random Fourier features can transform the kernelized problem into a linear one. See [41] for more discussions."
    }, {
      "heading" : "3.2 Linear Time Bipartite Ranking",
      "text" : "According to Theorem 1, to learn a ranking function f(w), it is sufficient to learn the dual variables α and β by solving the problem in (6). For this purpose, we adopt the accelerated gradient method due to its light computation per iteration, and refer the obtained algorithm as TopPush. Specifically, we choose the Nesterov’s method [30, 29] that achieves an optimal convergence rate O(1/T 2) for smooth objective function. One of the key features of the Nesterov’s method is that it maintains two sequences of solutions: {(αk,βk)} and {(sαk ; s β k)}, where the sequence of auxiliary solutions {(sαk ; s β k)} is introduced to exploit the smoothness of the objective to achieve a faster convergence rate. Algorithm 1 shows the key steps3 of the Nesterov’s method for solving the problem in (6), where the gradients of the objective function g(α,β) can be efficiently computed as\n∇αg(α,β) = X+ν>/λm+ `′∗(α) , ∇βg(α,β) = −X−ν>/λm . (8)\nwhere ν = α>X+ − β>X− and `′∗(·) is the derivative of `∗(·).\nAlgorithm 1 The TopPush Algorithm Input: X+ ∈ Rm×d, X− ∈ Rn×d, λ, Output: w 1: initialize α1 = α0 = 0m, β1 = β0 = 0n, and let t−1 = 0, t0 = 1, L0 = 1m+n 2: repeat for k = 1, 2, . . . 3: compute sak = αk + ωk(αk −αk−1) and sβk = βk + ωk(βk − βk−1), where ωk = tk−2−1 tk−1\n4: compute gα = ∇αg(sαk , sβk) and gβ = ∇βg(s α k , s β k) based on (8) 5: find Lk > Lk−1 such that g(αk+1,βk+1) > g(sαk , s β k) + (‖gα‖\n2 + ‖gβ‖2)/(2Lk), where [αk+1;βk+1] = πΞ([α ′ k+1;β ′ k+1]) with α ′ k+1 = s\nα k − 1Lk gα and β ′ k+1 = s β k − 1 Lk gβ 6: update tk = (1 + √ 1 + 4t2k−1)/2 7: until convergence (i.e., |g(αk+1,βk+1)− g(αk,βk)| < ) 8: return w = 1\nλ·m (α > kX + − β>k X−)\nIt should be noted that, (6) is a constrained problem, and therefore, at each step of gradient mapping, we have to project the dual solution into the domain Ξ (i.e, [αk+1;βk+1] = πΞ([α′k+1;β ′ k+1]) in step 5) to keep them feasible. Below, we discuss how to solve this projection step efficiently.\nProjection Step For clear notations, we expand the projection step into the problem\nmin α≥0,β≥0\n1 2 ‖α−α0‖2 + 1 2 ‖β − β0‖2 s.t. 1>mα = 1>nβ , (9)\nwhere α0 and β0 are the solutions obtained in the last iteration. We note that similar projection problems have been studied in [34, 24] where they either have O((m + n) log(m + n)) time complexity [34] or only provide approximate solutions [24]. Instead, based on the following proposition, we provide a method which find the exact solution to (9) inO(n+m) time. By using proof technique similar to that for Theorem 2 in [24], we can prove the following proposition: Proposition 1. The optimal solution to the projection problem in (9) is given by\nα∗ = [α0 − γ∗]+ and β∗ = [β0 + γ∗]+ , where γ∗ is the root of function ρ(γ) = ∑m i=1[α 0 i − γ]+ − ∑n j=1[β 0 j + γ]+ .\nBased on Proposition 1, we provide a method which find the exact solution to (9) in O(m+n) time. According to Proposition 1, the key to solving this problem is to find the root of ρ(γ). Instead of approximating the solution via bisection as in [24], we develop a divide-and-conquer method to find the exact solution of γ∗ in O(m + n) time, where a similar approach has been used in [10]. The basic idea is to first identify the smallest interval that contains the root based on a modification of the randomized median finding algorithm [8], and then solve the root exactly based on the interval. The detailed projection procedure can be found in the longer version [22].\n3The step size of the Nesterov’s method depends on the smoothness of the objective function. In current work we adopt the Nemirovski’s line search scheme [29] to compute the smoothness parameter, and the detailed algorithm can be found in [22]."
    }, {
      "heading" : "3.3 Convergence and Computational Complexity",
      "text" : "The theorem below states the convergence of the TopPush algorithm, which follows immediately from the convergence result for the Nesterov’s method [29]. Theorem 2. Let αT and βT be the solution output from TopPush after T iterations, we have\ng(αT ,βT ) ≤ min (α,β)∈Ξ g(α,β) +\nprovided T ≥ O(1/ √ ).\nFinally, since the computational cost of each iteration is dominated by the gradient evaluation and the projection step, the time complexity of each iteration is O((m + n)d) since the complexity of projection step isO(m+n) and the cost of computing the gradient isO((m+n)d). Combining this result with Theorem 2, we have, to find an -suboptimal solution, the total computational complexity of the TopPush algorithm is O((m+ n)d/ √ ), which is linear in the number of training instances.\nTable 1 compares the computational complexity of TopPush with that of the state-of-the-art algorithms. It is easy to see that TopPush is asymptotically more efficient than the state-of-the-art ranking algorithms4. For instances, it is much more efficient than InfinitePush and its sparse extension L1SVIP whose complexity depends on the number of positive-negative instance pairs; compared with SVMRank, SVMMAP and SVMpAUC that handle specific performance metrics via structuralSVM, the linear dependence on the number of training instances makes our TopPush approach more appealing, especially for large datasets."
    }, {
      "heading" : "3.4 Theoretical Guarantee",
      "text" : "We develop theoretical guarantee for the ranking performance of TopPush. In [33, 1], the authors have developed margin-based generalization bounds for the loss function L`∞ . One limitation with the analysis in [33, 1] is that they try to bound the probability for a positive instance to be ranked before any negative instance, leading to relatively pessimistic bounds5. Our analysis avoids this pitfall by considering the probability of ranking a positive instance before most negative instances.\nTo this end, we first define hb(x,w), the probability for any negative instance to be ranked above x using ranking function f(x) = w>x, as\nhb(x,w) = Ex−∼P− [ I(w>x ≤ w>x−) ] .\nSince we are interested in whether positive instances are ranked above most negative instances, we will measure the quality of f(x) = w>x by the probability for any positive instance to be ranked below δ percent of negative instances, i.e.,\nPb(w, δ) = Prx+∼P+ ( hb(x + i ,w) ≥ δ ) .\nClearly, if a ranking function achieves a high ranking accuracy at the top, it should have a large percentage of positive instances with ranking scores higher than most of the negative instances, leading to a small value for Pb(w, δ) with little δ. The following theorem bounds Pb(w, δ) for TopPush, and the detailed proof can be found in the longer version [22].\n4In Table 1, we report the complexity of SVMpAUCtight in [28], which is more efficient than SVM pAUC in [27].\nIn addition, SVMpAUCtight is used in experiments and we do not distinguish between them in this paper. 5For instance, for the bounds in [33], the failure probability can be as large as 1 if the parameter p is large.\nTheorem 3. Given training data S consisting of m independent samples from P+ and n independent samples from P−, let w∗ be the optimal solution to the problem in (5). Assume m ≥ 12 and n t, we have, with a probability at least 1− 2e−t,\nPb(w ∗, δ) ≤ L`(w∗, S) +O (√ (t+ logm)/m ) where δ = O( √ logm/n) and L`(w∗, S) = 1m ∑m i=1 `(max1≤j≤nw >x−j −w>x + i ).\nRemark Theorem 3 implies that if the empirical loss L`(w∗, S) ≤ O(logm/m), for most positive instance x+ (i.e., 1−O(logm/m)), the percentage of negative instances ranked above x+ is upper bounded by O( √ logm/n). We observe that m and n play different roles in the bound; that is, because the empirical loss compares the positive instances to the negative instance with the largest score, it usually grows significantly slower with increasing n. For instance, the largest absolute value of Gaussian random samples grows in log n. Thus, we believe that the main effect of increasing n in our bound is to reduce δ (decrease at the rate of 1/ √ n), especially when n is large. Meanwhile, by increasing the number of positive instances m, we will reduce the bound for Pb(w, δ), and consequently increase the chance of finding positive instances at the top."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Settings",
      "text" : "To evaluate the performance of the TopPush algorithm, we conduct a set of experiments on realworld datasets. Table 2 (left column) summarizes the datasets used in our experiments. Some of them were used in previous studies [1, 31, 3], and others are larger datasets from different domains. We compare TopPush with state-of-the-art algorithms that focus on accuracy at the top, including SVMMAP [42], SVMpAUC [28] with α = 0 and β = 1/n, AATP [3] and InfinitePush [1]. In addition, for completeness, several state-of-the-art classification and ranking models are included in the comparison: logistic regression (LR) for binary classification, cost-sensitive SVM (cs-SVM) that addresses imbalance class distribution by introducing a different misclassification cost for each class, and SVMRank [18] for AUC optimization. We implement TopPush and InfinitePush using MATLAB, implement AATP using CVX [14], and use LIBLINEAR [11] for LR and cs-SVM, and use the codes shared by the authors of the original works.\nWe measure the accuracy at the top by commonly used metrics6: (i) positives at the top (Pos@Top) [1, 31, 3], which is defined as the fraction of positive instances ranked above the topranked negative, (ii) average precision (AP) and (iii) normalized DCG scores (NDCG). On each dataset, experiments are run for thirty trials. In each trial, the dataset is randomly divided into two subsets: 2/3 for training and 1/3 for test. For all algorithms, we set the precision parameter to 10−4, choose other parameters by 5-fold cross validation (based on the average value of Pos@Top) on training set, and perform the evaluation on test set. Finally, averaged results over thirty trails are reported. All experiments are run on a machine with two Intel Xeon E7 CPUs and 16GB memory."
    }, {
      "heading" : "4.2 Results",
      "text" : "In table 2, we report the performance of the algorithms in comparison, where the statistics of testbeds are included in the first column of the table. For better comparison between the performance of TopPush and baselines, pairwise t-tests at significance level of 0.9 are performed and results are marks “• / ◦” in table 2 when TopPush is statistically significantly better/worse. When an evaluation task can not be completed in two weeks, it will be stopped automatically, and no result will be reported. As a consequence, we observe that results for some algorithms are missing in Table 2 for certain datasets, especially for large ones. We can see from Table 2 that TopPush, LR and cs-SVM succeed to finish the evaluation on all datasets (even the largest datasets url). In contrast, SVMRank, SVMRank and SVMpAUC fail to complete the training in time for several large datasets. InfinitePush and AATP have the worst scalability: they are only able to finish the smallest dataset diabetes. We thus conclude that overall, TopPush scales well to large datasets.\n6It is worth mentioning that we also measure the ranking performance by AUC, and the results can be found in [22]. In addition, more details of the experimental setting can be found there.\nPerformance Comparison In terms of evaluation metric Pos@Top, we find that TopPush yields similar performance as InfinitePush and AATP, and performs significantly better than the other baselines including LR and cs-SVM, SVMRank, SVMRank and SVMpAUC. This is consistent with the design of TopPush that aims to maximize the accuracy at the top of the ranked list. Since the loss function optimized by InfinitePush and AATP are similar as that for TopPush, it is not surprising that they yield similar performance. The key advantage of using the proposed algorithm versus InfinitePush and AATP is that it is computationally more efficient and scales well to large datasets. In terms of AP and NDCG, we observe that TopPush yield similar, if not better, performance as the state-of-the-art methods, such as SVMMAP and SVMpAUC, that are designed to optimize these metrics. Overall, we conclude that the proposed algorithm is effective in optimizing the ranking accuracy for the top ranked instances.\nTraining Efficiency To evaluate the computational efficiency, we set the parameters of different algorithms to be the values that are selected by cross-validation, and run these algorithms on full datasets that include both training and testing sets. Table 2 summarizes the training time of different algorithms. From the results, we can see that TopPush is faster than state-of-the-art ranking methods on most datasets. In fact, the training time of TopPush is similar to that of LR and cs-SVM\nimplemented by LIBLINEAR. Since the time complexity of learning a binary classification model is usually linear in the number of training instances, this result implicitly suggests a linear time complexity for the proposed algorithm.\nScalability We study how TopPush scales to different number of training examples by using the largest dataset url. Figure 1 shows the log-log plot for the training time of TopPush vs. the size of training data, where different lines correspond to different values of λ. For the purpose of comparison, we also include a black dash-dot line that tries to fit the training time by a linear function in the number of training instances (i.e., Θ(m + n)). From the plot, we can see that for different regularization parameter λ, the training time of TopPush increases even slower than the number of training data. This is consistent with our theoretical analysis given in Section 3.3."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this paper, we focus on bipartite ranking algorithms that optimize accuracy at the top of the ranked list. To this end, we consider to maximize the number of positive instances that are ranked above any negative instances, and develop an efficient algorithm, named as TopPush to solve related optimization problem. Compared with existing work on this topic, the proposed TopPush algorithm scales linearly in the number of training instances, which is in contrast to most existing algorithms for bipartite ranking whose time complexities dependents on the number of positive-negative instance pairs. Moreover, our theoretical analysis clearly shows that it will lead to a ranking function that places many positive instances the top of the ranked list. Empirical studies verify the theoretical claims: the TopPush algorithm is effective in maximizing the accuracy at the top and is significantly more efficient than the state-of-the-art algorithms for bipartite ranking. In the future, we plan to develop appropriate univariate loss, instead of pairwise ranking loss, for efficient bipartite ranking that maximize accuracy at the top.\nAcknowledgement This research was supported by the 973 Program (2014CB340501), NSFC (61333014), NSF (IIS-1251031), and ONR Award (N000141210431)."
    } ],
    "references" : [ {
      "title" : "The infinite push: A new support vector ranking algorithm that directly optimizes accuracy at the absolute top of the list",
      "author" : [ "S. Agarwal" ],
      "venue" : "SDM, pages 839–850",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Generalization bounds for the area under the ROC curve",
      "author" : [ "S. Agarwal", "T. Graepel", "R. Herbrich", "S. Har-Peled", "D. Roth" ],
      "venue" : "JMLR, 6:393–425",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Accuracy at the top",
      "author" : [ "S. Boyd", "C. Cortes", "M. Mohri", "A. Radovanovic" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2012
    }, {
      "title" : "Convex Optimization",
      "author" : [ "S. Boyd", "L. Vandenberghe" ],
      "venue" : "Cambridge University Press",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Learning to rank using gradient descent",
      "author" : [ "C. Burges", "T. Shaked", "E. Renshaw", "A. Lazier", "M. Deeds", "N. Hamilton", "G. Hullender" ],
      "venue" : "ICML, pages 89–96",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Ranking and empirical minimization of U -statistics",
      "author" : [ "S. Clémençon", "G. Lugosi", "N. Vayatis" ],
      "venue" : "Annals of Statistics, 36(2):844–874",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Ranking the best instances",
      "author" : [ "S. Clémençon", "N. Vayatis" ],
      "venue" : "JMLR, 8:2671–2699",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Introduction to algorithms",
      "author" : [ "T. Cormen", "C. Leiserson", "R. Rivest", "C. Stein" ],
      "venue" : "MIT Press",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "AUC optimization vs. error rate minimization",
      "author" : [ "C. Cortes", "M. Mohri" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2004
    }, {
      "title" : "Efficient projections onto the `1-ball for learning in high dimensions",
      "author" : [ "J. Duchi", "S. Shalev-Shwartz", "Y. Singer", "T. Chandra" ],
      "venue" : "ICML, pages 272–279",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "LIBLINEAR: A library for large linear classification",
      "author" : [ "R.-E. Fan", "K.-W. Chang", "C.-J. Hsieh", "X.-R. Wang", "C.-J. Lin" ],
      "venue" : "JMLR, 9:1871–1874",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "An efficient boosting algorithm for combining preferences",
      "author" : [ "Y. Freund", "R. Iyer", "R. Schapire", "Y. Singer" ],
      "venue" : "JMLR, 4:933–969",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "One-pass AUC optimization",
      "author" : [ "W. Gao", "R. Jin", "S. Zhu", "Z.-H. Zhou" ],
      "venue" : "ICML, pages 906–914",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "CVX: Matlab software for disciplined convex programming, version",
      "author" : [ "M. Grant", "S. Boyd" ],
      "venue" : "//cvxr.com/cvx,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2014
    }, {
      "title" : "The meaning and use of the area under a receiver operating characteristic (ROC) curve",
      "author" : [ "J. Hanley", "B. McNeil" ],
      "venue" : "Radiology, 143:29–36",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 1982
    }, {
      "title" : "Large Margin Rank Boundaries for Ordinal Regression",
      "author" : [ "R. Herbrich", "T. Graepel", "K. Obermayer" ],
      "venue" : "chapter Advances in Large Margin Classifiers, pages 115–132. MIT Press, Cambridge, MA",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "A support vector method for multivariate performance measures",
      "author" : [ "T. Joachims" ],
      "venue" : "ICML, pages 377–384, Bonn, Germany",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Training linear SVMs in linear time",
      "author" : [ "T. Joachims" ],
      "venue" : "KDD, pages 217–226",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Conjugate relation between loss functions and uncertainty sets in classification problems",
      "author" : [ "T. Kanamori", "A. Takeda", "T. Suzuki" ],
      "venue" : "JMLR, 14:1461–1504",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Bipartite ranking through minimization of univariate loss",
      "author" : [ "W. Kotlowski", "K. Dembczynski", "E. Hüllermeier" ],
      "venue" : "ICML, pages 1113–1120",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Direct optimization of ranking measures",
      "author" : [ "Q.V. Le", "A. Smola" ],
      "venue" : "CoRR, abs/0704.3359",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Top rank optimization in linear time",
      "author" : [ "N. Li", "R. Jin", "Z.-H. Zhou" ],
      "venue" : "CoRR, abs/1410.1462",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Efficient optimization of performance measures by classifier adaptation",
      "author" : [ "N. Li", "I.W. Tsang", "Z.-H. Zhou" ],
      "venue" : "IEEE-PAMI, 35(6):1370–1382",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Efficient Euclidean projections in linear time",
      "author" : [ "J. Liu", "J. Ye" ],
      "venue" : "ICML, pages 657–664",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Learning to Rank for Information Retrieval",
      "author" : [ "T.-Y. Liu" ],
      "venue" : "Springer",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "On the relationship between binary classification, bipartite ranking, and binary class probability estimation",
      "author" : [ "H. Narasimhan", "S. Agarwal" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2013
    }, {
      "title" : "A structural SVM based approach for optimizing partial AUC",
      "author" : [ "H. Narasimhan", "S. Agarwal" ],
      "venue" : "ICML, pages 516–524",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "SVM  pAUC: A new support vector method for optimizing partial AUC based on a tight convex upper bound",
      "author" : [ "H. Narasimhan", "S. Agarwal" ],
      "venue" : "KDD, pages 167–175",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Efficient methods in convex programming",
      "author" : [ "A. Nemirovski" ],
      "venue" : "Lecture Notes",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "Introductory Lectures on Convex Optimization",
      "author" : [ "Y. Nesterov" ],
      "venue" : "Kluwer Academic Publishers",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Sparse support vector infinite push",
      "author" : [ "A. Rakotomamonjy" ],
      "venue" : "ICML",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Learning optimal ranking with tensor factorization for tag recommendation",
      "author" : [ "S. Rendle", "L. Balby Marinho", "A. Nanopoulos", "L. Schmidt-Thieme" ],
      "venue" : "KDD, pages 727–736",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Margin-based ranking and an equivalence between adaboost and rankboost",
      "author" : [ "C. Rudin", "R. Schapire" ],
      "venue" : "JMLR, 10:2193–2232",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Efficient learning of label ranking by soft projections onto polyhedra",
      "author" : [ "S. Shalev-Shwartz", "Y. Singer" ],
      "venue" : "JMLR, 7:1567–1599",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Sparse semi-supervised learning using conjugate functions",
      "author" : [ "S. Sun", "J. Shawe-Taylor" ],
      "venue" : "JMLR, 11:2423– 2455",
      "citeRegEx" : "35",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "On the consistency of multiclass classification methods",
      "author" : [ "A. Tewari", "P. Bartlett" ],
      "venue" : "JMLR, 8:1007–1025",
      "citeRegEx" : "36",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Large margin methods for structured and interdependent output variables",
      "author" : [ "I. Tsochantaridis", "T. Joachims", "T. Hofmann", "Y. Altun" ],
      "venue" : "JMLR, 6:1453–1484",
      "citeRegEx" : "37",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Ranking with ordered weighted pairwise classification",
      "author" : [ "N. Usunier", "D. Buffoni", "P. Gallinari" ],
      "venue" : "ICML, pages 1057–1064, Montreal, Canada",
      "citeRegEx" : "38",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Learning to rank by optimizing NDCG measure",
      "author" : [ "H. Valizadegan", "R. Jin", "R. Zhang", "J. Mao" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 2009
    }, {
      "title" : "Multi-label learning with PRO loss",
      "author" : [ "M. Xu", "Y.-F. Li", "Z.-H. Zhou" ],
      "venue" : "AAAI, pages 998–1004",
      "citeRegEx" : "40",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Nyström method vs random Fourier features: A theoretical and empirical comparison",
      "author" : [ "T. Yang", "Y.-F. Li", "M. Mahdavi", "R. Jin", "Z.-H. Zhou" ],
      "venue" : "NIPS, pages 485–493. MIT Press",
      "citeRegEx" : "41",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "A support vector method for optimizing average precision",
      "author" : [ "Y. Yue", "T. Finley", "F. Radlinski", "T. Joachims" ],
      "venue" : "SIGIR, pages 271–278",
      "citeRegEx" : "42",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Online AUC maximization",
      "author" : [ "P. Zhao", "S.C.H. Hoi", "R. Jin", "T. Yang" ],
      "venue" : "ICML, pages 233–240, Bellevue, WA",
      "citeRegEx" : "43",
      "shortCiteRegEx" : null,
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 31,
      "context" : "It has attracted much attention because of its applications in several areas such as information retrieval and recommender systems [32, 25].",
      "startOffset" : 131,
      "endOffset" : 139
    }, {
      "referenceID" : 24,
      "context" : "It has attracted much attention because of its applications in several areas such as information retrieval and recommender systems [32, 25].",
      "startOffset" : 131,
      "endOffset" : 139
    }, {
      "referenceID" : 15,
      "context" : "These algorithms reduce the ranking problem into a binary classification problem by treating each positivenegative instance pair as a single object to be classified [16, 12, 5, 39, 38, 33, 1, 3].",
      "startOffset" : 165,
      "endOffset" : 194
    }, {
      "referenceID" : 11,
      "context" : "These algorithms reduce the ranking problem into a binary classification problem by treating each positivenegative instance pair as a single object to be classified [16, 12, 5, 39, 38, 33, 1, 3].",
      "startOffset" : 165,
      "endOffset" : 194
    }, {
      "referenceID" : 4,
      "context" : "These algorithms reduce the ranking problem into a binary classification problem by treating each positivenegative instance pair as a single object to be classified [16, 12, 5, 39, 38, 33, 1, 3].",
      "startOffset" : 165,
      "endOffset" : 194
    }, {
      "referenceID" : 38,
      "context" : "These algorithms reduce the ranking problem into a binary classification problem by treating each positivenegative instance pair as a single object to be classified [16, 12, 5, 39, 38, 33, 1, 3].",
      "startOffset" : 165,
      "endOffset" : 194
    }, {
      "referenceID" : 37,
      "context" : "These algorithms reduce the ranking problem into a binary classification problem by treating each positivenegative instance pair as a single object to be classified [16, 12, 5, 39, 38, 33, 1, 3].",
      "startOffset" : 165,
      "endOffset" : 194
    }, {
      "referenceID" : 32,
      "context" : "These algorithms reduce the ranking problem into a binary classification problem by treating each positivenegative instance pair as a single object to be classified [16, 12, 5, 39, 38, 33, 1, 3].",
      "startOffset" : 165,
      "endOffset" : 194
    }, {
      "referenceID" : 0,
      "context" : "These algorithms reduce the ranking problem into a binary classification problem by treating each positivenegative instance pair as a single object to be classified [16, 12, 5, 39, 38, 33, 1, 3].",
      "startOffset" : 165,
      "endOffset" : 194
    }, {
      "referenceID" : 2,
      "context" : "These algorithms reduce the ranking problem into a binary classification problem by treating each positivenegative instance pair as a single object to be classified [16, 12, 5, 39, 38, 33, 1, 3].",
      "startOffset" : 165,
      "endOffset" : 194
    }, {
      "referenceID" : 6,
      "context" : "Considering that for applications such as document retrieval and recommender systems, only the top ranked instances will be examined by users, there has been a growing interest in learning ranking functions that perform especially well at the top of the ranked list [7, 39, 38, 33, 1, 3, 27, 40].",
      "startOffset" : 266,
      "endOffset" : 295
    }, {
      "referenceID" : 38,
      "context" : "Considering that for applications such as document retrieval and recommender systems, only the top ranked instances will be examined by users, there has been a growing interest in learning ranking functions that perform especially well at the top of the ranked list [7, 39, 38, 33, 1, 3, 27, 40].",
      "startOffset" : 266,
      "endOffset" : 295
    }, {
      "referenceID" : 37,
      "context" : "Considering that for applications such as document retrieval and recommender systems, only the top ranked instances will be examined by users, there has been a growing interest in learning ranking functions that perform especially well at the top of the ranked list [7, 39, 38, 33, 1, 3, 27, 40].",
      "startOffset" : 266,
      "endOffset" : 295
    }, {
      "referenceID" : 32,
      "context" : "Considering that for applications such as document retrieval and recommender systems, only the top ranked instances will be examined by users, there has been a growing interest in learning ranking functions that perform especially well at the top of the ranked list [7, 39, 38, 33, 1, 3, 27, 40].",
      "startOffset" : 266,
      "endOffset" : 295
    }, {
      "referenceID" : 0,
      "context" : "Considering that for applications such as document retrieval and recommender systems, only the top ranked instances will be examined by users, there has been a growing interest in learning ranking functions that perform especially well at the top of the ranked list [7, 39, 38, 33, 1, 3, 27, 40].",
      "startOffset" : 266,
      "endOffset" : 295
    }, {
      "referenceID" : 2,
      "context" : "Considering that for applications such as document retrieval and recommender systems, only the top ranked instances will be examined by users, there has been a growing interest in learning ranking functions that perform especially well at the top of the ranked list [7, 39, 38, 33, 1, 3, 27, 40].",
      "startOffset" : 266,
      "endOffset" : 295
    }, {
      "referenceID" : 26,
      "context" : "Considering that for applications such as document retrieval and recommender systems, only the top ranked instances will be examined by users, there has been a growing interest in learning ranking functions that perform especially well at the top of the ranked list [7, 39, 38, 33, 1, 3, 27, 40].",
      "startOffset" : 266,
      "endOffset" : 295
    }, {
      "referenceID" : 39,
      "context" : "Considering that for applications such as document retrieval and recommender systems, only the top ranked instances will be examined by users, there has been a growing interest in learning ranking functions that perform especially well at the top of the ranked list [7, 39, 38, 33, 1, 3, 27, 40].",
      "startOffset" : 266,
      "endOffset" : 295
    }, {
      "referenceID" : 16,
      "context" : "The first group maximizes the ranking accuracy at the top of the ranked list by optimizing task specific metrics [17, 21, 23, 40], such as average precision (AP) [42], NDCG [39] and partial AUC [27, 28].",
      "startOffset" : 113,
      "endOffset" : 129
    }, {
      "referenceID" : 20,
      "context" : "The first group maximizes the ranking accuracy at the top of the ranked list by optimizing task specific metrics [17, 21, 23, 40], such as average precision (AP) [42], NDCG [39] and partial AUC [27, 28].",
      "startOffset" : 113,
      "endOffset" : 129
    }, {
      "referenceID" : 22,
      "context" : "The first group maximizes the ranking accuracy at the top of the ranked list by optimizing task specific metrics [17, 21, 23, 40], such as average precision (AP) [42], NDCG [39] and partial AUC [27, 28].",
      "startOffset" : 113,
      "endOffset" : 129
    }, {
      "referenceID" : 39,
      "context" : "The first group maximizes the ranking accuracy at the top of the ranked list by optimizing task specific metrics [17, 21, 23, 40], such as average precision (AP) [42], NDCG [39] and partial AUC [27, 28].",
      "startOffset" : 113,
      "endOffset" : 129
    }, {
      "referenceID" : 41,
      "context" : "The first group maximizes the ranking accuracy at the top of the ranked list by optimizing task specific metrics [17, 21, 23, 40], such as average precision (AP) [42], NDCG [39] and partial AUC [27, 28].",
      "startOffset" : 162,
      "endOffset" : 166
    }, {
      "referenceID" : 38,
      "context" : "The first group maximizes the ranking accuracy at the top of the ranked list by optimizing task specific metrics [17, 21, 23, 40], such as average precision (AP) [42], NDCG [39] and partial AUC [27, 28].",
      "startOffset" : 173,
      "endOffset" : 177
    }, {
      "referenceID" : 26,
      "context" : "The first group maximizes the ranking accuracy at the top of the ranked list by optimizing task specific metrics [17, 21, 23, 40], such as average precision (AP) [42], NDCG [39] and partial AUC [27, 28].",
      "startOffset" : 194,
      "endOffset" : 202
    }, {
      "referenceID" : 27,
      "context" : "The first group maximizes the ranking accuracy at the top of the ranked list by optimizing task specific metrics [17, 21, 23, 40], such as average precision (AP) [42], NDCG [39] and partial AUC [27, 28].",
      "startOffset" : 194,
      "endOffset" : 202
    }, {
      "referenceID" : 36,
      "context" : "Structural SVM [37] addresses this issue by translating the non-convexity into an exponential number of constraints.",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 35,
      "context" : "In addition, these methods are statistically inconsistent [36, 21], leading to suboptimal solutions.",
      "startOffset" : 58,
      "endOffset" : 66
    }, {
      "referenceID" : 20,
      "context" : "In addition, these methods are statistically inconsistent [36, 21], leading to suboptimal solutions.",
      "startOffset" : 58,
      "endOffset" : 66
    }, {
      "referenceID" : 37,
      "context" : "They design special convex loss functions that place more penalties on the ranking errors related to the top ranked instances [38, 33, 1].",
      "startOffset" : 126,
      "endOffset" : 137
    }, {
      "referenceID" : 32,
      "context" : "They design special convex loss functions that place more penalties on the ranking errors related to the top ranked instances [38, 33, 1].",
      "startOffset" : 126,
      "endOffset" : 137
    }, {
      "referenceID" : 0,
      "context" : "They design special convex loss functions that place more penalties on the ranking errors related to the top ranked instances [38, 33, 1].",
      "startOffset" : 126,
      "endOffset" : 137
    }, {
      "referenceID" : 32,
      "context" : "One deficiency of the existing theoretical studies [33, 1] on bipartite ranking is that they try to bound the probability for a positive instance to be ranked before any negative instance, leading to relatively pessimistic bounds.",
      "startOffset" : 51,
      "endOffset" : 58
    }, {
      "referenceID" : 0,
      "context" : "One deficiency of the existing theoretical studies [33, 1] on bipartite ranking is that they try to bound the probability for a positive instance to be ranked before any negative instance, leading to relatively pessimistic bounds.",
      "startOffset" : 51,
      "endOffset" : 58
    }, {
      "referenceID" : 31,
      "context" : "In the literature, bipartite ranking has found applications in many domains [32, 25], and its theoretical properties have been examined by several studies [2, 6, 20, 26].",
      "startOffset" : 76,
      "endOffset" : 84
    }, {
      "referenceID" : 24,
      "context" : "In the literature, bipartite ranking has found applications in many domains [32, 25], and its theoretical properties have been examined by several studies [2, 6, 20, 26].",
      "startOffset" : 76,
      "endOffset" : 84
    }, {
      "referenceID" : 1,
      "context" : "In the literature, bipartite ranking has found applications in many domains [32, 25], and its theoretical properties have been examined by several studies [2, 6, 20, 26].",
      "startOffset" : 155,
      "endOffset" : 169
    }, {
      "referenceID" : 5,
      "context" : "In the literature, bipartite ranking has found applications in many domains [32, 25], and its theoretical properties have been examined by several studies [2, 6, 20, 26].",
      "startOffset" : 155,
      "endOffset" : 169
    }, {
      "referenceID" : 19,
      "context" : "In the literature, bipartite ranking has found applications in many domains [32, 25], and its theoretical properties have been examined by several studies [2, 6, 20, 26].",
      "startOffset" : 155,
      "endOffset" : 169
    }, {
      "referenceID" : 25,
      "context" : "In the literature, bipartite ranking has found applications in many domains [32, 25], and its theoretical properties have been examined by several studies [2, 6, 20, 26].",
      "startOffset" : 155,
      "endOffset" : 169
    }, {
      "referenceID" : 14,
      "context" : "AUC is a commonly used evaluation metric for bipartite ranking [15, 9].",
      "startOffset" : 63,
      "endOffset" : 70
    }, {
      "referenceID" : 8,
      "context" : "AUC is a commonly used evaluation metric for bipartite ranking [15, 9].",
      "startOffset" : 63,
      "endOffset" : 70
    }, {
      "referenceID" : 14,
      "context" : "By exploring its equivalence to Wilcoxon-Mann-Whitney statistic [15], many ranking algorithms have been developed to optimize AUC by minimizing the ranking loss defined as",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 32,
      "context" : ", exponential and logistic loss) [33, 20], most of these methods need to enumerate all the positive-negative instance pairs, making them unattractive for large datasets.",
      "startOffset" : 33,
      "endOffset" : 41
    }, {
      "referenceID" : 19,
      "context" : ", exponential and logistic loss) [33, 20], most of these methods need to enumerate all the positive-negative instance pairs, making them unattractive for large datasets.",
      "startOffset" : 33,
      "endOffset" : 41
    }, {
      "referenceID" : 42,
      "context" : "Various methods have been developed to address this computational challenge [43, 13].",
      "startOffset" : 76,
      "endOffset" : 84
    }, {
      "referenceID" : 12,
      "context" : "Various methods have been developed to address this computational challenge [43, 13].",
      "startOffset" : 76,
      "endOffset" : 84
    }, {
      "referenceID" : 6,
      "context" : "Recently, there is a growing interest on optimizing ranking accuracy at the top [7, 3].",
      "startOffset" : 80,
      "endOffset" : 86
    }, {
      "referenceID" : 2,
      "context" : "Recently, there is a growing interest on optimizing ranking accuracy at the top [7, 3].",
      "startOffset" : 80,
      "endOffset" : 86
    }, {
      "referenceID" : 6,
      "context" : "Maximizing AUC is not suitable for this goal as indicated by the analysis in [7].",
      "startOffset" : 77,
      "endOffset" : 80
    }, {
      "referenceID" : 32,
      "context" : "To address this challenge, we propose to maximize the number of positive instances that are ranked before the first negative instance, which is known as positives at the top [33, 1, 3].",
      "startOffset" : 174,
      "endOffset" : 184
    }, {
      "referenceID" : 0,
      "context" : "To address this challenge, we propose to maximize the number of positive instances that are ranked before the first negative instance, which is known as positives at the top [33, 1, 3].",
      "startOffset" : 174,
      "endOffset" : 184
    }, {
      "referenceID" : 2,
      "context" : "To address this challenge, we propose to maximize the number of positive instances that are ranked before the first negative instance, which is known as positives at the top [33, 1, 3].",
      "startOffset" : 174,
      "endOffset" : 184
    }, {
      "referenceID" : 21,
      "context" : "More discussion about the relationship between (1) and (2) can be found in the longer version of the paper [22].",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 0,
      "context" : "It is easy to verify that the loss L(f ;S) in (3) is equivalent to the loss used in InfinitePush [1] (a special case of P -norm Push [33]), i.",
      "startOffset" : 97,
      "endOffset" : 100
    }, {
      "referenceID" : 32,
      "context" : "It is easy to verify that the loss L(f ;S) in (3) is equivalent to the loss used in InfinitePush [1] (a special case of P -norm Push [33]), i.",
      "startOffset" : 133,
      "endOffset" : 137
    }, {
      "referenceID" : 0,
      "context" : "As a result, the number of dual variables induced by L(f ;S) is n+m, linear in the number of training instances, which is significantly smaller than mn, the number of dual variables induced by L∞(f ;S) [1, 31].",
      "startOffset" : 202,
      "endOffset" : 209
    }, {
      "referenceID" : 30,
      "context" : "As a result, the number of dual variables induced by L(f ;S) is n+m, linear in the number of training instances, which is significantly smaller than mn, the number of dual variables induced by L∞(f ;S) [1, 31].",
      "startOffset" : 202,
      "endOffset" : 209
    }, {
      "referenceID" : 3,
      "context" : "Specifically, given a convex and differentiable function `(z), we can rewrite it in its convex conjugate form as `(z) = maxα∈Ω αz − `∗(α) , where `∗(α) is the convex conjugate of `(z) and Ω is the domain of dual variable [4].",
      "startOffset" : 221,
      "endOffset" : 224
    }, {
      "referenceID" : 34,
      "context" : "We note that dual form has been widely used to improve computational efficiency [35] and connect different styles of learning algorithms [19].",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 18,
      "context" : "We note that dual form has been widely used to improve computational efficiency [35] and connect different styles of learning algorithms [19].",
      "startOffset" : 137,
      "endOffset" : 141
    }, {
      "referenceID" : 21,
      "context" : "The dual form of (5) is given in the following theorem, whose detailed proof can be found in the longer version [22].",
      "startOffset" : 112,
      "endOffset" : 116
    }, {
      "referenceID" : 0,
      "context" : "This is in contrast to the InfinitPush algorithm in [1] that introduces mn dual variables and a higher computational cost.",
      "startOffset" : 52,
      "endOffset" : 55
    }, {
      "referenceID" : 3,
      "context" : "It is well known in the literature of optimization [4] that an O(1/T (2)) convergence rate can be achieved if the objective function is smooth, where T is the number of iterations; this also helps in designing efficient learning algorithm.",
      "startOffset" : 51,
      "endOffset" : 54
    }, {
      "referenceID" : 29,
      "context" : "Specifically, we choose the Nesterov’s method [30, 29] that achieves an optimal convergence rate O(1/T (2)) for smooth objective function.",
      "startOffset" : 46,
      "endOffset" : 54
    }, {
      "referenceID" : 28,
      "context" : "Specifically, we choose the Nesterov’s method [30, 29] that achieves an optimal convergence rate O(1/T (2)) for smooth objective function.",
      "startOffset" : 46,
      "endOffset" : 54
    }, {
      "referenceID" : 33,
      "context" : "We note that similar projection problems have been studied in [34, 24] where they either have O((m + n) log(m + n)) time complexity [34] or only provide approximate solutions [24].",
      "startOffset" : 62,
      "endOffset" : 70
    }, {
      "referenceID" : 23,
      "context" : "We note that similar projection problems have been studied in [34, 24] where they either have O((m + n) log(m + n)) time complexity [34] or only provide approximate solutions [24].",
      "startOffset" : 62,
      "endOffset" : 70
    }, {
      "referenceID" : 33,
      "context" : "We note that similar projection problems have been studied in [34, 24] where they either have O((m + n) log(m + n)) time complexity [34] or only provide approximate solutions [24].",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 23,
      "context" : "We note that similar projection problems have been studied in [34, 24] where they either have O((m + n) log(m + n)) time complexity [34] or only provide approximate solutions [24].",
      "startOffset" : 175,
      "endOffset" : 179
    }, {
      "referenceID" : 23,
      "context" : "By using proof technique similar to that for Theorem 2 in [24], we can prove the following proposition: Proposition 1.",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 23,
      "context" : "Instead of approximating the solution via bisection as in [24], we develop a divide-and-conquer method to find the exact solution of γ∗ in O(m + n) time, where a similar approach has been used in [10].",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 9,
      "context" : "Instead of approximating the solution via bisection as in [24], we develop a divide-and-conquer method to find the exact solution of γ∗ in O(m + n) time, where a similar approach has been used in [10].",
      "startOffset" : 196,
      "endOffset" : 200
    }, {
      "referenceID" : 7,
      "context" : "The basic idea is to first identify the smallest interval that contains the root based on a modification of the randomized median finding algorithm [8], and then solve the root exactly based on the interval.",
      "startOffset" : 148,
      "endOffset" : 151
    }, {
      "referenceID" : 21,
      "context" : "The detailed projection procedure can be found in the longer version [22].",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 28,
      "context" : "In current work we adopt the Nemirovski’s line search scheme [29] to compute the smoothness parameter, and the detailed algorithm can be found in [22].",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 21,
      "context" : "In current work we adopt the Nemirovski’s line search scheme [29] to compute the smoothness parameter, and the detailed algorithm can be found in [22].",
      "startOffset" : 146,
      "endOffset" : 150
    }, {
      "referenceID" : 17,
      "context" : "Algorithm Computational Complexity SVMRank [18] O (( (m+ n)d+ (m+ n) log(m+ n) ) / )",
      "startOffset" : 43,
      "endOffset" : 47
    }, {
      "referenceID" : 41,
      "context" : "SVMMAP [42] O (( (m+ n)d+ (m+ n) log(m+ n) ) / )",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 37,
      "context" : "OWPC [38] O (( (m+ n)d+ (m+ n) log(m+ n) ) / )",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 26,
      "context" : "SVMpAUC [27, 28] O (( n logn+m logm+ (m+ n)d ) / )",
      "startOffset" : 8,
      "endOffset" : 16
    }, {
      "referenceID" : 27,
      "context" : "SVMpAUC [27, 28] O (( n logn+m logm+ (m+ n)d ) / )",
      "startOffset" : 8,
      "endOffset" : 16
    }, {
      "referenceID" : 0,
      "context" : "InfinitePush [1] O (( mnd+mn log(mn) ) / 2 )",
      "startOffset" : 13,
      "endOffset" : 16
    }, {
      "referenceID" : 28,
      "context" : "The theorem below states the convergence of the TopPush algorithm, which follows immediately from the convergence result for the Nesterov’s method [29].",
      "startOffset" : 147,
      "endOffset" : 151
    }, {
      "referenceID" : 32,
      "context" : "In [33, 1], the authors have developed margin-based generalization bounds for the loss function L∞ .",
      "startOffset" : 3,
      "endOffset" : 10
    }, {
      "referenceID" : 0,
      "context" : "In [33, 1], the authors have developed margin-based generalization bounds for the loss function L∞ .",
      "startOffset" : 3,
      "endOffset" : 10
    }, {
      "referenceID" : 32,
      "context" : "One limitation with the analysis in [33, 1] is that they try to bound the probability for a positive instance to be ranked before any negative instance, leading to relatively pessimistic bounds5.",
      "startOffset" : 36,
      "endOffset" : 43
    }, {
      "referenceID" : 0,
      "context" : "One limitation with the analysis in [33, 1] is that they try to bound the probability for a positive instance to be ranked before any negative instance, leading to relatively pessimistic bounds5.",
      "startOffset" : 36,
      "endOffset" : 43
    }, {
      "referenceID" : 21,
      "context" : "The following theorem bounds Pb(w, δ) for TopPush, and the detailed proof can be found in the longer version [22].",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 27,
      "context" : "In Table 1, we report the complexity of SVM tight in [28], which is more efficient than SVM pAUC in [27].",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 26,
      "context" : "In Table 1, we report the complexity of SVM tight in [28], which is more efficient than SVM pAUC in [27].",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 32,
      "context" : "(5)For instance, for the bounds in [33], the failure probability can be as large as 1 if the parameter p is large.",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 0,
      "context" : "Some of them were used in previous studies [1, 31, 3], and others are larger datasets from different domains.",
      "startOffset" : 43,
      "endOffset" : 53
    }, {
      "referenceID" : 30,
      "context" : "Some of them were used in previous studies [1, 31, 3], and others are larger datasets from different domains.",
      "startOffset" : 43,
      "endOffset" : 53
    }, {
      "referenceID" : 2,
      "context" : "Some of them were used in previous studies [1, 31, 3], and others are larger datasets from different domains.",
      "startOffset" : 43,
      "endOffset" : 53
    }, {
      "referenceID" : 41,
      "context" : "We compare TopPush with state-of-the-art algorithms that focus on accuracy at the top, including SVM [42], SVM [28] with α = 0 and β = 1/n, AATP [3] and InfinitePush [1].",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 27,
      "context" : "We compare TopPush with state-of-the-art algorithms that focus on accuracy at the top, including SVM [42], SVM [28] with α = 0 and β = 1/n, AATP [3] and InfinitePush [1].",
      "startOffset" : 111,
      "endOffset" : 115
    }, {
      "referenceID" : 2,
      "context" : "We compare TopPush with state-of-the-art algorithms that focus on accuracy at the top, including SVM [42], SVM [28] with α = 0 and β = 1/n, AATP [3] and InfinitePush [1].",
      "startOffset" : 145,
      "endOffset" : 148
    }, {
      "referenceID" : 0,
      "context" : "We compare TopPush with state-of-the-art algorithms that focus on accuracy at the top, including SVM [42], SVM [28] with α = 0 and β = 1/n, AATP [3] and InfinitePush [1].",
      "startOffset" : 166,
      "endOffset" : 169
    }, {
      "referenceID" : 17,
      "context" : "In addition, for completeness, several state-of-the-art classification and ranking models are included in the comparison: logistic regression (LR) for binary classification, cost-sensitive SVM (cs-SVM) that addresses imbalance class distribution by introducing a different misclassification cost for each class, and SVM [18] for AUC optimization.",
      "startOffset" : 320,
      "endOffset" : 324
    }, {
      "referenceID" : 13,
      "context" : "We implement TopPush and InfinitePush using MATLAB, implement AATP using CVX [14], and use LIBLINEAR [11] for LR and cs-SVM, and use the codes shared by the authors of the original works.",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 10,
      "context" : "We implement TopPush and InfinitePush using MATLAB, implement AATP using CVX [14], and use LIBLINEAR [11] for LR and cs-SVM, and use the codes shared by the authors of the original works.",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 0,
      "context" : "We measure the accuracy at the top by commonly used metrics6: (i) positives at the top (Pos@Top) [1, 31, 3], which is defined as the fraction of positive instances ranked above the topranked negative, (ii) average precision (AP) and (iii) normalized DCG scores (NDCG).",
      "startOffset" : 97,
      "endOffset" : 107
    }, {
      "referenceID" : 30,
      "context" : "We measure the accuracy at the top by commonly used metrics6: (i) positives at the top (Pos@Top) [1, 31, 3], which is defined as the fraction of positive instances ranked above the topranked negative, (ii) average precision (AP) and (iii) normalized DCG scores (NDCG).",
      "startOffset" : 97,
      "endOffset" : 107
    }, {
      "referenceID" : 2,
      "context" : "We measure the accuracy at the top by commonly used metrics6: (i) positives at the top (Pos@Top) [1, 31, 3], which is defined as the fraction of positive instances ranked above the topranked negative, (ii) average precision (AP) and (iii) normalized DCG scores (NDCG).",
      "startOffset" : 97,
      "endOffset" : 107
    }, {
      "referenceID" : 21,
      "context" : "It is worth mentioning that we also measure the ranking performance by AUC, and the results can be found in [22].",
      "startOffset" : 108,
      "endOffset" : 112
    } ],
    "year" : 2014,
    "abstractText" : "Bipartite ranking aims to learn a real-valued ranking function that orders positive instances before negative instances. Recent efforts of bipartite ranking are focused on optimizing ranking accuracy at the top of the ranked list. Most existing approaches are either to optimize task specific metrics or to extend the rank loss by emphasizing more on the error associated with the top ranked instances, leading to a high computational cost that is super-linear in the number of training instances. We propose a highly efficient approach, titled TopPush, for optimizing accuracy at the top that has computational complexity linear in the number of training instances. We present a novel analysis that bounds the generalization error for the top ranked instances for the proposed approach. Empirical study shows that the proposed approach is highly competitive to the state-of-the-art approaches and is 10-100 times faster.",
    "creator" : null
  }
}