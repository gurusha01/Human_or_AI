{"title": "Online Rank Elicitation for Plackett-Luce: A Dueling Bandits Approach", "abstract": "We study the problem of online rank elicitation, assuming that rankings of a set of alternatives obey the Plackett-Luce distribution. Following the setting of the dueling bandits problem, the learner is allowed to query pairwise comparisons between alternatives, i.e., to sample pairwise marginals of the distribution in an online fashion. Using this information, the learner seeks to reliably predict the most probable ranking (or top-alternative). Our approach is based on constructing a surrogate probability distribution over rankings based on a sorting procedure, for which the pairwise marginals provably coincide with the marginals of the Plackett-Luce distribution. In addition to a formal performance and complexity analysis, we present first experimental studies.", "id": "7eacb532570ff6858afd2723755ff790", "authors": ["Bal\u00e1zs Sz\u00f6r\u00e9nyi", "R\u00f3bert Busa-Fekete", "Adil Paul", "Eyke H\u00fcllermeier"], "conference": "NIPS2015", "accepted": true, "reviews": [{"comments": "Small comments:\n\n- It should be mentioned explicitly somewhere that the pairwise marginals of the PL model are just a BTL distribution\n\n- Rem 5: the bound in [25] is for exact recovery, that given here for approximate recovery; this should be made clear\n\n- sec 9.1: several places: c or m [= --> \\in] {range}\n\n- p.7, last line: horizontal --> vertical\n\n- sec 9.2: another interesting experiment would be to compare with rank centrality in terms of not optimal recovery fraction, but say fraction of times an \\epsilon-optimal ranking is recovered (for some \\epsilon > 0); does your algorithm give better sample complexity in that case?\n\n The paper considers the problem of identifying (approximately) the most probable ranking over n items - or just the top-ranked item - assuming an underlying Plackett-Luce (PL) distribution, from active queries of pairwise comparisons from the distribution (this type of problem is also known as a dueling bandits problem). It proposes algorithms for both settings (identifying full ranking and identifying top-ranked item) based on a budgeted quicksort procedure that is shown to preserve pairwise comparison probabilities under the PL distribution. The paper gives query complexity bounds for both settings. Experiments show that under the PL model, the algorithm for finding the top item outperforms several other recently proposed algorithms. On the other hand, the algorithm for finding a full ranking does not outperform a simple passive sampling algorithm that uses a naive uniform sampling strategy, leaving open the possibility of designing a better active algorithm in this case.The paper is exceptionally well written and has interesting results and very well-designed experiments.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "In the setting of dueling bandits and under the PL model assumption, the authors consider two tasks: finding an approximate best arm and finding an approximate ranking of the arms. Both tasks relates to the estimations of the pairwise marginals of the underlying PL model, which is done with an early-stopped version of the QuickSort. This Budgeted QuickSort allows to build algorithms which sample complexity is O(M log^2 M). Experiments compare the sample complexity of the proposed algorithms against state-of-art methods.\n\nThe problem is not well-motivated, which is even more visible by the lack of experiments based on real-world dataset. This been said, I like the algorithms for their simplicity and the theoretical study that support them is correct. I didn't check proofs in appendix, but the results seems realistic. I would have appreciated a little discussion about the choice of the method to build confidence intervals in PLPAC -- e.g. is the algorithm sensitive to the method ?\n\nThe paper is correctly organized and reasonably easy to follow. I still find a bit curious to put an algorithm (AMPR-PLPAC) in supplementary material.\n\nAs I was saying, the problem is not well-motivated but the gain in terms of sample conplexity over existing algorithms is significant. The algorithm is interesting, the theoretical study is complete. However, problem is not well-motivated and looks like a niche problem. This feeling is strengthen by the experiments that are only on synthetic data.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper proposes the use of a (Budgeted) Quick-Sort algorithm for the rank elicitation problem (in the dueling bandits setting). The algorithm works by fitting the observations to those observed under a Plackett-Luce distribution. Under this assumption the model is then analyzed theoretically and studied empirically.\n\nWhile I like the overall idea in the paper, I had a few concerns starting with the restrictiveness of the model. Compared to closely related work, such as the vast work on the Dueling Bandits, the model here is analyzed under a very strict assumption of having been generated under a P-L model. Given that both the theoretical and empirical analysis is under this assumption, I'm unclear how impactful this will be given other existing algorithm. Some analysis and experimentation with even the smallest amount of violation from this P-L assumption would have added significant value in my opinion (given that real world data has no guarantees of coming from a P-L model). I also would have preferred ranking metrics to study performance at the AMPR problem in addition to optimal recovery rate, to better understand where the errors lie. Interesting application of QuickSort to the dueling bandits problem. However unsure of impact due to limiting model assumptions.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The authors propose an elicitation algorithm to compute the ranking over alternatives w.r.t. their parameters in Placket-Luce. The elicitation is guided quick sort and the sample complexity is bounded.\n\nThe paper is very well written. It clearly made a solid contribution to a natural and important problem. It would be nicer to see an lower bound on the sample complexity in the PAC framework for the problem considered in the paper. The main reason for not giving a higher recommendation is the presence of [1], which seems to have most of the conceptual setup of the model and problem. This is a clearly-written paper that made a solid (but not earthshaking) contribution to elicitation under the Plackett-Luce model.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "In this paper, the authors present dueling bandit approach where the arms are assumed to be ranked according to Placket-Luce distribution.\n\nTypically, bandit problems have regret analysis. What is presented in this paper is sample complexity: the number of samples required to obtain an \\epsilon-optimal arm with probability 1 - \\delta. I did not see any discussion about the regret bounds of the proposed algorithms. Also, how does the regret bound of the proposed algorithm compare with that of other existing\n\ndueling bandit algorithms? It was not clear from reading the paper.\n\nI think that one major limitation of the paper is that the experiments are based on synthetic data. It is not clear when the PL distribution assumption holds and to what problems, the proposed approach is applicable. The experiments seem too artificial.\n\nOther comments:\n\nLine 202: what is \"end\" after [M],?\n\nLine 7, algorithm 2, N should be \\hat{N}?\n\nThe authors present an algorithm in Supplementary material and its analysis in the main paper. I think it should be other way round.  Yet another approach for dueling bandit. Experiments are weak, it is not clear from the paper how the proposed method is better than existing approaches.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The authors have done a very good job in explaining the relevant literature in online preference based mechanisms. Both PAC-item and AMPR preference-based approximations are considered as goals for the problem of dueling bandit ranker. The authors build upon the fact that the pairwise comparisons executed by QuickSort algorithm in a stochastic setting are drawn from the pairwise marginals of the Plackett-Luce model. The idea of the Budgeted Quick-sort based algorithm seems simple enough -- however, I am not entirely convinced about its novelty. The elimination strategy used both for the PAC problem and the AMPR seems very intuitive (eliminate an item significantly beaten by another item). For the AMPR problem the authors estimate the Copeland score for every item. One contribution of the paper is that the authors give sample complexity bounds for both PAC and AMPR. The synthetic data results mostly follow the bounds covered in the theorems. One note is that the Condorcet winner is too restrictive of an assumption, thus \"forcing\" the authors to focus on the Placket Luce model which satisfies its existence.\n\n The contribution of this paper is to use a budgeted version of Quicksort to construct surrogate probability distributions over rankings. Based on the fact that the pairwise marginals using Quicksort coincide with the marginals of the Plackett Luce mode, they are able to take advantage of the transitivity properties of Placket-Luce.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
