{"title": "A hybrid sampler for Poisson-Kingman mixture models", "abstract": "This paper concerns the introduction of a new Markov Chain Monte Carlo scheme for posterior sampling in Bayesian nonparametric mixture models with priors that belong to the general Poisson-Kingman class. We present a novel and compact way of representing the infinite dimensional component of the model such that while explicitly representing this infinite component it has less memory and storage requirements than previous MCMC schemes. We describe  comparative  simulation  results  demonstrating  the  efficacy  of  the  proposed MCMC algorithm against existing marginal and conditional MCMC samplers.", "id": "459a4ddcb586f24efd9395aa7662bc7c", "authors": ["Maria Lomeli", "Stefano Favaro", "Yee Whye Teh"], "conference": "NIPS2015", "accepted": true, "reviews": [{"comments": "Summary:\n\n The authors present a new MCMC method for a general class of bayesian nonparametric models, namely Poisson-Kingman random probability measures.\n\nThey describe the class of models, the generative procedure and the insight that yields an mcmc routine for inference, as well as existing methods for the same/similar class of models, namely marginal and conditional samplers. They compare their sampler to standard marginal and conditional samplers, comparing effective sample size and running time.\n\n - Quality\n\nThis paper develops an inference method for a very general class of models.\n\nIt seems technically sound and provides an adequate summary of existing methods and how they relate to the method they present.\n\n - Clarity\n\nThis paper isn't that clearly written, which may be due to the page limit.\n\nFor instance, it is very difficult to decipher the notation in the generative procedure of section 2.1, which is arguably the most important section for appreciating the authors' contribution.\n\n - Originality\n\n It is my understanding that a sampler for this general class of models is novel.\n\n - Significance\n\n If the idea were presented more fluidly, this paper could serve as a nice review and reference for this type of sampler.\n\nI think the idea has the potential to be impactful, but may fall short due to presentation.\n\n Comments:\n\n- A figure or diagram of your generative process (the stick breaking construction) and how it is distinct from the standard DP stick breaking construction of Ishwaran and James would make section 2 (as well as your methodological contribution in general) easier to understand.\n\n  This paper seems technically sound and potentially impactful, but needs work on presentation of its ideas.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "Overall I liked the paper although at times it is difficult to follow. The authors make a good effort at going from the process interpretation to the generative model interpretation and also repeatedly pointed out the main goal to achieve by their proposed method. If they can match it with extensive experiments I think this will be a great paper.\n\n The authors have answered my questions on experiments in their rebuttal and I hope that these details will be added in the final version. The paper presents a Hybrid MCMC sampler for Poisson-Kingman mixture model. It combines the usefulness of conditional and marginal sampler. The authors claim that this reduces the memory requirement while increasing mixing.My main criticism is with respect to the experiments done in this paper. They have shown result on uni-dimensional dataset without any experiments to show that their method is not effected with increasing dimension or size of datasets. Nor is their any experiment to show how significant of a reduction in memory requirement they get which has been mentioned as one of the main reasons for which this method should be used. This is why I did not give this paper a 7 score. I would request the authors to comment on this.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper proposes a new sampler for mixture models based on homogeneous completely random measures. The sampler is a hybrid of two existing classes of samplers and retains the favorable properties of each: the faster mixing times of the so-called conditional samplers, and the ability to exactly represent an infinite object with finite memory of the so-called marginal samplers. The paper uses results from Pitman's work on Poisson-Kingman partitions and size-biased sampling in order to derive a Gibbs sampling scheme for Poisson-Kingman mixture models. The authors show that the proposed sampler performs favorably, in terms of run time and of effective sample size, as compared to the existing conditional and marginal samplers.\n\nMixture models based on normalized CRMs have received an increasing amount of attention in the Bayesian non-parametrics literature in recent years, and the sampler proposed in this paper is a valuable tool for the community. The key technical insight is to represent the \"surplus mass\" as a variable in the sampler, and to obtain its complete conditional distribution by using Pitman's results on the joint distribution of the weights and the total mass of a CRM. The exposition is clear and the work is significant for the Bayesian non-parametrics community. The paper proposes an efficient sampler for a class of models that has received increasing attention in recent years. It is well-executed and clearly written, and provides an important tool for the Bayesian non-parametrics community.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
