{"title": "Online Prediction at the Limit of Zero Temperature", "abstract": "", "id": "cdf1035c34ec380218a8cc9a43d438f9", "authors": ["Mark Herbster", "Stephen Pasteris", "Shaona Ghosh"], "conference": "NIPS2015", "accepted": true, "reviews": [{"comments": "Online binary vertex classification over a graph. In the problem, initially the learner is provided with a graph $G$ and on each round, possibly adversarially a node from this graph is picked and the learner provides a label in $\\{0,1\\}$ for this node. Nature then reveals the true label $y_t$ for this node. The prediction made by the learner is based on the ising model when the temperature parameter approaches 0. However this is a compitationally hard problem to solve and so the authors propose an approximate scheme based on constructing Picard-Queyranne graphs that preserve combinatorial structure of minimum cuts. Now the learner makes predictions by playing an online game on the PQ graph instead. The authors provide a mistake bound for the algorithm. In the case when the graph is a tree the mistake bounds are comparable to treeopt algortihm\n\n I really liked the paper but it definitely was a hard read and the paper is not all that well written. Even the basic problem setup and description is staggered around in the first two sections. It would nice to give a bullet point type list to give a concise but complete description of the basic problem. The authors should also consider giving an informal proof outline and high level results in one of the first two sections. The 0-ising model is a very natural although intractable benchmark model to compare against. The comparison of the treeopt to the proposed algorithm is encouraging.The reduction to PG graphs and the prediciton PQ prediction game is interesting and novel\n\n Overall I believe the work is defintiely worth publishing. The problem considered is a very interesting one and has practical applications. The time complexity of the algorithm is order square of number of vertices which makes it suitable only for small to medium scale problems.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "Summary: -------- The paper studies prediction of labels on a graph, where the nodes are data points, the edges indicate similarity in label, and getting different labels on the sides of an edge is penalized. The authors analyze the problem in an online setting, and provide a general mistake bound (Thm. 4) that holds for any algorithm that has three properties: monotonicity (observing a label can only result in more predictions of that label), permutation-invariance (order of observations does not matter), and a \"Markov\" property (predictions on a node are influenced only by its immediate connections). Next, the authors provide two prediction strategies that satisfy these properties (Thm. 9), one of which (0-Ising) is computationally inefficient while the other (longest-path) has polynomial running time in the size of the graph. Finally, the authors show a per-cluster mistake bound for these two strategies (Thm. 10) that, combined with the general mistake bound of Thm. 4, results in a concrete bound for these two algorithms. The new bound retrieves the previous optimal bound on trees, while it still gives meaningful (in cases improved) bounds when the graph is not a tree.\n\nQuality and Clarity: -------------------- Generally, the paper is well-written: the setting, definitions, and logical steps are laid out and explained clearly, which makes the paper easy to read even for those who are not directly working in this area. There are some problems to fix, which I have mentioned at the end.\n\nThe theory seems to work, although I have not verified all the proofs in detail.\n\nOriginality and Significance: ----------------------------- The contribution that the paper lays out seems interesting and I think it will be useful for the community. However, I am not working in this area directly, so I leave a deeper comparison with the related work to other reviewers that are more familiar with the previous work in this particular area.\n\nOther issues: -------------\n\n- It is not specified what is the format of the max-flow returned in step 2 of Figure 1, which propagates to the definition of graph $$I$$ in step 3. In particular, in Figure 2(c), has 1->3->2 been in the max flow? If no, then why has 11->10->12 been there? If yes, then why are the edges 1-3 and 3-2 still in I? - On page 3, paragraph 2, line 7, please fix the definition of the set of edges of the quotient graph. - Perhaps the first sentence of Sec. 2 needs to be moved to the first page to become the first sentence of the last paragraph on that page. Then I think the phrase \"this graph\" on the third-to-last line on page 1 will have a close-by reference. - perhaps the references [3] and [4] on line 4 of the first paragraph are swapped.  This is a well-written paper. The theory seems to work and I think the contributions, as laid out in the paper, will be interesting to the community. However, I am not directly working in this specific area, so I leave it to the other reviewers to comment on the significance.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "** Summary of paper\n\n This paper presents a new online algorithm to predict label on a\n\n graph. The graph labeling prediction problem is motivated by\n\n semi-supervised learning where labeled and unlabeled are vertices\n\n on a graph and edges represent closeness of these data. This work\n\n uses an Ising model and seeks to optimize a bound on number of\n\n mistake made by the learner online given a constraint on the\n\n complexity of true labeling on the graph, such as the number of\n\n edges connecting disagreeing vertex in the graph.\n\n The paper exploits a transformation of the graph to Picard-Queyranne\n\n graph and analyses the mistake bounds for two prediction strategies\n\n via analysis of mistake bounds in PQ-games and per-cluster mistakes\n\n bounds. The final mistake bounds are compared with mistake bounds\n\n in existing literature.\n\n** Quality\n\n The final results reproduce the optimal result for online\n\n labelling problem on trees. In comparison to mistake bounds in\n\n existing literature, this paper's result is better when the graph\n\n can be covered by label-consistent clusters of different\n\n diameter. This is because the analysis is done per-cluster and this\n\n should be a better bound in most natural cases.\n\n** Clarity\n\n This paper is well written. The background material required to\n\n understand the PQ graphs is sufficiently covered.\n\n** Originality\n\n This paper makes novel use of PQ-graph and per-cluster analysis to\n\n achieve the final mistake bounds.\n\n** Significance\n\n The algorithms proposed and theoretical results constitute significant\n\n technical contributions.  This a high quality paper that makes novel use of a Picard-Queyranne graph to achieve new mistake bounds in the online graph label prediction problem. The new bounds are arguably better than existing ones for most natural graph labelling.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper discusses the problem of semi-supervised learning where data points are vertices on a graph and edges represent our belief that two vertices are likely to have the same label. The authors analyze a new method (longest-path) for predicting vertex labels incrementally (online) and characterize the number of mistakes made depending on the behaviour of the adversary (who chooses the next vertex and its label). The setup is assuming the labeling follows an underlying Ising distribution. The proposed method is analyzed with the help of a combinatorial structure (PQ graph) that collapses vertices of the same label. This allows for the development of a tractable algorithm (quadratic in the size of the graph) that avoids counting of the label cuts (sets of sedge connecting vertices with different labels).\n\n Quality: The results and analysis appear to be correct. The proposed new algorithm has tractable runtime and improves the error bound in certain settings.\n\n Clarity: I found the paper poorly structures and hard to follow. The introductory sections are well written and set the stage. However, the analysis does not follow smoothly. It is unclear where the paper is going and why the intermediate results on regular graphs are presented. Furthermore, the discussion section appears to give a lot of new information (e.g., summarizing the 4+1 proposed) methods for label prediction). The paper could benefit a lot by given all that information in the paper and not at the end to help evaluate the context and significance of this work.\n\n Originality, Significance: The paper proposes a new algorithm that makes use of the PQ-graph to reduce complexity. The longest-path algorithm can achieve lower error bounds in certain cases, and maths the optimal bound on trees. Unfortunately, The paper is outside my area so my ability to judge its significance and originality is limited.\n\n  The paper discusses error bounds for a new algorithm for predicting incrementally the labels of a graph in a semi-supervised setting. I found the flow of the paper not very smooth and thus hard to follow and evaluate the significance of the results.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
