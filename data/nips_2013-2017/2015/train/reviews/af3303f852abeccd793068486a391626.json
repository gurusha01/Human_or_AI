{"title": "Bayesian dark knowledge", "abstract": "We consider the problem of Bayesian parameter estimation for deep neural networks, which is important in problem settings where we may have little data, and/ or where we need accurate posterior predictive densities p(y|x, D), e.g., for applications involving bandits or active learning. One simple approach to this is to use online Monte Carlo methods, such as SGLD (stochastic gradient Langevin dynamics). Unfortunately, such a method needs to store many copies of the parameters (which wastes memory), and needs to make predictions using many versions of the model (which wastes time).We describe a method for \u201cdistilling\u201d a Monte Carlo approximation to the posterior predictive density into a more compact form, namely a single deep neural network. We compare to two very recent approaches to Bayesian neural networks, namely an approach based on expectation propagation [HLA15] and an approach based on variational Bayes [BCKW15]. Our method performs better than both of these, is much simpler to implement, and uses less computation at test time.", "id": "af3303f852abeccd793068486a391626", "authors": ["Anoop Korattikara Balan", "Vivek Rathod", "Kevin P. Murphy", "Max Welling"], "conference": "NIPS2015", "accepted": true, "reviews": [{"comments": "The proposed algorithm uses the KL distance between the true and the proposed posterior as the objective function. To compute the KL distance it uses stochastic gradient Langevin dynamics to effienctly sample from the posterior and to optimize it it uses stochastic gradient descent.\n\n The writing is quite clear. It is a simple but effective approach and the examples provided show its benefits quite convincingly.\n\n  The paper proposes a stochastic gradient algorithm to train a parametric model of the posterior predictive distribution of a Bayesian model.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "the main idea of the manuscript is, in a regression context, to approximate the predictive distribution with a simple tractable model in order to avoid the high cost required to approximate the true predictive distribution using Monte Carlo samples. The authors discuss why they want to use a Bayesian approach (and their claims are somewhat supported by their simulations) in contrast with a plug in approach. The approach developed comes with no surprise, but is natural and sensible : minimize an averaged KL divergence between the true predictive and the surrogate parametric model using the output of SGLD algorithm. Performance of the method is illustrated through simulations on some examples and, as for any manuscript, outperforms competitors. There are numerous parameters to choose in the algorithm, which is not discussed. Nothing surprising in the manuscript. It is an idea worth exploring.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper uses an online approximation to MCMC to draw parameters for a Bayesian neural network. The predictive distribution under these samples is then fitted using stochastic approximation. The comparisons are to recent work on approximate Bayesian inference applied to the same models and example problems. The claim being that it's a better method (at least in some ways). The paper does not yet present demonstrate that these methods will push forward any particular application.\n\nThe paper is a fairly natural extension of existing work. It is to-the-point, done well, presented clearly, and would be easy for others to try, so could have considerable impact.\n\nSome indication of training times would be useful. Presumably the training time is much slower than the other methods, as the abstract makes a point specifically about test time. However, this issue is simply dodged.\n\nI think it should be made clear in the paper that stochastic gradient Langevin dynamics only draws approximate samples from the posterior. Not just in the usual MCMC sense of requiring burn-in, but it doesn't even respect the posterior locally when exploring some mode for a long time. While there are various developments (cited), none of these offer the same sort of results as traditional batch MCMC on small problems. It's true that on large problems there isn't a better option, but I think it's important not to over-promise. The eagle-eyed reader will notice the posterior is wrong in Figure 2, but it's never really pointed out.\n\nI would remove the statement that the priors are equivalent to L_2 regularization. That's only if doing MAP estimation, which this work is emphatically not! It seems a shame to use simple spherical Gaussian priors, given all the work on Bayesian neural networks in the 1990s. It's hard to take these priors too seriously, especially in a very large and deep network.\n\nIn an engineering sense, the overall procedure is useful. Although future comparisons would be required to see if it really beats standard regularization, early stopping, drop-out, and various other hacks to avoid overfitting. In applications where the predictive distributions are the goal of inference, more work is also required to make approximate Bayesian inference at this scale trustworthy. However, this is an interesting step in the process.\n\n Minor:\n\nI personally don't think the title really captures the contribution. It may sound cool, but there isn't any discussion of eeking out \"hidden\" knowledge in the paper.\n\nI don't think the fitting algorithm is really plain SGD. The subsequent theta samples in the final line are dependent, so presumably some stochastic approximation argument needs to be made.\n\n$5e-6$ is ugly typesetting. I suggest $5\\!\\times\\!10^{-6}$, and $1e-5$ could just be $10^{-5}$.\n\nReferences: The NIPS styleguide says the references should use the numerical \"unsrt\" style. The references could have more complete details. Some proper nouns need capitalizing. Some authors only have initials, while most names are listed in full. This paper is a natural extension of Snelson and Ghahrahmani's \"Compact approximations to Bayesian predictive distributions\" (ICML 2005), using neural networks and online methods for the MCMC and gradient-based fitting. It's well done, bringing existing neat ideas up to date.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "Paper Title: Bayesian Dark Knowledge\n\nPaper Summary: This paper presents a method for approximately learning a Bayesian neural network model while avoiding major storage costs accumulated during training and computational costs during prediction. Typically, in Bayesian models, samples are generated, and a sample approximation to the posterior predictive distribution is formed. However, this requires storing many copies of the parameters of a model, which may require a great deal of storage/memory in high-parameter neural network models. Additionally, prediction on test data requires evaluation of all sampled models, which may be computationally costly. This paper aims to learn a model that makes (approximate) posterior-predictive-based predictions on test data without storing many copies of the parameter set. The method presented here accomplishes this by training a \"student\" model to approximate a Bayesian \"teacher's\" predictions---a procedure in the neural networks literature referred to as \"distillation\" (and also referred to in previous papers as \"model compression\"). However, the student and teacher are trained simultaneously in an online manner (so no large collection of samples are required to be stored, even during training). Experiments are shown on synthetic data (a toy 2D binary classification problem and a toy 1D regression problem), on classification for the MNIST dataset, and on regression for a housing dataset.\n\n Comments:\n\n- I feel that working to develop computational tools for practical Bayesian inference in neural networks is an important direction of research (in particular, tools that mitigate the issue of large storage/memory requirements when sampling in large-parameters Bayesian models), and I feel that this paper is making good steps in this direction.\n\n- One issue I have with the novelty of this paper is that the fundamental concept being developed here (student/teacher learning, or model distillation/compression) is not new --- the authors apply this existing idea in a new domain. However, I do feel the main novelty (and strength) of this paper is the clever way in which the algorithm carries out simultaneous online training of the teacher and student without requiring storage of samples. This is an online distillation/compression method in which the teacher is never \"fully trained\" (the teacher never actually provides full posterior-predictive \"labels\" for the student) and yet the student is still able to learn the \"full trained\" teacher's model.\n\n- One potential computational issue with the presented algorithm is that the student must be trained (to mimic the teacher), on the training dataset D', at every iteration during the MCMC algorithm. I believe this requires a great deal more training of the student than in typical distillation methods (which do not need to make many passes through the training dataset D'). This might be particularly problematic if D' is required to be large in order to achieve good performance. In general, I feel that there is not enough discussion about the training set D' (whether particular choices about D' affect the method's performance, and the particular details used in the experiments presented in this paper).\n\n- I feel that the experiments in this paper were not totally polished and thorough. The authors write that they could not enable a proper comparison of all methods on all datasets because (in part) \"the open source code for the EP approach only supports regression\" and \"we did not get access to the code for the VB approach in time for us to compare to it\". I appreciate the honesty here! However, it would be nice to complete these goals and polish the experiments section in this paper. I feel that the goal of this paper---to develop methods for Bayesian neural networks without the need to store and evaluate many copies of the model---is important, and that the presented method is a clever way of approaching this goal (though it is, in part, an application of existing methods). However, the paper could do a good deal more to polish the experiments section.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
