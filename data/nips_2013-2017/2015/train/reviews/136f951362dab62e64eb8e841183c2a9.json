{"title": "Time-Sensitive Recommendation From Recurrent User Activities", "abstract": "", "id": "136f951362dab62e64eb8e841183c2a9", "authors": ["Nan Du", "Yichen Wang", "Niao He", "Jimeng Sun", "Le Song"], "conference": "NIPS2015", "accepted": true, "reviews": [{"comments": "Paper proposes a new method for time-sensitive recommendations based on user activities. It is different from existing methods because it address the problem of time-varying user preferences. The paper also addresses prediction of the next returning time of a user. Learning is performed using an efficient optimization algorithm proposed by authors. Experimental section shows results on one synthetic data set in order to show that learning is efficient on large scale data and on two real data sets of modest size.\n\nFirst, is a problem of time-varying user preferences really that spread. It would be great to analyze the real data sets from experiments in order to make this claim. If so, is it varying mostly because new popular songs come out? Or there some other pattern?\n\nWhat is the motivation for predicting next returning time for user? Could you please motivate it before you claim it as contribution of a paper? How could a web-company use this prediction and for what?\n\nI believe there are some simple baselines for predicting the next returning time that were not tested: 1) the last time delay 2) the most occurred time delay. Also, I think that predicting the actual returning time of the user is too challenging. Instead, I would focus on a more simpler task that is easier to predict. For example predicting is user will have short delay (1-5 days), medium delay (5-14 days), long delay (14-33 days) or very long delay (>33 days) before he uses our service again.\n\nExperimental section: It was hard for me to get a sense of how significant the performance lift is compared to SVD. Is it groundbreaking (order of magnitude) or modest? Would the user feel the difference? How would these recommendations compare to recommending popular items? In many cases it is a hard baseline to beat, especially if popular items are re-calculated every day.\n\nSmall comments:\n\n1) Typo in last paragraph on page 3: \"and is abel to capture\", abel -> able\n\n2) In first paragraph of section 2 you start mentioning retweets and link creation in social networks without any references. The change of context was confusing.. best to rephrase. Paper addresses two problems: time-sensitive recommendations and returning time of user, without any real motivation on why these problems are relevant and how would solving it have an impact. Several baselines and analysis are missing (details bellow). Other than that, overall OK/marginal paper.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "-- Summary -- This paper proposed a point process collaborative filtering model to capture the temporal and recurrent structure between users and items. Specifically, for each pair of user and item, the event density is the sum of a constant intensity and a self-exciting intensity depending on the past events. Two sets of intensity are computed by two sets of user and item latent vectors respectively. The corresponding optimization algorithm is derived for parameter estimation and empirical studies have been done to demonstrate the advantage of the proposed methods to other commonly used alternatives.\n\n However, the experimental studies can be improved. For example, another sensible baseline would be a simple ensemble of STiC [12] and SVD. Since the authors argued that [12, 13] are not able to recommend completely new items, which can be covered by SVD, and it would be valuable to compare the proposed method to this simple ensemble. In addition, for the \\gamma function used for the self-exciting process, how is the bandwidth parameter \\sigma set? How sensitive would the results be if we vary \\sigma? Furthermore, there is no details about how some other important hyperparameters are chosen for both baseline methods and the proposed method, e.g. the dimension of the latent vectors.\n\nIt would also be helpful to provide more details of the characteristics of the two real world dataset. Since the paper is about temporal structure, it's useful to discuss about simple stats like the number of recurring events per user/item pair and how irregular the temporal pattern is.\n\n-- Quality -- The overall quality is reasonably good but not great.\n\n-- Clarity -- The paper presentation can be improved in terms of languages, typos, grammar errors.\n\n -- Originality --\n\nThe proposed method is an interesting combination of point process and latent factor models.\n\n-- Significance --\n\nBoth the problem and the method have good practical values.  This paper proposed a point process collaborative filtering model to capture the temporal and recurrent structure between users and items. The corresponding optimization algorithm is derived for parameter estimation and empirical studies have been done to demonstrate the advantage of the proposed methods to other commonly used alternatives. However, the experimental studies and the presentation can be improved.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper presents a novel algorithm to tackle time-sensitive recommendation by capturing low-rank structure in a user-item matrix and by using Hawkes process. The algorithm can be solved in a distributed fashion and achieves better results than existing methods.\n\nQuality: Overall I think the paper took a principled approach to model the observation (ratings) using stochastic processes. But I have a few comments.\n\nOne concern in theoretical part is in Eq. (8) and Theorem 2. In eq. 8, over what parameter do we take maximum? Is it over \\rho? In such case, can \\rho* be unbounded? In addition, theorem 2 is not used when the paper chose \\rho in experiments, which degrades the importance of the theorem.\n\nAnother comment is with the baselines in the experiments. To my knowledge, SVD++ [17] (the winner of Netflix challenge) is one of the best algorithm for time-sensitive algorithm. Adding SVD++ into baseline would improve the quality even better. Though I am not dissatisfied with the current baselines.\n\nClarity: The paper was well written and easy to follow.\n\nOriginality: To me the paper seems to be novel because time-sensitive recommendation is a relatively novel problem.\n\nSignificance: I think time-sensitive recommendation can be impactful.  This paper presents a novel algorithm to tackle time-sensitive recommendation by capturing low-rank structure in a user-item matrix and by using Hawkes process. The algorithm can be solved in a distributed fashion and achieves better results than existing methods.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
