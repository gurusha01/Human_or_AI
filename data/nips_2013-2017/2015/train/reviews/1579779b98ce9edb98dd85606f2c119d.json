{"title": "Efficient Non-greedy Optimization of Decision Trees", "abstract": "Decision trees and randomized forests are widely used in computer vision and machine learning. Standard algorithms for decision tree induction optimize the split functions one node at a time according to some splitting criteria. This greedy procedure often leads to suboptimal trees. In this paper, we present an algorithm for optimizing the split functions at all levels of the tree jointly with the leaf parameters, based on a global objective. We show that the problem of finding optimal linear-combination (oblique) splits for decision trees is related to structured prediction with latent variables, and we formulate a convex-concave upper bound on the tree's empirical loss. Computing the gradient of the proposed surrogate objective with respect to each training exemplar is O(d^2), where d is the tree depth, and thus training deep trees is feasible. The use of stochastic gradient descent for optimization enables effective training with large datasets. Experiments on several classification benchmarks demonstrate that the resulting non-greedy decision trees outperform greedy decision tree baselines.", "id": "1579779b98ce9edb98dd85606f2c119d", "authors": ["Mohammad Norouzi", "Maxwell Collins", "Matthew A. Johnson", "David J. Fleet", "Pushmeet Kohli"], "conference": "NIPS2015", "accepted": true, "reviews": [{"comments": "Edit after feedback: After discussion with the other reviewers and looking at the rebuttal, I still think this is a good paper that deserves publication on the basis of the elegance of the approach, and the fact that it is likely to lead to more research on related approaches. I do agree that the experimental results are a bit disappointing. Still, with stronger results I'd probably rate the paper even higher, so I think that this score is appropriate. Very clearly written paper proposes a nonconvex relaxation for global optimization of decision trees with a fixed structure.Elegant approach, but somewhat disappointing experimental results.One simple change would be, after using this global optimization, to throw away the last split in each tree and optimize it and the leaf node in the standard way, which might lead to better results.Also important to evaluate that global optimization should generally lead to more overfitting.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "Summary: A method for jointly training all parameters (decision splits and posterior probabilities) of decision trees is proposed. This is an important topic since current methods train trees in a greedy manner, layer by layer. The task is phrased as a single optimization problem which is then upper-bounded and approximated to obtain a tractable formulation.\n\nQuality - The paper is well written but there might be flaws in the reasoning. See below for details. Clarity - The derivation is clean but experiments and their presentation could be improved. Originality - Investigating joint training for decision trees is an important topic Significance - The proposed solution is valuable although there seem to be some shortcomings. See below for details.\n\nComments: - Flaw in the derivation of the empirical loss bound? At the very least the following argument in l.216f is confusing: `... for all values of $\\bg \\neq \\sgn(W\\bx)$, the right hand side can only become larger than when $\\bg = \\sgn(W\\bx)$ ...' Let's look at the following example to illustrate why I'm confused: W\\bx = [5;-5]\n\n--> \\hat \\bh = [1;-1] = \\sgn(W\\bx)\n\n--> \\hat \\bh^T W\\bx = 10\n\nChoosing g = [1;1] results in g^T W\\bx = 0. Therefore the right hand side of Eq. (7) is\n\ng^T W\\bx - \\hat \\bh^T W\\bx +\n\n\\ell(...) = -10 + \\ell(...)\n\nwhich could possibly be smaller than \\ell(...) and hence not a valid upper bound. Note that the proof of Prop. 1 in the supplementary material does not cover this case and is therefore incomplete.\n\n- Why are some of the leaves not assigned any data points? This seems strange and could indicate a problem with the objective or the initialization. The suggested heuristic of a fixed assignment of data-points to tree leaves seems sub-optimal but could possibly be motivated via expectation maximization/concave-convex procedure, similar to other clustering techniques?\n\n- I'm wondering about the importance for the design of the efficient loss-augmented inference. The depth of the tree seems to be at most 16 and greedily checking 2^16 = 65536 values still seems feasible. How much did the restricted search space introduced by the Hamming ball impact performance? One result is given in the supplementary material but does this generalize? And what means `# leaves'?\n\n- I'm missing a baseline which trains non-axis aligned split functions of trees in a standard greedy manner, i.e., without any initialization.\n\n- The depth of the tree needs to be specified ahead of time. I think this limitation should be discussed more carefully. The authors could also provide a more careful experimental evaluation regarding the depth parameter.\n\n--------------- Thanks to the authors for carefully explaining the reasoning behind the loss bound (Eq. 7). You might want to replace \\arg\\max with \\max. As stated in my summary I adjusted my score.\n\nAn experiment comparing the runtime could strengthen the paper. A more careful evaluation of the method would be desirable for the reader.  The submission considers an interesting problem of jointly training all parameters of decision trees. The experimental evaluation is somewhat limited and there could potentially be a flaw in the derivation. I'm happy to adjust my score given a careful explanation in the rebuttal.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The authors propose an interesting way to search for the best decision tree of a specific depth by posing it as a structured prediction problem. The methods work better than typical greedy approach for decision tree building in terms of test set accuracy, but the improvements tend to be small.\n\n The authors propose an interesting way to search for the best decision tree of a specific depth by posing it as a structured prediction problem. The methods work better than typical greedy approach for decision tree building in terms of test set accuracy, but the improvements tend to be small.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The submission proposes an algorithm for global optimization of decision trees based on a reformulation of the problem as (latent) structured prediction. The latent structured variables are sign vectors encoding the decisions made at each internal node in the tree.\n\nA non-differentiable and non-convex loss is proposed, which is then approximated by a differentiable (but still non-convex) upper bound.\n\nMinimizing this loss via SGD entails solving a sequence of loss-augmented inference problems, for which efficient algorithms are given. Experiments are shown comparing this method to a standard greedy training method.\n\nThe key contributions of the work are casting the global DT optimization as structured prediction and devising efficient algorithms to optimize the objective.\n\nThe way this is done is novel and interesting, and raises interesting questions.\n\nI have some concerns, however, about some practical considerations-especially concerning the motivation for the method and how significant the performance gains over naive methods are.\n\nConsidered purely as a method to globally optimize DTs, the method is intriguing in several ways.\n\nThe first advantage gained by casting the optimization as structured prediction is being able to perform SGD by solving a sequence of loss-augmented optimization problems that leverage the special structure of the problem.\n\nHowever, I think the most interesting result of this approach is that the gradient updates are sparse-if I'm not mistaken, each gradient step involves changing only one node's weight vector.\n\nThe submission presents this mainly as a computational advantage, but I believe that this property raises more intriguing possibilities that are not really acknowledged in the paper.\n\nOne could imagine optimizing over an infinitely deep tree by initially setting all weights to zero, and then gradually growing the tree by making more weights nonzero, thus letting the model's complexity grow naturally to fit the data.\n\nThis raises interesting questions: for example, would such a method prove to be equivalent to, or a variation of, any known greedy strategy?\n\nThis may be the case, if it turns out that it is always preferable to introduce a new node rather than revise an old node's weights.\n\nOr, with appropriate regularization, would such a method instead converge to a tree with a limited number of nodes (as Fig. 2 might suggest)?\n\nI think this issue cuts to the core of what makes the proposed method worthwhile compared to naive DTs, and deserves perhaps more careful analysis than is currently offered by the paper.\n\nFor instance, a critical issue left ambiguous is this: what happens if some node's weight is equal to zero?\n\nThe discussion on page 3 implies that we take the right branch, which seems like a dubious choice.\n\nIt seems like it would be preferable to output a decision at this node; later, we might decide to make this weight nonzero, corresponding to splitting the node.\n\nPrecisely defining what happens here is important, because it has a direct analog to pruning strategies for greedy training.\n\nI have one significant practical concern regarding the motivation for the work.\n\nNamely, I would say that plain DTs are useful mainly to the extent that they are interpretable; if the interpretability requirement is dropped, then it is usually better to use other methods, which generally offer much better performance.\n\nAs stated, I would expect the method to produce non-interpretable results, since the L2 regularization would produce dense weight vectors.\n\nAlthough switching to L1 regularization might help, it is possible that performance would drop if we were forced to regularize to the point where exactly 1-sparse splits were produced.\n\nSo, this would definitely need to be tested.\n\nMy other main concern is that the experiments don't go into enough detail regarding other baselines.\n\nNo details are given as to which pruning strategies were employed for the naive approach.\n\nSince a range of regularization parameters were tried for the proposed method, I would expect the naive method to be similarly tried with a few different pruning strategies and/or parameters.\n\nI think it would also be fair to try some other trivial strategies for global optimization, such as training a greedy method with random subsets of the training data, and choosing the one that minimizes the desired loss on the full training or validation set.\n\nRegarding clarity, the paper is reasonably well-written. My only comment is that the parts describing inference could be a bit clearer.\n\nSection 6.2, for example, could be summarized by saying that the objective is first maximized for all g corresponding to a given leaf, which is then maximized over all leaves.\n\nSection 6.4 could also be a little more explicit.\n\nIn summary, I think this is a very clever approach that raises some very interesting questions.\n\nHowever, it is unclear whether this is a practically useful method at this point, both due to the aforementioned interpretability issue (why use plain DTs in the first place, if they are not interpretable?) and due to a lack of details in the experiments.\n\nPS: although the title mentions forests, the paper does not address this case.\n\nPOST-REBUTTAL COMMENTS\n\nI still think that the case of zero weights is a critical case that deserves further analysis, for the reasons I brought up in my review.\n\nReading the rebuttal, it sounds like the weights are probably initialized randomly, which is why this issue doesn't seem to come up in practice.\n\nHowever, I have a feeling that what would really make this method interesting would be the case where the weights are initially zero and are gradually increased.\n\nI encourage the authors to consider this direction. The submission proposes a clever reformulation of global optimization of decision trees as structured prediction, along with an efficient algorithm to solve the optimization. Some aspects of the motivation for the work and experimental results are not that convincing, however.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper presents an algorithm for learning a decision tree with linear split functions at the nodes. The algorithm optimizes the tree parameters (i.e. the weights in the split functions and the distribution of the output variable at each leaf) in a global way, as opposed to the standard greedy way of learning trees. An upper bound on the tree's empirical loss is proposed, and to achieve a smoother optimization problem, this upper bound is regularized, via a L2 regularization of the split function weights. The algorithm then consists in using a stochastic gradient descent in order to identify the tree parameters that minimize the upper bound.\n\n The tree optimization problem is elegantly formulated, by establishing a link with structured prediction with latent variables. However, the empirical results that are shown in the paper do not really convince that a global optimization is a better alternative to a greedy learning of the tree. The globally optimized tree outperforms significantly the greedy tree on a couple of datasets only, while being more intensive computationally.\n\n The paper is well structured, but some points need to be clarified:\n\n- The stable version of SGD is not described very clearly. How are data points assigned to leaves? It would probably help to have a pseudo-code.\n\n- Figure 2: are these results obtained when applying SGD or stable SGD? What does an \"active\" leaf mean exactly?\n\n- In line 10 of Algorithm 1, \\Theta is updated and then projected on a simplex. In practice, how do you solve this projection problem? It would also maybe be worth mentioning that this projection ensures that the each line of \\Theta sums up to one.\n\n Minor comments / typos:\n\n- In lines 407-408, you say that you tune the \"number of features evaluated when building an ordinary axis-aligned decision tree\". I am not sure to understand, since all the features are evaluated at each node when building a standard decision tree. - In equations (7), (8) and (9), \"argmax\" must be replaced with \"max\". - Figure 1 is never mentioned in the main text. - Line 141: \"...to the index of the leaf on by this path.\" Something is wrong at the end of this sentence. - Line 238: \"...the solution to loss-augmented inference...\" -> the solutions to... - Line 301: \"An key observation...\" -> A key... - Line 360: What is FSGD? - Line 404: \"...a tree with minimum training errors.\" I suppose you mean \"tuning\" errors?\n\nIn the supplementary material:\n\n- Line 29: max_{g \\in sgn...} -> max_{g = sgn...} - Line 30: sgn(Wx)^T Wx + l(\\Theta^Tf(g), y)... -> sgn(Wx)^T Wx +\n\nl(\\Theta^Tf(sgn(Wx)), y)\n\n The tree optimization problem is elegantly formulated, but the results shown are not convincing.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
