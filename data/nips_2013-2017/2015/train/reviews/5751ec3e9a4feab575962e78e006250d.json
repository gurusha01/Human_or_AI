{"title": "The Population Posterior and Bayesian Modeling on Streams", "abstract": "Many modern data analysis problems involve inferences from streaming data. However, streaming data is not easily amenable to the standard probabilistic modeling approaches, which assume that we condition on finite data. We develop population variational Bayes, a new approach for using Bayesian modeling to analyze streams of data. It approximates a new type of distribution, the population posterior, which combines the notion of a population distribution of the data with Bayesian inference in a probabilistic model.  We study our method with latent Dirichlet allocation and Dirichlet process mixtures on several large-scale data sets.", "id": "5751ec3e9a4feab575962e78e006250d", "authors": ["James McInerney", "Rajesh Ranganath", "David Blei"], "conference": "NIPS2015", "accepted": true, "reviews": [{"comments": "Update after author feedback and discussion: I am disappointed in the feedback and the authors not commenting about the practicality of the method for actual streaming data, and thus decreasing my score. As far as I understand, the algorithm could resample any earlier points again and hence to apply it one would need to record and repeatedly access the entire stream. This is clearly not comparable with real streaming algorithms and this would need to be made more explicit. Interesting suggestion to generalise Bayesian inference for infinite data streams. I would have liked to see more comparisons about how the problem could be approached in a Bayesian setting by changing the model, and did not see how this is streaming as you might in theory have to resample the very first data points again much later.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This paper proposed the population posterior distribution for Bayesian modeling of streams of data and showed how stochastic optimization could be used to find a good approximation.\n\nThe proposed framework and algorithm were demonstrated on both latent Dirichlet allocation and Dirichlet process mixture models on text and geolocation data and were shown to perform better than previous work in some cases.\n\nOverall, I think the main idea of the paper is very interesting and it would fit in well at NIPS.\n\nThere are a few aspects of the paper that could use some more discussion though.\n\nFirst, the authors were very careful throughout the paper to use the term \"Bayesian modeling\", except the title uses \"Bayesian inference\", which this paper definitely does not provide a method for.\n\nThe title should really use \"Bayesian modeling\" instead.\n\nAlso, the notation used in Eqs. 3 and 4 for the local variables is confusing as they're being optimized to the expectation of a population average.\n\nHowever, they're local to a particular data point.\n\nPerhaps there's a better way to write this because as written it looks like the learned local variational parameters will just be mess because they'll all be averaged together.\n\nI see how everything works in the actual algorithm, I'm just hoping there's a clean way to write this in Eqs. 3 and 4.\n\nAlso, the step-size for gradient-ascent was never introduced in the algorithm.\n\nFinally, in the paragraph around line 153, the authors say that optimizing the F-ELBO is not guaranteed to minimize the KL, but in the sentence immediately after they say they show that it does in Appendix A.\n\nThis needs to be explained better, because these sentences say opposite things.\n\nA quick discussion about the \\alpha parameter is given in the experiments, however, the fact that it controls the level of uncertainty in the approximate posteriors is extremely important (one of the selling points of the method is that the posterior doesn't collapse to a point).\n\nIt would be great to have some discussion of this earlier on, especially since it is essentially a dataset size.\n\nAdditionally, there's no discussion of whether or not the algorithm converges to anything and what that means.\n\nOne selling point of the population posterior by the authors is that since there's always model mismatch the posterior concentrating on a point in the parameter space is a bad thing.\n\nBut this statement seems to have the underlying assumption that people think that\n\ntheir model is converging to the data generating distribution as more data arrives.\n\nBut I'm not certain people actually think this.\n\nHaving a fixed level of uncertainty (at least a lower-bound on it) through the \\alpha parameter seems really useful for streaming data, I just don't think model mismatch is a good selling point.\n\nThe experiments section is well done and the experiments are convincing.\n\nOne question is whether some discussion can be made on why SVB does worse.\n\nIs it local optima?\n\nAdditionally, the authors should state the actual step-size schedules that they used.\n\nAre the results sensitive to the step-size schedule?\n\nLastly, how many replicates of permuting the order of the data did you use and can error bars be included?\n\nThe rest of my comments are minor:\n\n - There are a lot of typos that need to be fixed.\n\n - There is no future work in the \"Discussion and Future Work\" section.\n\nDefinitely include some because this is really interesting work.\n\nI would like to reiterate that I thoroughly enjoyed this paper and the ideas it proposed.\n\nI hope the authors address my concerns, especially those regarding clarity of presentation, and I think it would be a great addition to the proceedings. This paper proposed an interesting method for Bayesian modeling of streaming data.It would be a nice addition to the NIPS proceedings.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "In this paper, population Bayesian inference is proposed for stream data.\n\nBy introducing population distribution, the authors try to increase model flexibility with population posterior. Stochastic population variational inference is proposed for model parameter learning.\n\nExperimental results are reported in comparison with stream VB and stochastic VB.\n\n There are several issues need to be addressed: 1) A more clear statement about the necessarily of population distribution is needed.\n\n2) According to the paper, population VB should be able to capture the change of the data stream. But if \u001a data points are from the current data set, what is difference between population\n\nVB and SVI?\n\nWhy the sampling procedure for population VB can capture the current stream change if all data sample are treat equally?\n\n3) With population distribution and parameter \u001a, we may get a more flexible model. But it comes with more computational cost due to the sampling procedure and additional parameter tuning.\n\nCould the authors give a quantified computation time for all of the three methods on the data sets? Also details on how to choose \u001a.\n\n 4)\n\nThe reasons why population VB performs worse than stream VB on Twitter dataset.\n\n Population Bayesian inference is proposed but lacks technical soundness.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "- Summary of Paper\n\n - The paper describes the development of an evidence lower bound\n\n (ELBO) constructed by averaging over a data-generating\n\n distribution. The paper shows that optimizing this ELBO leads to\n\n impressive results on very large data streaming applications. - Quality\n\n - L039: \"the standard approach to probabilitic modeling\", might be\n\n better stated as \"the standard approach to Bayesian probabilitic\n\n modeling\" since we can build a probabilitic model without a data\n\n set in hand.\n\n - L044: On initial reading, my reaction was, \"Why shouldn't the\n\n Bayesian posterior become more confident with more data? Indeed,\n\n this is a desirable property of Bayesian inference procedures.\n\n Also, \"over-dispersion\" is a well-known problem for many\n\n generalized linear models and the typical solution there is to\n\n build a better model. So, isn't the solution here, to build a\n\n better model? Or if there is uncertainty about the model, perhaps\n\n we should average over models in some way.\" However, later, some\n\n clarity is provided in that the procedure aims to be robust to\n\n model specification in a different way.\n\n - L051: Again, my initial reaidng of this paragraph caused me to be\n\n concerned that the real problem with Bayesian updating on data\n\n streams is not the Bayesian procedure, but the way the model has\n\n been specified. If the data stream is changing and we haven't\n\n explicitely modeled that, then of course the updates may yeild\n\n poor inferences, but that's not because our updating procedure is\n\n flawed, but because our model is flawed. Here again, it seems\n\n that the proposed procedure is trying to be robust to model\n\n specification issues that really cause problem on data streams.\n\n Perhaps the narrative in these introductory paragraphs can be\n\n sharpened to set up the nice work presented later.\n\n - L056: The claim is that explicitly modeling the time series\n\n incurs a heavy inferential cost. Can this claim be supported with\n\n a citation or other evidence?\n\n - L165: Is there a misplaced parenthesis and perhaps a missing\n\n \\beta in the variantional distribution in the F-ELBO?\n\n - L165: The standard ELBO is conditional on a particular data set x\n\n and the F-ELBO is an average over data set x provided by the\n\n population distribution X ~ F_\\alpha. I'm curious if taking this\n\n average causes the F-ELBO to preferentially optimize the ELBO\n\n over modes of F_\\alpha. Whereas, if we conditioned on a\n\n particular x, as in the ELBO, it wouldn't matter how likely that\n\n data set is under F_\\alpha. Can the authors comment on the\n\n tradeoffs of marginalizing over F_\\alpha versus conditioning on a\n\n sample from it?\n\n - The results primarily deal with prediction rather than parameter\n\n estimation. This is entirely appropriate given the applications\n\n where streaming data is typically found. However, is there\n\n anything that can be said about the parameter estimates,\n\n especially given the first-order goal of maximizing the ELBO or\n\n F-ELBO is to obtain parameter estimates?\n\n - I do like that the F-ELBO explains SVI and provides a nice\n\n framework for understanding that sampling procedure. But, I\n\n wonder if one has in hand a generative model for p(X), what is\n\n the costs/benefits of using that distribution as an averaging\n\n distribution instead of X ~ F_\\alpha? I understand that if our\n\n model is misspecified, averaging with respect to that model may\n\n exacerbate the updating problems outlined, and instead drawing\n\n samples from F_\\alpha is model-independent. Is there any guidance\n\n as to another reason p(X) is a poor choice? - Clarity\n\n - It would help to clarify exactly where the problems identified in\n\n paragraph 2 and 3 in the introduction lie. L042 says that the\n\n problems are with \"Bayesian updating on data streams\", but L044\n\n says \"the first problem is that Bayesian posteriors will become\n\n overconfident\" and L051 says \"the data stream might change over\n\n time\". After reading these assertions several times, it becomes\n\n clear what is intended, but I think the statement on L044 could\n\n be better as \"The first problem with Bayesian updating on data\n\n streams is that Bayesian posteriors will become overconfident\"\n\n and L051 could be \"The second problem with Bayesian updating on\n\n data streams is that the data stream might change over time\n\n causing ...\" - Originality\n\n - The paper is original and provides a good justification for SVI. - Significance\n\n - I find the paper to be highly significant and I hope will be a\n\n welcome addition in the community.  The paper describes an innovative way to handle inference in streaming data scenarios. Notwithstanding a few questions about the procedure, I find it a significant and important contribution to the community.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The authors propose a variational objective that minimises the KL to a \"population posterior\", that is the expectation of the usual posterior under an empirical distribution. They then use this formulation to derive a streaming variational algorithm where the objective is parameterised by an empirical distribution.\n\n The introduction seems to claim that online Bayesian posteriors converge to a point mass: asymptotically, is this not correct and a consequence of consistency? Is the point the convergence can be premature? If so, how much of this is due to the variational (or other) posterior approximation which tends to underestimate uncertainty? i.e., is the problem really with Bayesian inference or with the approximation taken?\n\nEq (3): min -> argmin?  This is a very nice treatment of streaming Bayesian inference via variational methods. The experiments are strong, and the formalism is quite elegant.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
