{
  "name" : "136f951362dab62e64eb8e841183c2a9.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Time-Sensitive Recommendation From Recurrent User Activities",
    "authors" : [ "Nan Du", "Yichen Wang" ],
    "emails" : [ "dunan@gatech.edu,", "yichen.wang@gatech.edu,", "nhe6@gatech.edu", "lsong@cc.gatech.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Delivering personalized user experiences is believed to play a crucial role in the long-term engagement of users to modern web-services [26]. For example, making recommendations on proper items at the right moment can make personal assistant services on mainstream mobile platforms more competitive and usable, since people tend to have different activities depending on the temporal/spatial contexts such as morning vs. evening, weekdays vs. weekend (see for example Figure 1(a)). Unfortunately, most existing recommendation techniques are mainly optimized at predicting users’ onetime preference (often denoted by integer ratings) on items, while users’ continuously time-varying preferences remain largely under explored.\nBesides, traditional user feedback signals (e.g. user-item ratings, click-through-rates, etc.) have been increasingly argued to be ineffective to represent real engagement of users due to the sparseness and nosiness of the data [26]. The temporal patterns at which users return to the services (items) thus becomes a more relevant metric to evaluate their satisfactions [12]. Furthermore, successful predictions of the returning time not only allows a service to keep track of the evolving user preferences, but also helps a service provider to improve their marketing strategies. For most web companies, if we can predict when users will come back next, we could make ads bidding more economic, allowing marketers to bid on time slots. After all, marketers need not blindly bid all time slots indiscriminately. In the context of modern electronic health record data, patients may have several diseases that have complicated dependencies on each other shown at the bottom of Figure 1(a). The occurrence of one disease could trigger the progression of another. Predicting the returning time on certain disease can effectively help doctors to take proactive steps to reduce the potential risks. However, since most models in literature are particularly optimized for predicting ratings [16, 23, 15, 3, 25, 13, 21],\nexploring the recurrent temporal dynamics of users’ returning behaviors over time becomes more imperative and meaningful than ever before.\nAlthough the aforementioned applications come from different domains, we seek to capture them in a unified framework by addressing the following two related questions: (1) how to recommend the most relevant item at the right moment, and (2) how to accurately predict the next returningtime of users to existing services. More specifically, we propose a novel convex formulation of the problems by establishing an under explored connection between self-exciting point processes and low-rank models. We also develop a new optimization algorithm to solve the low rank point process estimation problem efficiently. Our algorithm blends proximal gradient and conditional gradient methods, and achieves the optimal O(1/t) convergence rate. As further demonstrated by our numerical experiments, the algorithm scales up to millions of user-item pairs and hundreds of millions of temporal events, and achieves superb predictive performance on the two time-sensitive problems on both synthetic and real datasets. Furthermore, our model can be readily generalized to incorporate other contextual information by making the intensity function explicitly depend on the additional spatial, textual, categorical, and user profile information.\nRelated Work. The very recent work of Kapoor et al. [12, 11] is most related to our approach. They attempt to predict the returning time for music streaming service based on survival analysis [1] and hidden semi-markov model. Although these methods explicitly consider the temporal dynamics of user-item pairs, a major limitation is that the models cannot generalize to recommend any new item in future time, which is a crucial difference compared to our approach. Moreover, survival analysis is often suitable for modeling a single terminal event [1], such as infection and death, by assuming that the inter-event time to be independent. However, in many cases this assumption might not hold."
    }, {
      "heading" : "2 Background on Temporal Point Processes",
      "text" : "This section introduces necessary concepts from the theory of temporal point processes [4, 5, 6]. A temporal point process is a random process of which the realization is a sequence of events {ti} with ti ∈ R+ and i ∈ Z+ abstracted as points on the time line. Let the history T be the list of event time {t1, t2, . . . , tn} up to but not including the current time t. An important way to characterize temporal point processes is via the conditional intensity function, which is the stochastic model for the next event time given all previous events. Within a small window [t, t + dt), λ(t)dt = P {event in [t, t+ dt)|T } is the probability for the occurrence of a new event given the history T . The functional form of the intensity λ(t) is designed to capture the phenomena of interests [1]. For instance, a homogeneous Poisson process has a constant intensity over time, i.e., λ(t) = λ0 > 0, which is independent of the history T . The inter-event gap thus conforms to the exponential distribution with the mean being 1/λ0. Alternatively, for an inhomogeneous Poisson process, its intensity function is also assumed to be independent of the history T but can be a simple function of time, i.e., λ(t) = g(t) > 0. Given a sequence of events T = {t1, . . . , tn}, for any t > tn, we characterize the conditional probability that no event happens during [tn, t) and the conditional density f(t|T ) that an event occurs at time t as S(t|T ) = exp ( − ∫ t tn λ(τ) dτ ) and f(t|T ) =\nλ(t)S(t|T ) [1]. Then given a sequence of events T = {t1, . . . , tn}, we express its likelihood by\n`({t1, . . . , tn}) = ∏\nti∈T λ(ti) · exp\n( − ∫ T\n0\nλ(τ) dτ ) . (1)"
    }, {
      "heading" : "3 Low Rank Hawkes Processes",
      "text" : "In this section, we present our model in terms of low-rank self-exciting Hawkes processes, discuss its possible extensions and provide solutions to our proposed time-sensitive recommendation problems."
    }, {
      "heading" : "3.1 Modeling Recurrent User Activities with Hawkes Processes",
      "text" : "Figure 1(b) highlights the basic setting of our model. For each observed user-item pair (u, i), we model the occurrences of user u’s past consumption events on item i as a self-exciting Hawkes process [10] with the intensity:\nλ(t) = γ0 + α ∑\nti∈T γ(t, ti), (2)\nwhere γ(t, ti) > 0 is the triggering kernel capturing temporal dependencies, α > 0 scales the magnitude of the influence of each past event, γ0 > 0 is a baseline intensity, and the summation of the kernel terms is history dependent and thus a stochastic process by itself.\nWe have a twofold rationale behind this modeling choice. First, the baseline intensity γ0 captures users’ inherent and long-term preferences to items, regardless of the history. Second, the triggering kernel γ(t, ti) quantifies how the influence from each past event evolves over time, which makes the intensity function depend on the history T . Thus, a Hawkes process is essentially a conditional Poisson process [14] in the sense that conditioned on the history T , the Hawkes process is a Poisson process formed by the superposition of a background homogeneous Poisson process with the intensity γ0 and a set of inhomogeneous Poisson processes with the intensity γ(t, ti). However, because the events in the past can affect the occurrence of the events in future, the Hawkes process in general is more expressive than a Poisson process, which makes it particularly useful for modeling repeated activities by keeping a balance between the long and the short term aspects of users’ preferences."
    }, {
      "heading" : "3.2 Transferring Knowledge with Low Rank Models",
      "text" : "So far, we have shown modeling a sequence of events from a single user-item pair. Since we cannot observe the events from all user-item pairs, the next step is to transfer the learned knowledge to unobserved pairs. Given m users and n items, we represent the intensity function between user u and item i as λu,i(t) = λu,i0 + α u,i ∑ tu,ij ∈T u,i γ(t, tu,ij ), where λ u,i 0 and α\nu,i are the (u, i)-th entry of the m-by-n non-negative base intensity matrix Λ0 and the self-exciting matrixA, respectively.\nHowever, the two matrices of coefficients Λ0 and A contain too many parameters. Since it is often believed that users’ behaviors and items’ attributes can be categorized into a limited number of prototypical types, we assume that Λ0 and A have low-rank structures. That is, the nuclear norms of these parameter matrices are small ‖Λ0‖∗ 6 λ′, ‖A‖∗ 6 β′. Some researchers also explicitly assume that the two matrices factorize into products of low rank factors. Here we assume the above nuclear norm constraints in order to obtain convex parameter estimation procedures later."
    }, {
      "heading" : "3.3 Triggering Kernel Parametrization and Extensions",
      "text" : "Because it is only required that the triggering kernel should be nonnegative and bounded, feature ψu,i in 3 often has analytic forms when γ(t, tu,ij ) belongs to many flexible parametric families, such as the Weibull and Log-logistic distributions [1]. For the simplest case, γ(t, tu,ij ) takes the exponential form γ(t, tu,ij ) = exp(−(t− t u,i j )/σ). Alternatively, we can make the intensity function λu,i(t) depend on other additional context information associated with each event. For instance, we can make the base intensity Λ0 depend on user-profiles and item-contents [9, 7]. We might also extend Λ0 and A into tensors to incorporate the location information. Furthermore, we can even learn the triggering kernel directly using nonparametric methods [8, 30]. Without loss of generality, we stick with the exponential form in later sections."
    }, {
      "heading" : "3.4 Time-Sensitive Recommendation",
      "text" : "Once we have learned Λ0 andA, we are ready to solve our proposed problems as follows :\n(a) Item recommendation. At any given time t, for each user-item pair (u, i), because the intensity function λu,i(t) indicates the tendency that user u will consume item i at time t, for each user u, we recommend the proper items by the following procedures :\n1. Calculate λu,i(t) for each item i. 2. Sort the items by the descending order of λu,i(t). 3. Return the top-k items.\n(b) Returning-time prediction: for each user-item pair (u, i), the intensity function λu,i(t) dominates the point patterns along time. Given the history T u,i = {t1, t2, . . . , tn}, we calculate the density of the next event time by f(t|T u,i) = λu,i(t) exp ( − ∫ t tn λu,i(t)dt ) , so we can use the\nexpectation to predict the next event. Unfortunately, this expectation often does not have analytic forms due to the complexity of λu,i(t) for Hawkes process, so we approximate the returning-time as following :\n1. Draw samples { t1n+1, . . . , t m n+1 } ∼ f(t|T u,i) by Ogata’s thinning algorithm [19].\n2. Estimate the returning-time by the sample average 1m ∑m i=1 t i n+1"
    }, {
      "heading" : "4 Parameter Estimation",
      "text" : "Having presented our model, in this section, we develop a new algorithm which blends proximal gradient and conditional gradient methods to learn the model efficiently."
    }, {
      "heading" : "4.1 Convex Formulation",
      "text" : "Let T u,i be the set of events induced between u and i. We express the log-likelihood of observing each sequence T u,i based on Equation 1 as :\n` ( T u,i|Λ0,A ) = ∑\ntu,ij ∈T u,i log(w>u,iφ u,i j )−w > u,iψ u,i, (3)\nwhere wu,i = (Λ0(u, i),A(u, i)) >, φu,ij = (1, ∑ tu,ik <t u,i j γ(tu,ij , t u,i k )) > and ψu,i =\n(T, ∑ tu,ij ∈T u,i ∫ T tu,ij γ(t, tu,ij )dt) >. When γ(t, tu,ij ) is the exponential kernel, ψ u,i can be ex-\npressed as ψu,i = (T, ∑ tu,ij ∈T u,i\nσ(1 − exp(−(T − tu,ij )/σ)))>. Then, the log-likelihood of observing all event sequences O = { T u,i } u,i\nis simply a summation of each individual term by ` (O) = ∑ T u,i∈O ` ( T u,i ) . Finally, we can have the following convex formulation :\nOPT = min Λ0,A − 1 |O| ∑ T u,i∈O ` ( T u,i|Λ0,A ) + λ‖Λ0‖∗ + β‖A‖∗ subject to Λ0,A > 0, (4)\nwhere the matrix nuclear norm ‖ ·‖∗, which is a summation of all singular values, is commonly used as a convex surrogate for the matrix rank function [24]. One off-the-shelf solution to 4 is proposed in [29] based on ADMM. However, the algorithm in [29] requires, at each iteration, a full SVD for computing the proximal operator, which is often prohibitive with large matrices. Alternatively, we might turn to more efficient conditional gradient algorithms [28], which require instead, the much cheaper linear minimization oracles. However, the non-negativity constraints in our problem prevent the linear minimization from having a simple analytical solution."
    }, {
      "heading" : "4.2 Alternative Formulation",
      "text" : "The difficulty of directly solving the original formulation 4 is caused by the fact that the nonnegative constraints are entangled with the non-smooth nuclear norm penalty. To address this challenge, we approximate 4 using a simple penalty method. Specifically, given ρ > 0, we arrive at the next formulation 5 by introducing two auxiliary variables Z1 and Z2 with some penalty function, such as the squared Frobenius norm.\nÔPT = min Λ0,A,Z1,Z2 − 1 |O| ∑ T u,i∈O ` ( T u,i|Λ0,A ) + λ‖Z1‖∗ + β‖Z2‖∗ + ρ‖Λ0 −Z1‖2F\n+ ρ‖A−Z2‖2F subject to Λ0,A > 0. (5)\nAlgorithm 1: Learning Hawkes-Recommender Input: O = { T u,i } , ρ > 0 Output: Y1 = [Λ0;A] Choose to initialize X01 and X02 = X01 ; Set Y 0 = X0; for k = 1, 2, . . . do\nδk = 2 k+1 ; Uk−1 = (1− δk)Y k−1 + δkXk−1 ; Xk1 = ProxUk−1 ( ηk∇1(f(Uk−1)) ) ;\nXk2 = LMOψ ( ∇2(f(Uk−1)) ) ;\nY k = (1− δk)Y k−1 + δkXk; end\nAlgorithm 2: ProxUk−1 ( ηk∇1(f(Uk−1)) ) Xk1 = ( Uk−1 − ηk∇1(f(Uk−1)) ) + ; Algorithm 3: LMOψ ( ∇2(f(Uk−1))\n) (u1, v1), (u2, v2) top singular vector pairs of −∇2(f(Uk−1))[Z1] and −∇2(f(Uk−1))[Z2]; Xk2 [Z1] = u1v > 1 , Xk2 [Z2] = u2v>2 ; Find αk1 and αk2 by solving (6); Xk2 [Z1] = α k 1X k 2 [Z1]; Xk2 [Z2] = α k 2X k 2 [Z2];\nWe show in Theorem 1 that when ρ is properly chosen, these two formulations lead to the same optimum. See appendix for the complete proof. More importantly, the new formulation 5 allows us to handle the non-negativity constraints and nuclear norm regularization terms separately.\nTheorem 1. With the condition ρ > ρ∗, the optimal value ÔPT of the problem 5 coincides with the optimal value OPT in the problem 4 of interest, where ρ∗ is a problem dependent threshold,\nρ∗ = max\n{ λ (‖Λ∗0‖∗ − ‖Z∗1‖∗) + β (‖A∗‖∗ − ‖Z∗2‖∗)\n‖Λ∗0 −Z∗1‖2F + ‖A∗ −Z∗2‖2F\n} ."
    }, {
      "heading" : "4.3 Efficient Optimization: Proximal Method Meets Conditional Gradient",
      "text" : "Now, we are ready to present Algorithm 1 for solving 5 efficiently. Denote X1 = [Λ0;A], X2 = [Z1;Z2] and X = [X1;X2]. We use the bracket [·] notation X1[Λ0],X1[A],X2[Z1],X2[Z2] to represent the respective part for simplicity. Let f(X) := f(Λ0,A,Z1,Z2) = − 1|O| ∑ T u,i∈O ` ( T u,i|Λ0,A ) + ρ‖Λ0 −Z1‖2F + ρ‖A−Z2‖2F .\nThe course of our action is straightforward: at each iteration, we apply cheap projection gradient for blockX1 and cheap linear minimization for blockX2 and maintain three interdependent sequences{ Uk } k>1 , { Y k } k>1 and { Xk } k>1\nbased on the accelerated scheme in [17, 18]. To be more specific, the algorithm consists of two main subroutines:\nProximal Gradient. When updating X1, we compute directly the associated proximal operator, which in our case, reduces to the simple projection Xk1 = ( Uk−1 − ηk∇1f(Uk−1) ) +\n, where (·)+ simply sets the negative coordinates to zero.\nConditional Gradient. When updating X2, instead of computing the proximal operator, we call the linear minimization oracle (LMOψ): Xk2 [Z1] = argmin {〈pk[Z1],Z1〉+ ψ(Z1)} where pk = ∇2(f(Uk−1)) is the partial derivative with respect to X2 and ψ(Z1) = λ‖Z1‖∗. We do similar updates forXk2 [Z2]. The overall performance clearly depends on the efficiency of this LMO, which can be solved efficiently in our case as illustrated in Algorithm 3. Following [27], the linear minimization for our situation requires only : (i) computing Xk2 [Z1] = argmin‖Z1‖∗61 〈pk[Z1],Z1〉, where the minimizer is readily given byXk2 [Z1] = u1v > 1 , and u1, v1 are the top singular vectors of −pk[Z1]; and (ii) conducting a line-search that produces a scaling factor αk1 = argminα1>0 h(α1)\nh(α1) := ρ‖Y k−11 [Λ0]− (1− δk)Y k−1 2 [Z1]− δk(α1Xk2 [Z1])‖2F + λδkα1 + C, (6)\nwhere C = λ(1− δk)‖Y k−12 [Z1]‖∗. The quadratic problem (6) admits a closed-form solution and thus can be computed efficiently. We repeat the same process for updating αk2 accordingly."
    }, {
      "heading" : "4.4 Convergence Analysis",
      "text" : "Denote F (X) = f(X)+ψ(X2) as the objective in formulation 5, whereX = [X1;X2]. We establish the following convergence results for Algorithm 1 described above when solving formulation 5. Please refer to Appendix for complete proof.\nTheorem 2. Let { Y k }\nbe the sequence generated by Algorithm 1 by setting δk = 2/(k + 1), and ηk = (δk)−1/L. Then for k > 1, we have\nF (Y k)− ÔPT 6 4LD1 k(k + 1) + 2LD2 k + 1 . (7)\nwhere L corresponds to the Lipschitz constant of∇f(X) and D1 and D2 are some problem dependent constants.\nRemark. Let g(Λ0, A) denote the objective in formulation 4, which is the original problem of our interest. By invoking Theorem 1, we further have, g(Y k[Λ0],Y k[A]) − OPT 6 4LD1k(k+1) + 2LD2 k+1 . The analysis builds upon the recursions from proximal gradient and conditional gradient methods. As a result, the overall convergence rate comes from two parts, as reflected in (7). Interestingly, one can easily see that for both the proximal and the conditional gradient parts, we achieve the respective optimal convergence rates. When there is no nuclear norm regularization term, the results recover the well-known optimal O(1/t2) rate achieved by proximal gradient method for smooth convex optimization. When there is no nonnegative constraint, the results recover the well-known O(1/t) rate attained by conditional gradient method for smooth convex minimization. When both nuclear norm and non-negativity are in present, the proposed algorithm, up to our knowledge, is first of its kind, that achieves the best of both worlds, which could be of independent interest."
    }, {
      "heading" : "5 Experiments",
      "text" : "We evaluate our algorithm by comparing with state-of-the-art competitors on both synthetic and real datasets. For each user, we randomly pick 20-percent of all the items she has consumed and hold out the entire sequence of events. Besides, for each sequence of the other 80-percent items, we further split it into a pair of training/testing subsequences. For each testing event, we evaluate the predictive accuracy on two tasks :\n(a) Item Recommendation: suppose the testing event belongs to the user-item pair (u, i). Ideally item i should rank top at the testing moment. We record its predicted rank among all items. Smaller value indicates better performance. (b) Returning-Time Prediction: we predict the returning-time from the learned intensity function and compute the absolute error with respect to the true time.\nWe repeat these two evaluations on all testing events. Because the predictive tasks on those entirely held-out sequences are much more challenging, we report the total mean absolute error (MAE) and that specific to the set of entirely heldout sequences, separately."
    }, {
      "heading" : "5.1 Competitors",
      "text" : "Poisson process is a relaxation of our model by assuming each user-item pair (u, i) has only a constant base intensity Λ0(u, i), regardless of the history. For task (a), it gives static ranks regardless of the time. For task (b), it produces an estimate of the average inter-event gaps. In many cases, the Poisson process is a hard baseline in that the most popular items often have large base intensity, and recommending popular items is often a strong heuristic.\nSTiC [11] fits a semi-hidden Markov model to each observed user-item pair. Since it can only make recommendations specific to the few observed items visited before, instead of the large number of new items, we only evaluate its performance on the returning time prediction task. For the set of entirely held-out sequences, we use the average predicted inter-event time from each observed item as the final prediction.\nSVD is the classic matrix factorization model. The implicit user feedback is converted into an explicit rating using the frequency of item consumptions [2]. Since it is not designed for predicting the returning time, we report its performance on the time-sensitive recommendation task as a reference.\nTensor factorization generalizes matrix factorization to include time. We compare with the stateof-art method [3] which considers poisson regression as the loss function to fit the number of events in each discretized time slot and shows better performance compared to other alternatives with the squared loss [25, 13, 22, 21]. We report the performance by (1) using the parameters fitted only in the last interval, and (2) using the average parameters over all time intervals. We denote these two variants with varying number of intervals as Tensor-#-Last and Tensor-#-Avg."
    }, {
      "heading" : "5.2 Results",
      "text" : "Synthetic data. We generate two 1,024-by-1,204 user-item matrices Λ0 andAwith rank five as the ground-truth. For each user-item pair, we simulate 1,000 events by Ogata’s thinning algorithm [19] with an exponential triggering kernel and get 100 million events in total. The bandwidth for the triggering kernel is fixed to one. By theorem 1, it is inefficient to directly estimate the exact value of the threshold value for ρ. Instead, we tune ρ, λ and β to give the best performance.\nHow does our algorithm converge ? Figure 2(a) shows that it only requires a few hundred iterations to descend to a decent error for both Λ0 and A, indicating algorithm 1 converges very fast. Since the true parameters are low-rank, Figure 2(b-c) verify that it only requires a modest number of observed entries, each of which induces a small number of events (1,000) to achieve a good estimation performance. Figure 2(d) further illustrates that algorithm 1 scales linearly as the training set grows.\nWhat is the predictive performance ? Figure 2(e-f) confirm that algorithm 1 achieves the best predictive performance compared to other baselines. In Figure 2(e), all temporal methods outperform the static SVD since this classic baseline does not consider the underlying temporal dynamics of the observed sequences. In contrast, although the Poisson regression also produces static rankings of the items, it is equivalent to recommending the most popular items over time. This simple heuristic can still give competitive performance. In Figure 2(f), since the occurrence of a new event depends on the whole past history instead of the last one, the performance of STiC deteriorates vastly. The other tensor methods predict the returning time with the information from different time intervals. However, because our method automatically adapts different contributions of each past event to the prediction of the next event, it can achieve the best prediction performance overall.\nReal data. We also evaluate the proposed method on real datasets. last.fm consists of the music streaming logs between 1,000 users and 3,000 artists. There are around 20,000 observed user-artist pairs with more than one million events in total. tmall.com contains around 100K shopping events between 26,376 users and 2,563 stores. The unit time for both dataset is hour. MIMIC II medical dataset is a collection of de-identified clinical visit records of Intensive Care Unit patients for seven years. We filtered out 650 patients and 204 diseases. Each event records the time when a patient was diagnosed with a specific disease. The time unit is week. All model parameters ρ, λ, β, the kernel bandwidth and the latent rank of other baselines are tuned to give the best performance.\nDoes the history help ? Because the true temporal dynamics governing the event patterns are unobserved, we first investigate whether our model assumption is reasonable. Our Hawkes model considers the self-exciting effects from past user activities, while the survival analysis applied in [11]\nassumes i.i.d. inter-event gaps which might conform to an exponential (Poisson process) or Rayleigh distribution. According to the time-change theorem [6], given a sequence T = {t1, . . . , tn} and a particular point process with intensity λ(t), the set of samples {∫ ti ti−1 λ(t)dt }n i=1\nshould conform to a unit-rate exponential distribution if T is truly sampled from the process. Therefore, we compare the theoretical quantiles from the exponential distribution with the fittings of different models to a real sequence of (listening/shopping/visiting) events. The closer the slope goes to one, the better a model matches the event patterns. Figure 3 clearly shows that our Hawkes model can better explain the observed data compared to the other survival analysis models.\nWhat is the predictive performance ? Finally, we evaluate the prediction accuracy in the 2nd and 3rd column of Figure 3. Since holding-out an entire testing sequence is more challenging, the performance on the Heldout group is a little lower than that on the average Total group. However, across all cases, since the proposed model is able to better capture the temporal dynamics of the observed sequences of events, it can achieve a better performance on both tasks in the end."
    }, {
      "heading" : "6 Conclusions",
      "text" : "We propose a novel convex formulation and an efficient learning algorithm to recommend relevant services at any given moment, and to predict the next returning-time of users to existing services. Empirical evaluations on large synthetic and real data demonstrate its superior scalability and predictive performance. Moreover, our optimization algorithm can be used for solving general nonnegative matrix rank minimization problem with other convex losses under mild assumptions, which may be of independent interest.\nAcknowledge The research was supported in part by NSF IIS-1116886, NSF/NIH BIGDATA 1R01GM108341, NSF CAREER IIS-1350983."
    } ],
    "references" : [ {
      "title" : "Survival and event history analysis: a process point of view",
      "author" : [ "O. Aalen", "O. Borgan", "H. Gjessing" ],
      "venue" : "Springer,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Towards time-dependant recommendation based on implicit feedback",
      "author" : [ "L. Baltrunas", "X. Amatriain" ],
      "venue" : null,
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2009
    }, {
      "title" : "On tensors, sparsity, and nonnegative factorizations",
      "author" : [ "E.C. Chi", "T.G. Kolda" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2012
    }, {
      "title" : "Point processes, volume 12",
      "author" : [ "D. Cox", "V. Isham" ],
      "venue" : "Chapman & Hall/CRC,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1980
    }, {
      "title" : "Multivariate point processes",
      "author" : [ "D. Cox", "P. Lewis" ],
      "venue" : "Selected Statistical Papers of Sir David Cox: Volume 1, Design of Investigations, Statistical Methods and Applications, 1:159,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "An introduction to the theory of point processes: volume II: general theory and structure, volume 2",
      "author" : [ "D. Daley", "D. Vere-Jones" ],
      "venue" : "Springer,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Dirichlet-hawkes processes with applications to clustering continuous-time document streams",
      "author" : [ "N. Du", "M. Farajtabar", "A. Ahmed", "A.J. Smola", "L. Song" ],
      "venue" : "KDD’15,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Learning networks of heterogeneous influence",
      "author" : [ "N. Du", "L. Song", "A. Smola", "M. Yuan" ],
      "venue" : "Advances in Neural Information Processing Systems 25, pages 2789–2797,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Uncover topic-sensitive information diffusion networks",
      "author" : [ "N. Du", "L. Song", "H. Woo", "H. Zha" ],
      "venue" : "Artificial Intelligence and Statistics (AISTATS),",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Spectra of some self-exciting and mutually exciting point processes",
      "author" : [ "A.G. Hawkes" ],
      "venue" : "Biometrika, 58(1):83–90,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1971
    }, {
      "title" : "Just in time recommendations: Modeling the dynamics of boredom in activity streams",
      "author" : [ "K. Kapoor", "K. Subbian", "J. Srivastava", "P. Schrater" ],
      "venue" : "WSDM, pages 233–242,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "A hazard based approach to user return time prediction",
      "author" : [ "K. Kapoor", "M. Sun", "J. Srivastava", "T. Ye" ],
      "venue" : "KDD’14, pages 1719–1728,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Multiverse recommendation: N-dimensional tensor factorization for context-aware collaborative filtering",
      "author" : [ "A. Karatzoglou", "X. Amatriain", "L. Baltrunas", "N. Oliver" ],
      "venue" : "Proceeedings of the 4 ACM Conference on Recommender Systems (RecSys),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "On doubly stochastic poisson processes",
      "author" : [ "J. Kingman" ],
      "venue" : "Mathematical Proceedings of the Cambridge Philosophical Society, pages 923–930,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 1964
    }, {
      "title" : "Yahoo! music recommendations: Modeling music ratings with temporal dynamics and item taxonomy",
      "author" : [ "N. Koenigstein", "G. Dror", "Y. Koren" ],
      "venue" : "Proceedings of the Fifth ACM Conference on Recommender Systems, RecSys ’11, pages 165–172,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Collaborative filtering with temporal dynamics",
      "author" : [ "Y. Koren" ],
      "venue" : "Knowledge discovery and data mining KDD, pages 447–456,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "An optimal method for stochastic composite optimization",
      "author" : [ "G. Lan" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "The complexity of large-scale convex programming under a linear optimization oracle",
      "author" : [ "G. Lan" ],
      "venue" : "arXiv preprint arxiv:1309.5550v2,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "On lewis’ simulation method for point processes",
      "author" : [ "Y. Ogata" ],
      "venue" : "Information Theory, IEEE Transactions on, 27(1):23–31,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 1981
    }, {
      "title" : "Stochastic alternating direction method of multipliers",
      "author" : [ "H. Ouyang", "N. He", "L.Q. Tran", "A. Gray" ],
      "venue" : "ICML,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Who, what, when, and where: Multi-dimensional collaborative recommendations using tensor factorization on sparse user-generated data",
      "author" : [ "J.Z.J.L. Preeti Bhargava", "Thomas Phan" ],
      "venue" : "In WWW,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2015
    }, {
      "title" : "Rubik: Knowledge guided tensor factorization and completion for health data analytics",
      "author" : [ "Y. Wang", "R. Chen", "J. Ghosh", "J. Denny", "A. Kho", "Y. Chen", "B. Malin", "J. Sun" ],
      "venue" : "KDD,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Time-Variant Factorization Models Context-Aware Ranking with Factorization Models",
      "author" : [ "S. Rendle" ],
      "venue" : "volume 330 of Studies in Computational Intelligence, chapter 9, pages 137–153.",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Some np-complete problems in linear algebra",
      "author" : [ "S. Sastry" ],
      "venue" : "Honors Projects,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 1990
    }, {
      "title" : "Temporal collaborative filtering with bayesian probabilistic tensor factorization",
      "author" : [ "L. Xiong", "X. Chen", "T.-K. Huang", "J.G. Schneider", "J.G. Carbonell" ],
      "venue" : "SDM, pages 211–222. SIAM,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Beyond clicks: Dwell time for personalization",
      "author" : [ "X. Yi", "L. Hong", "E. Zhong", "N.N. Liu", "S. Rajan" ],
      "venue" : "Proceedings of the 8th ACM Conference on Recommender Systems, RecSys ’14, pages 113–120,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Efficient structured matrix rank minimization",
      "author" : [ "A.W. Yu", "W. Ma", "Y. Yu", "J.G. Carbonell", "S. Sra" ],
      "venue" : "NIPS,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Conditional gradient algorithms for norm-regularized smooth convex optimization",
      "author" : [ "A.N. Zaid Harchaoui", "Anatoli Juditsky" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2013
    }, {
      "title" : "Learning social infectivity in sparse low-rank networks using multidimensional hawkes processes",
      "author" : [ "K. Zhou", "H. Zha", "L. Song" ],
      "venue" : "Artificial Intelligence and Statistics (AISTATS),",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Learning triggering kernels for multi-dimensional hawkes processes",
      "author" : [ "K. Zhou", "H. Zha", "L. Song" ],
      "venue" : "International Conference on Machine Learning (ICML),",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 25,
      "context" : "1 Introduction Delivering personalized user experiences is believed to play a crucial role in the long-term engagement of users to modern web-services [26].",
      "startOffset" : 151,
      "endOffset" : 155
    }, {
      "referenceID" : 25,
      "context" : ") have been increasingly argued to be ineffective to represent real engagement of users due to the sparseness and nosiness of the data [26].",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 11,
      "context" : "The temporal patterns at which users return to the services (items) thus becomes a more relevant metric to evaluate their satisfactions [12].",
      "startOffset" : 136,
      "endOffset" : 140
    }, {
      "referenceID" : 15,
      "context" : "However, since most models in literature are particularly optimized for predicting ratings [16, 23, 15, 3, 25, 13, 21],",
      "startOffset" : 91,
      "endOffset" : 118
    }, {
      "referenceID" : 22,
      "context" : "However, since most models in literature are particularly optimized for predicting ratings [16, 23, 15, 3, 25, 13, 21],",
      "startOffset" : 91,
      "endOffset" : 118
    }, {
      "referenceID" : 14,
      "context" : "However, since most models in literature are particularly optimized for predicting ratings [16, 23, 15, 3, 25, 13, 21],",
      "startOffset" : 91,
      "endOffset" : 118
    }, {
      "referenceID" : 2,
      "context" : "However, since most models in literature are particularly optimized for predicting ratings [16, 23, 15, 3, 25, 13, 21],",
      "startOffset" : 91,
      "endOffset" : 118
    }, {
      "referenceID" : 24,
      "context" : "However, since most models in literature are particularly optimized for predicting ratings [16, 23, 15, 3, 25, 13, 21],",
      "startOffset" : 91,
      "endOffset" : 118
    }, {
      "referenceID" : 12,
      "context" : "However, since most models in literature are particularly optimized for predicting ratings [16, 23, 15, 3, 25, 13, 21],",
      "startOffset" : 91,
      "endOffset" : 118
    }, {
      "referenceID" : 20,
      "context" : "However, since most models in literature are particularly optimized for predicting ratings [16, 23, 15, 3, 25, 13, 21],",
      "startOffset" : 91,
      "endOffset" : 118
    }, {
      "referenceID" : 0,
      "context" : "They attempt to predict the returning time for music streaming service based on survival analysis [1] and hidden semi-markov model.",
      "startOffset" : 98,
      "endOffset" : 101
    }, {
      "referenceID" : 0,
      "context" : "Moreover, survival analysis is often suitable for modeling a single terminal event [1], such as infection and death, by assuming that the inter-event time to be independent.",
      "startOffset" : 83,
      "endOffset" : 86
    }, {
      "referenceID" : 3,
      "context" : "This section introduces necessary concepts from the theory of temporal point processes [4, 5, 6].",
      "startOffset" : 87,
      "endOffset" : 96
    }, {
      "referenceID" : 4,
      "context" : "This section introduces necessary concepts from the theory of temporal point processes [4, 5, 6].",
      "startOffset" : 87,
      "endOffset" : 96
    }, {
      "referenceID" : 5,
      "context" : "This section introduces necessary concepts from the theory of temporal point processes [4, 5, 6].",
      "startOffset" : 87,
      "endOffset" : 96
    }, {
      "referenceID" : 0,
      "context" : "The functional form of the intensity λ(t) is designed to capture the phenomena of interests [1].",
      "startOffset" : 92,
      "endOffset" : 95
    }, {
      "referenceID" : 9,
      "context" : "For each observed user-item pair (u, i), we model the occurrences of user u’s past consumption events on item i as a self-exciting Hawkes process [10] with the intensity:",
      "startOffset" : 146,
      "endOffset" : 150
    }, {
      "referenceID" : 13,
      "context" : "Thus, a Hawkes process is essentially a conditional Poisson process [14] in the sense that conditioned on the history T , the Hawkes process is a Poisson process formed by the superposition of a background homogeneous Poisson process with the intensity γ0 and a set of inhomogeneous Poisson processes with the intensity γ(t, ti).",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 0,
      "context" : "3 Triggering Kernel Parametrization and Extensions Because it is only required that the triggering kernel should be nonnegative and bounded, feature ψ in 3 often has analytic forms when γ(t, t j ) belongs to many flexible parametric families, such as the Weibull and Log-logistic distributions [1].",
      "startOffset" : 294,
      "endOffset" : 297
    }, {
      "referenceID" : 8,
      "context" : "For instance, we can make the base intensity Λ0 depend on user-profiles and item-contents [9, 7].",
      "startOffset" : 90,
      "endOffset" : 96
    }, {
      "referenceID" : 6,
      "context" : "For instance, we can make the base intensity Λ0 depend on user-profiles and item-contents [9, 7].",
      "startOffset" : 90,
      "endOffset" : 96
    }, {
      "referenceID" : 7,
      "context" : "Furthermore, we can even learn the triggering kernel directly using nonparametric methods [8, 30].",
      "startOffset" : 90,
      "endOffset" : 97
    }, {
      "referenceID" : 29,
      "context" : "Furthermore, we can even learn the triggering kernel directly using nonparametric methods [8, 30].",
      "startOffset" : 90,
      "endOffset" : 97
    }, {
      "referenceID" : 18,
      "context" : ", t m n+1 } ∼ f(t|T ) by Ogata’s thinning algorithm [19].",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 23,
      "context" : "T u,i∈O ` ( T |Λ0,A ) + λ‖Λ0‖∗ + β‖A‖∗ subject to Λ0,A > 0, (4) where the matrix nuclear norm ‖ ·‖∗, which is a summation of all singular values, is commonly used as a convex surrogate for the matrix rank function [24].",
      "startOffset" : 214,
      "endOffset" : 218
    }, {
      "referenceID" : 28,
      "context" : "One off-the-shelf solution to 4 is proposed in [29] based on ADMM.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 28,
      "context" : "However, the algorithm in [29] requires, at each iteration, a full SVD for computing the proximal operator, which is often prohibitive with large matrices.",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 27,
      "context" : "Alternatively, we might turn to more efficient conditional gradient algorithms [28], which require instead, the much cheaper linear minimization oracles.",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 16,
      "context" : "k>1 based on the accelerated scheme in [17, 18].",
      "startOffset" : 39,
      "endOffset" : 47
    }, {
      "referenceID" : 17,
      "context" : "k>1 based on the accelerated scheme in [17, 18].",
      "startOffset" : 39,
      "endOffset" : 47
    }, {
      "referenceID" : 26,
      "context" : "Following [27], the linear minimization for our situation requires only : (i) computing X 2 [Z1] = argmin‖Z1‖∗61 〈pk[Z1],Z1〉, where the minimizer is readily given byX 2 [Z1] = u1v > 1 , and u1, v1 are the top singular vectors of −pk[Z1]; and (ii) conducting a line-search that produces a scaling factor α 1 = argminα1>0 h(α1) h(α1) := ρ‖Y k−1 1 [Λ0]− (1− δ)Y k−1 2 [Z1]− δ(α1X 2 [Z1])‖(2)F + λδα1 + C, (6) where C = λ(1− δ)‖Y k−1 2 [Z1]‖∗.",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 10,
      "context" : "STiC [11] fits a semi-hidden Markov model to each observed user-item pair.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 1,
      "context" : "The implicit user feedback is converted into an explicit rating using the frequency of item consumptions [2].",
      "startOffset" : 105,
      "endOffset" : 108
    }, {
      "referenceID" : 2,
      "context" : "We compare with the stateof-art method [3] which considers poisson regression as the loss function to fit the number of events in each discretized time slot and shows better performance compared to other alternatives with the squared loss [25, 13, 22, 21].",
      "startOffset" : 39,
      "endOffset" : 42
    }, {
      "referenceID" : 24,
      "context" : "We compare with the stateof-art method [3] which considers poisson regression as the loss function to fit the number of events in each discretized time slot and shows better performance compared to other alternatives with the squared loss [25, 13, 22, 21].",
      "startOffset" : 239,
      "endOffset" : 255
    }, {
      "referenceID" : 12,
      "context" : "We compare with the stateof-art method [3] which considers poisson regression as the loss function to fit the number of events in each discretized time slot and shows better performance compared to other alternatives with the squared loss [25, 13, 22, 21].",
      "startOffset" : 239,
      "endOffset" : 255
    }, {
      "referenceID" : 21,
      "context" : "We compare with the stateof-art method [3] which considers poisson regression as the loss function to fit the number of events in each discretized time slot and shows better performance compared to other alternatives with the squared loss [25, 13, 22, 21].",
      "startOffset" : 239,
      "endOffset" : 255
    }, {
      "referenceID" : 20,
      "context" : "We compare with the stateof-art method [3] which considers poisson regression as the loss function to fit the number of events in each discretized time slot and shows better performance compared to other alternatives with the squared loss [25, 13, 22, 21].",
      "startOffset" : 239,
      "endOffset" : 255
    }, {
      "referenceID" : 18,
      "context" : "For each user-item pair, we simulate 1,000 events by Ogata’s thinning algorithm [19] with an exponential triggering kernel and get 100 million events in total.",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 10,
      "context" : "Our Hawkes model considers the self-exciting effects from past user activities, while the survival analysis applied in [11]",
      "startOffset" : 119,
      "endOffset" : 123
    }, {
      "referenceID" : 5,
      "context" : "According to the time-change theorem [6], given a sequence T = {t1, .",
      "startOffset" : 37,
      "endOffset" : 40
    } ],
    "year" : 2015,
    "abstractText" : "By making personalized suggestions, a recommender system is playing a crucial role in improving the engagement of users in modern web-services. However, most recommendation algorithms do not explicitly take into account the temporal behavior and the recurrent activities of users. Two central but less explored questions are how to recommend the most desirable item at the right moment, and how to predict the next returning time of a user to a service. To address these questions, we propose a novel framework which connects self-exciting point processes and low-rank models to capture the recurrent temporal patterns in a large collection of user-item consumption pairs. We show that the parameters of the model can be estimated via a convex optimization, and furthermore, we develop an efficient algorithm that maintains O(1/ ) convergence rate, scales up to problems with millions of user-item pairs and hundreds of millions of temporal events. Compared to other state-of-the-arts in both synthetic and real datasets, our model achieves superb predictive performance in the two time-sensitive recommendation tasks. Finally, we point out that our formulation can incorporate other extra context information of users, such as profile, textual and spatial features.",
    "creator" : null
  }
}