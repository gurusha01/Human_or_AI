{
  "name" : "7eacb532570ff6858afd2723755ff790.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Online Rank Elicitation for Plackett-Luce: A Dueling Bandits Approach",
    "authors" : [ "Balázs Szörényi", "Róbert Busa-Fekete", "Adil Paul", "Eyke Hüllermeier" ],
    "emails" : [ "szorenyibalazs@gmail.com", "busarobi@upb.de", "adil.paul@upb.de", "eyke@upb.de" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Several variants of learning-to-rank problems have recently been studied in an online setting, with preferences over alternatives given in the form of stochastic pairwise comparisons [6]. Typically, the learner is allowed to select (presumably most informative) alternatives in an active way—making a connection to multi-armed bandits, where single alternatives are chosen instead of pairs, this is also referred to as the dueling bandits problem [28].\nMethods for online ranking can mainly be distinguished with regard to the assumptions they make about the probabilities p\ni,j that, in a direct comparison between two alternatives i and j, the former is preferred over the latter. If these probabilities are not constrained at all, a complexity that grows quadratically in the number M of alternatives is essentially unavoidable [27, 8, 9]. Yet, by exploiting (stochastic) transitivity properties, which are quite natural in a ranking context, it is possible to devise algorithms with better performance guaranties, typically of the order M logM [29, 28, 7].\nThe idea of exploiting transitivity in preference-based online learning establishes a natural connection to sorting algorithms. Naively, for example, one could simply apply an efficient sorting algorithm such as MergeSort as an active sampling scheme, thereby producing a random order of the alternatives. What can we say about the optimality of such an order? The problem is that the probability distribution (on rankings) induced by the sorting algorithm may not be well attuned with the original preference relation (i.e., the probabilities p\ni,j\n).\nIn this paper, we will therefore combine a sorting algorithm, namely QuickSort [15], and a stochastic preference model that harmonize well with each other—in a technical sense to be detailed later on. This harmony was first presented in [1], and our main contribution is to show how it can be exploited for online rank elicitation. More specifically, we assume that pairwise comparisons obey the marginals of a Plackett-Luce model [24, 19], a widely used parametric distribution over rankings (cf. Section 5). Despite the quadratic worst case complexity of QuickSort, we succeed in developing its budgeted version (presented in Section 6) with a complexity of O(M logM). While only returning partial orderings, this version allows us to devise PAC-style algorithms that find, respectively, a close-to-optimal item (Section 7) and a close-to-optimal ranking of all items (Section 8), both with high probability."
    }, {
      "heading" : "2 Related Work",
      "text" : "Several studies have recently focused on preference-based versions of the multi-armed bandit setup, also known as dueling bandits [28, 6, 30], where the online learner is only able to compare arms in a pairwise manner. The outcome of the pairwise comparisons essentially informs the learner about pairwise preferences, i.e., whether or not an option is preferred to another one. A first group of papers, including [28, 29], assumes the probability distributions of pairwise comparisons to possess certain regularity property, such as strong stochastic transitivity. A second group does not make assumptions of that kind; instead, a target (“ground-truth”) ranking is derived from the pairwise preferences, for example using the Copeland, Borda count and Random Walk procedures [9, 8, 27]. Our work is obviously closer to the first group of methods. In particular, the study presented in this paper is related to [7] which investigates a similar setup for the Mallows model.\nThere are several approaches to estimating the parameters of the Plackett-Luce (PL) model, including standard statistical methods such as likelihood estimation [17] and Bayesian parameter estimation [14]. Pairwise marginals are also used in [26], in connection with the method-of-moments approach; nevertheless, the authors assume that full rankings are observed from a PL model.\nAlgorithms for noisy sorting [2, 3, 12] assume a total order over the items, and that the comparisons are representative of that order (if i precedes j, then the probability of option i being preferred to j is bigger than some > 1/2). In [25], the data is assumed to consist of pairwise comparisons generated by a Bradley-Terry model, however, comparisons are not chosen actively but according to some fixed probability distribution.\nPure exploration algorithms for the stochastic multi-armed bandit problem sample the arms a certain number of times (not necessarily known in advance), and then output a recommendation, such as the best arm or the m best arms [4, 11, 5, 13]. While our algorithms can be viewed as pure exploration strategies, too, we do not assume that numerical feedback can be generated for individual options; instead, our feedback is qualitative and refers to pairs of options."
    }, {
      "heading" : "3 Notation",
      "text" : "A set of alternatives/options/items to be ranked is denoted by I. To keep the presentation simple, we assume that items are identified by natural numbers, so I = [M ] = {1, . . . ,M}. A ranking is a bijection r on I, which can also be represented as a vector r = (r\n1\n, . . . , r\nM ) = (r(1), . . . , r(M)), where r\nj = r(j) is the rank of the jth item. The set of rankings can be identified with the symmetric group S\nM of order M . Each ranking r naturally defines an associated ordering o = (o 1 , . . . , o M ) 2 S M\nof the items, namely the inverse o = r 1 defined by or(j) = j for all j 2 [M ]. For a permutation r, we write r(i, j) for the permutation in which r\ni and r j , the ranks of items i and j, are replaced with each other. We denote by L(r\ni = j) = {r 2 S M | r i = j} the subset of permutations for which the rank of item i is j, and by L(r\nj\n> r\ni ) = {r 2 S M | r j > r i } those for which the rank of j is higher than the rank of i, that is, item i is preferred to j, written i j. We write i r j to indicate that i is preferred to j with respect to ranking r. We assume S\nM to be equipped with a probability distribution P : S M ! [0, 1]; thus, for each ranking r, we denote by P(r) the probability to observe this ranking. Moreover, for each pair of items i and j, we denote by\np\ni,j\n= P(i j) = X\nr2L(rj>ri)\nP(r) (1)\nthe probability that i is preferred to j (in a ranking randomly drawn according to P). These pairwise probabilities are called the pairwise marginals of the ranking distribution P. We denote the matrix composed of the values p\ni,j by P = [p i,j ] 1i,jM ."
    }, {
      "heading" : "4 Preference-based Approximations",
      "text" : "Our learning problem essentially consists of making good predictions about properties of P. Concretely, we consider two different goals of the learner, depending on whether the application calls for the prediction of a single item or a full ranking of items:\nIn the first problem, which we call PAC-Item or simply PACI, the goal is to find an item that is almost as good as the optimal one, with optimality referring to the Condorcet winner. An item i⇤ is\na Condorcet winner if p i ⇤ ,i > 1/2 for all i 6= i⇤. Then, we call an item j a PAC-item, if it is beaten by the Condorcet winner with at most an ✏-margin: |p\ni ⇤ ,j 1/2| < ✏. This setting coincides with those considered in [29, 28]. Obviously, it requires the existence of a Condorcet winner, which is indeed guaranteed in our approach, thanks to the assumption of a Plackett-Luce model.\nThe second problem, called AMPR, is defined as finding the most probable ranking [7], that is, r\n⇤ = argmaxr2SM P(r). This problem is especially challenging for ranking distributions for which the order of two items is hard to elicit (because many entries of P are close to 1/2). Therefore, we again relax the goal of the learner and only require it to find a ranking r with the following property: There is no pair of items 1  i, j  M , such that r⇤\ni\n< r ⇤ j , r i > r j and p i,j > 1/2 + ✏. Put in words, the ranking r is allowed to differ from r⇤ only for those items whose pairwise probabilities are close to 1/2. Any ranking r satisfying this property is called an approximately most probable ranking (AMPR).\nBoth goals are meant to be achieved with probability at least 1 , for some > 0. Our learner operates in an online setting. In each iteration, it is allowed to gather information by asking for a single pairwise comparison between two items—or, using the dueling bandits jargon, to pull two arms. Thus, it selects two items i and j, and then observes either preference i j or j i; the former occurs with probability p\ni,j as defined in (1), the latter with probability p j,i = 1 p i,j . Based on this observation, the learner updates its estimates and decides either to continue the learning process or to terminate and return its prediction. What we are mainly interested in is the sample complexity of the learner, that is, the number of pairwise comparisons it queries prior to termination.\nBefore tackling the problems introduced above, we need some additional notation. The pair of items chosen by the learner in the t-th comparison is denoted (it, jt), where it < jt, and the feedback received is defined as ot = 1 if it jt and ot = 0 if jt it. The set of steps among the first t iterations in which the learner decides to compare items i and j is denoted by It\ni,j = {` 2 [t] | (i`, j`) = (i, j)}, and the size of this set by nt\ni,j\n= #I\nt\ni,j .1 The proportion of “wins” of item i against item j up to iteration t is then given by bp t\ni,j\n=\n1\nn t i,j P `2Iti,j o\n`. Since our samples are independent and identically distributed (i.i.d.), the relative frequency bp t\ni,j is a reasonable estimate of the pairwise probability (1)."
    }, {
      "heading" : "5 The Plackett-Luce Model",
      "text" : "The Plackett-Luce (PL) model is a widely-used probability distribution on rankings [24, 19]. It is parameterized by a “skill” vector v = (v\n1\n, . . . , v\nM ) 2 RM +\nand mimics the successive construction of a ranking by selecting items position by position, each time choosing one of the remaining items i with a probability proportional to its skill v\ni\n. Thus, with o = r 1, the probability of a ranking r is\nP(r |v) = MY\ni=1\nv oi\nv oi + voi+1 + · · ·+ voM . (2)\nAs an appealing property of the PL model, we note that the marginal probabilities (1) are very easy to calculate [21], as they are simply given by\np\ni,j\n=\nv\ni\nv\ni\n+ v\nj\n. (3)\nLikewise, the most probable ranking r⇤ can be obtained quite easily, simply by sorting the items according to their skill parameters, that is, r⇤\ni\n< r ⇤ j iff v i > v j . Moreover, the PL model satisfies strong stochastic transitivity, i.e., p\ni,k max(p i,j , p j,k ) whenever p i,j 1/2 and p j,k 1/2 [18]."
    }, {
      "heading" : "6 Ranking Distributions based on Sorting",
      "text" : "In the classical sorting literature, the outcome of pairwise comparisons is deterministic and determined by an underlying total order of the items, namely the order the sorting algorithm seeks to find. Now, if the pairwise comparisons are stochastic, the sorting algorithm can still be run, however, the result it will return is a random ranking. Interestingly, this is another way to define a probability distribution over the rankings: P(r) = P(r |P) is the probability that r is returned by the algorithm if\n1We omit the index t if there is no danger of confusion.\nstochastic comparisons are specified by P. Obviously, this view is closely connected to the problem of noisy sorting (see the related work section).\nIn a recent work by Ailon [1], the well-known QuickSort algorithm is investigated in a stochastic setting, where the pairwise comparisons are drawn from the pairwise marginals of the Plackett-Luce model. Several interesting properties are shown about the ranking distribution based on QuickSort, notably the property of pairwise stability. We denote the QuickSort-based ranking distribution by P QS\n(· |P), where the matrix P contains the marginals (3) of the Plackett-Luce model. Then, it can be shown that P\nQS (· |P) obeys the property of pairwise stability, which means that it preserves the marginals, although the distributions themselves might not be identical, i.e., P\nQS (· |P) 6= P(· |v). Theorem 1 (Theorem 4.1 in [1]). Let P be given by the pairwise marginals (3), i.e., p\ni,j\n= v\ni\n/(v\ni\n+\nv\nj ). Then, p i,j = P QS (i j |P) = Pr2L(rj>ri) PQS(r |P).\nOne drawback of the QuickSort algorithm is its complexity: To generate a random ranking, it compares O(M2) items in the worst case. Next, we shall introduce a budgeted version of the QuickSort algorithm, which terminates if the algorithm compares too many pairs, namely, more than O(M logM). Upon termination, the modified Quicksort algorithm only returns a partial order. Nevertheless, we will show that it still preserves the pairwise stability property."
    }, {
      "heading" : "6.1 The Budgeted QuickSort-based Algorithm",
      "text" : "Algorithm 1 BQS(A,B) Require: A, the set to be sorted, and a budget B Ensure: (r, B00), where B00 is the remaining bud-\nget, and r is the (partial) order that was constructed based on B B00 samples 1: Initialize r to be the empty partial order over A 2: if B  0 or |A|  1 then return (r, 0) 3: pick an element i 2 A uniformly at random 4: for all j 2 A \\ {i} do 5: draw a random sample o\nij according to the PL marginal (3)\n6: update r accordingly 7: A\n0 = {j 2 A | j 6= i & o i,j = 0} 8: A\n1 = {j 2 A | j 6= i & o i,j = 1} 9: (r0, B0) = BQS(A\n0 , B |A|+ 1) 10: (r00, B00) = BQS(A\n1\n, B 0 )\n11: update r based on r0 and r00 12: return (r, B00)\nAlgorithm 1 shows a budgeted version of the QuickSort-based random ranking generation process described in the previous section. It works in a way quite similar to the standard QuickSort-based algorithm, with the notable difference of terminating as soon as the number of pairwise comparisons exceeds the budget B, which is a parameter assumed as an input. Obviously, the BQS algorithm run with A = [M ] and B = 1 (or B > M2) recovers the original QuickSort-based sampling algorithm as a special case.\nA run of BQS(A,1) can be represented quite naturally as a random tree ⌧ : the root is labeled [M ], end whenever a call to BQS(A,B) initiates a recursive call BQS(A0, B0), a child node with label A0 is added to the node with label A. Note that each such tree determines a ranking, which is denoted by r\n⌧\n, in a natural way.\nThe random ranking generated by BQS(A,1) for some subset A ✓ [M ] was analyzed by Ailon [1], who showed that it gives back the same marginals as the original Plackett-Luce model (as recalled in Theorem 1). Now, for B > 0, denote by ⌧B the tree the algorithm would have returned for the budget B instead of 1. 2 Additionally, let T B denote the set of all possible outcomes of ⌧B , and for two distinct indices i and j, let T B\ni,j denote the set of all trees T 2 T B in which i and j are incomparable in the associated ranking (i.e., some leaf of T is labelled by a superset of {i, j}). The main result of this section is that BQS does not introduce any bias in the marginals (3), i.e., Theorem 1 also holds for the budgeted version of BQS. Proposition 2. For any B > 0, any set A ✓ I and any indices i, j 2 A, the partial order r = r\n⌧\nB\ngenerated by BQS(A,B) satisfies P(i r j | ⌧B 2 T B \\ T B i,j ) = vi vi+vj .\nThat is, whenever two items i and j are comparable by the partial ranking r generated by BQS, i r j with probability exactly vi\nvi+vj . The basic idea of the proof (deferred to the appendix) is to\nshow that, conditioned on the event that i and j are incomparable by r, i r j would have been 2Put differently, ⌧ is obtained from ⌧B by continuing the execution of BQS ignoring the stopping criterion B  0.\nobtained with probability vi vi+vj in case execution of BQS had been continued (see Claim 6). The result then follows by combining this with Theorem 1."
    }, {
      "heading" : "7 The PAC-Item Problem and its Analysis",
      "text" : "Algorithm 2 PLPAC( , ✏) 1: for i, j = 1 ! M do . Initialization 2: bp\ni,j\n= 0 . b P = [bp\ni,j\n] M⇥M 3: n\ni,j\n= 0 . b N = [n\ni,j\n] M⇥M 4: Set A = {1, . . . ,M} 5: repeat 6: r = BQS(A, a 1) where a = #A .\nSorting based random ranking 7: update the entries of bP and N correspond-\ning to A based on r\n8: set c i,j =\nr 1\n2ni,j log\n4M 2 n 2 i,j\nfor all i 6= j 9: for (i, j 2 A) ^ (i 6= j) do\n10: if bp i,j + c i,j < 1/2 then 11: A = A \\ {i} . Discard 12: C = {i 2 A | (8j 2 A \\ {i})\nbp i,j c i,j > 1/2 ✏} 13: until (#C 1) 14: return C\nOur algorithm for finding the PAC item is based on the sorting-based sampling technique described in the previous section. The pseudocode of the algorithm, called PLPAC, is shown in Algorithm 2. In each iteration, we generate a ranking, which is partial (line 6), and translate this ranking into pairwise comparisons that are used to update the estimates of the pairwise marginals. Based on these estimates, we apply a simple elimination strategy, which consists of eliminating an item i if it is significantly beaten by another item j, that is, bp\ni,j\n+ c\ni,j < 1/2 (lines 9– 11). Finally, the algorithm terminates when it finds a PAC-item for which, by definition, |p\ni ⇤ ,i 1/2| < ✏. To identify an item i as a PAC-item, it is enough to guarantee that i is not beaten by any j 2 A with a margin bigger than ✏, that is, p\ni,j > 1/2 ✏ for all j 2 A. This sufficient condition is implemented in line 12. Since we only have empirical estimates of the p\ni,j values, the test of the condition does of course also take the confidence intervals into account.\nNote that v i = v j , i 6= j, implies p i,j = 1/2. In this case, it is not possible to decide whether p i,j is above 1/2 or not on the basis of a finite number of pairwise comparisons. The ✏-relaxation of the goal to be achieved provides a convenient way to circumvent this problem."
    }, {
      "heading" : "7.1 Sample Complexity Analysis of PLPAC",
      "text" : "First, let rt denote the (partial) ordering produced by BQS in the t-th iteration. Note that each of these (partial) orderings defines a bucket order: The indices are partitioned into different classes (buckets) in such a way that none of the pairs are comparable within one class, but pairs from different classes are; thus, if i and i0 belong to some class and j and j0 belong to some other class, then either i rt j and i0 rt j0, or j rt i and j0 rt i0. More specifically, the BQS algorithm with budget a 1 (line 6) always results in a bucket order containing only two buckets since no recursive call is carried out with this budget. Then one might show that the optimal arm i⇤ and an arbitrary arm i( 6= i⇤) fall into different buckets “often enough”. This observation allows us to upper-bound the number of pairwise comparisons taken by PLPAC with high probability. The proof of the next theorem is deferred to Appendix B. Theorem 3. Set\ni = (1/2)max{✏, p i ⇤ ,i 1/2} = (1/2)max{✏, vi⇤ vi 2(vi⇤+vi) } for each index i 6= i⇤. With probability at least 1 , after O ⇣ max\ni 6=i⇤ 1\n2 i log\nM\ni\n⌘ calls for BQS with budget M\n1, PLPAC terminates and outputs an ✏-optimal arm. Therefore, the total number of samples is O ⇣ M max\ni 6=i⇤ 1\n2 i log\nM\ni\n⌘ .\nIn Theorem 3, the dependence on M is of order M logM . It is easy to show that ⌦(M logM) is a lower bound, therefore our result is optimal from this point of view.\nOur model assumptions based on the PL model imply some regularity properties for the pairwise marginals, such as strong stochastic transitivity and stochastic triangle inequality (see Appendix A of [28] for the proof). Therefore, the INTERLEAVED FILTER [28] and BEAT THE MEAN [29] algorithms can be directly applied in our online framework. Both algorithms achieve a similar sample complexity of order M logM . Yet, our experimental study in Section 9.1 clearly shows that, provided our model assumptions on pairwise marginals are valid, PLPAC outperforms both algorithms in terms of empirical sample complexity."
    }, {
      "heading" : "8 The AMPR Problem and its Analysis",
      "text" : "For strictly more than two elements, the sorting-based surrogate distribution and the PL distribution are in general not identical, although their mode rankings coincide [1]. The mode r⇤ of a PL model is the ranking that sorts the items in decreasing order of their skill values: r\ni\n< r\nj iff v i > v j\nfor any i 6= j. Moreover, since v i > v j implies p i,j\n> 1/2, sorting based on the Copeland score b\ni = #{1  j  M | (i 6= j) ^ (p i,j > 1/2)} yields a most probable ranking r⇤. Our algorithm is based on estimating the Copeland score of the items. Its pseudo-code is shown in Algorithm 3 in Appendix C. As a first step, it generates rankings based on sorting, which is used to update the pairwise probability estimates bP. Then, it computes a lower and upper bound b\ni\nand b i\nfor each of the scores b i . The lower bound is given as b i = #{j 2 [M ]\\{i} | bp i,j c > 1/2}, which is the number of items that are beaten by item i based on the current empirical estimates of pairwise marginals. Similarly, the upper bound is given as b\ni\n= b\ni\n+ s\ni , where s i = #{j 2 [M ] \\ {i} | 1/2 2 [bp\ni,j c, bp i,j + c]}. Obviously, s i\nis the number of pairs for which, based on the current empirical estimates, it cannot be decided whether p\ni,j\nis above or below 1/2.\nAs an important observation, note that there is no need to generate a full ranking based on sorting in every case, because if [b\ni\n, b\ni ] \\ [b j , b j ] = ;, then we already know the order of items i and j with respect to r⇤. Motivated by this observation, consider the interval graph G = ([M ], E) based on the [b\ni\n, b\ni ], where E = {(i, j) 2 [M ]2 | [b i , b i ]\\ [b j , b j ] 6= ;}. Denote the connected components of this graph by C\n1\n, . . . , C\nk ✓ [M ]. Obviously, if two items belong to different components, then they do not need to be compared anymore. Therefore, it is enough to call the sorting-based sampling with the connected components.\nFinally, the algorithm terminates if the goal is achieved (line 20). More specifically, it terminates if there is no pair of items i and j, for which the ordering with respect to r⇤ is not elicited yet, i.e., [b\ni\n, b\ni ] \\ [b j , b j ] 6= ;, and their pairwise probabilities is close to 1/2, i.e., |p i,j 1/2| < ✏."
    }, {
      "heading" : "8.1 Sample Complexity Analysis of PLPAC-AMPR",
      "text" : "Denote by q\nM the expected number of comparisons of the (standard) QuickSort algorithm on M elements, namely, q\nM = 2M logM + O(logM) (see e.g., [22]). Thanks to the concentration property of the performance of the QuickSort algorithm, there is no pair of items that falls into the same bucket “too often” in bucket order which is output by BQS. This observation allows us to upper-bound the number of pairwise comparisons taken by PLPAC-AMPR with high probability. The proof of the next theorem is deferred to Appendix D.\nTheorem 4. Set 0 (i) = (1/2)max{✏, v(i+1) v(i) 2(v(i+1)+v(i)) } for each 1  i  M , where v (i) denotes the i-\nth largest skill parameter. With probability at least 1 , after O ⇣ max\n1iM 1 1\n( 0 (i) )\n2 log M\n0 (i)\n⌘\ncalls for BQS with budget 3 2 q M , the algorithm PLPAC terminates and outputs an ✏-optimal arm.\nTherefore, the total number of samples is O ⇣ (M logM)max\n1iM 1 1\n( 0 (i) )\n2 log M\n0 (i)\n⌘ .\nRemark 5. The RankCentrality algorithm proposed in [23] converts the empirical pairwise marginals bP into a row-stochastic matrix bQ. Then, considering bQ as a transition matrix of a Markov chain, it ranks the items based on its stationary distribution. In [25], the authors show that if the pairwise marginals obey a PL distribution, this algorithm produces the mode of this distribution if the sample size is sufficiently large. In their setup, the learning algorithm has no influence on the selection of pairs to be compared; instead, comparisons are sampled using a fixed underlying distribution over the pairs. For any sampling distribution, their PAC bound is of order at least M3, whereas our sample complexity bound in Theorem 4 is of order M log2 M ."
    }, {
      "heading" : "9 Experiments",
      "text" : "Our approach strongly exploits the assumption of a data generating process that can be modeled by means of a PL distribution. The experimental studies presented in this section are mainly aimed at showing that it is doing so successfully, namely, that it has advantages compared to other approaches in situations where this model assumption is indeed valid. To this end, we work with synthetic data.\nNevertheless, in order to get an idea of the robustness of our algorithm toward violation of the model assumptions, some first experiments on real data are presented in Appendix I.3"
    }, {
      "heading" : "9.1 The PAC-Item Problem",
      "text" : "We compared our PLPAC algorithm with other preference-based algorithms applicable in our setting, namely INTERLEAVED FILTER (IF) [28], BEAT THE MEAN (BTM) [29] and MALLOWSMPI [7]. While each of these algorithms follows a successive elimination strategy and discards items one by one, they differ with regard to the sampling strategy they follow. Since the time horizon must be given in advance for IF, we run it with T 2 {100, 1000, 10000}, subsequently referred to as IF(T ). The BTM algorithm can be accommodated into our setup as is (see Algorithm 3 in [29]). The MALLOWSMPI algorithm assumes a Mallows model [20] instead of PL as an underlying probability distribution over rankings, and it seeks to find the Condorcet winner—it can be applied in our setting, too, since a Condorcet winner does exist for PL. Since the baseline methods are not able to handle ✏-approximation except the BTM, we run our algorithm with ✏ = 0 (and made sure that v\ni 6= v j for all 1  i 6= j  M ).\nWe tested the learning algorithm by setting the parameters of PL to v i = 1/(c + i) with c = {0, 1, 2, 3, 5}. The parameter c controls the complexity of the rank elicitation task, since the gaps between pairwise probabilities and 1/2 are of the form |p\ni,j 1/2| = | 1 2 1 1+\ni+c j+c |, which converges to zero as c ! 1. We evaluated the algorithm on this test case with varying numbers of items M = {5, 10, 15} and with various values of parameter c, and plotted the sample complexities, that is, the number of pairwise comparisons taken by the algorithms prior to termination. The results are shown in Figure 1 (only for c = {0, 2, 5}, the rest of the plots are deferred to Appendix E). As can be seen, the PLPAC algorithm significantly outperforms the baseline methods if the pairwise comparisons match with the model assumption, namely, they are drawn from the marginals of a PL distribution. MALLOWSMPI achieves a performance that is slightly worse than PLPAC for M = 5, and its performance is among the worst ones for M = 15. This can be explained by the elimination strategy of MALLOWSMPI, which heavily relies on the existence of a gap min\ni 6=j |pi,j 1/2| > 0 between all pairwise probabilities and 1/2; in our test case, the minimal gap p\nM,M 1 1/2 = 1 2 1/(c+M) 1/2 > 0 is getting smaller with increasing M and c . The poor performance of BTM for large c and M can be explained by the same argument."
    }, {
      "heading" : "9.2 The AMPR Problem",
      "text" : "Since the RankCentrality algorithm produces the most probable ranking if the pairwise marginals obey a PL distribution and the sample size is sufficiently large (cf. Remark 5), it was taken as a baseline. Using the same test case as before, input data of various size was generated for RankCentrality based on uniform sampling of pairs to be compared. Its performance is shown by the black lines in Figure 2 (the results for c = {1, 3, 4} are again deferred to Appendix F). The accuracy in a single run of the algorithm is 1 if the output of RankCentrality is identical with the most probable ranking, and 0 otherwise; this accuracy was averaged over 100 runs.\n3In addition, we conducted some experiments to asses the impact of parameter ✏ and to test our algorithms based on Clopper-Pearson confidence intervals. These experiments are deferred to Appendix H and G due to lack of space.\nSample size 102 104 106\nO pt\nim al\nre co\nve ry\nfr ac\ntio n\n0\n0.2\n0.4\n0.6\n0.8\n1\nRankCentrality (M=5) RankCentrality (M=10) RankCentrality (M=15) PLPAC-AMPR (M=5) PLPAC-AMPR (M=10) PLPAC-AMPR (M=15)\n(a) c = 0 Sample size\n102 104 106\nO pt\nim al\nre co\nve ry\nfr ac\ntio n\n0\n0.2\n0.4\n0.6\n0.8\n1\nRankCentrality (M=5) RankCentrality (M=10) RankCentrality (M=15) PLPAC-AMPR (M=5) PLPAC-AMPR (M=10) PLPAC-AMPR (M=15)\n(b) c = 2 Sample size\n102 104 106\nO pt\nim al\nre co\nve ry\nfr ac\ntio n\n0\n0.2\n0.4\n0.6\n0.8\n1\nRankCentrality (M=5) RankCentrality (M=10) RankCentrality (M=15) PLPAC-AMPR (M=5) PLPAC-AMPR (M=10) PLPAC-AMPR (M=15)\n(c) c = 5\nFigure 2: Sample complexity for finding the approximately most probable ranking (AMPR) with parameters M 2 {5, 10, 15}, = 0.05, ✏ = 0. The results are averaged over 100 repetitions.\nWe also run our PLPAC-AMPR algorithm and determined the number of pairwise comparisons it takes prior to termination. The horizontal lines in Figure 2 show the empirical sample complexity achieved by PLPAC-AMPR with ✏ = 0. In accordance with Theorem 4, the accuracy of PLPACAMPR was always significantly higher than 1 (actually equal to 1 in almost every case). As can be seen, RankCentrality slightly outperforms PLPAC-AMPR in terms of sample complexity, that is, it achieves an accuracy of 1 for a smaller number of pairwise comparisons. Keep in mind, however, that PLPAC-AMPR only terminates when its output is correct with probability at least 1 . Moreover, it computes the confidence intervals for the statistics it uses based on the ChernoffHoeffding bound, which is known to be very conservative. As opposed to this, RankCentrality is an offline algorithm without any performance guarantee if the sample size in not sufficiently large (see Remark 5). Therefore, it is not surprising that, asymptotically, its empirical sample complexity shows a better behavior than the complexity of our online learner.\nAs a final remark, ranking distributions can principally be defined based on any sorting algorithm, for example MergeSort. However, to the best of our knowledge, pairwise stability has not yet been shown for any sorting algorithm other than QuickSort. We empirically tested the MergeSort algorithm in our experimental study, simply by using it in place of budgeted QuickSort in the PLPAC-AMPR algorithm. We found MergeSort inappropriate for the PL model, since the accuracy of PLPAC-AMPR, when being used with MergeSort instead of QuickSort, drastically drops on complex tasks; for details, see Appendix J. The question of pairwise stability of different sorting algorithms for various ranking distributions, such as the Mallows model, is an interesting research avenue to be explored."
    }, {
      "heading" : "10 Conclusion and Future Work",
      "text" : "In this paper, we studied different problems of online rank elicitation based on pairwise comparisons under the assumption of a Plackett-Luce model. Taking advantage of this assumption, our idea is to construct a surrogate probability distribution over rankings based on a sorting procedure, namely QuickSort, for which the pairwise marginals provably coincide with the marginals of the PL distribution. In this way, we manage to exploit the (stochastic) transitivity properties of PL, which is at the origin of the efficiency of our approach, together with the idea of replacing the original QuickSort with a budgeted version of this algorithm. In addition to a formal performance and complexity analysis of our algorithms, we also presented first experimental studies showing the effectiveness of our approach.\nNeedless to say, in addition to the problems studied in this paper, there are many other interesting problems that can be tackled within the preference-based framework of online learning. For example, going beyond a single item or ranking, we may look for a good estimate bP of the entire distribution P, for example, an estimate with small Kullback-Leibler divergence: KL ⇣ P, bP ⌘ < ✏. With\nregard to the use of sorting algorithms, another interesting open question is the following: Is there any sorting algorithm with a worst case complexity of order M logM , which preserves the marginal probabilities? This question might be difficult to answer since, as we conjecture, the MergeSort and the InsertionSort algorithms, which are both well-known algorithms with an M logM complexity, do not satisfy this property."
    } ],
    "references" : [ {
      "title" : "Reconciling real scores with binary comparisons: A new logistic based model for ranking",
      "author" : [ "Nir Ailon" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2008
    }, {
      "title" : "Noisy sorting without resampling",
      "author" : [ "M. Braverman", "E. Mossel" ],
      "venue" : "Proceedings of the nineteenth annual ACM-SIAM Symposium on Discrete algorithms, pages 268–276",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Sorting from noisy information",
      "author" : [ "M. Braverman", "E. Mossel" ],
      "venue" : "CoRR, abs/0910.1191",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Pure exploration in multi-armed bandits problems",
      "author" : [ "S. Bubeck", "R. Munos", "G. Stoltz" ],
      "venue" : "Proceedings of the 20th ALT, ALT’09, pages 23–37, Berlin, Heidelberg",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Multiple identifications in multi-armed bandits",
      "author" : [ "S. Bubeck", "T. Wang", "N. Viswanathan" ],
      "venue" : "Proceedings of The 30th ICML, pages 258–265",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "A survey of preference-based online learning with bandit algorithms",
      "author" : [ "R. Busa-Fekete", "E. Hüllermeier" ],
      "venue" : "Algorithmic Learning Theory (ALT), volume 8776, pages 18–39",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Preference-based rank elicitation using statistical models: The case of Mallows",
      "author" : [ "R. Busa-Fekete", "E. Hüllermeier", "B. Szörényi" ],
      "venue" : "(ICML), volume 32 (2), pages 1071–1079",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Pac rank elicitation through adaptive sampling of stochastic pairwise preferences",
      "author" : [ "R. Busa-Fekete", "B. Szörényi", "E. Hüllermeier" ],
      "venue" : "AAAI, pages 1701–1707",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Top-k selection based on adaptive sampling of noisy preferences",
      "author" : [ "R. Busa-Fekete", "B. Szörényi", "P. Weng", "W. Cheng", "E. Hüllermeier" ],
      "venue" : "Proceedings of the 30th ICML, JMLR W&CP, volume 28",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "The Use of Confidence or Fiducial Limits Illustrated in the Case of the Binomial",
      "author" : [ "C.J. Clopper", "E.S. Pearson" ],
      "venue" : "Biometrika, 26(4):404–413",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1934
    }, {
      "title" : "PAC bounds for multi-armed bandit and markov decision processes",
      "author" : [ "E. Even-Dar", "S. Mannor", "Y. Mansour" ],
      "venue" : "Proceedings of the 15th COLT, pages 255–270",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Computing with noisy information",
      "author" : [ "Uriel Feige", "Prabhakar Raghavan", "David Peleg", "Eli Upfal" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1994
    }, {
      "title" : "Multi-bandit best arm identification",
      "author" : [ "V. Gabillon", "M. Ghavamzadeh", "A. Lazaric", "S. Bubeck" ],
      "venue" : "NIPS 24, pages 2222–2230",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Bayesian inference for plackett-luce ranking models",
      "author" : [ "J. Guiver", "E. Snelson" ],
      "venue" : "Proceedings of the 26th ICML, pages 377–384",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Quicksort",
      "author" : [ "C.A.R. Hoare" ],
      "venue" : "Comput. J., 5(1):10–15",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 1962
    }, {
      "title" : "Probability inequalities for sums of bounded random variables",
      "author" : [ "W. Hoeffding" ],
      "venue" : "Journal of the American Statistical Association, 58:13–30",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 1963
    }, {
      "title" : "MM algorithms for generalized bradley-terry models",
      "author" : [ "D.R. Hunter" ],
      "venue" : "The Annals of Statistics, 32(1):384– 406",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Handbook of Mathematical Psychology",
      "author" : [ "R. Luce", "P. Suppes" ],
      "venue" : "chapter Preference, Utility and Subjective Probability, pages 249–410. Wiley",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 1965
    }, {
      "title" : "Individual choice behavior: A theoretical analysis",
      "author" : [ "R.D. Luce" ],
      "venue" : "Wiley",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 1959
    }, {
      "title" : "Non-null ranking models",
      "author" : [ "C. Mallows" ],
      "venue" : "Biometrika, 44(1):114–130",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 1957
    }, {
      "title" : "Analyzing and Modeling Rank Data",
      "author" : [ "John I. Marden" ],
      "venue" : null,
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 1995
    }, {
      "title" : "Large deviations for quicksort",
      "author" : [ "C.J.H. McDiarmid", "R.B. Hayward" ],
      "venue" : "Journal of Algorithms, 21(3):476– 507",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Iterative ranking from pairwise comparisons",
      "author" : [ "S. Negahban", "S. Oh", "D. Shah" ],
      "venue" : "Advances in Neural Information Processing Systems, pages 2483–2491",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "The analysis of permutations",
      "author" : [ "R. Plackett" ],
      "venue" : "Applied Statistics, 24:193–202",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 1975
    }, {
      "title" : "A statistical convergence perspective of algorithms for rank aggregation from pairwise data",
      "author" : [ "Arun Rajkumar", "Shivani Agarwal" ],
      "venue" : "In ICML,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2014
    }, {
      "title" : "Generalized method-of-moments for rank aggregation",
      "author" : [ "H.A. Soufiani", "W.Z. Chen", "D.C. Parkes", "L. Xia" ],
      "venue" : "Advances in Neural Information Processing Systems (NIPS), pages 2706–2714",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Generic exploration and k-armed voting bandits",
      "author" : [ "T. Urvoy", "F. Clerot", "R. Féraud", "S. Naamane" ],
      "venue" : "Proceedings of the 30th ICML, JMLR W&CP, volume 28, pages 91–99",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "The k-armed dueling bandits problem",
      "author" : [ "Y. Yue", "J. Broder", "R. Kleinberg", "T. Joachims" ],
      "venue" : "Journal of Computer and System Sciences, 78(5):1538–1556",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Beat the mean bandit",
      "author" : [ "Y. Yue", "T. Joachims" ],
      "venue" : "Proceedings of the ICML, pages 241–248",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Relative upper confidence bound for the k-armed dueling bandit problem",
      "author" : [ "M. Zoghi", "S. Whiteson", "R. Munos", "M. Rijke" ],
      "venue" : "ICML, pages 10–18",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : "1 Introduction Several variants of learning-to-rank problems have recently been studied in an online setting, with preferences over alternatives given in the form of stochastic pairwise comparisons [6].",
      "startOffset" : 198,
      "endOffset" : 201
    }, {
      "referenceID" : 27,
      "context" : "Typically, the learner is allowed to select (presumably most informative) alternatives in an active way—making a connection to multi-armed bandits, where single alternatives are chosen instead of pairs, this is also referred to as the dueling bandits problem [28].",
      "startOffset" : 259,
      "endOffset" : 263
    }, {
      "referenceID" : 26,
      "context" : "If these probabilities are not constrained at all, a complexity that grows quadratically in the number M of alternatives is essentially unavoidable [27, 8, 9].",
      "startOffset" : 148,
      "endOffset" : 158
    }, {
      "referenceID" : 7,
      "context" : "If these probabilities are not constrained at all, a complexity that grows quadratically in the number M of alternatives is essentially unavoidable [27, 8, 9].",
      "startOffset" : 148,
      "endOffset" : 158
    }, {
      "referenceID" : 8,
      "context" : "If these probabilities are not constrained at all, a complexity that grows quadratically in the number M of alternatives is essentially unavoidable [27, 8, 9].",
      "startOffset" : 148,
      "endOffset" : 158
    }, {
      "referenceID" : 28,
      "context" : "Yet, by exploiting (stochastic) transitivity properties, which are quite natural in a ranking context, it is possible to devise algorithms with better performance guaranties, typically of the order M logM [29, 28, 7].",
      "startOffset" : 205,
      "endOffset" : 216
    }, {
      "referenceID" : 27,
      "context" : "Yet, by exploiting (stochastic) transitivity properties, which are quite natural in a ranking context, it is possible to devise algorithms with better performance guaranties, typically of the order M logM [29, 28, 7].",
      "startOffset" : 205,
      "endOffset" : 216
    }, {
      "referenceID" : 6,
      "context" : "Yet, by exploiting (stochastic) transitivity properties, which are quite natural in a ranking context, it is possible to devise algorithms with better performance guaranties, typically of the order M logM [29, 28, 7].",
      "startOffset" : 205,
      "endOffset" : 216
    }, {
      "referenceID" : 14,
      "context" : "In this paper, we will therefore combine a sorting algorithm, namely QuickSort [15], and a stochastic preference model that harmonize well with each other—in a technical sense to be detailed later on.",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 0,
      "context" : "This harmony was first presented in [1], and our main contribution is to show how it can be exploited for online rank elicitation.",
      "startOffset" : 36,
      "endOffset" : 39
    }, {
      "referenceID" : 23,
      "context" : "More specifically, we assume that pairwise comparisons obey the marginals of a Plackett-Luce model [24, 19], a widely used parametric distribution over rankings (cf.",
      "startOffset" : 99,
      "endOffset" : 107
    }, {
      "referenceID" : 18,
      "context" : "More specifically, we assume that pairwise comparisons obey the marginals of a Plackett-Luce model [24, 19], a widely used parametric distribution over rankings (cf.",
      "startOffset" : 99,
      "endOffset" : 107
    }, {
      "referenceID" : 27,
      "context" : "2 Related Work Several studies have recently focused on preference-based versions of the multi-armed bandit setup, also known as dueling bandits [28, 6, 30], where the online learner is only able to compare arms in a pairwise manner.",
      "startOffset" : 145,
      "endOffset" : 156
    }, {
      "referenceID" : 5,
      "context" : "2 Related Work Several studies have recently focused on preference-based versions of the multi-armed bandit setup, also known as dueling bandits [28, 6, 30], where the online learner is only able to compare arms in a pairwise manner.",
      "startOffset" : 145,
      "endOffset" : 156
    }, {
      "referenceID" : 29,
      "context" : "2 Related Work Several studies have recently focused on preference-based versions of the multi-armed bandit setup, also known as dueling bandits [28, 6, 30], where the online learner is only able to compare arms in a pairwise manner.",
      "startOffset" : 145,
      "endOffset" : 156
    }, {
      "referenceID" : 27,
      "context" : "A first group of papers, including [28, 29], assumes the probability distributions of pairwise comparisons to possess certain regularity property, such as strong stochastic transitivity.",
      "startOffset" : 35,
      "endOffset" : 43
    }, {
      "referenceID" : 28,
      "context" : "A first group of papers, including [28, 29], assumes the probability distributions of pairwise comparisons to possess certain regularity property, such as strong stochastic transitivity.",
      "startOffset" : 35,
      "endOffset" : 43
    }, {
      "referenceID" : 8,
      "context" : "A second group does not make assumptions of that kind; instead, a target (“ground-truth”) ranking is derived from the pairwise preferences, for example using the Copeland, Borda count and Random Walk procedures [9, 8, 27].",
      "startOffset" : 211,
      "endOffset" : 221
    }, {
      "referenceID" : 7,
      "context" : "A second group does not make assumptions of that kind; instead, a target (“ground-truth”) ranking is derived from the pairwise preferences, for example using the Copeland, Borda count and Random Walk procedures [9, 8, 27].",
      "startOffset" : 211,
      "endOffset" : 221
    }, {
      "referenceID" : 26,
      "context" : "A second group does not make assumptions of that kind; instead, a target (“ground-truth”) ranking is derived from the pairwise preferences, for example using the Copeland, Borda count and Random Walk procedures [9, 8, 27].",
      "startOffset" : 211,
      "endOffset" : 221
    }, {
      "referenceID" : 6,
      "context" : "In particular, the study presented in this paper is related to [7] which investigates a similar setup for the Mallows model.",
      "startOffset" : 63,
      "endOffset" : 66
    }, {
      "referenceID" : 16,
      "context" : "There are several approaches to estimating the parameters of the Plackett-Luce (PL) model, including standard statistical methods such as likelihood estimation [17] and Bayesian parameter estimation [14].",
      "startOffset" : 160,
      "endOffset" : 164
    }, {
      "referenceID" : 13,
      "context" : "There are several approaches to estimating the parameters of the Plackett-Luce (PL) model, including standard statistical methods such as likelihood estimation [17] and Bayesian parameter estimation [14].",
      "startOffset" : 199,
      "endOffset" : 203
    }, {
      "referenceID" : 25,
      "context" : "Pairwise marginals are also used in [26], in connection with the method-of-moments approach; nevertheless, the authors assume that full rankings are observed from a PL model.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 1,
      "context" : "Algorithms for noisy sorting [2, 3, 12] assume a total order over the items, and that the comparisons are representative of that order (if i precedes j, then the probability of option i being preferred to j is bigger than some > 1/2).",
      "startOffset" : 29,
      "endOffset" : 39
    }, {
      "referenceID" : 2,
      "context" : "Algorithms for noisy sorting [2, 3, 12] assume a total order over the items, and that the comparisons are representative of that order (if i precedes j, then the probability of option i being preferred to j is bigger than some > 1/2).",
      "startOffset" : 29,
      "endOffset" : 39
    }, {
      "referenceID" : 11,
      "context" : "Algorithms for noisy sorting [2, 3, 12] assume a total order over the items, and that the comparisons are representative of that order (if i precedes j, then the probability of option i being preferred to j is bigger than some > 1/2).",
      "startOffset" : 29,
      "endOffset" : 39
    }, {
      "referenceID" : 24,
      "context" : "In [25], the data is assumed to consist of pairwise comparisons generated by a Bradley-Terry model, however, comparisons are not chosen actively but according to some fixed probability distribution.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 3,
      "context" : "Pure exploration algorithms for the stochastic multi-armed bandit problem sample the arms a certain number of times (not necessarily known in advance), and then output a recommendation, such as the best arm or the m best arms [4, 11, 5, 13].",
      "startOffset" : 226,
      "endOffset" : 240
    }, {
      "referenceID" : 10,
      "context" : "Pure exploration algorithms for the stochastic multi-armed bandit problem sample the arms a certain number of times (not necessarily known in advance), and then output a recommendation, such as the best arm or the m best arms [4, 11, 5, 13].",
      "startOffset" : 226,
      "endOffset" : 240
    }, {
      "referenceID" : 4,
      "context" : "Pure exploration algorithms for the stochastic multi-armed bandit problem sample the arms a certain number of times (not necessarily known in advance), and then output a recommendation, such as the best arm or the m best arms [4, 11, 5, 13].",
      "startOffset" : 226,
      "endOffset" : 240
    }, {
      "referenceID" : 12,
      "context" : "Pure exploration algorithms for the stochastic multi-armed bandit problem sample the arms a certain number of times (not necessarily known in advance), and then output a recommendation, such as the best arm or the m best arms [4, 11, 5, 13].",
      "startOffset" : 226,
      "endOffset" : 240
    }, {
      "referenceID" : 28,
      "context" : "This setting coincides with those considered in [29, 28].",
      "startOffset" : 48,
      "endOffset" : 56
    }, {
      "referenceID" : 27,
      "context" : "This setting coincides with those considered in [29, 28].",
      "startOffset" : 48,
      "endOffset" : 56
    }, {
      "referenceID" : 6,
      "context" : "The second problem, called AMPR, is defined as finding the most probable ranking [7], that is,",
      "startOffset" : 81,
      "endOffset" : 84
    }, {
      "referenceID" : 23,
      "context" : "5 The Plackett-Luce Model The Plackett-Luce (PL) model is a widely-used probability distribution on rankings [24, 19].",
      "startOffset" : 109,
      "endOffset" : 117
    }, {
      "referenceID" : 18,
      "context" : "5 The Plackett-Luce Model The Plackett-Luce (PL) model is a widely-used probability distribution on rankings [24, 19].",
      "startOffset" : 109,
      "endOffset" : 117
    }, {
      "referenceID" : 20,
      "context" : "(2) As an appealing property of the PL model, we note that the marginal probabilities (1) are very easy to calculate [21], as they are simply given by",
      "startOffset" : 117,
      "endOffset" : 121
    }, {
      "referenceID" : 17,
      "context" : ", p i,k max(p i,j , p j,k ) whenever p i,j 1/2 and p j,k 1/2 [18].",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 0,
      "context" : "In a recent work by Ailon [1], the well-known QuickSort algorithm is investigated in a stochastic setting, where the pairwise comparisons are drawn from the pairwise marginals of the Plackett-Luce model.",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 0,
      "context" : "The random ranking generated by BQS(A,1) for some subset A ✓ [M ] was analyzed by Ailon [1], who showed that it gives back the same marginals as the original Plackett-Luce model (as recalled in Theorem 1).",
      "startOffset" : 88,
      "endOffset" : 91
    }, {
      "referenceID" : 27,
      "context" : "Our model assumptions based on the PL model imply some regularity properties for the pairwise marginals, such as strong stochastic transitivity and stochastic triangle inequality (see Appendix A of [28] for the proof).",
      "startOffset" : 198,
      "endOffset" : 202
    }, {
      "referenceID" : 27,
      "context" : "Therefore, the INTERLEAVED FILTER [28] and BEAT THE MEAN [29] algorithms can be directly applied in our online framework.",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 28,
      "context" : "Therefore, the INTERLEAVED FILTER [28] and BEAT THE MEAN [29] algorithms can be directly applied in our online framework.",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 0,
      "context" : "8 The AMPR Problem and its Analysis For strictly more than two elements, the sorting-based surrogate distribution and the PL distribution are in general not identical, although their mode rankings coincide [1].",
      "startOffset" : 206,
      "endOffset" : 209
    }, {
      "referenceID" : 22,
      "context" : "The RankCentrality algorithm proposed in [23] converts the empirical pairwise marginals b P into a row-stochastic matrix b Q.",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 24,
      "context" : "In [25], the authors show that if the pairwise marginals obey a PL distribution, this algorithm produces the mode of this distribution if the sample size is sufficiently large.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 27,
      "context" : "1 The PAC-Item Problem We compared our PLPAC algorithm with other preference-based algorithms applicable in our setting, namely INTERLEAVED FILTER (IF) [28], BEAT THE MEAN (BTM) [29] and MALLOWSMPI [7].",
      "startOffset" : 152,
      "endOffset" : 156
    }, {
      "referenceID" : 28,
      "context" : "1 The PAC-Item Problem We compared our PLPAC algorithm with other preference-based algorithms applicable in our setting, namely INTERLEAVED FILTER (IF) [28], BEAT THE MEAN (BTM) [29] and MALLOWSMPI [7].",
      "startOffset" : 178,
      "endOffset" : 182
    }, {
      "referenceID" : 6,
      "context" : "1 The PAC-Item Problem We compared our PLPAC algorithm with other preference-based algorithms applicable in our setting, namely INTERLEAVED FILTER (IF) [28], BEAT THE MEAN (BTM) [29] and MALLOWSMPI [7].",
      "startOffset" : 198,
      "endOffset" : 201
    }, {
      "referenceID" : 28,
      "context" : "The BTM algorithm can be accommodated into our setup as is (see Algorithm 3 in [29]).",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 19,
      "context" : "The MALLOWSMPI algorithm assumes a Mallows model [20] instead of PL as an underlying probability distribution over rankings, and it seeks to find the Condorcet winner—it can be applied in our setting, too, since a Condorcet winner does exist for PL.",
      "startOffset" : 49,
      "endOffset" : 53
    } ],
    "year" : 2015,
    "abstractText" : "We study the problem of online rank elicitation, assuming that rankings of a set of alternatives obey the Plackett-Luce distribution. Following the setting of the dueling bandits problem, the learner is allowed to query pairwise comparisons between alternatives, i.e., to sample pairwise marginals of the distribution in an online fashion. Using this information, the learner seeks to reliably predict the most probable ranking (or top-alternative). Our approach is based on constructing a surrogate probability distribution over rankings based on a sorting procedure, for which the pairwise marginals provably coincide with the marginals of the PlackettLuce distribution. In addition to a formal performance and complexity analysis, we present first experimental studies.",
    "creator" : null
  }
}