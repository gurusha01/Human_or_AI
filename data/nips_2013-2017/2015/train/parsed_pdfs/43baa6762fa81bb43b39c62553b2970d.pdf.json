{
  "name" : "43baa6762fa81bb43b39c62553b2970d.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Analysis of Robust PCA via Local Incoherence",
    "authors" : [ "Huishuai Zhang", "Yi Zhou", "Yingbin Liang" ],
    "emails" : [ "hzhan23@syr.edu", "yzhou35@syr.edu", "yliang06@syr.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "We investigate the robust PCA problem of decomposing an observed matrix into the sum of a low-rank and a sparse error matrices via convex programming Principal Component Pursuit (PCP). In contrast to previous studies that assume the support of the error matrix is generated by uniform Bernoulli sampling, we allow non-uniform sampling, i.e., entries of the low-rank matrix are corrupted by errors with unequal probabilities. We characterize conditions on error corruption of each individual entry based on the local incoherence of the low-rank matrix, under which correct matrix decomposition by PCP is guaranteed. Such a refined analysis of robust PCA captures how robust each entry of the low rank matrix combats error corruption. In order to deal with non-uniform error corruption, our technical proof introduces a new weighted norm and develops/exploits the concentration properties that such a norm satisfies."
    }, {
      "heading" : "1 Introduction",
      "text" : "We consider the problem of robust Principal Component Analysis (PCA). Suppose a n-by-n1 data matrix M can be decomposed into a low-rank matrix L and a sparse matrix S as\nM = L+ S. (1)\nRobust PCA aims to find L and S with M given. This problem has been extensively studied recently. In [1, 2], Principal Component Pursuit (PCP) has been proposed to solve the robust PCA problem via the following convex programming\nPCP: minimize L,S kLk⇤ + kSk1 (2)\nsubject to M = L+ S,\nwhere k · k⇤ denotes the nuclear norm, i.e., the sum of singular values, and k · k1 denotes the l1 norm i.e., the sum of absolute values of all entries. It was shown in [1, 2] that PCP successfully recovers L and S if the two matrices are distinguishable from each other in properties, i.e., L is not sparse and S is not low-rank. One important quantity that determines similarity of L to a sparse matrix is the incoherence of L, which measures how column and row spaces of L are aligned with canonical basis and between themselves. Namely, suppose that L is a rank-r matrix with SVD L = U⌃V ⇤, where ⌃ is a r ⇥ r diagonal matrix with singular values as its diagonal entries, U is a n⇥ r matrix with columns as the left singular vectors of L, V is a n⇥ r matrix with columns as the right singular vectors of L, and V ⇤ denotes the transpose of V . The incoherence of L is measured\n1In this paper, we focus on square matrices for simplicity. Our results can be extended to rectangular matrices in a standard way.\nby µ = max{µ 0 , µ 1 }, where µ 0 and µ 1 are defined as\nkU⇤e i k  r µ 0 r\nn , kV ⇤e j\nk  r µ 0 r\nn , for all i, j = 1, · · · , n (3)\nkUV ⇤k1  r µ 1 r\nn2 . (4)\nPrevious studies suggest that the incoherence crucially determines conditions on sparsity of S in order for PCP to succeed. For example, Theorem 2 in [3] explicitly shows that the matrix L with larger µ can tolerate only smaller error density to guarantee correct matrix decomposition by PCP. In all previous work on robust PCA, the incoherence is defined to be the maximum over all column and row spaces of L as in (3) and (4), which can be viewed as the global parameter for the entire matrix L, and consequently, characterization of error density is based on such global (and in fact the worst case) incoherence.\nIn fact, each (i, j) entry of the low rank matrix L can be associated with a local incoherence parameter µ\nij , which is less than or equal to the global parameter µ, and then the allowable entry-wise error density can be potentially higher than that characterized based on the global incoherence. Thus, the total number of errors that the matrix can tolerate in robust PCA can be much higher than that characterized based on the global incoherence when errors are distributed accordingly. Motivated by such an observation, this paper aims to characterize conditions on error corruption of each entry of the low rank matrix based on the corresponding local incoherence parameter, which guarantee success of PCP. Such conditions imply how robust each individual entry of L to resist error corruption. Naturally, the error corruption probability is allowed to be non-uniform over the matrix (i.e., locations of non-zero entries in S are sampled non-uniformly).\nWe note that the notion of local incoherence was first introduced in [4] for studying the matrix completion problem, in which local incoherence determines the local sampling density in order to guarantee correct matrix completion. Here, local incoherence plays a similar role, and determines the maximum allowable error density at each entry to guarantee correct matrix decomposition. The difference lies in that local incoherence here depends on both localized µ\n0 and µ 1 rather than only on localized µ\n0 in matrix completion due to further difficulty of robust PCA, in which locations of error corrupted entries are unknown, as pointed out in [1, 3].\nOur Contribution. In this paper, we investigate a more general robust PCA problem, in which entries of the low rank matrix are corrupted by non-uniformly distributed Bernoulli errors. We characterize the conditions that guarantee correct matrix decomposition by PCP. Our result identifies the local incoherence (defined by localized µ\n0 and µ 1 for each entry of the low rank matrix) to determine the condition that each local Bernoulli error corruption parameter should satisfy. Our results provide the following useful understanding of the robust PCA problem:\n• Our characterization provides a localized (and hence more refined) view of robust PCA, and determines how robust each entry of the low rank matrix combats error corruption. • Our results suggest that the total number of errors that the low-rank matrix can tolerate depends on how errors are distributed over the matrix. • Via cluster problems, our results provide an evidence that µ 1\nis necessary in characterizing conditions for robust PCA.\nIn order to deal with non-uniform error corruption, our technical proof introduces a new weighted norm denoted by l\nw(1), which involves the information of both localized µ0 and µ1 and is hence different from the weighted norms introduced in [4] for matrix completion. Thus, our proof necessarily involves new technical developments associated with such a new norm.\nRelated Work. A closely related but different problem from robust PCA is matrix completion, in which a low-rank matrix is partially observed and is to be completed. Such a problem has been previously studied in [5–8], and it was shown that a rank-r n-by-n matrix can be provably recoverable by convex optimization with as few as ⇥(max{µ\n0 , µ 1 }nr log2 n)2 observed entries. Later on, it was shown in [4] that µ\n1 does not affect sample complexity for matrix completion and hence ⇥(µ\n0 nr log2 n) observed entries are sufficient for guaranteeing correct matrix completion. It was further shown in [9] that a coherent low-rank matrix (i.e., with large µ\n0 ) can be recovered with 2f(n) 2 ⇥(g(n)) means k\n1 · g(n)  f(n)  k 2 · g(n) for some positive k 1 , k 2 .\n⇥(nr log2 n) observations as long as the sampling probability is proportional to the leverage score (i.e., localized µ\n0 ). Our problem can be viewed as its counterpart in robust PCA, where the difference lies in the local incoherence in our problem depends on both localized µ\n0 and µ 1 .\nRobust PCA aims to decompose an observed matrix into the sum of a low-rank matrix and a sparse matrix. In [2, 10], robust PCA with fixed error matrix was studied, and it was shown that the maximum number of errors in any row or column should be bounded from above in order to guarantee correct decomposition by PCP. Robust PCA with random error matrix was investigated in a number of studies. It has been shown in [1] that such decomposition can be exact with high probability if the percentage of corrupted entries is small enough, under the assumptions that the low-rank matrix is incoherent and the support set of the sparse matrix is uniformly distributed. It was further shown in [11] that if signs of nonzero entries in the sparse matrix are randomly chosen, then an adjusted convex optimization can produce exact decomposition even when the percentage of corrupted entries goes to one (i.e., error is dense). The problem was further studied in [1, 3, 12] for the case with the error-corrupted low-rank matrix only partially observed. Our work provides a more refined (i.e. entry-wise) view of robust PCA with random error matrix, aiming at understanding how local incoherence affects susceptibility of each matrix entry to error corruption."
    }, {
      "heading" : "2 Model and Main Result",
      "text" : ""
    }, {
      "heading" : "2.1 Problem Statement",
      "text" : "We consider the robust PCA problem introduced in Section 1. Namely, suppose an n-by-n matrix M can be decomposed into two parts: M = L+ S, where L is a low rank matrix and S is a sparse (error) matrix. We assume that the rank of L is r, and the support of S is selected randomly but non-uniformly. More specifically, let ⌦ denote the support of S and then ⌦ ✓ [n] ⇥ [n], where [n] denotes the set {1, 2, . . . , n}. The event {(i, j) 2 ⌦} is independent across different pairs (i, j) and\nP ((i, j) 2 ⌦) = ⇢ ij , (5)\nwhere ⇢ ij represents the probability that the (i, j)-entry of L is corrupted by error. Hence, ⌦ is determined by Bernoulli sampling with non-uniform probabilities.\nWe study both the random sign and fixed sign models for S. For the fixed sign model, we assume signs of nonzero entries in S are arbitrary and fixed, whereas for the random sign model, we assume that signs of nonzero entries in S are independently distributed Bernoulli variables, randomly taking values +1 or 1 with probability 1/2 as follows:\n[sgn(S)] ij =\n8\n<\n:\n1 with prob. ⇢ ij /2 0 with prob. 1 ⇢\nij\n1 with prob. ⇢ ij /2.\n(6)\nIn this paper, our goal is to characterize conditions on ⇢ ij that guarantees correct recovery of L and S with observation of M .\nWe provide some notations that are used throughout this paper. A matrix X is associated with five norms: kXk\nF denotes the Frobenius norm, kXk⇤ denotes the nuclear norm (i.e., the sum of singular values), kXk denotes the spectral norm (i.e., the largest singular value), and kXk\n1 and kXk1 represent respectively the l\n1 and l1 norms of the long vector stacked by X . The inner product between two matrices is defined as hX,Y i := trace(X⇤Y ). For a linear operator A that acts on the space of matrices, kAk denotes the operator norm given by kAk = sup{kXkF=1} kAXkF ."
    }, {
      "heading" : "2.2 Main Theorems",
      "text" : "We adopt the PCP to solve the robust PCA problem. We define the following local incoherence parameters, which play an important role in our characterization of conditions on entry-wise ⇢\nij\n.\nµ 0ij :=\nn\n2r\nkU⇤e i k2 + kV ⇤e j k2 , µ 1ij :=\nn2([UV ⇤] ij ) 2\nr (7)\nµ ij := max{µ 0ij , µ 1ij }. (8) It is clear that µ\n0ij  µ 0 and µ 1ij  µ 1 for all i, j = 1, · · · , n. We note that although max i,j µ ij > 1, some µ\nij\nmight take values as small as zero.\nWe first consider the robust PCA problem under the random sign model as introduced in Section 2.1. The following theorem characterizes the condition that guarantees correct recovery by PCP. Theorem 1. Consider the robust PCA problem under the random sign model. If\n1 ⇢ ij\nmax ⇢\nC 0\nr\nµ ij r\nn log n,\n1\nn3\nfor some sufficiently large constant C 0 and for all i, j 2 [n], then PCP yields correct matrix recovery with = 1\n32 p n logn , with probability at least 1 cn 10 for some constant c.\nWe note that the term 1/n3 is introduced to justify dual certificate conditions in the proof (see Appendix A.2). We further note that satisfying the condition in Theorem 1 implies C\n0\np\nµr/n log n  1, which is an essential bound required in our proof and coincides with the conditions in previous studies [1, 12]. Although we set = 1\n32 p n logn for the sake of proof, in practice is often determined via cross validation.\nThe above theorem suggests that the local incoherence parameter µ ij is closely related to how robust each entry of L to error corruption in matrix recovery. An entry corresponding to smaller µ\nij\ntolerates larger error density ⇢ ij . This is consistent with the result in [4] for matrix completion, in which smaller local incoherence parameter requires lower local sampling rate. The difference lies in that here both µ\n0ij and µ 1ij play roles in µ ij whereas only µ 0ij matters in matrix completion. The necessity of µ\n1ij\nfor robust PCA is further demonstrated in Section 2.3 via an example.\nTheorem 1 also provides a more refined view for robust PCA in the dense error regime, in which the error corruption probability approaches one. Such an interesting regime was previously studied in [3, 11]. In [11], it is argued that PCP with adaptive yields exact recovery even when the error corruption probability approaches one if errors take random signs and the dimension n is sufficiently large. In [3], it is further shown that PCP with a fixed also yields exact recovery and the scaling behavior of the error corruption probability is characterized. The above Theorem 1 further provides the scaling behavior of the local entry-wise error corruption probability ⇢\nij as it approaches one, and captures how such scaling behavior depends on local incoherence parameters µ\nij . Such a result implies that robustness of PCP depends not only on the error density but also on how errors are distributed over the matrix with regard to µ\nij\n.\nWe next consider the robust PCA problem under the fixed sign model as introduced in Section 2.1. In this case, non-zero entries of the error matrix S can take arbitrary and fixed values, and only locations of non-zero entries are random. Theorem 2. Consider the robust PCA problem under the fixed sign model. If\n(1 2⇢ ij\n) max ⇢\nC 0\nr\nµ ij r\nn log n,\n1\nn3\nfor some sufficient large constant C 0 and for all i, j 2 [n], then PCP yields correct recovery with = 1\n32 p n logn , with probability at least 1 cn 10 for some constant c.\nTheorem 2 follows from Theorem 1 by adapting the elimination and derandomization arguments [1, Section 2.2] as follows. Let ⇢ be the matrix with each (i, j)-entry being ⇢\nij . If PCP yields exact recovery with a certain probability for the random sign model with the parameter 2⇢, then it also yields exact recovery with at least the same probability for the fixed sign model with locations of non-zero entries sampled using Bernoulli model with the parameter ⇢.\nWe now compare Theorem 2 for robust PCA with non-uniform error corruption to Theorem 1.1 in [1] for robust PCA with uniform error corruption. It is clear that if we set ⇢\ni,j = ⇢ for all i, j 2 [n], then the two models are the same. It can then be easily checked that conditions p µr/n log n  ⇢ r and ⇢  ⇢ s\nin Theorem 1.1 of [1] implies the conditions in Theorem 2. Thus, Theorem 2 provides a more relaxed condition than Theorem 1.1 in [1]. Such benefit of condition relaxation should be attributed to the new golfing scheme introduced in [3, 12], and this paper provides a more refined view of robust PCA by further taking advantage of such a new golfing scheme to analyze local conditions.\nMore importantly, Theorem 2 characterizes relationship between local incoherence parameters and local error corruption probabilities, which implies that different areas of the low-rank matrix have\ndifferent levels of ability to resist errors: a more incoherent area (i.e., with smaller µ ij ) can tolerate more errors. Thus, Theorem 2 illustrates the following interesting fact. Whether PCP yields correct recovery depends not only on the total number of errors but also on how errors are distributed. If more errors are distributed to more incoherent areas (i.e, with smaller µ\nij ), then more errors in total can be tolerated. However, if errors are distributed in an opposite manner, then only smaller number of errors can be tolerated."
    }, {
      "heading" : "2.3 Implication on Cluster Matrix",
      "text" : "In this subsection, we further illustrate our result when the low rank matrix is a cluster matrix. Although robust PCA and even more sophisticated approaches have been applied to solve clustering problems, e.g., [13–15], our perspective here is to demonstrate how local incoherence affects entrywise robustness to error corruption, which has not been illustrated in previous studies.\nSuppose there are n elements to be clustered. We use a cluster matrix L to represent the clustering relationship of these n elements with L\nij = 1 if elements i and j are in the same cluster and L ij = 0\notherwise. Thus, with appropriate ordering of the elements, L is a block diagonal matrix with all diagonal blocks containing all ‘1’s and off-diagonal blocks containing all ‘0’s. Hence, the rank r of L equals the number of clusters, which is typically small compared to n. Suppose these entries are corrupted by errors that flip entries from one to zero or from zero to one. This can be thought of as adding a (possibly sparse) error matrix S to L so that the observed matrix is L + S. Then PCP can be applied to recover the cluster matrix L.\nWe first consider an example with clusters having equal size n/r. We set n = 600 and r = 4 (i.e., four equal-size clusters). We apply errors to diagonal-block entries and off-diagonal-block entries respectively with the probabilities ⇢\nd and ⇢ od . In Fig. 1a, we plot recovery accuracy of PCP for each pairs of (⇢\nod , ⇢ d ). It is clear from the figure that failure occurs for larger ⇢ od than ⇢ d , which thus implies that off-diagonal blocks are more robust to errors than diagonal blocks. This can be explained by Theorem 2 as follows. For a cluster matrix with equal cluster size n/r, the local incoherence parameters are given by\nµ 0ij = 1 for all (i, j), and µ 1ij =\n⇢\nr, (i, j) is in diagonal blocks 0, (i, j) is in off-diagonal blocks,\nand thus\nµ ij = max{µ 0ij , µ 1ij } = ⇢ r, (i, j) is in diagonal blocks 1, (i, j) is in off-diagonal blocks.\nBased on Theorem 2, it is clear that diagonal-block entries are more locally coherent and hence are more vulnerable to errors, whereas off-diagonal-block entries are more locally incoherent and hence are more robust to errors.\nMoreover, this example also demonstrates the necessity of µ 1 in the robust PCA problem. [4] showed that µ\n1 is not necessary for matrix completion and argued informally that µ 1 is necessary for robust PCA by connecting the robust PCA problem to hardness of finding a small clique in a large random graph. Here, the above example provides an evidence for such a fact. In the example, µ\n0ij are the same over the entire matrix, and hence it is µ\n1ij that differentiates incoherence between diagonal blocks and off-diagonal blocks, and thus differentiates their robustness to errors.\nWe then consider the case with two clusters that have different sizes: cluster1 size 500 versus cluster2 size 100. Hence, r = 2. We apply errors to block diagonal entries corresponding to clusters 1 and 2 respectively with the probabilities ⇢\n1 and ⇢ 2 . In Fig. 1b, we plot the recovery accuracy of PCP for each pair of (⇢\n1 , ⇢ 2 ). It is clear from the figure that failure occurs for larger ⇢ 1 than ⇢ 2 , which thus implies that entries corresponding to the larger cluster are more robust to errors than entries corresponding to smaller clusters. This can be explained by Theorem 2 because the local incoherence of a block diagonal entry is given by µ\nij\n=\nn\n2\nrK 2 , where K is the corresponding cluster size, and hence the error corruption probability should satisfy 1 2⇢\nij > C 0\np n\nK log n for correct recovery. Thus, a larger cluster can resist denser errors. This also coincides with the results on graph clustering in [13, 16]."
    }, {
      "heading" : "2.4 Outline of the Proof of Theorem 1",
      "text" : "The proof of Theorem 1 follows the idea established in [1] and further developed in [3, 12]. Our main technical development lies in analysis of non-uniform error corruption based on local incoherence parameters, for which we introduce a new weighted norm l\nw(1), and establish concentration properties and bounds associated with this norm. As a generalization of matrix infinity norm, l w(1) incorporates both µ\n0ij and µ 1ij , and is hence different from the weighted norms l µ(1) and lµ(1,2)\nin [9] by its role in the analysis for the robust PCA problem. We next outline the proof here and the detailed proofs are provided in Appendix A.\nWe first introduce some notations. We define the subspace T := {UX⇤ + Y V ⇤ : X,Y 2 Rn⇥r}, where U, V are left and right singular matrix of L. Then T induces a projection operator P\nT given by P\nT (M) = UU⇤M+MV V ⇤ UU⇤MV V ⇤. Moreover, T?, the complement subspace to T , induces an orthogonal projection operator P\nT ? with P T ?(M) = (I UU⇤)M(I V V ⇤). We further define two operators associated with Bernoulli sampling. Let ⌦\n0 denote a generic subset of [n]⇥ [n]. We define a corresponding projection operator P\n⌦0 as P⌦0(M) = P\nij I{(i,j)2⌦0}hM, eie⇤j ieie⇤j , where I{·} is the indicator function. If ⌦0 is a random set generated by Bernoulli sampling with P((i, j) 2 ⌦\n0 ) = t ij with 0 < t ij  1 for all i, j 2 [n], we further define a linear operator R ⌦0 as\nR ⌦0(M) =\nP\nij\n1 tij I{(i,j)2⌦0}hM, eie⇤j ieie⇤j .\nWe further note that throughout this paper “with high probability” means “with probability at least 1 cn 10”, where the constant c may be different in various contexts. Our proof includes two main steps: establishing that existence of a certain dual certificate is sufficient to guarantee correct recovery and constructing such a dual certificate. For the first step, we establish the following proposition.\nProposition 1. If 1 ⇢ ij max n C 0\nq\nµijr\nn log n, 1 n 3\no\n, PCP yields a unique solution which agrees with the correct (L, S) with high probability if there exists a dual certificate Y obeying\nP ⌦ Y = 0, (9)\nkY k1 \n4\n, (10)\nkP T ?( sgn(S) + Y )k  1 4 , (11)\nkP T (Y + sgn(S) UV ⇤)k F\n n2\n(12)\nwhere = 1 32 p n logn .\nThe proof of the above proposition adapts the idea in [1,12] for uniform errors to non-uniform errors. In particular, the proof exploits the properties of R\n⌦ associated with non-uniform errors, which are presented as Lemma 1 (established in [9]) and Lemma 2 in Appendix A.1.\nProposition 1 suggests that it suffices to prove Theorem 1 if we find a dual certificate Y that satisfies the dual certificate conditions (9)-(12). Thus, the second step is to construct Y via the golfing scheme. Although we adapt the steps in [12] to construct the dual certificate Y , our analysis requires new technical development based on local incoherence parameters. Recall the following definitions in Section 2.1: P((i, j) 2 ⌦) = ⇢\nij and P((i, j) 2 ) = p ij , where = ⌦c and p ij = 1 ⇢ ij .\nConsider the golfing scheme with nonuniform sizes as suggested in [12] to establish bounds with fewer log factors. Let =\n1 [ 2 [ · · · [ l , where { k } are independent random sets given by\nP((i, j) 2 1 ) =\np ij\n6\n, P((i, j) 2 k ) = q ij , for k = 2, · · · , l.\nThus, if ⇢ ij = (1 pij 6 )(1 q ij ) l 1, the two sampling strategies are equivalent. Due to the overlap between {\nk }, we have q ij\n5 6\npij l 1 . We set l = b5 log n + 1c and construct a dual certificate Y in the following iterative way:\nZ 0 = P T (UV ⇤ sgn(S)) (13) Z k = (P T P T R kPT )Zk 1, for k = 1, · · · , l (14)\nY = l X\nk=1\nR kZk 1. (15)\nIt is then sufficient to show that such constructed Y satisfies the dual certificate conditions (9)-(12). Condition (9) is due to the construction of Y . Condition (12) can be shown by a concentration property of each iteration step (14) with k · k\nF characterized in Lemma 3 in Appendix A.1. In order to show that Y satisfies conditions (10) and (11), we introduce the following weighted norm. Let ŵ\nij\n=\nq\nµijr\nn 2 and wij = max{ŵij , ✏}, where ✏ is the smallest nonzero ŵij . Here ✏ is introduced to avoid singularity. Then for any matrix Z, define\nkZk w(1) = max\ni,j\n|Z ij | w\nij\n. (16)\nIt is easy to verify k · k w(1) is a well defined norm. We can then show that each iteration step (14) with k · k and k · k w(1) norms satisfies two concentration properties characterized respectively in Lemmas 4 and 5, which are essential to prove conditions (10) and (11)."
    }, {
      "heading" : "3 Numerical Experiments",
      "text" : "In this section, we provide numerical experiments to demonstrate our theoretical results. In these experiments, we adopt an augmented Lagrange multiplier algorithm in [17] to solve the PCP. We set = 1/ p n log n. A trial of PCP (for a given realization of error locations) is declared to be\nsuccessful if ˆL recovered by PCP satisfies kˆL Lk F /kLk F  10 3. We apply the following three models to construct the low rank matrix L.\n• Bernoulli model: L = XX⇤ where X is n⇥r matrix with entries independently taking values +1/ p n and 1/ p n equally likely. • Gaussian model: L = XX⇤, where X is n ⇥ r matrix with entries independently sampled from Gaussian distribution N (0, 1/n).\n• Cluster model: L is a block diagonal matrix with r equal-size blocks containing all ‘1’s. In order to demonstrate that the local incoherence parameter affects local robustness to error corruptions, we study the following two types of error corruption models.\n• Uniform error corruption: sgn(S ij ) is generated as (6) with ⇢ ij = ⇢ for all i, j 2 [n], and S = sgn(S).\n• Adaptive error corruption: sgn(S ij ) is generated as (6) with ⇢ ij = ⇢ n\n2 p\n1/µij P\nij\np 1/µij for all i, j 2\n[n], and S = sgn(S). It is clear in both cases, the error matrix has the same average error corruption percentage ⇢, but in adaptive error corruption, the local error corruption probability is adaptive to the local incoherence.\nOur first experiment demonstrates that robustness of PCP to error corruption not only depends on the number of errors but also depends on how errors are distributed over the matrix. For all three\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0\n0.2\n0.4\n0.6\n0.8\n1\nError percentage ρ\nF a ilu\nre f re\nq u e n cy\nuniform error adaptive error\n(a) Bernoulli model 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7\n0\n0.2\n0.4\n0.6\n0.8\n1\nError percentage ρ\nF a ilu\nre f re\nq u e n cy\nuniform error adaptive error\n(b) Gaussian model 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7\n0\n0.2\n0.4\n0.6\n0.8\n1\nError percentage ρ\nF a ilu\nre f re\nq u e n cy\nuniform noise adaptive noise\n(c) Cluster model\nFigure 2: Recovery failure of PCP versus error corruption percentage.\nlow rank matrix models, we set n = 1200 and rank r = 10. For each low rank matrix model, we apply the uniform and adaptive error matrices, and plot the failure frequency of PCP versus the error corruption percentage ⇢ in Fig. 2. For each value of ⇢, we perform 50 trials of independent error corruption and count the number of failures of PCP. Each plot of Fig. 2 compares robustness of PCP to uniform error corruption (the red square line) and adaptive error corruption (the blue circle line). We observe that PCP can tolerate more errors in the adaptive case. This is because the adaptive error matrix is distributed based on the local incoherence parameter, where error density is higher in areas where matrices can tolerate more errors. Furthermore, comparison among the three plots in Fig. 2 illustrates that the gap between uniform and adaptive error matrices is the smallest for Bernoulli model and the largest for cluster model. Our theoretic results suggest that the gap is due to the variation of the local incoherence parameter across the matrix, which can be measured by the variance of µ\nij . Larger variance of µ ij should yield larger gap. Our numerical calculation of the variances for three models yield Var(µ\nBernoulli ) = 1.2109, Var(µ Gaussian ) = 2.1678, and Var(µ\ncluster\n) = 7.29, which confirms our explanation.\nWe next study the phase transition in rank and error corruption probability. For the three low-rank matrix models, we set n = 1200. In Fig. 3, we plot the error corruption percentage versus the rank of L for both uniform and adaptive error corruption models. Each point on the curve records the maximum allowable error corruption percentage under the corresponding rank such that PCP yields correction recovery. We count a (r, ⇢) pair to be successful if nine trials out of ten are successful. We first observe that in each plot of Fig. 3, PCP is more robust in adaptive error corruption due to the same reason explained above. We further observe that the gap between the uniform and adaptive error corruption changes as the rank changes. In the low-rank regime, the gap is largely determined by the variance of incoherence parameter µ\nij as we argued before. As the rank increases, the gap is more dominated by the rank and less affected by the local incoherence. Eventually for large enough rank, no error can be tolerated no matter how errors are distributed."
    }, {
      "heading" : "4 Conclusion",
      "text" : "We characterize refined conditions under which PCP succeeds to solve the robust PCA problem. Our result shows that the ability of PCP to correctly recover a low-rank matrix from errors is related not only to the total number of corrupted entries but also to locations of corrupted entries, more essentially to the local incoherence of the low rank matrix. Such result is well supported by our numerical experiments. Moreover, our result has rich implication when the low rank matrix is a cluster matrix, and our result coincides with state-of-the-art studies on clustering problems via low rank cluster matrix. Our result may motivate the development of weighted PCP to improve recovery performance similar to the weighted algorithms developed for matrix completion in [9, 18]."
    } ],
    "references" : [ {
      "title" : "Robust principal component analysis",
      "author" : [ "E.J. Candès", "X. Li", "Y. Ma", "J. Wright" ],
      "venue" : "Journal of the ACM (JACM),",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2011
    }, {
      "title" : "Rank-sparsity incoherence for matrix decomposition",
      "author" : [ "V. Chandrasekaran", "S. Sanghavi", "P.A. Parrilo", "A.S. Willsky" ],
      "venue" : "SIAM Journal on Optimization,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2011
    }, {
      "title" : "Low-rank matrix recovery from errors and erasures",
      "author" : [ "Y. Chen", "A. Jalali", "S. Sanghavi", "C. Caramanis" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2013
    }, {
      "title" : "Incoherence-optimal matrix completion",
      "author" : [ "Y. Chen" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2015
    }, {
      "title" : "Exact matrix completion via convex optimization",
      "author" : [ "E.J. Candès", "B. Recht" ],
      "venue" : "Foundations of Computational mathematics,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2009
    }, {
      "title" : "The power of convex relaxation: Near-optimal matrix completion",
      "author" : [ "E.J. Candès", "T. Tao" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2010
    }, {
      "title" : "Recovering low-rank matrices from few coefficients in any basis",
      "author" : [ "D. Gross" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2011
    }, {
      "title" : "Guaranteed minimum-rank solutions of linear matrix equations via nuclear norm minimization",
      "author" : [ "B. Recht", "M. Fazel", "P.A. Parrilo" ],
      "venue" : "SIAM Review,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2010
    }, {
      "title" : "Completing any low-rank matrix, provably",
      "author" : [ "Y. Chen", "S. Bhojanapalli", "S. Sanghavi", "R. Ward" ],
      "venue" : "arXiv preprint arXiv:1306.2979,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2013
    }, {
      "title" : "Robust matrix decomposition with sparse corruptions",
      "author" : [ "D. Hsu", "S.M. Kakade", "T. Zhang" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2011
    }, {
      "title" : "Dense error correction for low-rank matrices via principal component pursuit",
      "author" : [ "A. Ganesh", "J. Wright", "X. Li", "E.J. Candes", "Y. Ma" ],
      "venue" : "In IEEE International Symposium on Information Theory (ISIT),",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2010
    }, {
      "title" : "Compressed sensing and matrix completion with constant proportion of corruptions",
      "author" : [ "X. Li" ],
      "venue" : "Constructive Approximation,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2013
    }, {
      "title" : "Finding dense clusters via “low rank+ sparse",
      "author" : [ "S. Oymak", "B. Hassibi" ],
      "venue" : "decomposition. arXiv preprint arXiv:1104.5186,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2011
    }, {
      "title" : "Clustering sparse graphs",
      "author" : [ "Y. Chen", "S. Sanghavi", "H. Xu" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2012
    }, {
      "title" : "Improved graph clustering",
      "author" : [ "Y. Chen", "S. Sanghavi", "H. Xu" ],
      "venue" : "IEEE Transactions on Information Theory,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2014
    }, {
      "title" : "Clustering partially observed graphs via convex optimization",
      "author" : [ "Y. Chen", "A. Jalali", "S. Sanghavi", "H. Xu" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2014
    }, {
      "title" : "The augmented lagrange multiplier method for exact recovery of corrupted low-rank matrices",
      "author" : [ "Z. Lin", "M. Chen", "Y. Ma" ],
      "venue" : "arXiv preprint arXiv:1009.5055,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2010
    }, {
      "title" : "Collaborative filtering in a non-uniform world: Learning with the weighted trace norm",
      "author" : [ "N. Srebro", "R.R. Salakhutdinov" ],
      "venue" : "In Advances in Neural Information Processing Systems (NIPS),",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2010
    }, {
      "title" : "Introduction to the non-asymptotic analysis of random matrices",
      "author" : [ "R. Vershynin" ],
      "venue" : "arXiv preprint arXiv:1011.3027,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2010
    }, {
      "title" : "User-friendly tail bounds for sums of random matrices",
      "author" : [ "J.A. Tropp" ],
      "venue" : "Foundations of Computational Mathematics,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "In [1, 2], Principal Component Pursuit (PCP) has been proposed to solve the robust PCA problem via the following convex programming PCP: minimize",
      "startOffset" : 3,
      "endOffset" : 9
    }, {
      "referenceID" : 1,
      "context" : "In [1, 2], Principal Component Pursuit (PCP) has been proposed to solve the robust PCA problem via the following convex programming PCP: minimize",
      "startOffset" : 3,
      "endOffset" : 9
    }, {
      "referenceID" : 0,
      "context" : "It was shown in [1, 2] that PCP successfully recovers L and S if the two matrices are distinguishable from each other in properties, i.",
      "startOffset" : 16,
      "endOffset" : 22
    }, {
      "referenceID" : 1,
      "context" : "It was shown in [1, 2] that PCP successfully recovers L and S if the two matrices are distinguishable from each other in properties, i.",
      "startOffset" : 16,
      "endOffset" : 22
    }, {
      "referenceID" : 2,
      "context" : "For example, Theorem 2 in [3] explicitly shows that the matrix L with larger μ can tolerate only smaller error density to guarantee correct matrix decomposition by PCP.",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 3,
      "context" : "We note that the notion of local incoherence was first introduced in [4] for studying the matrix completion problem, in which local incoherence determines the local sampling density in order to guarantee correct matrix completion.",
      "startOffset" : 69,
      "endOffset" : 72
    }, {
      "referenceID" : 0,
      "context" : "0 in matrix completion due to further difficulty of robust PCA, in which locations of error corrupted entries are unknown, as pointed out in [1, 3].",
      "startOffset" : 141,
      "endOffset" : 147
    }, {
      "referenceID" : 2,
      "context" : "0 in matrix completion due to further difficulty of robust PCA, in which locations of error corrupted entries are unknown, as pointed out in [1, 3].",
      "startOffset" : 141,
      "endOffset" : 147
    }, {
      "referenceID" : 3,
      "context" : "In order to deal with non-uniform error corruption, our technical proof introduces a new weighted norm denoted by l w(1), which involves the information of both localized μ0 and μ1 and is hence different from the weighted norms introduced in [4] for matrix completion.",
      "startOffset" : 242,
      "endOffset" : 245
    }, {
      "referenceID" : 3,
      "context" : "Later on, it was shown in [4] that μ 1 does not affect sample complexity for matrix completion and hence ⇥(μ 0 nr log2 n) observed entries are sufficient for guaranteeing correct matrix completion.",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 8,
      "context" : "It was further shown in [9] that a coherent low-rank matrix (i.",
      "startOffset" : 24,
      "endOffset" : 27
    }, {
      "referenceID" : 1,
      "context" : "In [2, 10], robust PCA with fixed error matrix was studied, and it was shown that the maximum number of errors in any row or column should be bounded from above in order to guarantee correct decomposition by PCP.",
      "startOffset" : 3,
      "endOffset" : 10
    }, {
      "referenceID" : 9,
      "context" : "In [2, 10], robust PCA with fixed error matrix was studied, and it was shown that the maximum number of errors in any row or column should be bounded from above in order to guarantee correct decomposition by PCP.",
      "startOffset" : 3,
      "endOffset" : 10
    }, {
      "referenceID" : 0,
      "context" : "It has been shown in [1] that such decomposition can be exact with high probability if the percentage of corrupted entries is small enough, under the assumptions that the low-rank matrix is incoherent and the support set of the sparse matrix is uniformly distributed.",
      "startOffset" : 21,
      "endOffset" : 24
    }, {
      "referenceID" : 10,
      "context" : "It was further shown in [11] that if signs of nonzero entries in the sparse matrix are randomly chosen, then an adjusted convex optimization can produce exact decomposition even when the percentage of corrupted entries goes to one (i.",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 0,
      "context" : "The problem was further studied in [1, 3, 12] for the case with the error-corrupted low-rank matrix only partially observed.",
      "startOffset" : 35,
      "endOffset" : 45
    }, {
      "referenceID" : 2,
      "context" : "The problem was further studied in [1, 3, 12] for the case with the error-corrupted low-rank matrix only partially observed.",
      "startOffset" : 35,
      "endOffset" : 45
    }, {
      "referenceID" : 11,
      "context" : "The problem was further studied in [1, 3, 12] for the case with the error-corrupted low-rank matrix only partially observed.",
      "startOffset" : 35,
      "endOffset" : 45
    }, {
      "referenceID" : 0,
      "context" : "We further note that satisfying the condition in Theorem 1 implies C 0 p μr/n log n  1, which is an essential bound required in our proof and coincides with the conditions in previous studies [1, 12].",
      "startOffset" : 193,
      "endOffset" : 200
    }, {
      "referenceID" : 11,
      "context" : "We further note that satisfying the condition in Theorem 1 implies C 0 p μr/n log n  1, which is an essential bound required in our proof and coincides with the conditions in previous studies [1, 12].",
      "startOffset" : 193,
      "endOffset" : 200
    }, {
      "referenceID" : 3,
      "context" : "This is consistent with the result in [4] for matrix completion, in which smaller local incoherence parameter requires lower local sampling rate.",
      "startOffset" : 38,
      "endOffset" : 41
    }, {
      "referenceID" : 2,
      "context" : "Such an interesting regime was previously studied in [3, 11].",
      "startOffset" : 53,
      "endOffset" : 60
    }, {
      "referenceID" : 10,
      "context" : "Such an interesting regime was previously studied in [3, 11].",
      "startOffset" : 53,
      "endOffset" : 60
    }, {
      "referenceID" : 10,
      "context" : "In [11], it is argued that PCP with adaptive yields exact recovery even when the error corruption probability approaches one if errors take random signs and the dimension n is sufficiently large.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 2,
      "context" : "In [3], it is further shown that PCP with a fixed also yields exact recovery and the scaling behavior of the error corruption probability is characterized.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 0,
      "context" : "1 in [1] for robust PCA with uniform error corruption.",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 0,
      "context" : "1 of [1] implies the conditions in Theorem 2.",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 2,
      "context" : "Such benefit of condition relaxation should be attributed to the new golfing scheme introduced in [3, 12], and this paper provides a more refined view of robust PCA by further taking advantage of such a new golfing scheme to analyze local conditions.",
      "startOffset" : 98,
      "endOffset" : 105
    }, {
      "referenceID" : 11,
      "context" : "Such benefit of condition relaxation should be attributed to the new golfing scheme introduced in [3, 12], and this paper provides a more refined view of robust PCA by further taking advantage of such a new golfing scheme to analyze local conditions.",
      "startOffset" : 98,
      "endOffset" : 105
    }, {
      "referenceID" : 12,
      "context" : "This also coincides with the results on graph clustering in [13, 16].",
      "startOffset" : 60,
      "endOffset" : 68
    }, {
      "referenceID" : 15,
      "context" : "This also coincides with the results on graph clustering in [13, 16].",
      "startOffset" : 60,
      "endOffset" : 68
    }, {
      "referenceID" : 0,
      "context" : "4 Outline of the Proof of Theorem 1 The proof of Theorem 1 follows the idea established in [1] and further developed in [3, 12].",
      "startOffset" : 91,
      "endOffset" : 94
    }, {
      "referenceID" : 2,
      "context" : "4 Outline of the Proof of Theorem 1 The proof of Theorem 1 follows the idea established in [1] and further developed in [3, 12].",
      "startOffset" : 120,
      "endOffset" : 127
    }, {
      "referenceID" : 11,
      "context" : "4 Outline of the Proof of Theorem 1 The proof of Theorem 1 follows the idea established in [1] and further developed in [3, 12].",
      "startOffset" : 120,
      "endOffset" : 127
    }, {
      "referenceID" : 8,
      "context" : "As a generalization of matrix infinity norm, l w(1) incorporates both μ 0ij and μ 1ij , and is hence different from the weighted norms l μ(1) and lμ(1,2) in [9] by its role in the analysis for the robust PCA problem.",
      "startOffset" : 157,
      "endOffset" : 160
    }, {
      "referenceID" : 0,
      "context" : "The proof of the above proposition adapts the idea in [1,12] for uniform errors to non-uniform errors.",
      "startOffset" : 54,
      "endOffset" : 60
    }, {
      "referenceID" : 11,
      "context" : "The proof of the above proposition adapts the idea in [1,12] for uniform errors to non-uniform errors.",
      "startOffset" : 54,
      "endOffset" : 60
    }, {
      "referenceID" : 8,
      "context" : "In particular, the proof exploits the properties of R ⌦ associated with non-uniform errors, which are presented as Lemma 1 (established in [9]) and Lemma 2 in Appendix A.",
      "startOffset" : 139,
      "endOffset" : 142
    }, {
      "referenceID" : 11,
      "context" : "Although we adapt the steps in [12] to construct the dual certificate Y , our analysis requires new technical development based on local incoherence parameters.",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 11,
      "context" : "Consider the golfing scheme with nonuniform sizes as suggested in [12] to establish bounds with fewer log factors.",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 16,
      "context" : "In these experiments, we adopt an augmented Lagrange multiplier algorithm in [17] to solve the PCP.",
      "startOffset" : 77,
      "endOffset" : 81
    } ],
    "year" : 2015,
    "abstractText" : "We investigate the robust PCA problem of decomposing an observed matrix into the sum of a low-rank and a sparse error matrices via convex programming Principal Component Pursuit (PCP). In contrast to previous studies that assume the support of the error matrix is generated by uniform Bernoulli sampling, we allow non-uniform sampling, i.e., entries of the low-rank matrix are corrupted by errors with unequal probabilities. We characterize conditions on error corruption of each individual entry based on the local incoherence of the low-rank matrix, under which correct matrix decomposition by PCP is guaranteed. Such a refined analysis of robust PCA captures how robust each entry of the low rank matrix combats error corruption. In order to deal with non-uniform error corruption, our technical proof introduces a new weighted norm and develops/exploits the concentration properties that such a norm satisfies.",
    "creator" : null
  }
}