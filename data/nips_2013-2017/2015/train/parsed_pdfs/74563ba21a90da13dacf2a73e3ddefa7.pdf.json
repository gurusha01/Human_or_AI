{
  "name" : "74563ba21a90da13dacf2a73e3ddefa7.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Statistical Topological Data Analysis – A Kernel Perspective",
    "authors" : [ "Roland Kwitt", "Stefan Huber", "Weili Lin" ],
    "emails" : [ "rkwitt@gmx.at", "stefan.huber@ist.ac.at", "mn@cs.unc.edu", "weili_lin@med.unc.edu", "ulrich@bauer.org" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Over the past years, advances in adopting methods from algebraic topology to study the “shape” of data (e.g., point clouds, images, shapes) have given birth to the field of topological data analysis (TDA) [5]. In particular, persistent homology has been widely established as a tool for capturing “relevant” topological features at multiple scales. The output is a summary representation in the form of so called barcodes or persistence diagrams, which, roughly speaking, encode the life span of the features. These “topological summaries” have been successfully used in a variety of different fields, including, but not limited to, computer vision and medical imaging. Applications range from the analysis of cortical surface thickness [8] to the structure of brain networks [15], brain artery trees [2] or histology images for breast cancer analysis [22].\nDespite the success of TDA in these areas, a statistical treatment of persistence diagrams (e.g., computing means or variances) turns out to be difficult, not least because of the unusual structure of the barcodes as intervals, rather than numerical quantities [1]. While substantial advancements in\nthe direction of statistical TDA have been made by studying the structure of the space of persistence diagrams endowed with p-Wasserstein metrics (or variants thereof) [18, 19, 28, 11], it is technically and computationally challenging to work in this space. In a machine learning context, we would rather work with Hilbert spaces, primarily due to the highly regular structure and the abundance of readily available and well-studied methods for statistics and learning.\nOne way to circumvent issues such as non-uniqueness of the Fréchet mean [18] or computationally intensive algorithmic strategies [28] is to consider mappings of persistence barcodes into linear function spaces. Statistical computations can then be performed based on probability theory on Banach spaces [14]. However, the methods proposed in [4] cannot guarantee that different probability distributions can always be distinguished by a statistical test.\nContribution. In this work, we consider the task of statistical computations with persistence diagrams. Our contribution is to approach this problem by leveraging the theory of embedding probability measures into reproducing kernel Hilbert spaces [23], in our case, probability measures on the space of persistence diagrams. In particular, we start with a recently introduced kernel on persistence diagrams by Reininghaus et al. [20] and identify missing properties that are essential for a well-founded use in the aforementioned framework. By enforcing mild restrictions on the underlying space, we can in fact close the remaining gaps and prove that a minor modification of the kernel is universal in the sense of Steinwart [25] (see Section 3). Our experiments demonstrate, on a couple of synthetic and real-world data samples, how this universal kernel enables a principled solution to the selected problem of (kernel-based) two-sample hypothesis testing.\nRelated work. In the following, we focus our attention on work related to a statistical treatment of persistent homology. Since this is a rather new field, several avenues are pursued in parallel. Mileyko et al. [18] study properties of the set of persistence diagrams when endowed with the p-Wasserstein metric. They show, for instance, that under this metric, the space is Polish and the Fréchet mean exists. However, it is not unique and no algorithmic solution is provided. Turner et al. [28] later show that the L2-Wasserstein metric on the set of persistence diagrams yields a geodesic space, and that the additional structure can be leveraged to construct an algorithm for computing the Fréchet mean and to prove a law of large numbers. In [19], Munch et al. take a different approach and introduce a probabilistic variant of the Fréchet mean as a probability measure on persistence diagrams. While this yields a unique mean, the solution itself is not a persistence diagram anymore. Techniques for computing confidence sets for persistence diagrams are investigated by Fasy et al. [11]. The authors focus on the Bottleneck metric (i.e., a special case of the p-Wasserstein metric when p = ∞), remarking that similar results could potentially be obtained for the case of the p-Wasserstein metric under stronger assumptions on the underlying topological space.\nWhile the aforementioned results concern properties of the set of persistence diagrams equipped with p-Wasserstein metrics, a different strategy is advocated by Bubenik in [4]. The key idea is to circumvent the peculiarities of the metric by mapping persistence diagrams into function spaces. One such representation is the persistence landscape, i.e., a sequence of 1-Lipschitz functions in a Banach space. While it is in general not possible to go back and forth between landscapes and persistence diagrams, the Banach space structure enables a well-founded theoretical treatment of statistical concepts, such as averages or confidence intervals [14]. Chazal et al. [6] establish additional convergence results and propose a bootstrap procedure for obtaining confidence sets.\nAnother, less statistically oriented, approach towards a convenient summary of persistence barcodes is followed by Adcock et al. [1]. The idea is to attach numerical quantities to persistence barcodes, which can then be used as input to any machine learning algorithm in the form of feature vectors. This strategy is rooted in a study of algebraic functions on barcodes. However, it does not necessarily guarantee stability of the persistence summary representation, which is typically a desired property of a feature map [20].\nOur proposed approach to statistical TDA is also closely related to work in the field of kernel-based learning techniques [21] or, to be more specific, to the embedding of probability measures into a RKHS [23] and the study of suitable kernel functions in that context [7, 24]. In fact, the idea of mapping probability measures into a RKHS has led to many developments generalizing statistical concepts, such as two-sample testing [13], testing for conditional independence, or statistical inference [12], form Euclidean spaces to other domains equipped with a kernel. In the context of supervised learning with TDA, Reininghaus et al. [20] recently established a first connection to\nkernel-based learning techniques via the definition of a positive definite kernel on persistence diagrams. While positive definiteness is sufficient for many techniques, such as support vector machines or kernel PCA, additional properties are required in the context of embedding probability measures.\nOrganization. Section 2 briefly reviews some background material and introduces some notation. In Section 3, we show how a slight modification of the kernel in [20] fits into the framework of embedding probability measures into a RKHS. Section 4 presents a set of experiments on synthetic and real data, highlighting the advantages of the kernel. Finally, Section 5 summarizes the main contributions and discusses future directions."
    }, {
      "heading" : "2 Background",
      "text" : "Since our discussion of statistical TDA from a kernel perspective is largely decoupled from how the topological summaries are obtained, we only review two important notions for the theory of persistent homology: filtrations and persistence diagrams. For a thorough treatment of the topic, we refer the reader to [10]. We also briefly review the concept of embedding probability measures into a RKHS, following [23].\nFiltrations. A standard approach to TDA assigns to some metric space (M,dM) a growing sequence of simplicial complexes (indexed by a parameter t ∈ R), typically referred to as a filtration. Recall that an abstract simplicial complex is a collection of nonempty sets that is closed under taking nonempty subsets. Persistent homology then studies the evolution of the homology of these complexes for a growing parameter t. Some widely used constructions, particularly for point cloud data, are the Vietoris–Rips and the Čech complex. The Vietoris–Rips complex is a simplicial complex with vertex set M such that [x0, . . . , xm] is an m-simplex iff maxi, j≤m dM(xi , x j ) ≤ t. For a point set M ⊂ Rd in Euclidean space, the Čech complex is a simplicial complex with vertex set M ⊂ Rd such that [x0, . . . , xm] is an m-simplex iff the closed balls of radius t centered at the xi have a non-empty common intersection.\nA more general way of obtaining a filtration is to consider the sublevel sets f −1(−∞, t], for t ∈ R, of a function f : X → R on a topological space X. For instance, in the case of surfaces meshes, a commonly used function is the heat kernel signature (HKS) [27]. The Čech and Vietoris–Rips filtrations appear as special cases, both being sublevel set filtrations of an appropriate function on the subsets (abstract simplices) of the vertex set M: for the Čech filtration, the function assigns to each subset the radius of its smallest enclosing sphere, while for the Vietoris–Rips filtration, the function assigns to each subset its diameter (equivalently, the length of its longest edge).\nPersistence diagrams. Studying the evolution of the topology of a filtration allows us to capture interesting properties of the metric or function used to generate the filtration. Persistence diagrams provide a concise description of the changes in homology that occur during this process.\nExisting connected components may merge, cycles may appear, etc. This leads to the appearance and disappearance of homological features of different dimension. Persistent homology tracks the birth b and death d of such topological features. The multiset of points p, where each point p = (b,d) corresponds to a birth/death time pair, is called the persistence diagram of the filtration. An example of a per-\nsistence diagram for 0-dimensional features (i.e., connected components) of a function f : X → R with X = R is shown in Fig. 2. We use the identifiers F,G to denote persistence diagrams in the remainder of the paper. Since d > b, all points lie in the half-plane above the diagonal.\nRKHS embedding of probability measures. An important concept for our work is the embedding of probability measures into reproducing kernel Hilbert spaces [23]. Consider a Borel probability measure P defined on a compact metric space (X,d), which we observe through the i.i.d. sample X = {xi }mi=1 with xi ∼ P. Furthermore, let k : X × X → R be a positive definite kernel, i.e., a function which realizes an inner product k (x, y) = 〈φ(x), φ(y)〉G with x, y ∈ X in some Hilbert space G for some (possibly unknown) map φ : X → G (see [26, Definition 4.1.]). Also, let H be the associated RKHS, generated by functions kx = k (x, ·) : X → R induced by the kernel, i.e., H = span{kx : x ∈ X} = span{〈φ(x), φ(·)〉G : x ∈ X}, with the scalar product 〈kx , ky〉H = k (x, y).\nThe linear structure on the RKHSH admits the construction of means. The embedding of a probability measure P on X is now accomplished via the mean map µ : P 7→ µP = Ex∼P[kx ]. If this map is injective, the kernel k is called characteristic. This is true, in particular, ifH is dense in the space of continuous functions X → R (with the supremum norm), in which case we refer to the kernel as universal [25]. While a universal kernel is always characteristic, the converse is not true.\nSince it has been shown [13] that the empirical estimate of the mean, µX = 1/m ∑\ni kxi , is a good proxy for µP , the injectivity of µ can be used to define distances between distributions P and Q, observed via samples X = {xi }mi=1 and Y = {yi } n i=1. Specifically, this can be done via the maximum mean discrepancy\nMMD[F ,P,Q] = sup f ∈F (Ex∼P[ f (x)] − Ey∼Q[ f (y)]), (1)\nwhere F denotes a suitable class of functions X → R, and Ex∼P[ f (x)] denotes the expectation of f (x) w.r.t. P (which can be written as 〈µP , f 〉 by virtue of the reproducing property of k). Gretton et al. [13] restrict F to functions on a unit ball in H , i.e., F = { f ∈ H : ‖ f ‖∞ ≤ 1}, and show that Eq. (1) can be expressed as the RHKS distance between the means µP and µQ of the measures P and Q as MMD2[F ,P,Q] = ‖µP − µQ ‖2H . Empirical estimates of this quantity are given in [13]. This connection is of particular importance to us, since it allows for two-sample hypothesis testing in a principled manner given a suitable (characteristic/universal) kernel. Prominent examples of universal kernels for X = Rd are the Gaussian RBF kernel k (x, y) = e−γ ‖x−y ‖2 and the kernel e〈x,y〉. However, without a characteristic/universal kernel, MMD[F ,P,Q] = 0 does not imply P = Q. A well-known example of a non-characteristic kernel is the scalar product kernel k (x, y) = 〈x, y〉 with x, y ∈ Rd . Even if P , Q, e.g., if the variances of the distributions differ, the MMD will still be zero if the means are equal.\nIn the context of a statistical treatment of persistent homology, the ability to embed probability measures on the space of persistence diagrams into a RKHS is appealing. Specifically, the problem of testing whether two different samples exhibit significantly different homological features – as captured in the persistence diagram – boils down to a two-sample test with null hypothesis H0 : µP = µQ vs. a general alternative HA : µP , µQ , where P and Q are probability measures on the set of persistence diagrams. The computation of this test only involves evaluations of the kernel. Enabling this procedure via a suitable universal kernel will be discussed next."
    }, {
      "heading" : "3 The universal persistence scale space kernel",
      "text" : "In the following, for 1 ≤ q ≤ ∞ we let Dq = {F | dW ,q (F,∅) < ∞}, denote the metric space of persistence diagrams with the q-Wasserstein metric dW ,q 1, where ∅ is the empty diagram. In [18, Theorem 1], Mileyko et al. show that (Dq ,dW ,q ) is a complete metric space. When the subscript q is omitted, we do not refer to any specific instance of q-Wasserstein metric.\nLet us fix the numbers N ∈ N and R ∈ R. We denote by S the subset of D consisting of those persistence diagrams that are birth-death bounded by R (i.e., for every D ∈ S the birth/death time of its points is less or equal to R; see [18, Definition 5]) and whose total multiplicities (i.e., the sum of multiplicities of all points in a diagram) are bounded by N . While this might appear restrictive at first sight, it does not really pose a limitation in practice. In fact, for data generated by some finite process (e.g., meshes have a finite number of vertices/faces, images have limited resolution, etc.), establishing N and R is typically not a problem. We remark that the aforementioned restriction is similar to enforcing boundedness of the support of persistence landscapes in [4, Section 3.6].\nIn [20], Reininghaus et al. introduce the persistence scale space (PSS) kernel as a stable, multi-scale kernel on the set D of persistence diagrams of finite total multiplicity, i.e., each diagram contains only finitely many points. Let p = (b,d) denote a point in a diagram F ∈ D, and let p = (d,b) denote its mirror image across the diagonal. Further, let Ω = {x = (x1, x2) ∈ R2, x2 ≥ x1}. The feature map Φσ : D → L2(Ω) is given as the solution of a heat diffusion problem with a Dirichlet boundary condition on the diagonal by\n1The q-Wasserstein metric is defined as dW ,q (F,G) = infγ ( ∑ x∈F ‖x − γ(x)‖ q ∞)1/q , where γ ranges over all bijections from F ∪ D to G ∪ D, with D denoting the multiset of diagonal points (t, t), each with countably infinite multiplicity.\nΦσ (F) : Ω→ R, x 7→ 1\n4πσ ∑ p∈F e− ‖x−p‖2 4σ − e− ‖x−p‖2 4σ . (2)\nThe kernel kσ : D × D → R is then given in closed form as\nkσ (F,G) = 〈Φσ (F),Φσ (G)〉L2 (Ω) = 1\n8πσ ∑ p∈F q∈G e− ‖p−q ‖2 8σ − e− ‖p−q ‖2 8σ . (3)\nfor σ > 0 and F,G ∈ D. By construction, positive definiteness of kσ is guaranteed. The kernel is stable in the sense that the distance dσ (F,G) = √ k (F,F) + k (G,G) − 2k (F,G) is bounded up to a constant by dW ,1(F,G) [20, Theorem 2].\nWe have the following property: Proposition 1. Restricting the kernel in Eq. (3) to S × S, the mean map µ sends a probability measure P on S to an element µP ∈ H .\nProof. The claim immediately follows from [13, Lemma 3] and [24, Proposition 2], since kσ is measurable and bounded on S, and hence µP ∈ H .\nWhile positive definiteness enables the use of kσ in many kernel-based learning techniques [21], we are interested in assessing whether it is universal, or if we can construct a universal kernel from kσ (see Section 2). The following theorem of Christmann and Steinwart [7] is particularly relevant to this question. Theorem 1. (cf. Theorem 2.2 of [7]) Let X be a compact metric space and G a separable Hilbert space such that there exists a continuous and injective mapΦ : X → G. Furthermore, let K : R→ R be a function that is analytic on some neighborhood of 0, i.e., it can locally be expressed by its Taylor series\nK (t) = ∞∑ n=0 antn , t ∈ [−r,r].\nIf an > 0 for all n ∈ N0, then k : X × X → R,\nk (x, y) = K (〈Φ(x),Φ(y)〉G ) = ∞∑ n=0 an〈Φ(x),Φ(y)〉nG . (4)\nis a universal kernel.\nKernels of the form Eq. (4) are typically referred to as Taylor kernels.\nNote that universality of a kernel on X refers to a specific choice of metric on X. By using the same argument as for the linear dot-product kernel in Rd (see above), the PSS kernel kσ cannot be universal with respect to the metric dkσ , which is induced by the scalar product defining kσ . On the other hand, it is unclear whether kσ is universal with respect to the metric dW ,q . However, we do have the following result: Proposition 2. The kernel kUσ : S × S → R,\nkUσ (F,G) = exp(kσ (F,G)), (5)\nis universal with respect to the metric dW ,1.\nProof. We prove this proposition by means of Theorem 1. We set G = L2(Ω), which is a separable Hilbert space. As shown in Reininghaus et al. [20], the feature map Φσ : D → L2(Ω) is injective. Furthermore, it is continuous by construction, as the metric on D is induced by the norm on L2(Ω), and so is Φσ restricted to S. The function K : R → R is defined as x 7→ exp(x), and hence is analytic on R. Its Taylor coefficients an are 1/n!, and thus are positive for any n.\nIt remains to show that (S,dW ,1) is a compact metric space. First, define R = ΩN ∩ ([−R,R]2)N , which is a bounded, closed, and therefore compact subspace of (R2)N . Now consider the function\nf : R → S that maps (p1, . . . ,pN ) ∈ R to the persistence diagram {pi : 1 ≤ i ≤ N if pi < ∂Ω} ∈ S. We note that for all D = {p1, . . . ,pn } ∈ S, with n ≤ N , there exists an X ∈ R, e.g., X = (p1, . . . ,pn ,0, . . . ,0), such that f (X ) = D; this implies S = f (R). Next, we show that f is 1-Lipschitz continuous w.r.t. the 1-Wasserstein distance on persistence diagrams, i.e.,\n∀X = (p1, . . . ,pN ),Y = (q1, . . . ,qN ) ∈ R : dW ,1( f (X ), f (Y )) ≤ d(X,Y ), where we defined d as infγ ∑ 1≤i≤N ‖pi − γ(pi )‖∞ with γ ranging over all bijections between {p1, . . . ,pN } and {q1, . . . ,qN }. In other words, d corresponds to the 1-Wasserstein distance without allowing matches to the diagonal. Now, by definition, dW ,1( f (X ), f (Y )) ≤ d(X,Y ), because all bijections considered by d are also admissible for dW ,1. Since thus R is compact and f is continuous, we have that S = f (R) is compact as well.\nWe refer to the kernel of Eq. (5) as the universal persistence scale-space (u-PSS) kernel.\nRemark. While we prove Prop. 1 for the PSS kernel in Eq. (3), it obviously also holds for kUσ , since exponentiation does neither invalidate measurability nor boundedness.\nRelation to persistence landscapes. As the feature map Φσ of Eq. (2) defines a function-valued summary of persistent homology in the Hilbert space L2(Ω), the results on probability in Banach spaces [14], used in [4] for persistence landscapes, naturally apply to Φσ as well. This includes, for instance, the law of large numbers or the central limit theorem [4, Theorems 9,10]. Conversely, considering a persistence landscape λ(D) as a function in L2(N × R) or L2(R2) yields a positive definite kernel 〈λ(·), λ(·)〉L2 on persistence diagrams. However, it is unclear whether a universal kernel can be constructed from persistence landscapes in a way similar to the definition of kUσ . In particular, we are not aware of a proof that the construction of persistence landscapes, considered as functions in L2, is continuous with respect to dW ,qfor some 1 ≤ q ≤ ∞. For a more detailed treatment of the differences between Φσ and persistence landscapes, we refer the reader to [20]."
    }, {
      "heading" : "4 Experiments",
      "text" : "We first describe a set of experiments on synthetic data appearing in previous work to illustrate the use of the PSS feature map Φσ and the universal persistence scale-space kernel on two different tasks. We then present two applications on real-world data, where we assess differences in the persistent homology of functions on 3D surfaces of lateral ventricles and corpora callosa with respect to different group assignments (i.e., age, demented/non-demented). In all experiments, filtrations and the persistence diagrams are obtained using Dipha2, which can directly handle our types of input data. Source code to reproduce the experiments is available at https://goo.gl/KouBPT."
    }, {
      "heading" : "4.1 Synthetic data",
      "text" : "Computation of the mean PSS function. We repeat the experiment from [19, 4] of sampling from the union of two overlapping annuli. In particular, we repeatedly (N = 30 times) draw samples of size 100 (out of 10000), and then compute persistence diagrams F1, . . . ,FN for 1-dim. features by considering sublevel sets of the distance function from the points. Finally, we compute the mean of the PSS functions Φσ (Fi ) defined by the feature map from Eq. (2). This simply amounts to computing 1/N · Φσ (F1 ∪ · · · ∪ FN ). A visualization of the pointwise average, for a fixed choice of σ, is shown in Fig. 2. We remind the reader that the convergence results used in [4] equally hold for this feature map, as explained in Section 3. In particular, the above process of taking means converges to the expected value of the PSS function. As can be seen in Fig. 2, the two 1-dim. holes manifest themselves as two “bumps” at different positions in the mean PSS function.\n2available online: https://code.google.com/p/dipha/\nTorus vs. sphere. In this slightly more involved example, we repeat an experiment from [4, Section 4.3] on the problem of discriminating between a sphere and a torus in R3, based on random samples drawn from both objects. In particular, we repeatedly (N times) draw samples from the torus and the sphere (corresponding to measures P and Q) and then compute persistence diagrams. Eventually, we test the null-hypothesis H0 : P = Q, i.e., that samples were drawn from the same object; cf. [4] for a thorough description of the full setup. We remark that our setup uses the Delaunay triangulation of the point samples instead of the Coxeter–Freudenthal–Kuhn triangulation of a regular grid as in [4].\nConceptually, the important difference is in the two-sample testing strategy. In [4], two factors influence the test: (1) the choice of a functional to map the persistence landscape to a scalar and (2) the choice of test statistic. Bubenik chooses a z-test to test for equality between the mean persistence landscapes. In contrast, we can test for true equality in distribution. This is possible since universality of the kernel ensures that the MMD of Eq. (1) is a metric for the space of probability measures on persistence diagrams. All p-values are obtained by bootstrapping the test statistic under H0 over 104 random permutations. We further vary the number of samples/object used to compute the MMD statistic from N = 10 to N = 100 and add Gaussian noise N (0,0.1) in one experiment. Results are shown in Fig. 3 over a selection of u-PSS scales σ ∈ {100,10,1,0.1,0.01,0.001}. For 0-dimension features and no noise, we can always reject H0 at α = 0.05 significance. For 1-dim. features and no noise, we need at least 60 samples to reliably reject H0 at the same level of α."
    }, {
      "heading" : "4.2 Real-world data",
      "text" : "We use two real-world datasets in our experiments: (1) 3D surfaces of the corpus callosum and (2) 3D surfaces of the lateral ventricles from neotates. The corpus callosum surfaces were obtained from the longitudinal dataset of the OASIS brain database3. We use all subject data from the first visit, and the grouping criteria is disease state: dementia vs. non-dementia. Note that the demented group is comprised of individuals with very mild to mild AD. This discrimination is based on the clinical dementia rating (CDR) score; Marcus et al. [17] explain this dataset in detail. The lateral ventricle dataset is an extended version of [3]. It contains data from 43 neonates. All subjects were repeatedly imaged approximately every 3 months (starting from 2 weeks) in the first year and every 6 months in the second year. According to Bompard et al. [3], the ventricle growth is the dominant effect and occurs in a non-uniform manner most significantly during the first 6 months. This raises the question whether age also has an impact on the shape of these brain structures that can be detected by persistent homology of the HKS (see Setup below, or Section 2) function. Hence, we set our grouping criteria to be developmental age: ≤ 6 months vs. > 6 months. It is important to note that the heat kernel signature is not scale-invariant. For that reason, we normalize the (mean-subtracted) configuration matrices (containing the vertex coordinates of each mesh) by their Euclidean norm, cf. [9]. This ensures that our analysis is not biased by growth (scaling) effects.\n3available online: http://www.oasis-brains.org\nSetup. We follow an experimental setup, similar to [16] and [20], and compute the heat kernel signature [27] for various times ti as a function defined on the 3D surface meshes. In all experiments, we use the proposed kernel u-PSS kernel kUσ of Eq. (5) and vary the HKS time ti in 1 = t1 < t2 < · · · < t20 = 10.5; Regarding the u-PSS kernel scale σi , we sweep from 10−9 = σ1 < · · · < σ10 = 101. Null- (H0) and alternative (HA) hypotheses are defined as in Section 2 with two samples of persistence diagrams {Fi }mi=1, {Gi } n i=1. The test statistic under H0 is bootstrapped using B = 5 · 10 4 random permutations. This is also the setup recommended in [13] for low samples sizes.\nResults. Figure 4 shows the estimated p-values for both datasets as a function of the u-PSS kernel scale and the HKS time for 1-dim. features. The false discovery rate is controlled by the BenjaminiHochberg procedure. On the lateral ventricle data, we observe p-values < 0.01 (for the right ventricles), especially around HKS times t10 to t15, cf. Fig. 4(a). Since the results for left and right lateral ventricles are similar, only the p-values plots for the right lateral ventricle are shown. In general, the results indicate that, at specific settings of ti , the HKS function captures salient shape features of the surface, which lead to statistically significant differences in the persistent homology. We do, however, point out that there is no clear guideline on how to choose the HKS time. In fact, setting ti too low might emphasize noise, while setting ti too high tends to smooth-out details, as can be seen in the illustration of the HKS time on the left-hand side of Fig. 4. On the corpus callosum data, cf. Fig. 4(b), no significant differences in the persistent homology of the two groups (again for 1-dim. features) can be identified with p-values ranging from 0.1 to 0.9. This does not allow to reject H0 at any reasonable level."
    }, {
      "heading" : "5 Discussion",
      "text" : "With the introduction of a universal kernel for persistence diagrams in Section 3, we enable the use of this topological summary representation in the framework of embedding probability measures into reproducing kernel Hilbert spaces. While our experiments are mainly limited to two-sample hypothesis testing, our kernel allows to use a wide variety of statistical techniques and learning methods which are situated in that framework. It is important to note that our construction, via Theorem 1, essentially depends on a restriction of the set D to a compact metric space. We remark that similar conditions are required in [4] in order to enable statistical computations, e.g., constraining the support of the persistence landscapes. However, it will be interesting to investigate which properties of the kernel remain valid when lifting these restrictions. From an application point of view, we have shown that we can test for a statistical difference in the distribution of persistence diagrams. This is in contrast to previous work, where hypothesis testing is typically limited to test for specific properties of the distributions, such as equality in mean.\nAcknowledgements. This work has been partially supported by the Austrian Science Fund, project no. KLI 00012. We also thank the anonymous reviewers for their valuable comments/suggestions."
    } ],
    "references" : [ {
      "title" : "The ring of algebraic functions on persistence bar codes",
      "author" : [ "A. Adcock", "E. Carlsson", "G. Carlsson" ],
      "venue" : "arXiv, available at http://arxiv.org/abs/1304.0530",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Persistent homology analysis of brain artery trees",
      "author" : [ "P. Bendich", "J.S. Marron", "E. Miller", "A. Pieloch", "S. Skwerer" ],
      "venue" : "arXiv, available at http://arxiv.org/abs/1411.6652",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Multivariate longitudinal shape analysis of human lateral ventricles during the first twenty-four months of life",
      "author" : [ "L. Bompard", "S. Xu", "M. Styner", "B. Paniagua", "M. Ahn", "Y. Yuan", "V. Jewells", "W. Gao", "D. Shen", "H. Zhu", "W. Lin" ],
      "venue" : "PLoS One",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Statistical topological data analysis using persistence landscapes",
      "author" : [ "P. Bubenik" ],
      "venue" : "JMLR, 16:77–102",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Topology and data",
      "author" : [ "G. Carlsson" ],
      "venue" : "Bull. Amer. Math. Soc., 46:255–308",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "F",
      "author" : [ "F. Chazal", "B.T. Fasy" ],
      "venue" : "Lecci A. Rinaldo, and L. Wasserman. Stochastic convergence of persistence landscapes and silhouettes. In SoCG",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Universal kernels on non-standard input spaces",
      "author" : [ "A. Christmann", "I. Steinwart" ],
      "venue" : "NIPS",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Persistence diagrams of cortical surface data",
      "author" : [ "M.K. Chung", "P. Bubenik", "P.T. Kim" ],
      "venue" : "IPMI",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Statistical shape analysis",
      "author" : [ "I.L. Dryden", "K.V. Mardia" ],
      "venue" : "Wiley series in probability and statistics. Wiley",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Computational Topology",
      "author" : [ "H. Edelsbrunner", "J. Harer" ],
      "venue" : "An Introduction. AMS",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Confidence sets for persistence diagrams",
      "author" : [ "B. Fasy", "F. Lecci", "A. Rinaldo", "L. Wasserman", "S. Balakrishnan", "A. Singh" ],
      "venue" : "Ann. Statist., 42(6):2301–2339",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Kernel Bayes’ rule: Bayesian inference with positive definite kernels",
      "author" : [ "K. Fukumizu", "L. Song", "A. Gretton" ],
      "venue" : "JMLR, 14:3753–3783",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "A kernel two-sample test",
      "author" : [ "A. Gretton", "K.M. Borgwardt", "M.J. Rasch", "B. Schölkopf", "A. Smola" ],
      "venue" : "JMLR, 13:723–773",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Probability in Banach spaces",
      "author" : [ "M. Ledoux", "M. Talagrand" ],
      "venue" : "Classics in Mathematics. Springer",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 1991
    }, {
      "title" : "Hole detection in metabolic connectivity of Alzheimer’s disease using k-Laplacian",
      "author" : [ "H. Lee", "M.K. Chung", "H. Kang", "D.S. Lee" ],
      "venue" : "MICCAI",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Persistence-based structural recognition",
      "author" : [ "C. Li", "M. Ovsjanikov", "F. Chazal" ],
      "venue" : "CVPR",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Open access series of imaging studies: longitudinal MRI data in nondemented and demented older adults",
      "author" : [ "D.S. Marcus", "A.F. Fotenos", "J.G. Csernansky", "J.C. Morris", "R.L. Buckner" ],
      "venue" : "J. Cognitive Neurosci., 22(12):2677–2684",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Probability measures on the space of persistence diagrams",
      "author" : [ "Y. Mileyko", "S. Mukherjee", "J. Harer" ],
      "venue" : "Inverse Probl., 27(12)",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Probabilistic Fréchet means and statistics on vineyards",
      "author" : [ "E. Munch", "P. Bendich", "S. Mukherjee", "J. Mattingly", "J. Harer" ],
      "venue" : "CoRR",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "A stable multi-scale kernel for topological machine learning",
      "author" : [ "R. Reininghaus", "U. Bauer", "S. Huber", "R. Kwitt" ],
      "venue" : "CVPR",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Learning with Kernels: Support Vector Machines",
      "author" : [ "B. Schölkopf", "A.J. Smola" ],
      "venue" : "Regularization, Optimization, and Beyond. MIT Press, Cambridge, MA, USA",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Topological descriptors of histology images",
      "author" : [ "N. Singh", "H.D. Couture", "J.S. Marron", "C. Perou", "M. Niethammer" ],
      "venue" : "MLMI",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Hilbert space embedding for distributions",
      "author" : [ "A. Smola", "A. Gretton", "L. Song", "B. Schölkopf" ],
      "venue" : "ALT",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Hilbert space embeddings and metrics on probability measures",
      "author" : [ "B. Sriperumbudur", "A. Gretton", "K. Fukumizu", "B. Schölkopf", "G. Lanckriet" ],
      "venue" : "JMLR, 11:1517–1561",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "On the influence of the kernel on the consistency of support vector machines",
      "author" : [ "I. Steinwart" ],
      "venue" : "JMLR, 2:67– 93",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Support Vector Machines",
      "author" : [ "I. Steinwart", "A. Christmann" ],
      "venue" : "Springer",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "A concise and probably informative multi-scale signature based on heat diffusion",
      "author" : [ "J. Sun", "M. Ovsjanikov", "L. Guibas" ],
      "venue" : "SGP",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Fréchet means for distributions of persistence diagrams",
      "author" : [ "K. Turner", "Y. Mileyko", "S. Mukherjee", "J. Harer" ],
      "venue" : "Discrete Comput. Geom., 52(1):44–70",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : ", point clouds, images, shapes) have given birth to the field of topological data analysis (TDA) [5].",
      "startOffset" : 97,
      "endOffset" : 100
    }, {
      "referenceID" : 7,
      "context" : "Applications range from the analysis of cortical surface thickness [8] to the structure of brain networks [15], brain artery trees [2] or histology images for breast cancer analysis [22].",
      "startOffset" : 67,
      "endOffset" : 70
    }, {
      "referenceID" : 14,
      "context" : "Applications range from the analysis of cortical surface thickness [8] to the structure of brain networks [15], brain artery trees [2] or histology images for breast cancer analysis [22].",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 1,
      "context" : "Applications range from the analysis of cortical surface thickness [8] to the structure of brain networks [15], brain artery trees [2] or histology images for breast cancer analysis [22].",
      "startOffset" : 131,
      "endOffset" : 134
    }, {
      "referenceID" : 21,
      "context" : "Applications range from the analysis of cortical surface thickness [8] to the structure of brain networks [15], brain artery trees [2] or histology images for breast cancer analysis [22].",
      "startOffset" : 182,
      "endOffset" : 186
    }, {
      "referenceID" : 0,
      "context" : ", computing means or variances) turns out to be difficult, not least because of the unusual structure of the barcodes as intervals, rather than numerical quantities [1].",
      "startOffset" : 165,
      "endOffset" : 168
    }, {
      "referenceID" : 17,
      "context" : "the direction of statistical TDA have been made by studying the structure of the space of persistence diagrams endowed with p-Wasserstein metrics (or variants thereof) [18, 19, 28, 11], it is technically and computationally challenging to work in this space.",
      "startOffset" : 168,
      "endOffset" : 184
    }, {
      "referenceID" : 18,
      "context" : "the direction of statistical TDA have been made by studying the structure of the space of persistence diagrams endowed with p-Wasserstein metrics (or variants thereof) [18, 19, 28, 11], it is technically and computationally challenging to work in this space.",
      "startOffset" : 168,
      "endOffset" : 184
    }, {
      "referenceID" : 27,
      "context" : "the direction of statistical TDA have been made by studying the structure of the space of persistence diagrams endowed with p-Wasserstein metrics (or variants thereof) [18, 19, 28, 11], it is technically and computationally challenging to work in this space.",
      "startOffset" : 168,
      "endOffset" : 184
    }, {
      "referenceID" : 10,
      "context" : "the direction of statistical TDA have been made by studying the structure of the space of persistence diagrams endowed with p-Wasserstein metrics (or variants thereof) [18, 19, 28, 11], it is technically and computationally challenging to work in this space.",
      "startOffset" : 168,
      "endOffset" : 184
    }, {
      "referenceID" : 17,
      "context" : "One way to circumvent issues such as non-uniqueness of the Fréchet mean [18] or computationally intensive algorithmic strategies [28] is to consider mappings of persistence barcodes into linear function spaces.",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 27,
      "context" : "One way to circumvent issues such as non-uniqueness of the Fréchet mean [18] or computationally intensive algorithmic strategies [28] is to consider mappings of persistence barcodes into linear function spaces.",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 13,
      "context" : "Statistical computations can then be performed based on probability theory on Banach spaces [14].",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 3,
      "context" : "However, the methods proposed in [4] cannot guarantee that different probability distributions can always be distinguished by a statistical test.",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 22,
      "context" : "Our contribution is to approach this problem by leveraging the theory of embedding probability measures into reproducing kernel Hilbert spaces [23], in our case, probability measures on the space of persistence diagrams.",
      "startOffset" : 143,
      "endOffset" : 147
    }, {
      "referenceID" : 19,
      "context" : "[20] and identify missing properties that are essential for a well-founded use in the aforementioned framework.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 24,
      "context" : "By enforcing mild restrictions on the underlying space, we can in fact close the remaining gaps and prove that a minor modification of the kernel is universal in the sense of Steinwart [25] (see Section 3).",
      "startOffset" : 185,
      "endOffset" : 189
    }, {
      "referenceID" : 17,
      "context" : "[18] study properties of the set of persistence diagrams when endowed with the p-Wasserstein metric.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 27,
      "context" : "[28] later show that the L2-Wasserstein metric on the set of persistence diagrams yields a geodesic space, and that the additional structure can be leveraged to construct an algorithm for computing the Fréchet mean and to prove a law of large numbers.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 3,
      "context" : "While the aforementioned results concern properties of the set of persistence diagrams equipped with p-Wasserstein metrics, a different strategy is advocated by Bubenik in [4].",
      "startOffset" : 172,
      "endOffset" : 175
    }, {
      "referenceID" : 13,
      "context" : "While it is in general not possible to go back and forth between landscapes and persistence diagrams, the Banach space structure enables a well-founded theoretical treatment of statistical concepts, such as averages or confidence intervals [14].",
      "startOffset" : 240,
      "endOffset" : 244
    }, {
      "referenceID" : 5,
      "context" : "[6] establish additional convergence results and propose a bootstrap procedure for obtaining confidence sets.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 19,
      "context" : "However, it does not necessarily guarantee stability of the persistence summary representation, which is typically a desired property of a feature map [20].",
      "startOffset" : 151,
      "endOffset" : 155
    }, {
      "referenceID" : 20,
      "context" : "Our proposed approach to statistical TDA is also closely related to work in the field of kernel-based learning techniques [21] or, to be more specific, to the embedding of probability measures into a RKHS [23] and the study of suitable kernel functions in that context [7, 24].",
      "startOffset" : 122,
      "endOffset" : 126
    }, {
      "referenceID" : 22,
      "context" : "Our proposed approach to statistical TDA is also closely related to work in the field of kernel-based learning techniques [21] or, to be more specific, to the embedding of probability measures into a RKHS [23] and the study of suitable kernel functions in that context [7, 24].",
      "startOffset" : 205,
      "endOffset" : 209
    }, {
      "referenceID" : 6,
      "context" : "Our proposed approach to statistical TDA is also closely related to work in the field of kernel-based learning techniques [21] or, to be more specific, to the embedding of probability measures into a RKHS [23] and the study of suitable kernel functions in that context [7, 24].",
      "startOffset" : 269,
      "endOffset" : 276
    }, {
      "referenceID" : 23,
      "context" : "Our proposed approach to statistical TDA is also closely related to work in the field of kernel-based learning techniques [21] or, to be more specific, to the embedding of probability measures into a RKHS [23] and the study of suitable kernel functions in that context [7, 24].",
      "startOffset" : 269,
      "endOffset" : 276
    }, {
      "referenceID" : 12,
      "context" : "In fact, the idea of mapping probability measures into a RKHS has led to many developments generalizing statistical concepts, such as two-sample testing [13], testing for conditional independence, or statistical inference [12], form Euclidean spaces to other domains equipped with a kernel.",
      "startOffset" : 153,
      "endOffset" : 157
    }, {
      "referenceID" : 11,
      "context" : "In fact, the idea of mapping probability measures into a RKHS has led to many developments generalizing statistical concepts, such as two-sample testing [13], testing for conditional independence, or statistical inference [12], form Euclidean spaces to other domains equipped with a kernel.",
      "startOffset" : 222,
      "endOffset" : 226
    }, {
      "referenceID" : 19,
      "context" : "[20] recently established a first connection to",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "In Section 3, we show how a slight modification of the kernel in [20] fits into the framework of embedding probability measures into a RKHS.",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 9,
      "context" : "For a thorough treatment of the topic, we refer the reader to [10].",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 22,
      "context" : "We also briefly review the concept of embedding probability measures into a RKHS, following [23].",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 26,
      "context" : "For instance, in the case of surfaces meshes, a commonly used function is the heat kernel signature (HKS) [27].",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 22,
      "context" : "An important concept for our work is the embedding of probability measures into reproducing kernel Hilbert spaces [23].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 24,
      "context" : "This is true, in particular, ifH is dense in the space of continuous functions X → R (with the supremum norm), in which case we refer to the kernel as universal [25].",
      "startOffset" : 161,
      "endOffset" : 165
    }, {
      "referenceID" : 12,
      "context" : "Since it has been shown [13] that the empirical estimate of the mean, μX = 1/m ∑ i kxi , is a good proxy for μP , the injectivity of μ can be used to define distances between distributions P and Q, observed via samples X = {xi } i=1 and Y = {yi } n i=1.",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 12,
      "context" : "[13] restrict F to functions on a unit ball in H , i.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "Empirical estimates of this quantity are given in [13].",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 20,
      "context" : "While positive definiteness enables the use of kσ in many kernel-based learning techniques [21], we are interested in assessing whether it is universal, or if we can construct a universal kernel from kσ (see Section 2).",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 6,
      "context" : "The following theorem of Christmann and Steinwart [7] is particularly relevant to this question.",
      "startOffset" : 50,
      "endOffset" : 53
    }, {
      "referenceID" : 6,
      "context" : "2 of [7]) Let X be a compact metric space and G a separable Hilbert space such that there exists a continuous and injective mapΦ : X → G.",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 19,
      "context" : "[20], the feature map Φσ : D → L2(Ω) is injective.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 13,
      "context" : "(2) defines a function-valued summary of persistent homology in the Hilbert space L2(Ω), the results on probability in Banach spaces [14], used in [4] for persistence landscapes, naturally apply to Φσ as well.",
      "startOffset" : 133,
      "endOffset" : 137
    }, {
      "referenceID" : 3,
      "context" : "(2) defines a function-valued summary of persistent homology in the Hilbert space L2(Ω), the results on probability in Banach spaces [14], used in [4] for persistence landscapes, naturally apply to Φσ as well.",
      "startOffset" : 147,
      "endOffset" : 150
    }, {
      "referenceID" : 19,
      "context" : "For a more detailed treatment of the differences between Φσ and persistence landscapes, we refer the reader to [20].",
      "startOffset" : 111,
      "endOffset" : 115
    }, {
      "referenceID" : 18,
      "context" : "We repeat the experiment from [19, 4] of sampling from the union of two overlapping annuli.",
      "startOffset" : 30,
      "endOffset" : 37
    }, {
      "referenceID" : 3,
      "context" : "We repeat the experiment from [19, 4] of sampling from the union of two overlapping annuli.",
      "startOffset" : 30,
      "endOffset" : 37
    }, {
      "referenceID" : 3,
      "context" : "We remind the reader that the convergence results used in [4] equally hold for this feature map, as explained in Section 3.",
      "startOffset" : 58,
      "endOffset" : 61
    }, {
      "referenceID" : 3,
      "context" : "[4] for a thorough description of the full setup.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "We remark that our setup uses the Delaunay triangulation of the point samples instead of the Coxeter–Freudenthal–Kuhn triangulation of a regular grid as in [4].",
      "startOffset" : 156,
      "endOffset" : 159
    }, {
      "referenceID" : 3,
      "context" : "In [4], two factors influence the test: (1) the choice of a functional to map the persistence landscape to a scalar and (2) the choice of test statistic.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 2,
      "context" : "The lateral ventricle dataset is an extended version of [3].",
      "startOffset" : 56,
      "endOffset" : 59
    }, {
      "referenceID" : 2,
      "context" : "[3], the ventricle growth is the dominant effect and occurs in a non-uniform manner most significantly during the first 6 months.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 15,
      "context" : "We follow an experimental setup, similar to [16] and [20], and compute the heat kernel signature [27] for various times ti as a function defined on the 3D surface meshes.",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 19,
      "context" : "We follow an experimental setup, similar to [16] and [20], and compute the heat kernel signature [27] for various times ti as a function defined on the 3D surface meshes.",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 26,
      "context" : "We follow an experimental setup, similar to [16] and [20], and compute the heat kernel signature [27] for various times ti as a function defined on the 3D surface meshes.",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 12,
      "context" : "This is also the setup recommended in [13] for low samples sizes.",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 3,
      "context" : "We remark that similar conditions are required in [4] in order to enable statistical computations, e.",
      "startOffset" : 50,
      "endOffset" : 53
    } ],
    "year" : 2015,
    "abstractText" : "We consider the problem of statistical computations with persistence diagrams, a summary representation of topological features in data. These diagrams encode persistent homology, a widely used invariant in topological data analysis. While several avenues towards a statistical treatment of the diagrams have been explored recently, we follow an alternative route that is motivated by the success of methods based on the embedding of probability measures into reproducing kernel Hilbert spaces. In fact, a positive definite kernel on persistence diagrams has recently been proposed, connecting persistent homology to popular kernel-based learning techniques such as support vector machines. However, important properties of that kernel enabling a principled use in the context of probability measure embeddings remain to be explored. Our contribution is to close this gap by proving universality of a variant of the original kernel, and to demonstrate its effective use in twosample hypothesis testing on synthetic as well as real-world data.",
    "creator" : null
  }
}