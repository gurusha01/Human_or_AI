{"title": "Deep Poisson Factor Modeling", "abstract": "We propose a new deep architecture for topic modeling, based on Poisson Factor Analysis (PFA) modules. The model is composed of a Poisson distribution to model observed vectors of counts, as well as a deep hierarchy of hidden binary units. Rather than using logistic functions to characterize the probability that a latent binary unit is on, we employ a Bernoulli-Poisson link, which allows PFA modules to be used repeatedly in the deep architecture. We also describe an approach to build discriminative topic models, by adapting PFA modules. We derive efficient inference via MCMC and stochastic variational methods, that scale with the number of non-zeros in the data and binary units, yielding significant efficiency, relative to models based on logistic links. Experiments on several corpora demonstrate the advantages of our model when compared to related deep models.", "id": "d72fbbccd9fe64c3a14f85d225a046f4", "authors": ["Ricardo Henao", "Zhe Gan", "James Lu", "Lawrence Carin"], "conference": "NIPS2015", "accepted": true, "reviews": [{"comments": "This paper proposes a novel probabilistic deep architecture for modelling count data. In addition the authors propose a modelling extension for multi-class classification problems (i.e., discriminative modelling). The authors derive two inference techniques, one sampling one and a variational inference one, and show empirical gains compared to unsupervised methods using several large-scale datasets.\n\nQuestions/Comments: - I found the model to be clearly explained and motivated. I enjoyed\n\n reading Section 2.3. I think adding a figure to illustrate Equations 3\n\n would be useful. - I think it may be slightly misleading to imply that [23] does not scale\n\n wrt to the number of zeros. My understanding is that using a Poisson\n\n likelihood allows all methods to effectively ignore the zeros. Further\n\n it seems like most of the computational gains come from that rather than\n\n from higher-layers (which are typically much smaller). [23] also does allow\n\n non-linear activation functions. - Computation. It appears that your model scales well. It would be\n\n interesting to have an idea of how computation scales and how long it\n\n takes to learn on these larger datasets. Providing a rough comparison to\n\n competing models (docNADE, LDA, and replicated softmax) would also be\n\n useful. - When reporting the results of the classification experiments it seems\n\n like you are only comparing to unsupervised techniques. In that sense\n\n the comparison is not absolutely fair. It would be good to add, at\n\n least, one simple supervised baseline (e.g., a small neural net with a\n\n softmax output and the word frequencies as inputs).\n\nOther comments: - line 165: Sparsity of the Dirichlet relies on your choice of parameters\n\n (eta). I think it would be good to make it clear.  - This is a good paper. The model scales, and pushes ourunderstanding of deep generative models. The discriminative extension isalso worth noting. Empirical results are relatively good as well.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper presents a multilayer model of count vectors using Poisson Factor Analysis at all layers (providing interpretable topics) and binary units connecting these layers (learning topic correlations). MCMC and SVI inference is straightforward -- all conditional posteriors are in closed form --\n\nand inference scales in the number of non-zero observations and hidden units. The model is an incremental change from Zhou et al. (2012), removing the gobal beta-Bernoulli process and using the Bernoulli-Poisson link to avoid using sigmoid belief networks.\n\nBoth the model and inference described in the paper are elegant. The model is only an incremental improvement from prior work (notably Zhou et al. (2012)), but it's likely to be of significant interest to the community.\n\n 1. The experimental analysis has been done with an eye towards comparing to other deep and one-layer models. However, there's hardly any effort in exploring the proposed model itself.\n\n a. how did you fix the layer widths? have you studied more than 2 layers?\n\n b. how does the model deal with overdispersion in data?\n\n c. how should the layer widths decay with depth?\n\n 2. it's surprising that even your one-layer model does significantly better than ORSM and LDA (which is similar to PFA). is this due to your approach to discriminative topic models? there is no explanation provided.\n\n3. why is ORSM not included in Table 1? The paper presents a tweak to existing deep network topic models (combining ideas from Zhou et al. (2012) and Zhou et al. (2015)) and shows how a hierarchy of Poisson Factor Analysis units can be connected using hidden binary units.Although an incremental contribution, both MCMC and variational inference are made much simpler due to local conjugacy and experimental results show superior performance. The paper is lacking in a experimental investigation into the network structure -- instead it seems to be arbitrarily fixed. It is still likely to be of much interest to the deep learning and topic modeling community.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper extends previous work on using deep Poisson Factor Analysis (PFA) for topic modeling by using a Bernoulli-Poisson link, instead of logistic functions. The paper also describes a way to jointly model documents and their associated discrete labels. Experiments show the proposed method outperform related baselines in held-out perplexities and classification accuracy.\n\nThe paper extends existing work (Gan et al, ICML'15 in particular) to provide a more flexible way to define the prior on documents' proportions over topics. Even though mostly a combination of existing ideas, I think the paper provides some advances in applying deep models for topic modeling. Here are some of my detailed comments:\n\n- It is interesting to see that both MCMC and variational inference techniques are included. One of the arguments for using VI in the paper is its scalability. It would be interesting to see comparison on running time between the two inference techniques.\n\n- Jointly capturing documents with their associated metadata is a well-studied problem. I am wondering why the performance of traditional supervised topic models such as sLDA (for classification) are not included for comparison in Section 5.\n\n- For readers who are not familiar with conventional notations of deep models, I would suggest including some figure to illustrate the different layers and their input/output in Section 2.  The paper extends and improves previous work on using deep Poisson Factor Analysis for topic modeling. While mostly a combination of existing ideas, I think the paper provides some advances in applying deep models for topic modeling.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
