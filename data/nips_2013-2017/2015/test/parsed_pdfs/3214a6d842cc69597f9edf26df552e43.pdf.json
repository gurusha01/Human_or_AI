{
  "name" : "3214a6d842cc69597f9edf26df552e43.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Kullback-Leibler Proximal Variational Inference",
    "authors" : [ "Mohammad Emtiyaz Khan", "Pierre Baqué" ],
    "emails" : [ "emtiyaz@gmail.com", "pierre.baque@epfl.ch", "francois.fleuret@idiap.ch", "pascal.fua@epfl.ch" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Variational methods are a popular alternative to Markov chain Monte Carlo (MCMC) methods for Bayesian inference. They have been used extensively for their speed and ease of use. In particular, methods based on the evidence lower bound optimization (ELBO) are quite popular because they convert a difficult integration problem to an optimization problem. This reformulation enables the application of optimization techniques for large-scale Bayesian inference.\nRecently, an approach called stochastic variational inference (SVI) has gained popularity for inference in conditionally-conjugate exponential family models [1]. SVI exploits the geometry of the posterior distribution by using natural gradients and uses a stochastic method to improve scalability. The resulting updates are simple and easy to implement.\nSeveral generalizations of SVI have been proposed for general latent-variable models where the lower bound might be intractable [2, 3, 4]. These generalizations, although important, do not take the geometry of the posterior distribution into account.\nIn addition, none of these approaches exploit the structure of the lower bound. In practice, not all factors of the joint distribution introduce difficulty in the optimization. It is therefore desirable to treat “difficult” terms differently from “easy” terms.\n∗A note on contributions: P. Baqué proposed the use of the KL proximal term and showed that the resulting proximal steps have closed-form solutions. The rest of the work was carried out by M. E. Khan.\nIn this context, we propose a splitting method for variational inference; this method exploits both the structure and the geometry of the lower bound. Our approach is based on the proximal-gradient framework. We make two important contributions. First, we propose a proximal-point algorithm that uses the Kullback-Leibler (KL) divergence as the proximal term. We show that the addition of this term incorporates the geometry of the posterior distribution. We establish the equivalence of our approach to variational methods that use natural gradients (e.g., [1, 5, 6]).\nSecond, following the proximal-gradient framework, we propose a splitting approach for variational inference. In this approach, we linearize difficult terms such that the resulting optimization problem is easy to solve. We apply this approach to variational inference on non-conjugate models. We show that linearizing non-conjugate terms leads to subproblems that have closed-form solutions. Our approach therefore converts inference in a non-conjugate model to subproblems that involve inference in well-known conjugate models, and for which efficient implementation exists."
    }, {
      "heading" : "2 Latent Variable Models and Evidence Lower-Bound Optimization",
      "text" : "Consider a general latent-variable model with data vector y of length N and the latent vector z of length D, following a joint distribution p(y, z) (we drop the parameters of the distribution from the notation). ELBO approximates the posterior p(z|y) by a distribution q(z|λ) that maximizes a lower bound to the marginal likelihood. Here, λ is the vector of parameters of the distribution q. As shown in (1), the lower bound is obtained by first multiplying and then dividing by q(z|λ), and then applying Jensen’s inequality by using concavity of log. The approximate posterior q(z|λ) is obtained by maximizing the lower bound with respect to λ.\nlog p(y) = log ∫ q(z|λ)p(y, z)\nq(z|λ) dz ≥ max λ Eq(z|λ)\n[ log p(y, z)\nq(z|λ)\n] := L(λ). (1)\nUnfortunately, the lower bound may not always be easy to optimize, e.g., some terms in the lower bound might be intractable or might admit a form that is not easy to optimize. In addition, the optimization can be slow when N and D are large."
    }, {
      "heading" : "3 The KL Proximal-Point Algorithm for Conjugate Models",
      "text" : "In this section, we introduce a proximal-point method based on Kullback-Leibler (KL) proximal function and establish its relation to the existing approaches based on natural gradients [1, 5, 6]. In particular, for conditionally-conjugate exponential-family models, we show that each iteration of our proximal-point approach is equivalent to a step along the natural gradient.\nThe Kullback-Leibler (KL) divergence between two distributions q(z|λ) and q(z|λ′) is defined as follows: DKL[q(z|λ) ‖ q(z|λ\n′)] := Eq(z|λ)[log q(z|λ) − log q(z|λ′)]. Using the KL divergence as the proximal term, we introduce a proximal-point algorithm that generates a sequence of λk by solving the following subproblems:\nKL Proximal-Point : λk+1 = arg max λ L(λ)− 1 βk DKL[q(z|λ) ‖ q(z|λk)], (2)\ngiven an initial value λ0 and a bounded sequence of step-size βk > 0,\nOne benefit of using the KL term is that it takes the geometry of the posterior distribution into account. This fact has lead to their extensive use in both the optimization and statistics literature, e.g., for speeding up the expectation-maximization algorithm [7, 8], for convex optimization [9], for message-passing in graphical models [10], and for approximate Bayesian inference [11, 12, 13].\nRelationship to the methods that use natural gradients: An alternative approach to incorporate the geometry of the posterior distribution is to use natural gradients [6, 5, 1]. We now establish its relationship to our approach. The natural gradient can be interpreted as finding a descent direction that ensures a fixed amount of change in the distribution. For variational inference, this is equivalent to the following [1, 14]:\narg max ∆λ L(λk + ∆λ), s.t. DsymKL [q(z|λk + ∆λ) ‖ q(z|λk)] ≤ , (3)\nwhere DsymKL is the symmetric KL divergence. It appears that the proximal-point subproblem (2) is related to a Lagrangian of the above optimization. In fact, as we show below, the two problems are equivalent for conditionally conjugate exponential-family models.\nWe consider the set-up described in [15], which is a bit more general than that of [1]. Consider a Bayesian network with nodes zi and a joint distribution ∏ i p(zi|pai) where pai are the parents of zi. We assume that each factor is an exponential-family distribution defined as follows:\np(zi|pai) := hi(zi) exp [ ηTi (pai)Ti(zi)−Ai(ηi) ] , (4)\nwhere ηi is the natural parameter, Ti(zi) is the sufficient statistics, Ai(ηi) is the partition function and hi(zi) is the base measure. We seek a factorized approximation shown in (5), where each zi belongs to the same exponential-family distribution as the joint distribution. The parameters of this distribution are denoted by λi to differentiate them from the joint-distribution parameters ηi. Also note that the subscript refers to the factor i, not to the iteration.\nq(z|λ) = ∏ i qi(zi|λi), where qi(zi) := hi(z) exp [ λTi Ti(zi)−Ai(λi) ] . (5)\nFor this model, we show the following equivalence between a gradient-descent method based on natural gradients and our proximal-point approach. The proof is given in the supplementary material. Theorem 1. For the model shown in (4) and the posterior approximation shown in (5), the sequence λk generated by the proximal-point algorithm of (2) is equal to the one obtained using gradientdescent along the natural gradient with step lengths βk/(1 + βk).\nProof of convergence : Convergence of the proximal-point algorithm shown in (2) is proved in [8]. We give a summary of the results here. We assume βk = 1, however the proof holds for any bounded sequence of βk. Let the space of all λ be denoted by S. Define the set S0 := {λ ∈ S : L(λ) ≥ L(λ0)}. Then, ‖λk+1 − λk‖ → 0 under the following conditions:\n(A) Maximum of L exist and the gradient of L is continuous and defined in S0. (B) The KL divergence and its gradient are continuous and defined in S0 × S0. (C) DKL[q(z|λ) ‖ q(z|λ ′)] = 0 only when λ′ = λ.\nIn our case, the conditions (A) and (B) are either assumed or satisfied, and the condition (C) can be ensured by choosing an appropriate parameterization of q."
    }, {
      "heading" : "4 The KL Proximal-Gradient Algorithm for Non-conjugate Models",
      "text" : "The proximal-point algorithm of (2) might be difficult to optimize for non-conjugate models, e.g., due to the non-conjugate factors. In this section, we present an algorithm based on the proximalgradient framework where we first split the objective function into “difficult” and “easy” terms, and then, to simplify the optimization, linearize the difficult term. See [16] for a good review of proximal methods for machine learning.\nWe split the ratio p(y, z)/q(z|λ) ≡ c p̃d(z|λ)p̃e(z|λ), where p̃d contains all factors that make the optimization difficult, and p̃e contains the rest (c is a constant). This results in the following split:\nL(λ) = Eq(z|λ) [ log\np(y, z|θ) q(z|λ) ] := Eq(z|λ)[log p̃d(z|λ)]︸ ︷︷ ︸\nf(λ)\n+Eq(z|λ)[log p̃e(z|λ)]︸ ︷︷ ︸ h(λ) + log c, (6)\nNote that p̃d and p̃e can be un-normalized factors in the distribution. In the worst case, we can set p̃e(z|λ) ≡ 1 and take the rest as p̃d(z|λ). We give an example of the split in the next section. The main idea is to linearize the difficult term f such that the resulting problem admits a simple form. Specifically, we use a proximal-gradient algorithm that solves the following sequence of subproblems to maximize L as shown below. Here,5f(λk) is the gradient of f at λk.\nKL Proximal-Gradient:λk+1 = arg max λ\nλT 5 f(λk) + h(λ)− 1\nβk DKL[q(z|λ) ‖ q(z|λk)]. (7)\nNote that our linear approximation is equivalent to the one used in gradient descent. Also, the approximation is tight at λk. Therefore, it does not introduce any error in the optimization, rather it only acts as a surrogate to take the next step. Existing variational methods have used approximations such as ours, e.g., see [17, 18, 19]. Most of these methods first approximate the log p̃d(z|λ) term by using a linear or quadratic approximation and then compute the expectation. As a result the approximation is not tight and can result in a bad performance [20]. In contrast, our approximation is applied directly to E[log p̃d(z|λ)] and therefore is tight at λk. The convergence of our approach is covered under the results shown in [21]; they prove convergence of an algorithm more general algorithm than ours. Below, we summarize the results. As before, we assume that the maximum exists and L is continuous. We make three additional assumptions. First, the gradient of f is L-Lipschitz continuous in S, i.e., ||5f(λ)−5f(λ′)|| ≤ L||λ−λ′||, ∀λ,λ′ ∈ S. Second, the function h is concave. Third, there exists an α > 0 such that,\n(λk+1 − λk)T 51 DKL[q(z|λk+1) ‖ q(z|λk)] ≥ α‖λk+1 − λk‖2, (8) where51 denotes the gradient with respect to the first argument. Under these conditions, ‖λk+1 − λk‖ → 0 when 0 < βk < α/L. The choice of constant α is also discussed in [21]. Note that even though h is required to be concave, f could be non-convex. The lower bound usually contains concave terms, e.g., in the entropy term. In the worst case when there are no concave terms, we can simply choose h ≡ 0."
    }, {
      "heading" : "5 Examples of KL Proximal-Gradient Variational Inference",
      "text" : "In this section, we show a few examples where the subproblem (7) has a closed-form solution.\nGeneralized linear model : We consider the generalized linear model shown in (9). Here, y is the output vector (of length N ) whose n’th entry is equal to yn, whereas X is an N × D feature matrix that contains feature vectors xTn as rows. The weight vector z is a Gaussian with mean µ and covariance Σ. To obtain the probability of yn, the linear predictor xTnz is passed through p(yn|·).\np(y, z) := N∏ n=1 p(yn|xTnz)N (z|µ,Σ). (9)\nWe restrict the posterior distribution to be a Gaussian q(z|λ) = N (z|m,V) with mean m and covariance V, therefore λ := {m,V}. For this posterior family, the non-Gaussian terms p(yn|xTnz) are difficult to handle, while the Gaussian term N (z|µ,Σ) is easy because it is conjugate to q. Therefore, we set p̃e(z|λ) ≡ N (z|µ,Σ)/N (z|m,V) and let the rest of the terms go in p̃d. By substituting in (6) and using the definition of the KL divergence, we get the lower bound shown below in (10). The first term is the function f that will be linearized, and the second term is the function h.\nL(m,V) := N∑ n=1\nEq(z|λ)[log p(yn|xTnz)]︸ ︷︷ ︸ f(m,V )\n+Eq(z|λ) [ log N (z|µ,Σ) N (z|m,V) ] ︸ ︷︷ ︸\nh(m,V )\n. (10)\nFor linearization, we compute the gradient of f using the chain rule. Denote fn(m̃n, ṽn) := Eq(z|λ)[log p(yn|xTnz)] where m̃n := xTnm and ṽn := xTnVxn. Gradients of f w.r.t. m and V can then be expressed in terms of gradients of fn w.r.t. m̃n and ṽn:\n5mf(m,V) = N∑ n=1 xn 5m̃n fn(m̃n, ṽn), 5Vf(m,V) = N∑ n=1 xnx T n 5ṽn fn(m̃n, ṽn), (11)\nFor notational simplicity, we denote the gradient of fn at m̃nk := xTnmk and ṽnk := x T nVkxn by, αnk := −5m̃n fn(m̃nk, ṽnk), γnk := −25ṽn fn(m̃nk, ṽnk). (12) Using (11) and (12), we get the following linear approximation of f :\nf(m,V) ≈ λT 5 f(λk) := mT [5mf(mk,Vk)] + Tr [V {5Vf(mk,Vk)}] (13)\n= − N∑ n=1 [ αnk (x T nm) + 1 2γnk (x T nVxn) ] . (14)\nSubstituting the above in (7), we get the following subproblem in the k’th iteration:\n(mk+1,Vk+1) = arg max m,V 0 − N∑ n=1 [ αnk (x T nm) + 1 2γnk (x T nVxn) ] + Eq(z|λ) [ N (z|µ,Σ) N (z|m,V) ] − 1 βk DKL [N (z|m,V)||N (z|mk,Vk)] , (15)\nTaking the gradient w.r.t. m and V and setting it to zero, we get the following closed-form solutions (details are given in the supplementary material):\nV−1k+1 = rkV −1 k + (1− rk) [ Σ−1 + XT diag(γk)X ] , (16)\nmk+1 = [ (1− rk)Σ−1 + rkV−1k ]−1 [ (1− rk)(Σ−1µ−XTαk) + rkV−1k mk ] , (17)\nwhere rk := 1/(1 + βk) and αk and γk are vectors of αnk and γnk respectively, for all k.\nComputationally efficient updates : Even though the updates are available in closed form, they are not efficient when dimensionality D is large. In such a case, an explicit computation of V is costly because the resulting D ×D matrix is extremely large. We now derive efficient updates that avoids an explicit computation of V.\nOur derivation involves two key steps. The first step is to show that Vk+1 can be parameterized by γk. Specifically, if we initialize V0 = Σ, then we can show that:\nVk+1 = [ Σ−1 + XT diag(γ̃k+1)X ]−1 , where γ̃k+1 = rkγ̃k + (1− rk)γk. (18)\nwith γ̃0 = γ0. A detailed derivation is given in the supplementary material.\nThe second key step is to express the updates in terms of m̃n and ṽn. For this purpose, we define some new quantities. Let m̃ be a vector whose n’th entry is m̃n. Similarly, let ṽ be the vector of ṽn for all n. Denote the corresponding vectors in the k’th iteration by m̃k and ṽk, respectively. Finally, define µ̃ = Xµ and Σ̃ = XΣXT .\nNow, by using the fact that m̃ = Xm and ṽ = diag(XVXT ) and by applying the Woodbury matrix identity, we can express the updates in terms of m̃ and ṽ, as shown below (a detailed derivation is given in the supplementary material):\nm̃k+1 = m̃k + (1− rk)(I− Σ̃B−1k )(µ̃− m̃k − Σ̃αk), where Bk := Σ̃ + [diag(rkγ̃k)] −1,\nṽk+1 = diag(Σ̃)− diag(Σ̃A−1k Σ̃), where Ak := Σ̃ + [diag(γ̃k)] −1. (19)\nNote that these updates depend on µ̃, Σ̃,αk, and γk (whose size only depends on N and is independent ofD). Most importantly, these updates avoid an explicit computation of V and only require storing m̃k and ṽk, both of which scale linearly with N .\nAlso note that the matrix Ak and Bk differ only slightly and we can reduce computation by using Ak in place of Bk. In our experiments, this does not create any convergence issues.\nTo assess convergence, we can use the optimality condition. By taking the norm of the derivative of L at mk+1 and Vk+1 and simplifying, we get the following criteria: ‖µ̃ − m̃k+1 − Σ̃αk+1‖22 + Tr[Σ̃ { diag(γ̃k − γk+1 − 1) } Σ̃] ≤ , for some > 0 (derivation is in the supplementary material).\nLinear-Basis Function Model and Gaussian Process : The algorithm presented above can be extended to linear-basis function models by using the weight-space view presented in [22]. Consider a non-linear basis function φ(x) that maps a D-dimensional feature vector into an N -dimensional feature space. The generalized linear model of (9) is extended to a linear basis function model by replacing xTnz with the latent function g(x) := φ(x)\nT z. The Gaussian prior on z then translates to a kernel function κ(x,x′) := φ(x)TΣφ(x) and a mean function µ̃(x) := φ(x)Tµ in the latent function space. Given input vectors xn, we define the kernel matrix Σ̃ whose (i, j)’th entry is equal to κ(xi,xj) and the mean vector µ̃ whose i’th entry is µ̃(xi).\nAssuming a Gaussian posterior distribution over the latent function g(x), we can compute its mean m̃(x) and variance ṽ(x) using the proximal-gradient algorithm. We define m̃ to be the vector of\nAlgorithm 1 Proximal-gradient algorithm for linear basis function models and Gaussian process\nGiven: Training data (y,X), test data x∗, kernel mean µ̃, covariance Σ̃, step-size sequence rk, and threshold . Initialize: m̃0 ← µ̃, ṽ0 ← diag(Σ̃) and γ̃0 ← δ11. repeat\nFor all n in parallel: αnk ←5m̃nfn(m̃nk, ṽnk) and γnk ←5ṽnfn(m̃nk, ṽnk). Update m̃k and ṽk using (19). γ̃k+1 ← rkγ̃k + (1− rk)γk.\nuntil ‖µ̃− m̃k − Σ̃αk‖+ Tr[Σ̃ diag(γ̃k − γk+1 − 1)Σ̃] > . Predict test inputs x∗ using (20).\nm̃(xn) for all n and similarly ṽ to be the vector of all ṽ(xn). Following the same derivation as the previous section, we can show that the updates of (19) give us the posterior mean m̃ and variance ṽ. These updates are the kernalized version of (16) and (17).\nFor prediction, we only need the converged value of αk and γk, denoted by α ∗ and γ∗, respectively. Given a new input x∗, define κ∗∗ := κ(x∗,x∗) and κ∗ to be a vector whose n’th entry is equal to κ(xn,x∗). The predictive mean and variance can be computed as shown below:\nṽ(x∗) = κ∗∗ − κT∗ [Σ̃ + (diag(γ̃ ∗))−1]−1κ∗ , m̃(x∗) = µ̃∗ − κT∗α∗ (20)\nA pseudo-code is given in Algorithm 1. Here, we initialize γ̃ to a small constant δ1, otherwise solving the first equation might be ill-conditioned.\nThese updates also work for the Gaussian process (GP) models with a kernel k(x,x′) and mean function µ̃(x), and for many other latent Gaussian models such as matrix factorization models."
    }, {
      "heading" : "6 Experiments and Results",
      "text" : "We now present some results on the real data. Our goal is to show that our approach gives comparable results to existing methods and is easy to implement. We also show that, in some cases, our method is significantly faster than the alternatives due to the kernel trick.\nWe show results on three models: Bayesian logistic regression, GP classification with logistic likelihood, and GP regression with Laplace likelihood. For these likelihoods, expectations can be computed (almost) exactly, for which we used the methods described in [23, 24]. We use a fixed step-size of βk = 0.25 and 1 for logistic and Laplace likelihoods, respectively.\nWe consider three datasets for each model. A summary is given in Table 1. These datasets can be found at the data repository1 of LIBSVM and UCI.\nBayesian Logistic Regression: Results for Bayesian logistic regression are shown in Table 2. We consider two datasets. For ‘a1a’, N > D, and, for ‘Colon’, N < D. We compare our ‘proximal’ method to three other existing methods: the ‘MAP’ method which finds the mode of the penalized log-likelihood, the ‘Mean-Field’ method where the distribution is factorized across dimensions, and the ‘Cholesky’ method of [25]. We implemented these methods using ‘minFunc’ software by Mark Schmidt2. We used L-BFGS for optimization. All algorithms are stopped when optimality condition is below 10−4. We set the Gaussian prior to Σ = δI and µ = 0. To set the hyperparameter δ, we use cross-validation for MAP, and maximum marginal-likelihood estimate for the rest of the methods. As we compare running times as well, we use a common range of hyperparameter values for all methods. These values are shown in Table 1.\nFor Bayesian methods, we report the negative of the marginal likelihood approximation (‘Neg-LogLik’). This is (the negative of) the value of the lower bound at the maximum. We also report the log-loss computed as follows:− ∑ n log p̂n/N where p̂n are the predictive probabilities of the test data and N is the total number of test-pairs. A lower value is better and a value of 1 is equivalent to random coin-flipping. In addition, we report the total time taken for hyperparameter selection.\n1https://archive.ics.uci.edu/ml/datasets.html and http://www.csie.ntu.edu.tw/∼cjlin/libsvmtools/datasets/ 2Available at https://www.cs.ubc.ca/∼schmidtm/Software/minFunc.html\nFor MAP, this is the total cross-validation time, whereas for Bayesian methods it is the time taken to compute ‘Neg-Log-Lik’ for all hyperparameters values over the whole range.\nWe summarize these results in Table 2. For all columns, a lower value is better. We see that for ‘a1a’, fully Bayesian methods perform slightly better than MAP. More importantly, the Proximal method is faster than the Cholesky method but obtains the same error and marginal likelihood estimate. For the Proximal method, we use updates of (17) and (16) because D N , but even in this scenario, the Cholesky method is slow due to expensive line-search for a large number of parameters.\nFor the ‘Colon’ dataset, we use the update (19) for the Proximal method. We do not compare to the Cholesky method because it is too slow for the large datasets. In Table 2, we see that, our implementation is as fast as the Mean-Field method but performs significantly better.\nOverall, with the Proximal method, we achieve the same results as the Cholesky method but take less time. In some cases, we can also match the running time of the Mean-Field method. Note that the Mean-Field method does not give bad predictions and the minimum value of log-loss are comparable to our approach. However, as Neg-Log-Lik values for the Mean-Field method are inaccurate, it ends up choosing a bad hyperparameter value. This is expected as the Mean-Field method makes an extreme approximation. Therefore, cross-validation is more appropriate for the Mean-Field method.\nGaussian process classification and regression: We compare the Proximal method to expectation propagation (EP) and Laplace approximation. We use the GPML toolbox for this comparison. We used a squared-exponential kernel for the Gaussian process with two scale parameters σ and l (as defined in GPML toolbox). We do a grid search over these hyperparameters. The grid values are given in Table 1. We report the log-loss and running time for each method.\nThe left plot in Figure 1 shows the log-loss for GP classification on USPS 3vs5 dataset, where the Proximal method shows very similar behaviour to EP. These results are summarized in Table 3. We see that our method performs similar to EP, sometimes a bit better. The running times of EP and the Proximal method are also comparable. The advantage of our approach is that it is easier to implement compared to EP and it is also numerically robust. The predictive probabilities obtained with EP and the Proximal method for ’USPS 3vs5’ dataset are shown in the right plot of Figure 1. The horizontal axis shows the test examples in an ascending order; the examples are sorted according to their predictive probabilities obtained with EP. The probabilities themselves are shown in the y-axis. A higher value implies a better performance, therefore the Proximal method gives\nestimates better than EP. The improvement in the performance is due to the numerical error in the likelihood implementation. For the Proximal method, we use the method of [23], which is quite accurate. Designing such accurate likelihood approximations for EP is challenging."
    }, {
      "heading" : "7 Discussion and Future Work",
      "text" : "In this paper, we have proposed a proximal framework that uses the KL proximal term to take the geometry of the posterior distribution into account. We established the equivalence between our proximal-point algorithm and natural-gradient methods. We proposed a proximal-gradient algorithm that exploits the structure of the bound to simplify the optimization. An important future direction is to apply stochastic approximations to approximate gradients. This extension is discussed in [21]. It is also important to design a line-search method to set the step sizes. In addition, our proximal framework can also be used for distributed optimization in variational inference [26, 11]."
    }, {
      "heading" : "Acknowledgments",
      "text" : "Mohammad Emtiyaz Khan would like to thank Masashi Sugiyama and Akiko Takeda from University of Tokyo, Matthias Grossglauser and Vincent Etter from EPFL, and Hannes Nickisch from Philips Research (Hamburg) for useful discussions and feedback. Pierre Baqué was supported in part by the Swiss National Science Foundation, under the grant CRSII2-147693 ”Tracking in the Wild”."
    } ],
    "references" : [ {
      "title" : "Stochastic variational inference",
      "author" : [ "Matthew D Hoffman", "David M Blei", "Chong Wang", "John Paisley" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2013
    }, {
      "title" : "Fixed-form variational posterior approximation through stochastic linear regression",
      "author" : [ "Tim Salimans", "David A Knowles" ],
      "venue" : "Bayesian Analysis,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2013
    }, {
      "title" : "Black box variational inference",
      "author" : [ "Rajesh Ranganath", "Sean Gerrish", "David M Blei" ],
      "venue" : "arXiv preprint arXiv:1401.0118,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2013
    }, {
      "title" : "Doubly Stochastic Variational Bayes for Non-Conjugate Inference",
      "author" : [ "Michalis Titsias", "Miguel Lázaro-Gredilla" ],
      "venue" : "In International Conference on Machine Learning,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2014
    }, {
      "title" : "Online model selection based on the variational Bayes",
      "author" : [ "Masa-Aki Sato" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2001
    }, {
      "title" : "Approximate Riemannian conjugate gradient learning for fixed-form variational Bayes",
      "author" : [ "A. Honkela", "T. Raiko", "M. Kuusela", "M. Tornio", "J. Karhunen" ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2011
    }, {
      "title" : "Kullback proximal algorithms for maximum-likelihood estimation",
      "author" : [ "Stéphane Chrétien", "Alfred OIII Hero" ],
      "venue" : "Information Theory, IEEE Transactions on,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2000
    }, {
      "title" : "An analysis of the EM algorithm and entropy-like proximal point methods",
      "author" : [ "Paul Tseng" ],
      "venue" : "Mathematics of Operations Research,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2004
    }, {
      "title" : "Convergence of proximal-like algorithms",
      "author" : [ "M. Teboulle" ],
      "venue" : "SIAM Jon Optimization,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1997
    }, {
      "title" : "Message-passing for graph-structured linear programs: Proximal projections, convergence and rounding schemes",
      "author" : [ "Pradeep Ravikumar", "Alekh Agarwal", "Martin J Wainwright" ],
      "venue" : "In International Conference on Machine Learning,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2008
    }, {
      "title" : "D-MFVI: Distributed mean field variational inference using Bregman ADMM",
      "author" : [ "Behnam Babagholami-Mohamadabadi", "Sejong Yoon", "Vladimir Pavlovic" ],
      "venue" : "arXiv preprint arXiv:1507.00824,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2015
    }, {
      "title" : "Scalable Bayesian inference via particle mirror descent",
      "author" : [ "Bo Dai", "Niao He", "Hanjun Dai", "Le Song" ],
      "venue" : "Computing Research Repository,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2015
    }, {
      "title" : "A trust-region method for stochastic variational inference with applications to streaming data",
      "author" : [ "Lucas Theis", "Matthew D Hoffman" ],
      "venue" : "International Conference on Machine Learning,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2015
    }, {
      "title" : "Revisiting natural gradient for deep networks",
      "author" : [ "Razvan Pascanu", "Yoshua Bengio" ],
      "venue" : "arXiv preprint arXiv:1301.3584,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2013
    }, {
      "title" : "On the convergence of stochastic variational inference in bayesian networks",
      "author" : [ "Ulrich Paquet" ],
      "venue" : "NIPS Workshop on variational inference,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2014
    }, {
      "title" : "Proximal algorithms in statistics and machine learning",
      "author" : [ "Nicholas G Polson", "James G Scott", "Brandon T Willard" ],
      "venue" : "arXiv preprint arXiv:1502.03175,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2015
    }, {
      "title" : "Bayesian non-linear independent component analysis by multilayer perceptrons",
      "author" : [ "Harri Lappalainen", "Antti Honkela" ],
      "venue" : "In Advances in independent component analysis,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2000
    }, {
      "title" : "Variational inference in nonconjugate models",
      "author" : [ "Chong Wang", "David M. Blei" ],
      "venue" : "J. Mach. Learn. Res.,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2013
    }, {
      "title" : "Large scale Bayesian inference and experimental design for sparse linear models",
      "author" : [ "M. Seeger", "H. Nickisch" ],
      "venue" : "SIAM Journal of Imaging Sciences,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2011
    }, {
      "title" : "Unsupervised variational Bayesian learning of nonlinear models",
      "author" : [ "Antti Honkela", "Harri Valpola" ],
      "venue" : "In Advances in neural information processing systems,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2004
    }, {
      "title" : "Convergence of Proximal-Gradient Stochastic Variational Inference under Non-Decreasing Step-Size Sequence",
      "author" : [ "Mohammad Emtiyaz Khan", "Reza Babanezhad", "Wu Lin", "Mark Schmidt", "Masashi Sugiyama" ],
      "venue" : "arXiv preprint arXiv:1511.00146,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2015
    }, {
      "title" : "Gaussian Processes for Machine Learning",
      "author" : [ "Carl Edward Rasmussen", "Christopher K.I. Williams" ],
      "venue" : null,
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2006
    }, {
      "title" : "Piecewise bounds for estimating Bernoulli-logistic latent Gaussian models",
      "author" : [ "B. Marlin", "M. Khan", "K. Murphy" ],
      "venue" : "In International Conference on Machine Learning,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2011
    }, {
      "title" : "Decoupled Variational Inference",
      "author" : [ "Mohammad Emtiyaz Khan" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2014
    }, {
      "title" : "Concave Gaussian variational approximations for inference in large-scale Bayesian linear models",
      "author" : [ "E. Challis", "D. Barber" ],
      "venue" : "In International conference on Artificial Intelligence and Statistics,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2011
    }, {
      "title" : "Bregman alternating direction method of multipliers",
      "author" : [ "Huahua Wang", "Arindam Banerjee" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Recently, an approach called stochastic variational inference (SVI) has gained popularity for inference in conditionally-conjugate exponential family models [1].",
      "startOffset" : 157,
      "endOffset" : 160
    }, {
      "referenceID" : 1,
      "context" : "Several generalizations of SVI have been proposed for general latent-variable models where the lower bound might be intractable [2, 3, 4].",
      "startOffset" : 128,
      "endOffset" : 137
    }, {
      "referenceID" : 2,
      "context" : "Several generalizations of SVI have been proposed for general latent-variable models where the lower bound might be intractable [2, 3, 4].",
      "startOffset" : 128,
      "endOffset" : 137
    }, {
      "referenceID" : 3,
      "context" : "Several generalizations of SVI have been proposed for general latent-variable models where the lower bound might be intractable [2, 3, 4].",
      "startOffset" : 128,
      "endOffset" : 137
    }, {
      "referenceID" : 0,
      "context" : "In this section, we introduce a proximal-point method based on Kullback-Leibler (KL) proximal function and establish its relation to the existing approaches based on natural gradients [1, 5, 6].",
      "startOffset" : 184,
      "endOffset" : 193
    }, {
      "referenceID" : 4,
      "context" : "In this section, we introduce a proximal-point method based on Kullback-Leibler (KL) proximal function and establish its relation to the existing approaches based on natural gradients [1, 5, 6].",
      "startOffset" : 184,
      "endOffset" : 193
    }, {
      "referenceID" : 5,
      "context" : "In this section, we introduce a proximal-point method based on Kullback-Leibler (KL) proximal function and establish its relation to the existing approaches based on natural gradients [1, 5, 6].",
      "startOffset" : 184,
      "endOffset" : 193
    }, {
      "referenceID" : 6,
      "context" : ", for speeding up the expectation-maximization algorithm [7, 8], for convex optimization [9], for message-passing in graphical models [10], and for approximate Bayesian inference [11, 12, 13].",
      "startOffset" : 57,
      "endOffset" : 63
    }, {
      "referenceID" : 7,
      "context" : ", for speeding up the expectation-maximization algorithm [7, 8], for convex optimization [9], for message-passing in graphical models [10], and for approximate Bayesian inference [11, 12, 13].",
      "startOffset" : 57,
      "endOffset" : 63
    }, {
      "referenceID" : 8,
      "context" : ", for speeding up the expectation-maximization algorithm [7, 8], for convex optimization [9], for message-passing in graphical models [10], and for approximate Bayesian inference [11, 12, 13].",
      "startOffset" : 89,
      "endOffset" : 92
    }, {
      "referenceID" : 9,
      "context" : ", for speeding up the expectation-maximization algorithm [7, 8], for convex optimization [9], for message-passing in graphical models [10], and for approximate Bayesian inference [11, 12, 13].",
      "startOffset" : 134,
      "endOffset" : 138
    }, {
      "referenceID" : 10,
      "context" : ", for speeding up the expectation-maximization algorithm [7, 8], for convex optimization [9], for message-passing in graphical models [10], and for approximate Bayesian inference [11, 12, 13].",
      "startOffset" : 179,
      "endOffset" : 191
    }, {
      "referenceID" : 11,
      "context" : ", for speeding up the expectation-maximization algorithm [7, 8], for convex optimization [9], for message-passing in graphical models [10], and for approximate Bayesian inference [11, 12, 13].",
      "startOffset" : 179,
      "endOffset" : 191
    }, {
      "referenceID" : 12,
      "context" : ", for speeding up the expectation-maximization algorithm [7, 8], for convex optimization [9], for message-passing in graphical models [10], and for approximate Bayesian inference [11, 12, 13].",
      "startOffset" : 179,
      "endOffset" : 191
    }, {
      "referenceID" : 5,
      "context" : "Relationship to the methods that use natural gradients: An alternative approach to incorporate the geometry of the posterior distribution is to use natural gradients [6, 5, 1].",
      "startOffset" : 166,
      "endOffset" : 175
    }, {
      "referenceID" : 4,
      "context" : "Relationship to the methods that use natural gradients: An alternative approach to incorporate the geometry of the posterior distribution is to use natural gradients [6, 5, 1].",
      "startOffset" : 166,
      "endOffset" : 175
    }, {
      "referenceID" : 0,
      "context" : "Relationship to the methods that use natural gradients: An alternative approach to incorporate the geometry of the posterior distribution is to use natural gradients [6, 5, 1].",
      "startOffset" : 166,
      "endOffset" : 175
    }, {
      "referenceID" : 0,
      "context" : "For variational inference, this is equivalent to the following [1, 14]:",
      "startOffset" : 63,
      "endOffset" : 70
    }, {
      "referenceID" : 13,
      "context" : "For variational inference, this is equivalent to the following [1, 14]:",
      "startOffset" : 63,
      "endOffset" : 70
    }, {
      "referenceID" : 14,
      "context" : "We consider the set-up described in [15], which is a bit more general than that of [1].",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 0,
      "context" : "We consider the set-up described in [15], which is a bit more general than that of [1].",
      "startOffset" : 83,
      "endOffset" : 86
    }, {
      "referenceID" : 7,
      "context" : "Proof of convergence : Convergence of the proximal-point algorithm shown in (2) is proved in [8].",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 15,
      "context" : "See [16] for a good review of proximal methods for machine learning.",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 19,
      "context" : "As a result the approximation is not tight and can result in a bad performance [20].",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 20,
      "context" : "The convergence of our approach is covered under the results shown in [21]; they prove convergence of an algorithm more general algorithm than ours.",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 20,
      "context" : "The choice of constant α is also discussed in [21].",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 21,
      "context" : "Linear-Basis Function Model and Gaussian Process : The algorithm presented above can be extended to linear-basis function models by using the weight-space view presented in [22].",
      "startOffset" : 173,
      "endOffset" : 177
    }, {
      "referenceID" : 22,
      "context" : "For these likelihoods, expectations can be computed (almost) exactly, for which we used the methods described in [23, 24].",
      "startOffset" : 113,
      "endOffset" : 121
    }, {
      "referenceID" : 23,
      "context" : "For these likelihoods, expectations can be computed (almost) exactly, for which we used the methods described in [23, 24].",
      "startOffset" : 113,
      "endOffset" : 121
    }, {
      "referenceID" : 24,
      "context" : "We compare our ‘proximal’ method to three other existing methods: the ‘MAP’ method which finds the mode of the penalized log-likelihood, the ‘Mean-Field’ method where the distribution is factorized across dimensions, and the ‘Cholesky’ method of [25].",
      "startOffset" : 246,
      "endOffset" : 250
    }, {
      "referenceID" : 22,
      "context" : "For the Proximal method, we use the method of [23], which is quite accurate.",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 25,
      "context" : "In addition, our proximal framework can also be used for distributed optimization in variational inference [26, 11].",
      "startOffset" : 107,
      "endOffset" : 115
    }, {
      "referenceID" : 10,
      "context" : "In addition, our proximal framework can also be used for distributed optimization in variational inference [26, 11].",
      "startOffset" : 107,
      "endOffset" : 115
    } ],
    "year" : 2015,
    "abstractText" : "We propose a new variational inference method based on a proximal framework that uses the Kullback-Leibler (KL) divergence as the proximal term. We make two contributions towards exploiting the geometry and structure of the variational bound. First, we propose a KL proximal-point algorithm and show its equivalence to variational inference with natural gradients (e.g., stochastic variational inference). Second, we use the proximal framework to derive efficient variational algorithms for non-conjugate models. We propose a splitting procedure to separate non-conjugate terms from conjugate ones. We linearize the non-conjugate terms to obtain subproblems that admit a closed-form solution. Overall, our approach converts inference in a non-conjugate model to subproblems that involve inference in well-known conjugate models. We show that our method is applicable to a wide variety of models and can result in computationally efficient algorithms. Applications to real-world datasets show comparable performances to existing methods.",
    "creator" : null
  }
}