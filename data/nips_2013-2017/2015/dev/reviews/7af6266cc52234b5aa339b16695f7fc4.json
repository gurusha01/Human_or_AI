{"title": "A Market Framework for Eliciting Private Data", "abstract": "We propose a mechanism for purchasing information from a sequence of participants.The participants may simply hold data points they wish to sell, or may have more sophisticated information; either way, they are incentivized to participate as long as they believe their data points are representative or their information will improve the mechanism's future prediction on a test set.The mechanism, which draws on the principles of prediction markets, has a bounded budget and minimizes generalization error for Bregman divergence loss functions.We then show how to modify this mechanism to preserve the privacy of participants' information: At any given time, the current prices and predictions of the mechanism reveal almost no information about any one participant, yet in total over all participants, information is accurately aggregated.", "id": "7af6266cc52234b5aa339b16695f7fc4", "authors": ["Bo Waggoner", "Rafael Frongillo", "Jacob D. Abernethy"], "conference": "NIPS2015", "accepted": true, "reviews": [{"comments": "The authors identify a strategy for compensating agents to disclose private and relevant data. The strategy draws on interesting ideas from the machine learning literature, including the use of the stochastic gradient descent algorithm to set the payment for the data. This allows effective compensation of agents while maintaining a limited budget. The authors also include mechanisms for preserving the privacy of agents, and identification of different \"profit maximizing\" strategies for agent to select given their confidence in their data. It appears that the substantive contribution is\n\nin identifying a mechanism that compensates agents for their data while maintaing a bounded budget.\n\nThe usefulness of this family of algorithms hinges on timely, available correct information.\n\nIf \"true samples\" will arise only in the distant future, then section 2.3 is not viable (see below), section 2.1 does not seem to offer much advantage over traditional betting markets (modulo the generalizability to more complex prediction function).\n\nSection 3 does not strike me as addressing a fundamentally serious problem: depending on the type of privacy one is concerned with, there seem to be simpler solutions to keep agent i from learning about agent j: (a) anonymized participation (b) anonymized relations between updates and agents (which agent made which trade is not available to other agents)\n\nThe really useful contribution here is a generalization of prediction markets to use sophisticated prediction tools, thus allowing for prediction markets to extend far beyond bets on single binary or scalar variables.\n\nThis is cool, but in practice it seems like it would offer little motivation for participation, unless the market happened to run along-side a constant stream of true samples, such that rewards could be evaluated quickly.\n\n(If I won't know what my data is bidding on, how much credit it might get, and when the rewards will come, why should i play?)\n\nSection 2.3 (offering to buy data) seems predicated on knowing the loss function of predictions, which means that the correct answers are known.\n\nIn that case, what's even the point of bidding on data?\n\nIf the answers are not known, then how does one come up with the marginal gain from a given data point?\n\nSeems to be a pretty fundamental catch-22.\n\nThere are a few possible ways out of this, but they all seem to open the system up to being gamed: - Use past true samples to evaluate the worth of new training data.\n\nHowever, then one can simply offer lots of training data to match known past samples, and reap the rewards by generating fake data to overfit past data. - Use some prediction divergence measure to evaluate the utility of new data (i.e., all data that changes my predictions is good).\n\nThis can obviously be gamed by generating crazy data to make predictions veer wildly offtrack.\n\n Thus, it seems that the only way to set up a cost function is in light of *future* true samples, and this seems to be a serious limitation insofar as the future is distant.\n\nIt absolutely precludes the kind of \"selling\" scheme in section 2.3 The authors propose a family of market algorithms that extend prediction markets by rewarding incremental improvements in prediction from contributed data.This is a really cool idea, however, the practical applications of this seem very limited because the market requires a known Loss function, so if the object of prediction is not known, then there is no way to set up accurate incentives.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "Summary: The authors propose adapting tools from the design and analysis of prediction markets to the problem of learning a good hypothesis when the training data is distributed amongst many parties.\n\nThe authors also propose modifications to guarantee differential privacy.\n\nIn more detail, the authors propose maintaining a current hypothesis, allowing participants to update this hypothesis (various \"betting languages\" for doing this are considered), and using a family of convex cost functions (parameterized by a domain element x) to charge/reward participants after the final hypothesis is applied to a test data point.\n\n(The choice of the cost functions is dictated by the loss function.)\n\nDifferential privacy is added by adapting the state-of-the-art techniques in \"continual observation\" models (where one want privacy at each time step, without paying linearly in the number of time steps).\n\nQuality: The stitching together of the various models and techniques is competently done.\n\nThe paper feels a bit weak on motivation.\n\nThe results have a \"here's what we know how to do\" flavor to them, as opposed to the more traditional \"here's a well-motivated problem\" and \"here's our solution and why it's better than previous/obvious solutions\" narrative.\n\nClarity: The writing quality is reasonably good.\n\nOriginality: None of the tools used are original.\n\nSome of their combinations here appear original.\n\nSignificance: I find the results modestly significant. The authors propose adapting tools from the design and analysis of prediction markets to the problem of learning a good hypothesis when the training data is distributed amongst many parties.The authors also propose modifications to guarantee differential privacy.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
