{"title": "Bounding the Cost of Search-Based Lifted Inference", "abstract": "Recently, there has been growing interest in systematic search-based and importance sampling-based lifted inference algorithms for statistical relational models (SRMs). These lifted algorithms achieve significant complexity reductions over their propositional counterparts by using lifting rules that leverage symmetries in the relational representation. One drawback of these algorithms is that they use an inference-blind representation of the search space, which makes it difficult to efficiently pre-compute tight upper bounds on the exact cost of inference without running the algorithm to completion. In this paper, we present a principled approach to address this problem. We introduce a lifted analogue of the propositional And/Or search space framework, which we call a lifted And/Or schematic. Given a schematic-based representation of an SRM, we show how to efficiently compute a tight upper bound on the time and space cost of exact inference from a current assignment and the remaining schematic. We show how our bounding method can be used within a lifted importance sampling algorithm, in order to perform effective Rao-Blackwellisation, and demonstrate experimentally that the Rao-Blackwellised version of the algorithm yields more accurate estimates on several real-world datasets.", "id": "dc82d632c9fcecb0778afbc7924494a6", "authors": ["David B. Smith", "Vibhav G. Gogate"], "conference": "NIPS2015", "accepted": true, "reviews": [{"comments": "The paper introduces an approach to estimate the partition function when doing lifted inference in statistical relational models. The paper is well written and clear and proposes a lifted version of the And/Or search space framework that, to the best of my knowledge, is novel.\n\nIn general, the ideas presented in the paper are sound.\n\n Nevertheless, the evaluation is a bit short and it fails to compare their approach to other approximations of the partition function. The authors do not include an analysis of the bounds of the approximation and a study of how it scales in general.\n\nIt is possible that their lifted And/Or framework can provide good reductions in the complexity of inference but their evaluation and results are too limited to tell. Nevertheless, this paper does introduce a novel algorithm that may prove useful for the NIPS community interested in lifted inference.\n\n In general, the ideas presented in the paper are sound. Nevertheless, the evaluation is a bit short and it fails to compare their approach to other approximations of the partition function.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "The paper introduces lifted and/or schematics, which are an abstract representation of the PTP search space. Analyzing the schematic lets us quantify the size of the search space. This is of independent theoretical interest (although the theory is not quite there yet to provide deep insights), and is practically useful in the context of Rao-Blackwellized importance sampling.\n\nI believe this type of work is important; we still lack understanding of lifted inference algorithms. The proposed schematics are not really simple enough to provide a whole lot of insight, but it's a move in the right direction. The presentation is okay, although I cannot verify many of the technical points with the time available to me.\n\nGiven that this is a theoretical paper, I wonder how powerful the framework is in terms of liftability. Can these schematics capture all known classes of models that are domain-liftable?\n\nThe paper misses the opportunity to relate to other similar techniques.\n\nHow are dtrees (used in recursive conditioning and knowledge compilation) related to and/or schematics?\n\nHow are first-order NNF circuits related to lifted and/or schematics? They look very similar, with counting nodes having a single child, which induces a summation when evaluated, and so on. There is some work on the complexity of evaluating partition functions from first-order NNF circuits, where the result is that it is exponential in the number of nested counting operations (existential quantifiers). This result seems related to the analysis in Section 4.\n\nHow does this relate to the first-order decomposition trees of Taghipour et al.? The footnote on page 3 says that these are not as tight: I would expect more details here (and perhaps an example of where the complexity differs).\n\nI like the importance sampling algorithm that uses the theory in a meaningful way. It's very convincing. I know these experiments are preliminary, but I would still like more details on the setup. For example, I do not believe that 10% evidence on webkb leaves you with any symmetries to exploit. I suspect that the evidence predicates were chosen to maximize the remaining symmetries (only evidence on page class, not on links?). It would be good to clarify.\n\nTypos: The theta_i on line 105 should be a t_i. With exchangeable variables on line 171, you mean exchangeable constants (the random variables after shattering are not fully exchangeable in general). Line 212: of depends.\n\n  This is good work on a very hard problem. The theoretical analysis is very difficult to follow but makes sense at a high level, when you know the lifted inference literature. The sampling application is cute and makes the theory immediately useful.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}, {"comments": "This is a paper on the line of combining lifted and approximate\n\ninference. In this case the two contributions are: estimates of the computional effort , and using an a Rao-Blackwellised lifted importance sampling. The text is well written, but assumes good understanding of previous work, namely ref [9] comes up all the time. I'd also like some more on RaoBlackwell. Experimentsl evslustion is weak.\n\n46-47 I understand the concept of inference unaware, but the idea that being aware of inference means having an idea of how much computation ahead is strange for me, because usually we just can't.\n\n54 - a traditional and-or tree is not a \"compact\"representation. What do you by \"pseudotree\"? Folded tree?\n\n57 - ok, I got\n\nthe idea, but why do you call it schematic?\n\n81-90 there is an and/or tree, which is a spanning tree for a graph that is the original graphical model, there is a mysterious pseudo-tree, there is anther final graph, I think I understnd but please try to define precisely what is what.\n\n119 ->new MLNs ? what do you define as a MLN?\n\n148-160 -> these are complex rules, should have a minimal description. Also explain decomposer,just citing [9] is not enough?\n\n176 - optimal? Is there an optimal?\n\n212 \"The overall complexity of depends:\"\n\nmissing word\n\n346 - which in turn decreases the 347 accuracy because fewer samples are gener- 348 ated.\n\n -> because time budget is fixed?\n\nSec 6 You previously said: \"We demonstrate experimentally that it vastly improves the accuracy of estimation on several real-world datasets.\" Is this a valid conclusion from your results?\n\n  This is a paper on the line of combining lifted and approximateinference. In this case the two contributions are: estimates of the computional effort, and using an a Rao-Blackwellised lifted importance sampling. The paper focus on the first, although I think the second quite interesting too. In general it looks like solid, robust work, but I don't see how the experimental results suppport the claims.", "IS_ANNOTATED": false, "IS_META_REVIEW": false}], "histories": []}
