{
  "name" : "3e7e0224018ab3cf51abb96464d518cd.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "No-Regret Learning in Bayesian Games",
    "authors" : [ "Jason Hartline", "Vasilis Syrgkanis" ],
    "emails" : [ "hartline@northwestern.edu", "vasy@microsoft.com", "eva@cs.cornell.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "A recent confluence of results from game theory and learning theory gives a simple explanation for why good outcomes in large families of strategically-complex games can be expected. The advance comes from (a) a relaxation the classical notion of equilibrium in games to one that corresponds to the outcome attained when players’ behavior ensures asymptotic no-regret, e.g., via standard online learning algorithms such as weighted majority, and (b) an extension theorem that shows that the standard approach for bounding the quality of classical equilibria automatically implies the same bounds on the quality of no-regret equilibria. This paper generalizes these results from static games to Bayesian games, for example, auctions.\nOur motivation for considering learning outcomes in Bayesian games is the following. Many important games model repeated interactions between an uncertain set of participants. Sponsored search, and more generally, online ad-auction market places, are important examples of such games. Platforms are running millions of auctions, with each individual auction slightly different and of only very small value, but such market places have high enough volume to be the financial basis of large industries. This online auction environment is best modeled by a repeated Bayesian game: the auction game is repeated over time, with the set of participants slightly different each time, depending on many factors from budgets of the players to subtle differences in the opportunities.\nA canonical example to which our methods apply is a single-item first-price auction with players’ values for the item drawn from a product distribution. In such an auction, players simultaneously submit sealed bids and the player with the highest bid wins and pays her bid. The utility of the winner is her value minus her bid; the utilities of the losers are zero. When the values are drawn from non-identical continuous distributions the Bayes-Nash equilibrium is given by a differential equation\nthat is not generally analytically tractable, cf. [8] (and generalizations of this model, computationally hard, see [3]). Again, though their Bayes-Nash equilibria are complex, we show that good outcomes can be expected in these kinds of auctions.\nOur approach to proving that good equilibria can be expected in repeated Bayesian games is to extend an analogous result for static games,1 i.e., the setting where the same game with the same payoffs and the same players is repeated. Nash equilibrium is the classical model of equilibrium for each stage of the static game. In such an equilibrium the strategies of players may be randomized; however, the randomizations of the players are independent. To measure the quality of outcomes in games Koutsoupias and Papadimitriou [9] introduced the price of anarchy, the ratio of the quality of the worst Nash equilibrium over a socially optimal solution. Price of anarchy results have been shown for large families of games, with a focus on those relevant for computer networks. Roughgarden [11] identified the canonical approach for bounding the price of anarchy of a game as showing that it satisfies a natural smoothness condition.\nThere are two fundamental flaws with Nash equilibrium as a description of strategic behavior. First, computing a Nash equilibrium can be PPAD hard and, thus, neither should efficient algorithms for computing a Nash equilibrium be expected nor should any dynamics (of players with bounded computational capabilities) converge to a Nash equilibrium. Second, natural behavior tends to introduce correlations in strategies and therefore does not converge to Nash equilibrium even in the limit. Both of these issues can be resolved for large families of games. First, there are relaxations of Nash equilibrium which allow for correlation in the players’ strategies. Of these, this paper will focus on coarse correlated equilibrium which requires the expected payoff of a player for the correlated strategy be no worse than the expected payoff of any action at the player’s disposal. Second, it was proven by Blum et al. [2] that the (asymptotic) no-regret property of many online learning algorithms implies convergence to the set of coarse correlated equilibria.2\nBlum et al. [2] extended the definition of the price of anarchy to outcomes obtained when each player follows a no-regret learning algorithm.3 As coarse correlated equilibrium generalize Nash equilibrium it could be that the worst case equilibrium under the former is worse than the latter. Roughgarden [11], however, observed that there is often no degradation; specifically, the very same smoothness property that he identified as implying good welfare in Nash equilibrium also proves good welfare of coarse correlated equilibrium (equivalently: for outcomes from no-regret learners). Thus, for a large family of static games, we can expect strategic behavior to lead to good outcomes.\nThis paper extends this theory to Bayesian games. Our contribution is two-fold: (i) We show an analog of the convergence of no-regret learning to coarse correlated equilibria in Bayesian games, which is of interest independently of our price of anarchy analysis; and (ii) we show that the coarse correlated equilibria of the Bayesian version of any smooth static game have good welfare. Combining these results, we conclude that no-regret learning in smooth Bayesian games achieves good welfare.\nThese results are obtained as follows. It is possible to view a Bayesian game as a stochastic game, i.e., where the payoff structure is fixed but there is a random action on the part of Nature. This viewpoint applied to the above auction example considers a population of bidders associated for each player and, in each stage, Nature uniformly at random selects one bidder from each population to participate in the auction. We re-interpret and strengthen a result of Syrgkanis and Tardos [12] by showing that the smoothness property of the static game (for any fixed profile of bidder values) implies smoothness of this stochastic game. From the perspective of coarse correlated equilibrium, there is no difference between a stochastic game and the non-stochastic game with each random variable replaced with its expected value. Thus, the smoothness framework of Roughgarden [11] extends this result to imply that the coarse correlated equilibria of the stochastic game are good. To show that we can expect good outcomes in Bayesian games, it suffices to show that no-regret learning converges to the coarse correlated equilibrium of this stochastic game. Importantly, when we consider learning algorithms there is a distinction between the stochastic game where players’ payoffs are random variables and the non-stochastic game where players’ payoffs are the expectation\n1In the standard terms of the game theory literature, we extend results for learning in games of complete information to games of incomplete information.\n2This result is a generalization of one of Foster and Vohra [7]. 3They referred to this price of anarchy for no-regret learners as the price of total anarchy.\nof these variables. Our analysis addressed this distinction and, in particular, shows that, in the stochastic game on populations, no-regret learning converges almost surely to the set of coarse correlated equilibrium. This result implies that the average welfare of no-regret dynamics will be good, almost surely, and not only in expectation over the random draws of Nature."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "This section describes a general game theoretic environment which includes auctions and resource allocation mechanisms. For this general environment we review the results from the literature for analyzing the social welfare that arises from no-regret learning dynamics in repeated game play. The subsequent sections of the paper will generalize this model and these results to Bayesian games, a.k.a., games of incomplete information.\nGeneral Game Form. A general game M is specified by a mapping from a profile a ∈ A ≡ A1 × · · · × An of allowable actions of players to an outcome. Behavior in a game may result in (possibly correlated) randomized actions a ∈ ∆(A).4 Player i’s utility in this game is determined by a profile of individual values v ∈ V ≡ V1 × · · · × Vn and the (implicit) outcome of the game; it is denoted Ui(a; vi) = Ea∼a [Ui(a; vi)]. In games with a social planner or principal who does not take an action in the game, the utility of the principal is R(a) = Ea∼a [R(a)]. In many games of interest, such as auctions or allocation mechanisms, the utility of the principal is the revenue from payments from the players. We will use the term mechanism and game interchangeably.\nIn a static game the payoffs of the players (given by v) are fixed. Subsequent sections will consider Bayesian games in the independent private value model, i.e., where player i’s value vi is drawn independently from the other players’ values and is known only privately to player i. Classical game theory assumes complete information for static games, i.e., that v is known, and incomplete information in Bayesian games, i.e., that the distribution over V is known. For our study of learning in games no assumptions of knowledge are made; however, to connect to the classical literature we will use its terminology of complete and incomplete information to refer to static and Bayesian games, respectively.\nSocial Welfare. We will be interested in analyzing the quality of the outcome of the game as defined by the social welfare, which is the sum of the utilities of the players and the principal. We will denote by SW (a; v) = ∑ i∈[n] Ui(a; vi) +R(a) the expected social welfare of mechanismM under a randomized action profile a. For any valuation profile v ∈ V we will denote the optimal social welfare, i.e, the maximum over outcomes of the game of the sum of utilities, by OPT(v).\nNo-regret Learning and Coarse Correlated Equilibria. For complete information games, i.e., fixed valuation profile v, Blum et al. [2] analyzed repeated play of players using no-regret learning algorithms, and showed that this play converges to a relaxation of Nash equilibrium, namely, coarse correlated equilibrium. Definition 1 (no regret). A player achieves no regret in a sequence of play a1, . . . , aT if his regret against any fixed strategy a′i vanishes to zero:\nlimT→∞ 1 T ∑T t=1(Ui(a ′ i, a t −i; vi)− Ui(at; vi)) = 0. (1)\nDefinition 2 (coarse correlated equilibrium, CCE). A randomized action profile a ∈ ∆(A) is a coarse correlated equilibrium of a complete information game with valuation profile v if for every player i and a′i ∈ Ai: Ea [Ui(a; vi)] ≥ Ea [Ui(a′i,a−i; vi)] (2) Theorem 3 (Blum et al. [2]). The empirical distribution of actions of any no-regret sequence in a repeated game converges to the set of CCE of the static game.\nPrice of Anarchy of CCE. Roughgarden [11] gave a unifying framework for comparing the social welfare, under various equilibrium notions including coarse correlated equilibrium, to the optimal social welfare by defining the notion of a smooth game. This framework was extended to games like auctions and allocation mechanisms by Syrgkanis and Tardos [12].\n4Bold-face symbols denote random variables.\nDefinition 4 (smooth mechanism). A mechanismM is (λ, µ)-smooth for some λ, µ ≥ 0 there exists an independent randomized action profile a∗(v) ∈ ∆(A1)×· · ·×∆(An) for each valuation profile v, such that for any action profile a ∈ A and valuation profile v ∈ V:∑\ni∈[n] Ui(a ∗ i (v), a−i; vi) ≥ λ · OPT(v)− µ ·R(a). (3)\nMany important games and mechanisms satisfy this smoothness definition for various parameters of λ and µ (see Figure 1); the following theorem shows that the welfare of any coarse correlated equilibrium in any of these games is nearly optimal. Theorem 5 (efficiency of CCE; [12]). If a mechanism is (λ, µ)-smooth then the social welfare of any course correlated equilibrium at least λmax{1,µ} of the optimal welfare, i.e., the price of anarchy satisfies POA ≤ max{1,µ}λ .\nPrice of Anarchy of No-regret Learning. Following Blum et al. [2], Theorem 3 and Theorem 5 imply that no-regret learning dynamics have near-optimal social welfare. Corollary 6 (efficiency of no-regret dyhamics; [12]). If a mechanism is (λ, µ)-smooth then the average welfare of any no-regret dynamics of the repeated game with a fixed player set and valuation profile, achieves average social welfare at least λmax{1,µ} of the optimal welfare, i.e., the price of anarchy satisfies POA ≤ max{1,µ}λ .\nImportantly, Corollary 6 holds the valuation profile v ∈ V fixed throughout the repeated game play. The main contribution of this paper is in extending this theory to games of incomplete information, e.g., where the values of the players are drawn at random in each round of game play."
    }, {
      "heading" : "3 Population Interpretation of Bayesian Games",
      "text" : "In the standard independent private value model of a Bayesian game there are n players. Player i has type vi drawn uniformly from the set of type Vi (and this distribution is denoted Fi).5 We will restrict attention to the case when the type space Vi is finite. A player’s strategy in this Bayesian game is a mapping si : Vi → Ai from a valuation vi ∈ Vi to an action ai ∈ Ai. We will denote with Σi = AVii the strategy space of each player and with Σ = Σ1 × . . . × Σn. In the game, each player i realizes his type vi from the distribution and then makes action si(vi) in the game.\nIn the population interpretation of the Bayesian game, also called the agent normal form representation [6], there are n finite populations of players. Each player in population i has a type vi which we assume to be distinct for each player in each population and across populations.6 The set of players in the population is denoted Vi. and the player in population i with type vi is called player vi. In the population game, each player vi chooses an action si(vi). Nature uniformly draws one player from\n5The restriction to the uniform distribution is without loss of generality for any finite type space and for any distribution over the type space that involves only rational probabilities.\n6The restriction to distinct types is without of loss of generality as we can always augment a type space with an index that does not affect player utilities.\neach population, and the game is played with those players’ actions. In other words, the utility of player vi from population i is:\nUAGi,vi(s) = Ev [Ui(s(v);vi) · 1{vi = vi}] (4)\nNotice that the population interpretation of the Bayesian game is in fact a stochastic game of complete information.\nThere are multiple generalizations of coarse correlated equilibria from games of complete information to games of incomplete information (c.f. [6], [1], [4]). One of the canonical definitions is simply the coarse correlated equilibrium of the stochastic game of complete information that is defined by the population interpretation above.7\nDefinition 7 (Bayesian coarse correlated equilibrium - BAYES-CCE). A randomized strategy profile s ∈ ∆(Σ) is a Bayesian coarse correlated equilibrium if for every a′i ∈ Ai and for every vi ∈ Vi:\nEsEv [Ui(s(v);vi) | vi = vi] ≥ EsEv [Ui(a′i, s−i(v−i);vi) | vi = vi] (5)\nIn a game of incomplete information the welfare in equilibrium will be compared to the expected ex-post optimal social welfare Ev[OPT(v)]. We will refer to the worst-case ratio of the expected optimal social welfare over the expected social welfare of any BAYES-CCE as BAYES-CCE-POA."
    }, {
      "heading" : "4 Learning in Repeated Bayesian Game",
      "text" : "Consider a repeated version of the population interpretation of a Bayesian game. At each iteration one player vi from each population is sampled uniformly and independently from other populations. The set of chosen players then participate in an instance of a mechanismM. We assume that each player vi ∈ Vi, uses some no-regret learning rule to play in this repeated game.8 In Definition 8, we describe the structure of the game and our notation more elaborately. Definition 8. The repeated Bayesian game ofM proceeds as follows. In stage t:\n1. Each player vi ∈ Vi in each population i picks an action sti(vi) ∈ Ai. We denote with sti ∈ A |Vi| i the function that maps a player vi ∈ Vi to his action.\n2. From each population i one player vti ∈ Vi is selected uniformly at random. Let vt = (vt1, . . . , v t n) be the chosen profile of players and s t(vt) = (st1(v t 1), . . . , s t n(v t n)) be the\nprofile of chosen actions.\n3. Each player vti participates in an instance of gameM, in the role of player i ∈ [n], with action sti(v t i) and experiences a utility of Ui(s\nt(vt); vti). All players not selected in Step 2 experience zero utility.\nRemark. We point out that for each player in a population to achieve no-regret he does not need to know the distribution of values in other populations. There exist algorithms that can achieve the no-regret property and simply require an oracle that returns the utility of a player at each iteration. Thus all we need to assume is that each player receives as feedback his utility at each iteration.\nRemark. We also note that our results would extend to the case where at each period multiple matchings are sampled independently and players potentially participate in more than one instance of the mechanismM and potentially with different players from the remaining population. The only thing that the players need to observe in such a setting is their average utility that resulted from their action sti(vi) ∈ Ai from all the instances that they participated at the given period. Such a scenario seems an appealing model in online ad auction marketplaces where players receive only average utility feedback from their bids.\n7This notion is the coarse analog of the agent normal form Bayes correlated equilibrium defined in Section 4.2 of Forges [6].\n8An equivalent and standard way to view a Bayesian game is that each player draws his value independently from his distribution each time the game is played. In this interpretation the player plays by choosing a strategy that maps his value to an action (or distribution over actions). In this interpretation our no-regret condition requires that the player not regret his actions for each possible value.\nBayesian Price of Anarchy for No-regret Learners. In this repeated game setting we want to compare the average social welfare of any sequence of play where each player uses a vanishing regret algorithm versus the average optimal welfare. Moreover, we want to quantify the worst-case such average welfare over all possible valuation distributions within each population:\nsup F1,...,Fn lim sup T→∞\n∑T t=1 OPT(v\nt)∑T t=1 SW M(st(vt);vt) (6)\nWe will refer to this quantity as the Bayesian price of anarchy for no-regret learners. The numerator of this term is simply the average optimal welfare when players from each population are drawn independently in each stage; it converges almost surely to the expected ex-post optimal welfare Ev[OPT(v)] of the stage game. Our main theorem is that if the mechanism is smooth and players follow no-regret strategies then the expected welfare is guaranteed to be close to the optimal welfare. Theorem 9 (Main Theorem). If a mechanism is (λ, µ)-smooth then the average (over time) welfare of any no-regret dynamics of the repeated Bayesian game achieves average social welfare at least\nλ max{1,µ} of the average optimal welfare, i.e. POA ≤ max{1,µ} λ , almost surely.\nRoadmap of the proof. In Section 5, we show that any vanishing regret sequence of play of the repeated Bayesian game, will converge almost surely to the Bayesian version of a coarse correlated equilibrium of the incomplete information stage game. Therefore the Bayesian price of total anarchy will be upper bounded by the efficiency of guarantee of any Bayesian coarse correlated equilibrium. Finally, in Section 6 we show that the price of anarchy bound of smooth mechanisms directly extends to Bayesian coarse correlated equilibria, thereby providing an upper bound on the Bayesian price of total anarchy of the repeated game.\nRemark. We point out that our definition of BAYES-CCE is inherently different and more restricted than the one defined in Caragiannis et al. [4]. There, a BAYES-CCE is defined as a joint distribution D over V ×A, such that if (v,a) ∼ D then for any vi ∈ Vi and a′i(vi) ∈ Ai: E(v,a) [Ui(a; vi)] ≥ E(v,a) [Ui(a′i(vi),a−i; vi)] (7) The main difference is that the product distribution defined by a distribution in ∆(Σ) and the distribution of values, cannot produce any possible joint distribution over (V,A), but the type of joint distributions are restricted to satisfy a conditional independence property described by [6]. Namely that player i’s action is conditionally independent of some other player j’s value, given player i’s type. Such a conditional independence property is essential for the guarantees that we will present in this work to extend to a BAYES-CCE and hence do not seem to extend to the notion given in [4]. However, as we will show in Section 5, the no-regret dynamics that we analyze, which are mathematically equivalent to the dynamics in [4], do converge to this smaller set of BAYES-CCE that we define and for which our efficiency guarantees will extend. This extra convergence property is not needed when the mechanism satisfies the stronger semi-smoothness property defined in [4] and thereby was not needed to show efficiency bounds in their setting."
    }, {
      "heading" : "5 Convergence of Bayesian No-Regret to BAYES-CCE",
      "text" : "In this section we show that no-regret learning in the repeated Bayesian game converges almost surely to the set of Bayesian coarse correlated equilibria. Any given sequence of play of the repeated Bayesian game, which we defined in Definition 8, gives rise to a sequence of strategy-value pairs (st, vt) where st = (st1, . . . , s t n) and s t i ∈ A Vi i , captures the actions that each player vi in population iwould have chosen, had they been picked. Then observe that all that matters to compute the average social welfare of the game for any given time step T , is the empirical distribution of pairs (s, v), up till time step T , denoted as DT , i.e. if (sT ,vT ) is a random sample from DT :\n1 T ∑T t=1 SW (s t(vt); vt) = E(sT ,vT ) [ SW (sT (vT );vT ) ] (8)\nLemma 10 (Almost sure convergence to BAYES-CCE). Consider a sequence of play of the random matching game, where each player uses a vanishing regret algorithm and let DT be the empirical distribution of (strategy, valuation) profile pairs up till time step T . Consider any subsequence of {DT }T that converges in distribution to some distribution D. Then, almost surely, D is a product distribution, i.e. D = Ds × Dv , with Ds ∈ ∆(Σ) and Dv × ∆(V) such that Dv = F and Ds ∈ BAYES-CCE of the static incomplete information game with distributional beliefs F .\nProof. We will denote with\nri(a ∗ i , a; vi) = Ui(a ∗ i , a−i; vi)− Ui(a; vi),\nthe regret of player vi from population i, for action a∗i at action profile a. For a vi ∈ Vi let xti(vi) = 1{vti = vi}. Since the sequence has vanishing regret for each player vi in population Pi, it must be that for any s∗i ∈ Σi: ∑T\nt=1 x t i(vi) · ri (s∗i (vi), st(vt); vi) ≤ o(T ) (9)\nFor any fixed T , letDTs ∈ ∆(Σ) denote the empirical distribution of st and let s be a random sample from DTs . For each s ∈ Σ, let Ts ⊂ [T ] denote the time steps such that st = s for each t ∈ Ts. Then we can re-write Equation (9) as:\nEs [ 1 |Ts| ∑ t∈Ts x t i(vi) · ri (s∗i (vi), st(vt); vi) ] ≤ o(T )T (10)\nFor any s ∈ Σ and w ∈ V , let Ts,w = {t ∈ Ts : vt = w}. Then we can re-write Equation (10) as: Es [∑\nw∈V |Ts,w| |Ts| 1{wi = vi} · ri (s ∗ i (vi), s(w); vi) ] ≤ o(T )T (11)\nNow we observe that |Ts,w||Ts| is the empirical frequency of the valuation vector w ∈ V , when filtered at time steps where the strategy vector was s. Since at each time step t the valuation vector vt is picked independently from the distribution of valuation profiles F , this is the empirical frequency of Ts independent samples from F . By standard arguments from empirical processes theory, if Ts →∞ then this empirical distribution converges almost surely to the distribution F . On the other hand if Ts doesn’t go to ∞, then the empirical frequency of strategy s vanishes to 0 as T → ∞ and therefore has measure zero in the above expectation as T → ∞. Thus for any convergent subsequence of {DT }, if D is the limit distribution, then if s is in the support of D, then almost surely the distribution of w conditional on strategy s is F . Thus we can write D as a product distribution Ds ×F . Moreover, if we denote with w the random variable that follows distribution F , then the limit of Equation (11) for any convergent sub-sequence, will give that:\na.s.: Es∼DsEw∼F [1{wi = vi} · ri (s∗i (vi), s(w); vi)] ≤ 0\nEquivalently, we get that Ds will satisfy that for all vi ∈ Vi and for all s∗i :\na.s.: Es∼DsEw∼F [ri (s∗i (wi), s(w);wi) | wi = vi] ≤ 0\nThe latter is exactly the BAYES-CCE condition from Definition 7. Thus Ds is in the set of BAYES-CCE of the static incomplete incomplete information game among n players, where the type profile is drawn from F .\nGiven the latter convergence theorem we can easily conclude the following the following theorem, whose proof is given in the supplementary material.\nTheorem 11. The price of anarchy for Bayesian no-regret dynamics is upper bounded by the price of anarchy of Bayesian coarse correlated equilibria, almost surely."
    }, {
      "heading" : "6 Efficiency of Smooth Mechanisms at Bayes Coarse Correlated Equilibria",
      "text" : "In this section we show that smoothness of a mechanismM implies that any BAYES-CCE of the incomplete information setting achieves at least λmax{1,µ} of the expected optimal welfare. To show this we will adopt the interpretation of BAYES-CCE that we used in the previous section, as coarse correlated equilibria of a more complex normal form game; the stochastic agent normal form representation of the Bayesian game. We can interpret this complex normal form game as the game that arises from a complete information mechanismMAG among ∑ i |Vi| players, which randomly samples one player from each of the n population and where the utility of a player in the complete information mechanismMAG is given by Equation (4). The set of possible outcomes in this agent\ngame corresponds to the set of mappings from a profile of chosen players to an outcome in the underlying mechanism M. The optimal welfare of this game, is then the expected ex-post optimal welfare OPTAG = Ev [OPT(v)].\nThe main theorem that we will show is that whenever mechanism M is (λ, µ)-smooth, then also mechanism MAG is (λ, µ)-smooth. Then we will invoke a theorem of [12, 11], which shows that any coarse correlated equilibrium of a complete information mechanism achieves at least λmax{1,µ} of the optimal welfare. By the equivalence between BAYES-CCE and CCE of this complete information game, we get that every BAYES-CCE of the Bayesian game achieves at least λmax{1,µ} of the expected optimal welfare. Theorem 12 (From complete information to Bayesian smoothness). If a mechanismM is (λ, µ)smooth, then for any vector of independent valuation distributions F = (F1, . . . ,Fn), the complete information mechanismMAG is also (λ, µ)-smooth.\nProof. Consider the following randomized deviation for each player vi ∈ Vi in population i: He random samples a valuation profile w ∼ F . Then he plays according to the randomized action s∗i (vi,w−i), i.e., the player deviates using the randomized action guaranteed by the smoothness property of mechanismM for his type vi and the random sample of the types of the others w−i. Consider an arbitrary action profile s = (s1, . . . , sn) for all players in all populations. In this context it is better to think of each si as a |Vi| dimensional vector inA|Vi|i and to view s as a ∑ i |Vi| dimensional vector. Then with s−vi we will denote all the components of this large vector except the ones corresponding to player vi ∈ Vi. Moreover, we will be denoting with v a sample from F drawn by mechanismMAG. We now argue about the expected utility of player vi from this deviation, which is:\nEw [ UAGi,vi(s ∗ i (vi,w−i), s−vi) ] = EwEv [Ui(s∗i (vi,w−i), s−i(v−i); vi) · 1{vi = vi}]\nSumming the latter over all players vi ∈ Vi in population i:∑ vi∈Vi Ew [ UAGi,vi(s ∗ i (vi,w−i), s−vi) ] = Ew,v [∑ vi∈Vi Ui(s ∗ i (vi,w−i), s−i(v−i); vi) · 1{vi = vi} ] = Ev,w [Ui(s∗i (vi,w−i), s−i(v−i);vi)] = Ev,w [Ui(s∗i (wi,w−i), s−i(v−i);wi)] = Ev,w [Ui(s∗i (w), s−i(v−i);wi)] ,\nwhere the second to last equation is an exchange of variable names and regrouping using independence. Summing over populations and using smoothness ofM, we get smoothness ofMAG:∑\ni∈[n] ∑ vi∈Vi Ew [ UAGi,vi(s ∗ i (vi,w−i), s−vi) ] = Ev,w [∑ i∈[n] Ui(s ∗ i (w), s−i(v−i);wi) ] ≥ Ev,w [λOPT(w)− µR(s(v))] = λEw [OPT(w)]− µRAG(s)\nCorollary 13. Every BAYES-CCE of the incomplete information setting of a smooth mechanism M, achieves expected welfare at least λmax{1,µ} of the expected optimal welfare."
    }, {
      "heading" : "7 Finite Time Analysis and Convergence Rates",
      "text" : "In the previous section we argued about the limit average efficiency of the game as time goes to infinity. In this section we analyze the convergence rate to BAYES-CCE and we show approximate efficiency results even for finite time, when players are allowed to have some -regret. Theorem 14. Consider the repeated matching game with a (λ, µ)-smooth mechanism. Suppose that for any T ≥ T 0, each player in each of the n populations has regret at most n . Then for every δ and ρ, there exists a T ∗(δ, ρ), such that for any T ≥ min{T 0, T ∗}, with probability 1− ρ:\n1 T ∑T t=1 SW (s t(vt); vt) ≥ λmax{1,µ}Ev [OPT(v)]− δ − µ · (12)\nMoreover, T ∗(δ, ρ) ≤ 54·n 3·|Σ|·|V|2·H3 δ3 log ( 2 ρ ) ."
    } ],
    "references" : [ {
      "title" : "Correlated Equilibrium in Games with Incomplete Information",
      "author" : [ "Dirk Bergemann", "Stephen Morris" ],
      "venue" : "Cowles Foundation Discussion Papers 1822,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2011
    }, {
      "title" : "Regret minimization and the price of total anarchy",
      "author" : [ "Avrim Blum", "MohammadTaghi Hajiaghayi", "Katrina Ligett", "Aaron Roth" ],
      "venue" : "In Proceedings of the Fortieth Annual ACM Symposium on Theory of Computing,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2008
    }, {
      "title" : "Simultaneous bayesian auctions and computational complexity",
      "author" : [ "Yang Cai", "Christos Papadimitriou" ],
      "venue" : "In Proceedings of the fifteenth ACM conference on Economics and Computation, EC",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2014
    }, {
      "title" : "Bounding the inefficiency of outcomes in generalized second price auctions",
      "author" : [ "Ioannis Caragiannis", "Christos Kaklamanis", "Panagiotis Kanellopoulos", "Maria Kyropoulou", "Brendan Lucier", "Renato Paes Leme", "Éva Tardos" ],
      "venue" : "Journal of Economic Theory,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2014
    }, {
      "title" : "Inefficiency of standard multi-unit auctions",
      "author" : [ "Bart de Keijzer", "Evangelos Markakis", "Guido Schfer", "Orestis Telelis" ],
      "venue" : "In HansL. Bodlaender and GiuseppeF. Italiano, editors, Algorithms ESA 2013,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2013
    }, {
      "title" : "Five legitimate definitions of correlated equilibrium in games with incomplete information",
      "author" : [ "Franoise Forges" ],
      "venue" : "Theory and Decision,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1993
    }, {
      "title" : "Asymmetric first-price auctions with uniform distributions: analytic solutions to the general case",
      "author" : [ "ToddR. Kaplan", "Shmuel Zamir" ],
      "venue" : "Economic Theory,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2012
    }, {
      "title" : "Worst-case equilibria",
      "author" : [ "Elias Koutsoupias", "Christos Papadimitriou" ],
      "venue" : "In Proceedings of the 16th annual conference on Theoretical aspects of computer science,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1999
    }, {
      "title" : "Price of anarchy for greedy auctions",
      "author" : [ "B. Lucier", "A. Borodin" ],
      "venue" : "In Proceedings of the Twenty- First Annual ACM-SIAM Symposium on Discrete Algorithms,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2010
    }, {
      "title" : "Intrinsic robustness of the price of anarchy",
      "author" : [ "T. Roughgarden" ],
      "venue" : "In Proceedings of the 41st annual ACM symposium on Theory of computing,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2009
    }, {
      "title" : "Composable and efficient mechanisms",
      "author" : [ "Vasilis Syrgkanis", "Éva Tardos" ],
      "venue" : "In Proceedings of the Forty-fifth Annual ACM Symposium on Theory of Computing,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2013
    }, {
      "title" : "Nash equilibria in competitive societies, with applications to facility location, traffic routing and auctions",
      "author" : [ "A. Vetta" ],
      "venue" : "In Foundations of Computer Science,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2002
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "[8] (and generalizations of this model, computationally hard, see [3]).",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[8] (and generalizations of this model, computationally hard, see [3]).",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 7,
      "context" : "To measure the quality of outcomes in games Koutsoupias and Papadimitriou [9] introduced the price of anarchy, the ratio of the quality of the worst Nash equilibrium over a socially optimal solution.",
      "startOffset" : 74,
      "endOffset" : 77
    }, {
      "referenceID" : 9,
      "context" : "Roughgarden [11] identified the canonical approach for bounding the price of anarchy of a game as showing that it satisfies a natural smoothness condition.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 1,
      "context" : "[2] that the (asymptotic) no-regret property of many online learning algorithms implies convergence to the set of coarse correlated equilibria.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "[2] extended the definition of the price of anarchy to outcomes obtained when each player follows a no-regret learning algorithm.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "Roughgarden [11], however, observed that there is often no degradation; specifically, the very same smoothness property that he identified as implying good welfare in Nash equilibrium also proves good welfare of coarse correlated equilibrium (equivalently: for outcomes from no-regret learners).",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 10,
      "context" : "We re-interpret and strengthen a result of Syrgkanis and Tardos [12] by showing that the smoothness property of the static game (for any fixed profile of bidder values) implies smoothness of this stochastic game.",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 9,
      "context" : "Thus, the smoothness framework of Roughgarden [11] extends this result to imply that the coarse correlated equilibria of the stochastic game are good.",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 1,
      "context" : "[2] analyzed repeated play of players using no-regret learning algorithms, and showed that this play converges to a relaxation of Nash equilibrium, namely, coarse correlated equilibrium.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "Roughgarden [11] gave a unifying framework for comparing the social welfare, under various equilibrium notions including coarse correlated equilibrium, to the optimal social welfare by defining the notion of a smooth game.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 10,
      "context" : "This framework was extended to games like auctions and allocation mechanisms by Syrgkanis and Tardos [12].",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 10,
      "context" : "Game/Mechanism (λ, μ) POA Reference Simultaneous First Price Auction with Submodular Bidders (1− 1/e, 1) e e−1 [12] First Price Multi-Unit Auction (1− 1/e, 1) e e−1 [5] First Price Position Auction (1/2, 1) 2 [12] All-Pay Auction (1/2, 1) 2 [12] Greedy Combinatorial Auction with d-complements (1− 1/e, d) de e−1 [10] Proportional Bandwitdth Allocation Mechanism (1/4, 1) 4 [12] Submodular Welfare Games (1, 1) 2 [13, 11] Congestion Games with Linear Delays (5/3, 1/3) 5/2 [11]",
      "startOffset" : 111,
      "endOffset" : 115
    }, {
      "referenceID" : 4,
      "context" : "Game/Mechanism (λ, μ) POA Reference Simultaneous First Price Auction with Submodular Bidders (1− 1/e, 1) e e−1 [12] First Price Multi-Unit Auction (1− 1/e, 1) e e−1 [5] First Price Position Auction (1/2, 1) 2 [12] All-Pay Auction (1/2, 1) 2 [12] Greedy Combinatorial Auction with d-complements (1− 1/e, d) de e−1 [10] Proportional Bandwitdth Allocation Mechanism (1/4, 1) 4 [12] Submodular Welfare Games (1, 1) 2 [13, 11] Congestion Games with Linear Delays (5/3, 1/3) 5/2 [11]",
      "startOffset" : 165,
      "endOffset" : 168
    }, {
      "referenceID" : 10,
      "context" : "Game/Mechanism (λ, μ) POA Reference Simultaneous First Price Auction with Submodular Bidders (1− 1/e, 1) e e−1 [12] First Price Multi-Unit Auction (1− 1/e, 1) e e−1 [5] First Price Position Auction (1/2, 1) 2 [12] All-Pay Auction (1/2, 1) 2 [12] Greedy Combinatorial Auction with d-complements (1− 1/e, d) de e−1 [10] Proportional Bandwitdth Allocation Mechanism (1/4, 1) 4 [12] Submodular Welfare Games (1, 1) 2 [13, 11] Congestion Games with Linear Delays (5/3, 1/3) 5/2 [11]",
      "startOffset" : 209,
      "endOffset" : 213
    }, {
      "referenceID" : 10,
      "context" : "Game/Mechanism (λ, μ) POA Reference Simultaneous First Price Auction with Submodular Bidders (1− 1/e, 1) e e−1 [12] First Price Multi-Unit Auction (1− 1/e, 1) e e−1 [5] First Price Position Auction (1/2, 1) 2 [12] All-Pay Auction (1/2, 1) 2 [12] Greedy Combinatorial Auction with d-complements (1− 1/e, d) de e−1 [10] Proportional Bandwitdth Allocation Mechanism (1/4, 1) 4 [12] Submodular Welfare Games (1, 1) 2 [13, 11] Congestion Games with Linear Delays (5/3, 1/3) 5/2 [11]",
      "startOffset" : 241,
      "endOffset" : 245
    }, {
      "referenceID" : 8,
      "context" : "Game/Mechanism (λ, μ) POA Reference Simultaneous First Price Auction with Submodular Bidders (1− 1/e, 1) e e−1 [12] First Price Multi-Unit Auction (1− 1/e, 1) e e−1 [5] First Price Position Auction (1/2, 1) 2 [12] All-Pay Auction (1/2, 1) 2 [12] Greedy Combinatorial Auction with d-complements (1− 1/e, d) de e−1 [10] Proportional Bandwitdth Allocation Mechanism (1/4, 1) 4 [12] Submodular Welfare Games (1, 1) 2 [13, 11] Congestion Games with Linear Delays (5/3, 1/3) 5/2 [11]",
      "startOffset" : 313,
      "endOffset" : 317
    }, {
      "referenceID" : 10,
      "context" : "Game/Mechanism (λ, μ) POA Reference Simultaneous First Price Auction with Submodular Bidders (1− 1/e, 1) e e−1 [12] First Price Multi-Unit Auction (1− 1/e, 1) e e−1 [5] First Price Position Auction (1/2, 1) 2 [12] All-Pay Auction (1/2, 1) 2 [12] Greedy Combinatorial Auction with d-complements (1− 1/e, d) de e−1 [10] Proportional Bandwitdth Allocation Mechanism (1/4, 1) 4 [12] Submodular Welfare Games (1, 1) 2 [13, 11] Congestion Games with Linear Delays (5/3, 1/3) 5/2 [11]",
      "startOffset" : 374,
      "endOffset" : 378
    }, {
      "referenceID" : 11,
      "context" : "Game/Mechanism (λ, μ) POA Reference Simultaneous First Price Auction with Submodular Bidders (1− 1/e, 1) e e−1 [12] First Price Multi-Unit Auction (1− 1/e, 1) e e−1 [5] First Price Position Auction (1/2, 1) 2 [12] All-Pay Auction (1/2, 1) 2 [12] Greedy Combinatorial Auction with d-complements (1− 1/e, d) de e−1 [10] Proportional Bandwitdth Allocation Mechanism (1/4, 1) 4 [12] Submodular Welfare Games (1, 1) 2 [13, 11] Congestion Games with Linear Delays (5/3, 1/3) 5/2 [11]",
      "startOffset" : 413,
      "endOffset" : 421
    }, {
      "referenceID" : 9,
      "context" : "Game/Mechanism (λ, μ) POA Reference Simultaneous First Price Auction with Submodular Bidders (1− 1/e, 1) e e−1 [12] First Price Multi-Unit Auction (1− 1/e, 1) e e−1 [5] First Price Position Auction (1/2, 1) 2 [12] All-Pay Auction (1/2, 1) 2 [12] Greedy Combinatorial Auction with d-complements (1− 1/e, d) de e−1 [10] Proportional Bandwitdth Allocation Mechanism (1/4, 1) 4 [12] Submodular Welfare Games (1, 1) 2 [13, 11] Congestion Games with Linear Delays (5/3, 1/3) 5/2 [11]",
      "startOffset" : 413,
      "endOffset" : 421
    }, {
      "referenceID" : 9,
      "context" : "Game/Mechanism (λ, μ) POA Reference Simultaneous First Price Auction with Submodular Bidders (1− 1/e, 1) e e−1 [12] First Price Multi-Unit Auction (1− 1/e, 1) e e−1 [5] First Price Position Auction (1/2, 1) 2 [12] All-Pay Auction (1/2, 1) 2 [12] Greedy Combinatorial Auction with d-complements (1− 1/e, d) de e−1 [10] Proportional Bandwitdth Allocation Mechanism (1/4, 1) 4 [12] Submodular Welfare Games (1, 1) 2 [13, 11] Congestion Games with Linear Delays (5/3, 1/3) 5/2 [11]",
      "startOffset" : 473,
      "endOffset" : 477
    }, {
      "referenceID" : 1,
      "context" : "[2], Theorem 3 and Theorem 5 imply that no-regret learning dynamics have near-optimal social welfare.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 10,
      "context" : "Corollary 6 (efficiency of no-regret dyhamics; [12]).",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 5,
      "context" : "In the population interpretation of the Bayesian game, also called the agent normal form representation [6], there are n finite populations of players.",
      "startOffset" : 104,
      "endOffset" : 107
    }, {
      "referenceID" : 5,
      "context" : "The main difference is that the product distribution defined by a distribution in ∆(Σ) and the distribution of values, cannot produce any possible joint distribution over (V,A), but the type of joint distributions are restricted to satisfy a conditional independence property described by [6].",
      "startOffset" : 289,
      "endOffset" : 292
    }, {
      "referenceID" : 3,
      "context" : "Such a conditional independence property is essential for the guarantees that we will present in this work to extend to a BAYES-CCE and hence do not seem to extend to the notion given in [4].",
      "startOffset" : 187,
      "endOffset" : 190
    }, {
      "referenceID" : 3,
      "context" : "However, as we will show in Section 5, the no-regret dynamics that we analyze, which are mathematically equivalent to the dynamics in [4], do converge to this smaller set of BAYES-CCE that we define and for which our efficiency guarantees will extend.",
      "startOffset" : 134,
      "endOffset" : 137
    }, {
      "referenceID" : 3,
      "context" : "This extra convergence property is not needed when the mechanism satisfies the stronger semi-smoothness property defined in [4] and thereby was not needed to show efficiency bounds in their setting.",
      "startOffset" : 124,
      "endOffset" : 127
    }, {
      "referenceID" : 10,
      "context" : "Then we will invoke a theorem of [12, 11], which shows that any coarse correlated equilibrium of a complete information mechanism achieves at least λ max{1,μ} of the optimal welfare.",
      "startOffset" : 33,
      "endOffset" : 41
    }, {
      "referenceID" : 9,
      "context" : "Then we will invoke a theorem of [12, 11], which shows that any coarse correlated equilibrium of a complete information mechanism achieves at least λ max{1,μ} of the optimal welfare.",
      "startOffset" : 33,
      "endOffset" : 41
    } ],
    "year" : 2015,
    "abstractText" : "Recent price-of-anarchy analyses of games of complete information suggest that coarse correlated equilibria, which characterize outcomes resulting from no-regret learning dynamics, have near-optimal welfare. This work provides two main technical results that lift this conclusion to games of incomplete information, a.k.a., Bayesian games. First, near-optimal welfare in Bayesian games follows directly from the smoothness-based proof of near-optimal welfare in the same game when the private information is public. Second, no-regret learning dynamics converge to Bayesian coarse correlated equilibrium in these incomplete information games. These results are enabled by interpretation of a Bayesian game as a stochastic game of complete information.",
    "creator" : null
  }
}