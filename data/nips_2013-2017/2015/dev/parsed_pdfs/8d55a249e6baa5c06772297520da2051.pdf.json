{
  "name" : "8d55a249e6baa5c06772297520da2051.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Learning Structured Output Representation using Deep Conditional Generative Models",
    "authors" : [ "Kihyuk Sohn", "Xinchen Yan", "Honglak Lee" ],
    "emails" : [ "ksohn@nec-labs.com,", "xcyan@umich.edu", "honglak@umich.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "In structured output prediction, it is important to learn a model that can perform probabilistic inference and make diverse predictions. This is because we are not simply modeling a many-to-one function as in classification tasks, but we may need to model a mapping from single input to many possible outputs. Recently, the convolutional neural networks (CNNs) have been greatly successful for large-scale image classification tasks [17, 30, 27] and have also demonstrated promising results for structured prediction tasks (e.g., [4, 23, 22]). However, the CNNs are not suitable in modeling a distribution with multiple modes [32].\nTo address this problem, we propose novel deep conditional generative models (CGMs) for output representation learning and structured prediction. In other words, we model the distribution of highdimensional output space as a generative model conditioned on the input observation. Building upon recent development in variational inference and learning of directed graphical models [16, 24, 15], we propose a conditional variational auto-encoder (CVAE). The CVAE is a conditional directed graphical model whose input observations modulate the prior on Gaussian latent variables that generate the outputs. It is trained to maximize the conditional log-likelihood, and we formulate the variational learning objective of the CVAE in the framework of stochastic gradient variational Bayes (SGVB) [16]. In addition, we introduce several strategies, such as input noise-injection and multi-scale prediction training methods, to build a more robust prediction model.\nIn experiments, we demonstrate the effectiveness of our proposed algorithm in comparison to the deterministic neural network counterparts in generating diverse but realistic output predictions using stochastic inference. We demonstrate the importance of stochastic neurons in modeling the structured output when the input data is partially provided. Furthermore, we show that the proposed training schemes are complimentary, leading to strong pixel-level object segmentation and labeling performance on Caltech-UCSD Birds 200 and the subset of Labeled Faces in the Wild dataset.\nIn summary, the contribution of the paper is as follows:\n• We propose CVAE and its variants that are trainable efficiently in the SGVB framework, and introduce novel strategies to enhance robustness of the models for structured prediction. • We demonstrate the effectiveness of our proposed algorithm with Gaussian stochastic neurons in modeling multi-modal distribution of structured output variables. • We achieve strong semantic object segmentation performance on CUB and LFW datasets.\nThe paper is organized as follows. We first review related work in Section 2. We provide preliminaries in Section 3 and develop our deep conditional generative model in Section 4. In Section 5, we evaluate our proposed models and report experimental results. Section 6 concludes the paper."
    }, {
      "heading" : "2 Related work",
      "text" : "Since the recent success of supervised deep learning on large-scale visual recognition [17, 30, 27], there have been many approaches to tackle mid-level computer vision tasks, such as object detection [6, 26, 31, 9] and semantic segmentation [4, 3, 23, 22], using supervised deep learning techniques. Our work falls into this category of research in developing advanced algorithms for structured output prediction, but we incorporate the stochastic neurons to model the conditional distributions of complex output representation whose distribution possibly has multiple modes. In this sense, our work shares a similar motivation to the recent work on image segmentation tasks using hybrid models of CRF and Boltzmann machine [13, 21, 37]. Compared to these, our proposed model is an end-to-end system for segmentation using convolutional architecture and achieves significantly improved performance on challenging benchmark tasks.\nAlong with the recent breakthroughs in supervised deep learning methods, there has been a progress in deep generative models, such as deep belief networks [10, 20] and deep Boltzmann machines [25]. Recently, the advances in inference and learning algorithms for various deep generative models significantly enhanced this line of research [2, 7, 8, 18]. In particular, the variational learning framework of deep directed graphical model with Gaussian latent variables (e.g., variational autoencoder [16, 15] and deep latent Gaussian models [24]) has been recently developed. Using the variational lower bound of the log-likelihood as the training objective and the reparameterization trick, these models can be easily trained via stochastic optimization. Our model builds upon this framework, but we focus on modeling the conditional distribution of output variables for structured prediction problems. Here, the main goal is not only to model the complex output representation but also to make a discriminative prediction. In addition, our model can effectively handle large-sized images by exploiting the convolutional architecture.\nThe stochastic feed-forward neural network (SFNN) [32] is a conditional directed graphical model with a combination of real-valued deterministic neurons and the binary stochastic neurons. The SFNN is trained using the Monte Carlo variant of generalized EM by drawing multiple samples from the feed-forward proposal distribution and weighing them differently with importance weights. Although our proposed Gaussian stochastic neural network (which will be described in Section 4.2) looks similar on surface, there are practical advantages in optimization of using Gaussian latent variables over the binary stochastic neurons. In addition, thanks to the recognition model used in our framework, it is sufficient to draw only a few samples during training, which is critical in training very deep convolutional networks."
    }, {
      "heading" : "3 Preliminary: Variational Auto-encoder",
      "text" : "The variational auto-encoder (VAE) [16, 24] is a directed graphical model with certain types of latent variables, such as Gaussian latent variables. A generative process of the VAE is as follows: a set of latent variable z is generated from the prior distribution pθ(z) and the data x is generated by the generative distribution pθ(x|z) conditioned on z: z ∼ pθ(z),x ∼ pθ(x|z). In general, parameter estimation of directed graphical models is often challenging due to intractable posterior inference. However, the parameters of the VAE can be estimated efficiently in the stochastic gradient variational Bayes (SGVB) [16] framework, where the variational lower bound of the log-likelihood is used as a surrogate objective function. The variational lower bound is written as:\nlog pθ(x) = KL (qφ(z|x)‖pθ(z|x)) + Eqφ(z|x) [ − log qφ(z|x) + log pθ(x, z) ] (1)\n≥ −KL (qφ(z|x)‖pθ(z)) + Eqφ(z|x) [ log pθ(x|z) ] (2)\nIn this framework, a proposal distribution qφ(z|x), which is also known as a “recognition” model, is introduced to approximate the true posterior pθ(z|x). The multilayer perceptrons (MLPs) are used to model the recognition and the generation models. Assuming Gaussian latent variables, the first term of Equation (2) can be marginalized, while the second term is not. Instead, the second term can be approximated by drawing samples z(l) (l = 1, ..., L) by the recognition distribution qφ(z|x), and the empirical objective of the VAE with Gaussian latent variables is written as follows:\nL̃VAE(x; θ, φ) = −KL (qφ(z|x)‖pθ(z)) + 1\nL L∑ l=1 log pθ(x|z(l)), (3)\nwhere z(l) = gφ(x, (l)), (l) ∼ N (0, I). Note that the recognition distribution qφ(z|x) is reparameterized with a deterministic, differentiable function gφ(·, ·), whose arguments are data x and the noise variable . This trick allows error backpropagation through the Gaussian latent variables, which is essential in VAE training as it is composed of multiple MLPs for recognition and generation models. As a result, the VAE can be trained efficiently using stochastic gradient descent (SGD)."
    }, {
      "heading" : "4 Deep Conditional Generative Models for Structured Output Prediction",
      "text" : "As illustrated in Figure 1, there are three types of variables in a deep conditional generative model (CGM): input variables x, output variables y, and latent variables z. The conditional generative process of the model is given in Figure 1(b) as follows: for given observation x, z is drawn from the prior distribution pθ(z|x), and the output y is generated from the distribution pθ(y|x, z). Compared to the baseline CNN (Figure 1(a)), the latent variables z allow for modeling multiple modes in conditional distribution of output variables y given input x, making the proposed CGM suitable for modeling one-to-many mapping. The prior of the latent variables z is modulated by the input x in our formulation; however, the constraint can be easily relaxed to make the latent variables statistically independent of input variables, i.e., pθ(z|x) = pθ(z) [15]. Deep CGMs are trained to maximize the conditional log-likelihood. Often the objective function is intractable, and we apply the SGVB framework to train the model. The variational lower bound of the model is written as follows (complete derivation can be found in the supplementary material):\nlog pθ(y|x) ≥ −KL (qφ(z|x,y)‖pθ(z|x)) + Eqφ(z|x,y) [ log pθ(y|x, z) ] (4)\nand the empirical lower bound is written as:\nL̃CVAE(x,y; θ, φ) = −KL (qφ(z|x,y)‖pθ(z|x)) + 1\nL L∑ l=1 log pθ(y|x, z(l)), (5)\nwhere z(l) = gφ(x,y, (l)), (l) ∼ N (0, I) and L is the number of samples. We call this model conditional variational auto-encoder1 (CVAE). The CVAE is composed of multiple MLPs, such as recognition network qφ(z|x,y), (conditional) prior network pθ(z|x), and generation network pθ(y|x, z). In designing the network architecture, we build the network components of the CVAE on top of the baseline CNN. Specifically, as shown in Figure 1(d), not only the direct input x, but also the initial guess ŷ made by the CNN are fed into the prior network. Such a recurrent connection has been applied for structured output prediction problems [23, 13, 28] to sequentially update the prediction by revising the previous guess while effectively deepening the convolutional network. We also found that a recurrent connection, even one iteration, showed significant performance improvement. Details about network architectures can be found in the supplementary material."
    }, {
      "heading" : "4.1 Output inference and estimation of the conditional likelihood",
      "text" : "Once the model parameters are learned, we can make a prediction of an output y from an input x by following the generative process of the CGM. To evaluate the model on structured output prediction tasks (i.e., in testing time), we can measure a prediction accuracy by performing a deterministic inference without sampling z, i.e., y∗ = argmaxy pθ(y|x, z∗), z∗ = E [ z|x ] .2\n1Although the model is not trained to reconstruct the input x, our model can be viewed as a type of VAE that performs auto-encoding of the output variables y conditioned on the input x at training time.\n2Alternatively, we can draw multiple z’s from the prior distribution and use the average of the posteriors to make a prediction, i.e., y∗ = argmaxy 1 L ∑L l=1 pθ(y|x, z (l)), z(l) ∼ pθ(z|x).\nAnother way to evaluate the CGMs is to compare the conditional likelihoods of the test data. A straightforward approach is to draw samples z’s using the prior network and take the average of the likelihoods. We call this method the Monte Carlo (MC) sampling:\npθ(y|x) ≈ 1\nS S∑ s=1 pθ(y|x, z(s)), z(s) ∼ pθ(z|x) (6)\nIt usually requires a large number of samples for the Monte Carlo log-likelihood estimation to be accurate. Alternatively, we use the importance sampling to estimate the conditional likelihoods [24]:\npθ(y|x) ≈ 1\nS S∑ s=1 pθ(y|x, z(s))pθ(z(s)|x) qφ(z(s)|x,y) , z(s) ∼ qφ(z|x,y) (7)"
    }, {
      "heading" : "4.2 Learning to predict structured output",
      "text" : "Although the SGVB learning framework has shown to be effective in training deep generative models [16, 24], the conditional auto-encoding of output variables at training may not be optimal to make a prediction at testing in deep CGMs. In other words, the CVAE uses the recognition network qφ(z|x,y) at training, but it uses the prior network pθ(z|x) at testing to draw samples z’s and make an output prediction. Since y is given as an input for the recognition network, the objective at training can be viewed as a reconstruction of y, which is an easier task than prediction. The negative KL divergence term in Equation (5) tries to close the gap between two pipelines, and one could consider allocating more weights on the negative KL term of an objective function to mitigate the discrepancy in encoding of latent variables at training and testing, i.e., −(1 + β)KL (qφ(z|x,y)‖pθ(z|x)) with β ≥ 0. However, we found this approach ineffective in our experiments. Instead, we propose to train the networks in a way that the prediction pipelines at training and testing are consistent. This can be done by setting the recognition network the same as the prior network, i.e., qφ(z|x,y) = pθ(z|x), and we get the following objective function:\nL̃GSNN(x,y; θ, φ) = 1\nL L∑ l=1 log pθ(y|x, z(l)) , where z(l) = gθ(x, (l)), (l) ∼ N (0, I) (8)\nWe call this model Gaussian stochastic neural network (GSNN).3 Note that the GSNN can be derived from the CVAE by setting the recognition network and the prior network equal. Therefore, the learning tricks, such as reparameterization trick, of the CVAE can be used to train the GSNN. Similarly, the inference (at testing) and the conditional likelihood estimation are the same as those of CVAE. Finally, we combine the objective functions of two models to obtain a hybrid objective:\nL̃hybrid = αL̃CVAE + (1− α)L̃GSNN, (9) where α balances the two objectives. Note that when α = 1, we recover the CVAE objective; when α = 0, the trained model will be simply a GSNN without the recognition network."
    }, {
      "heading" : "4.3 CVAE for image segmentation and labeling",
      "text" : "Semantic segmentation [5, 23, 6] is an important structured output prediction task. In this section, we provide strategies to train a robust prediction model for semantic segmentation problems. Specifically, to learn a high-capacity neural network that can be generalized well to unseen data, we propose to train the network with 1) multi-scale prediction objective and 2) structured input noise.\n3If we assume a covariance matrix of auxiliary Gaussian latent variables to 0, we have a deterministic counterpart of GSNN, which we call a Gaussian deterministic neural network (GDNN)."
    }, {
      "heading" : "4.3.1 Training with multi-scale prediction objective",
      "text" : "Y1/2Y1/4\nX 1/4 1\nloss loss\n1/2\nloss+ +\nY\n...\nthe multi-scale prediction at 3 different scales (1/4, 1/2, and original) for the training."
    }, {
      "heading" : "4.3.2 Training with input omission noise",
      "text" : "Adding noise to neurons is a widely used technique to regularize deep neural networks during the training [17, 29]. Similarly, we propose a simple regularization technique for semantic segmentation: corrupt the input data x into x̃ according to noise process and optimize the network with the following objective: L̃(x̃,y). The noise process could be arbitrary, but for semantic image segmentation, we consider random block omission noise. Specifically, we randomly generate a squared mask of width and height less than 40% of the image width and height, respectively, at random position and set pixel values of the input image inside the mask to 0. This can be viewed as providing more challenging output prediction task during training that simulates block occlusion or missing input. The proposed training strategy also is related to the denoising training methods [34], but in our case, we inject noise to the input data only and do not reconstruct the missing input."
    }, {
      "heading" : "5 Experiments",
      "text" : "We demonstrate the effectiveness of our approach in modeling the distribution of the structured output variables. For the proof of concept, we create an artificial experimental setting for structured output prediction using MNIST database [19]. Then, we evaluate the proposed CVAE models on several benchmark datasets for visual object segmentation and labeling, such as Caltech-UCSD Birds (CUB) [36] and Labeled Faces in the Wild (LFW) [12]. Our implementation is based on MatConvNet [33], a MATLAB toolbox for convolutional neural networks, and Adam [14] for adaptive learning rate scheduling algorithm of SGD optimization."
    }, {
      "heading" : "5.1 Toy example: MNIST",
      "text" : "To highlight the importance of probabilistic inference through stochastic neurons for structured output variables, we perform an experiment using MNIST database. Specifically, we divide each digit image into four quadrants, and take one, two, or three quadrant(s) as an input and the remaining quadrants as an output.4 As we increase the number of quadrants for an output, the input to output mapping becomes more diverse (in terms of one-to-many mapping).\nWe trained the proposed models (CVAE, GSNN) and the baseline deep neural network and compare their performance. The same network architecture, the MLP with two-layers of 1, 000 ReLUs for recognition, conditional prior, or generation networks, followed by 200 Gaussian latent variables, was used for all the models in various experimental settings. The early stopping is used during the training based on the estimation of the conditional likelihoods on the validation set.\n4Similar experimental setting has been used in the multimodal learning framework, where the left- and right halves of the digit images are used as two data modalities [1, 28].\nFor qualitative analysis, we visualize the generated output samples in Figure 3. As we can see, the baseline NNs can only make a single deterministic prediction, and as a result the output looks blurry and doesn’t look realistic in many cases. In contrast, the samples generated by the CVAE models are more realistic and diverse in shape; sometimes they can even change their identity (digit labels), such as from 3 to 5 or from 4 to 9, and vice versa.\nWe also provide a quantitative evidence by estimating the conditional log-likelihoods (CLLs) in Table 1. The CLLs of the proposed models are estimated in two ways as described in Section 4.1. For the MC estimation, we draw 10, 000 samples per example to get an accurate estimate. For the importance sampling, however, 100 samples per example were enough to obtain an accurate estimation of the CLL. We observed that the estimated CLLs of the CVAE significantly outperforms the baseline NN. Moreover, as measured by the per pixel performance gap, the performance improvement becomes more significant as we use smaller number of quadrants for an input, which is expected as the input-output mapping becomes more diverse."
    }, {
      "heading" : "5.2 Visual Object Segmentation and Labeling",
      "text" : "Caltech-UCSD Birds (CUB) database [36] includes 6, 033 images of birds from 200 species with annotations such as a bounding box of birds and a segmentation mask. Later, Yang et al. [37] annotated these images with more fine-grained segmentation masks by cropping the bird patches using the bounding boxes and resized them into 128 × 128 pixels. The training/test split proposed in [36] was used in our experiment, and for validation purpose, we partition the training set into 10 folds and cross-validated with the mean intersection over union (IoU) score over the folds. The final prediction on the test set was made by averaging the posterior from ensemble of 10 networks that are trained on each of the 10 folds separately. We increase the number of training examples via “data augmentation” by horizontally flipping the input and output images.\nWe extensively evaluate the variations of our proposed methods, such as CVAE, GSNN, and the hybrid model, and provide a summary results on segmentation mask prediction task in Table 2. Specifically, we report the performance of the models with different network architectures and training methods (e.g., multi-scale prediction or noise-injection training).\nFirst, we note that the baseline CNN already beat the previous state-of-the-art that is obtained by the max-margin Boltzmann machine (MMBM; pixel accuracy: 90.42, IoU: 75.92 with GraphCut for post-processing) [37] even without post-processing. On top of that, we observed significant performance improvement with our proposed deep CGMs.5 In terms of prediction accuracy, the GSNN performed the best among our proposed models, and performed even better when it is trained with hybrid objective function. In addition, the noise-injection training (Section 4.3) further improves the performance. Compared to the baseline CNN, the proposed deep CGMs significantly reduce the prediction error, e.g., 21% reduction in test pixel-level accuracy at the expense of 60% more time for inference.6 Finally, the performance of our two winning entries (GSNN and hybrid) on the validation sets are both significantly better than their deterministic counterparts (GDNN) with p-values less than 0.05, which suggests the benefit of stochastic latent variables.\n5As in the case of baseline CNNs, we found that using the multi-scale prediction was consistently better than the single-scale counterpart for all our models. So, we used the multi-scale prediction by default.\n6Mean inference time per image: 2.32 (ms) for CNN and 3.69 (ms) for deep CGMs, measured using GeForce GTX TITAN X card with MatConvNet; we provide more information in the supplementary material.\nWe also evaluate the negative CLL and summarize the results in Table 3. As expected, the proposed CGMs significantly outperform the baseline CNN while the CVAE showed the highest CLL.\nLabeled Faces in the Wild (LFW) database [12] has been widely used for face recognition and verification benchmark. As mentioned in [11], the face images that are segmented and labeled into semantically meaningful region labels (e.g., hair, skin, clothes) can greatly help understanding of the image through the visual attributes, which can be easily obtained from the face shape.\nFollowing region labeling protocols [35, 13], we evaluate the performance of face parts labeling on the subset of LFW database [35], which contains 1, 046 images that are labeled into 4 semantic categories, such as hair, skin, clothes, and background. We resized images into 128× 128 and used the same network architecture to the one used in the CUB experiment.\nWe provide summary results of pixel-level segmentation accuracy in Table 2 and the negative CLL in Table 3. We observe a similar trend as previously shown for the CUB database; the proposed deep CGMs outperform the baseline CNN in terms of segmentation accuracy as well as CLL. However, although the accuracies of the CGM variants are higher, the performance of GDNN was not significantly behind than those of GSNN and hybrid models. This may be because the level of variations in the output space of LFW database is less than that of CUB database as the face shapes are more similar and better aligned across examples. Finally, our methods significantly outperform other existing methods, which report 90.0% in [35] or 90.7% in [13], setting the state-of-the-art performance on the LFW segmentation benchmark."
    }, {
      "heading" : "5.3 Object Segmentation with Partial Observations",
      "text" : "We experimented on object segmentation under uncertainties (e.g., partial input and output observations) to highlight the importance of recognition network in CVAE and the stochastic neurons for missing value imputation. We randomly omit the input pixels at different levels of omission noise (25%, 50%, 70%) and different block sizes (1, 4, 8), and the task is to predict the output segmentation labels for the omitted pixel locations while given the partial labels for the observed input pixels. This can also be viewed as a segmentation task with noisy or partial observations (e.g., occlusions).\nTo make a prediction for CVAE with partial output observation (yo), we perform iterative inference of unobserved output (yu) and the latent variables (z) (in a similar fashion to [24]), i.e.,\nyu ∼ pθ(yu|x, z)↔ z ∼ qφ(z|x,yo,yu). (10)\nWe report the summary results in Table 4. The CVAE performs well even when the noise level is high (e.g., 50%), where the GDNN significantly fails. This is because the CVAE utilizes the partial segmentation information to iteratively refine the prediction of the rest. We visualize the generated samples at noise level of 50% in Figure 4. The prediction made by the GDNN is blurry, but the samples generated by the CVAE are sharper while maintaining reasonable shapes. This suggests that the CVAE can also be potentially useful for interactive segmentation (i.e., by iteratively incorporating partial output labels)."
    }, {
      "heading" : "6 Conclusion",
      "text" : "Modeling multi-modal distribution of the structured output variables is an important research question to achieve good performance on structured output prediction problems. In this work, we proposed stochastic neural networks for structured output prediction based on the conditional deep generative model with Gaussian latent variables. The proposed model is scalable and efficient in inference and learning. We demonstrated the importance of probabilistic inference when the distribution of output space has multiple modes, and showed strong performance in terms of segmentation accuracy, estimation of conditional log-likelihood, and visualization of generated samples.\nAcknowledgments This work was supported in part by ONR grant N00014-13-1-0762 and NSF CAREER grant IIS-1453651. We thank NVIDIA for donating a Tesla K40 GPU."
    } ],
    "references" : [ {
      "title" : "Deep canonical correlation analysis",
      "author" : [ "G. Andrew", "R. Arora", "J. Bilmes", "K. Livescu" ],
      "venue" : "In ICML,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2013
    }, {
      "title" : "Deep generative stochastic networks trainable by backprop",
      "author" : [ "Y. Bengio", "E. Thibodeau-Laufer", "G. Alain", "J. Yosinski" ],
      "venue" : "In ICML,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2014
    }, {
      "title" : "Deep neural networks segment neuronal membranes in electron microscopy",
      "author" : [ "D. Ciresan", "A. Giusti", "L.M. Gambardella", "J. Schmidhuber" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2012
    }, {
      "title" : "Scene parsing with multiscale feature learning, purity trees, and optimal covers",
      "author" : [ "C. Farabet", "C. Couprie", "L. Najman", "Y. LeCun" ],
      "venue" : "In ICML,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2012
    }, {
      "title" : "Learning hierarchical features for scene labeling",
      "author" : [ "C. Farabet", "C. Couprie", "L. Najman", "Y. LeCun" ],
      "venue" : "T. PAMI,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2013
    }, {
      "title" : "Region-based convolutional networks for accurate object detection and segmentation",
      "author" : [ "R. Girshick", "J. Donahue", "T. Darrell", "J. Malik" ],
      "venue" : "T. PAMI,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2015
    }, {
      "title" : "Multi-prediction deep Boltzmann machines",
      "author" : [ "I. Goodfellow", "M. Mirza", "A. Courville", "Y. Bengio" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2013
    }, {
      "title" : "Generative adversarial nets",
      "author" : [ "I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2014
    }, {
      "title" : "Spatial pyramid pooling in deep convolutional networks for visual recognition",
      "author" : [ "K. He", "X. Zhang", "S. Ren", "J. Sun" ],
      "venue" : "In ECCV,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2014
    }, {
      "title" : "A fast learning algorithm for deep belief nets",
      "author" : [ "G.E. Hinton", "S. Osindero", "Y. Teh" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2006
    }, {
      "title" : "Towards unconstrained face recognition",
      "author" : [ "G.B. Huang", "M. Narayana", "E. Learned-Miller" ],
      "venue" : "In CVPR Workshop on Perceptual Organization in Computer Vision,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2008
    }, {
      "title" : "Labeled faces in the wild: A database for studying face recognition in unconstrained environments",
      "author" : [ "G.B. Huang", "M. Ramesh", "T. Berg", "E. Learned-Miller" ],
      "venue" : "Technical Report 07-49,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2007
    }, {
      "title" : "Augmenting CRFs with Boltzmann machine shape priors for image labeling",
      "author" : [ "A. Kae", "K. Sohn", "H. Lee", "E. Learned-Miller" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2013
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "D.P. Kingma", "J. Ba" ],
      "venue" : "In ICLR,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2015
    }, {
      "title" : "Semi-supervised learning with deep generative models",
      "author" : [ "D.P. Kingma", "S. Mohamed", "D.J. Rezende", "M. Welling" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2014
    }, {
      "title" : "Auto-encoding variational Bayes",
      "author" : [ "D.P. Kingma", "M. Welling" ],
      "venue" : "In ICLR,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2013
    }, {
      "title" : "ImageNet classification with deep convolutional neural networks",
      "author" : [ "A. Krizhevsky", "I. Sutskever", "G.E. Hinton" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2012
    }, {
      "title" : "The neural autoregressive distribution estimator",
      "author" : [ "H. Larochelle", "I. Murray" ],
      "venue" : "JMLR, 15:29–37,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2011
    }, {
      "title" : "Gradient-based learning applied to document recognition",
      "author" : [ "Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner" ],
      "venue" : "Proceedings of the IEEE,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1998
    }, {
      "title" : "Unsupervised learning of hierarchical representations with convolutional deep belief networks",
      "author" : [ "H. Lee", "R. Grosse", "R. Ranganath", "A.Y. Ng" ],
      "venue" : "Communications of the ACM,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2011
    }, {
      "title" : "Exploring compositional high order pattern potentials for structured output learning",
      "author" : [ "Y. Li", "D. Tarlow", "R. Zemel" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2013
    }, {
      "title" : "Fully convolutional networks for semantic segmentation",
      "author" : [ "J. Long", "E. Shelhamer", "T. Darrell" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2015
    }, {
      "title" : "Recurrent convolutional neural networks for scene parsing",
      "author" : [ "P. Pinheiro", "R. Collobert" ],
      "venue" : "In ICML,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2013
    }, {
      "title" : "Stochastic backpropagation and approximate inference in deep generative models",
      "author" : [ "D.J. Rezende", "S. Mohamed", "D. Wierstra" ],
      "venue" : "In ICML,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2014
    }, {
      "title" : "Deep Boltzmann machines",
      "author" : [ "R. Salakhutdinov", "G.E. Hinton" ],
      "venue" : "In AISTATS,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2009
    }, {
      "title" : "OverFeat: Integrated recognition, localization and detection using convolutional networks",
      "author" : [ "P. Sermanet", "D. Eigen", "X. Zhang", "M. Mathieu", "R. Fergus", "Y. LeCun" ],
      "venue" : "In ICLR,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2013
    }, {
      "title" : "Very deep convolutional networks for large-scale image recognition",
      "author" : [ "K. Simonyan", "A. Zisserman" ],
      "venue" : "In ICLR,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2014
    }, {
      "title" : "Improved multimodal deep learning with variation of information",
      "author" : [ "K. Sohn", "W. Shang", "H. Lee" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2014
    }, {
      "title" : "Dropout: A simple way to prevent neural networks from overfitting",
      "author" : [ "N. Srivastava", "G. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov" ],
      "venue" : null,
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 1929
    }, {
      "title" : "Going deeper with convolutions",
      "author" : [ "C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2015
    }, {
      "title" : "Deep neural networks for object detection",
      "author" : [ "C. Szegedy", "A. Toshev", "D. Erhan" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2013
    }, {
      "title" : "Learning stochastic feedforward neural networks",
      "author" : [ "Y. Tang", "R. Salakhutdinov" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2013
    }, {
      "title" : "MatConvNet – convolutional neural networks for MATLAB",
      "author" : [ "A. Vedaldi", "K. Lenc" ],
      "venue" : "In ACMMM,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2015
    }, {
      "title" : "Extracting and composing robust features with denoising autoencoders",
      "author" : [ "P. Vincent", "H. Larochelle", "Y. Bengio", "P.-A. Manzagol" ],
      "venue" : "In ICML,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2008
    }, {
      "title" : "What are good parts for hair shape modeling",
      "author" : [ "N. Wang", "H. Ai", "F. Tang" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2012
    }, {
      "title" : "Caltech-UCSD Birds 200",
      "author" : [ "P. Welinder", "S. Branson", "T. Mita", "C. Wah", "F. Schroff", "S. Belongie", "P. Perona" ],
      "venue" : "Technical Report CNS-TR-2010-001, California Institute of Technology,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2010
    }, {
      "title" : "Max-margin Boltzmann machines for object segmentation",
      "author" : [ "J. Yang", "S. Sáfár", "M.-H. Yang" ],
      "venue" : "In CVPR,",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 16,
      "context" : "Recently, the convolutional neural networks (CNNs) have been greatly successful for large-scale image classification tasks [17, 30, 27] and have also demonstrated promising results for structured prediction tasks (e.",
      "startOffset" : 123,
      "endOffset" : 135
    }, {
      "referenceID" : 29,
      "context" : "Recently, the convolutional neural networks (CNNs) have been greatly successful for large-scale image classification tasks [17, 30, 27] and have also demonstrated promising results for structured prediction tasks (e.",
      "startOffset" : 123,
      "endOffset" : 135
    }, {
      "referenceID" : 26,
      "context" : "Recently, the convolutional neural networks (CNNs) have been greatly successful for large-scale image classification tasks [17, 30, 27] and have also demonstrated promising results for structured prediction tasks (e.",
      "startOffset" : 123,
      "endOffset" : 135
    }, {
      "referenceID" : 31,
      "context" : "However, the CNNs are not suitable in modeling a distribution with multiple modes [32].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 15,
      "context" : "Building upon recent development in variational inference and learning of directed graphical models [16, 24, 15], we propose a conditional variational auto-encoder (CVAE).",
      "startOffset" : 100,
      "endOffset" : 112
    }, {
      "referenceID" : 23,
      "context" : "Building upon recent development in variational inference and learning of directed graphical models [16, 24, 15], we propose a conditional variational auto-encoder (CVAE).",
      "startOffset" : 100,
      "endOffset" : 112
    }, {
      "referenceID" : 14,
      "context" : "Building upon recent development in variational inference and learning of directed graphical models [16, 24, 15], we propose a conditional variational auto-encoder (CVAE).",
      "startOffset" : 100,
      "endOffset" : 112
    }, {
      "referenceID" : 15,
      "context" : "It is trained to maximize the conditional log-likelihood, and we formulate the variational learning objective of the CVAE in the framework of stochastic gradient variational Bayes (SGVB) [16].",
      "startOffset" : 187,
      "endOffset" : 191
    }, {
      "referenceID" : 16,
      "context" : "2 Related work Since the recent success of supervised deep learning on large-scale visual recognition [17, 30, 27], there have been many approaches to tackle mid-level computer vision tasks, such as object detection [6, 26, 31, 9] and semantic segmentation [4, 3, 23, 22], using supervised deep learning techniques.",
      "startOffset" : 102,
      "endOffset" : 114
    }, {
      "referenceID" : 29,
      "context" : "2 Related work Since the recent success of supervised deep learning on large-scale visual recognition [17, 30, 27], there have been many approaches to tackle mid-level computer vision tasks, such as object detection [6, 26, 31, 9] and semantic segmentation [4, 3, 23, 22], using supervised deep learning techniques.",
      "startOffset" : 102,
      "endOffset" : 114
    }, {
      "referenceID" : 26,
      "context" : "2 Related work Since the recent success of supervised deep learning on large-scale visual recognition [17, 30, 27], there have been many approaches to tackle mid-level computer vision tasks, such as object detection [6, 26, 31, 9] and semantic segmentation [4, 3, 23, 22], using supervised deep learning techniques.",
      "startOffset" : 102,
      "endOffset" : 114
    }, {
      "referenceID" : 5,
      "context" : "2 Related work Since the recent success of supervised deep learning on large-scale visual recognition [17, 30, 27], there have been many approaches to tackle mid-level computer vision tasks, such as object detection [6, 26, 31, 9] and semantic segmentation [4, 3, 23, 22], using supervised deep learning techniques.",
      "startOffset" : 216,
      "endOffset" : 230
    }, {
      "referenceID" : 25,
      "context" : "2 Related work Since the recent success of supervised deep learning on large-scale visual recognition [17, 30, 27], there have been many approaches to tackle mid-level computer vision tasks, such as object detection [6, 26, 31, 9] and semantic segmentation [4, 3, 23, 22], using supervised deep learning techniques.",
      "startOffset" : 216,
      "endOffset" : 230
    }, {
      "referenceID" : 30,
      "context" : "2 Related work Since the recent success of supervised deep learning on large-scale visual recognition [17, 30, 27], there have been many approaches to tackle mid-level computer vision tasks, such as object detection [6, 26, 31, 9] and semantic segmentation [4, 3, 23, 22], using supervised deep learning techniques.",
      "startOffset" : 216,
      "endOffset" : 230
    }, {
      "referenceID" : 8,
      "context" : "2 Related work Since the recent success of supervised deep learning on large-scale visual recognition [17, 30, 27], there have been many approaches to tackle mid-level computer vision tasks, such as object detection [6, 26, 31, 9] and semantic segmentation [4, 3, 23, 22], using supervised deep learning techniques.",
      "startOffset" : 216,
      "endOffset" : 230
    }, {
      "referenceID" : 3,
      "context" : "2 Related work Since the recent success of supervised deep learning on large-scale visual recognition [17, 30, 27], there have been many approaches to tackle mid-level computer vision tasks, such as object detection [6, 26, 31, 9] and semantic segmentation [4, 3, 23, 22], using supervised deep learning techniques.",
      "startOffset" : 257,
      "endOffset" : 271
    }, {
      "referenceID" : 2,
      "context" : "2 Related work Since the recent success of supervised deep learning on large-scale visual recognition [17, 30, 27], there have been many approaches to tackle mid-level computer vision tasks, such as object detection [6, 26, 31, 9] and semantic segmentation [4, 3, 23, 22], using supervised deep learning techniques.",
      "startOffset" : 257,
      "endOffset" : 271
    }, {
      "referenceID" : 22,
      "context" : "2 Related work Since the recent success of supervised deep learning on large-scale visual recognition [17, 30, 27], there have been many approaches to tackle mid-level computer vision tasks, such as object detection [6, 26, 31, 9] and semantic segmentation [4, 3, 23, 22], using supervised deep learning techniques.",
      "startOffset" : 257,
      "endOffset" : 271
    }, {
      "referenceID" : 21,
      "context" : "2 Related work Since the recent success of supervised deep learning on large-scale visual recognition [17, 30, 27], there have been many approaches to tackle mid-level computer vision tasks, such as object detection [6, 26, 31, 9] and semantic segmentation [4, 3, 23, 22], using supervised deep learning techniques.",
      "startOffset" : 257,
      "endOffset" : 271
    }, {
      "referenceID" : 12,
      "context" : "In this sense, our work shares a similar motivation to the recent work on image segmentation tasks using hybrid models of CRF and Boltzmann machine [13, 21, 37].",
      "startOffset" : 148,
      "endOffset" : 160
    }, {
      "referenceID" : 20,
      "context" : "In this sense, our work shares a similar motivation to the recent work on image segmentation tasks using hybrid models of CRF and Boltzmann machine [13, 21, 37].",
      "startOffset" : 148,
      "endOffset" : 160
    }, {
      "referenceID" : 36,
      "context" : "In this sense, our work shares a similar motivation to the recent work on image segmentation tasks using hybrid models of CRF and Boltzmann machine [13, 21, 37].",
      "startOffset" : 148,
      "endOffset" : 160
    }, {
      "referenceID" : 9,
      "context" : "Along with the recent breakthroughs in supervised deep learning methods, there has been a progress in deep generative models, such as deep belief networks [10, 20] and deep Boltzmann machines [25].",
      "startOffset" : 155,
      "endOffset" : 163
    }, {
      "referenceID" : 19,
      "context" : "Along with the recent breakthroughs in supervised deep learning methods, there has been a progress in deep generative models, such as deep belief networks [10, 20] and deep Boltzmann machines [25].",
      "startOffset" : 155,
      "endOffset" : 163
    }, {
      "referenceID" : 24,
      "context" : "Along with the recent breakthroughs in supervised deep learning methods, there has been a progress in deep generative models, such as deep belief networks [10, 20] and deep Boltzmann machines [25].",
      "startOffset" : 192,
      "endOffset" : 196
    }, {
      "referenceID" : 1,
      "context" : "Recently, the advances in inference and learning algorithms for various deep generative models significantly enhanced this line of research [2, 7, 8, 18].",
      "startOffset" : 140,
      "endOffset" : 153
    }, {
      "referenceID" : 6,
      "context" : "Recently, the advances in inference and learning algorithms for various deep generative models significantly enhanced this line of research [2, 7, 8, 18].",
      "startOffset" : 140,
      "endOffset" : 153
    }, {
      "referenceID" : 7,
      "context" : "Recently, the advances in inference and learning algorithms for various deep generative models significantly enhanced this line of research [2, 7, 8, 18].",
      "startOffset" : 140,
      "endOffset" : 153
    }, {
      "referenceID" : 17,
      "context" : "Recently, the advances in inference and learning algorithms for various deep generative models significantly enhanced this line of research [2, 7, 8, 18].",
      "startOffset" : 140,
      "endOffset" : 153
    }, {
      "referenceID" : 15,
      "context" : ", variational autoencoder [16, 15] and deep latent Gaussian models [24]) has been recently developed.",
      "startOffset" : 26,
      "endOffset" : 34
    }, {
      "referenceID" : 14,
      "context" : ", variational autoencoder [16, 15] and deep latent Gaussian models [24]) has been recently developed.",
      "startOffset" : 26,
      "endOffset" : 34
    }, {
      "referenceID" : 23,
      "context" : ", variational autoencoder [16, 15] and deep latent Gaussian models [24]) has been recently developed.",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 31,
      "context" : "The stochastic feed-forward neural network (SFNN) [32] is a conditional directed graphical model with a combination of real-valued deterministic neurons and the binary stochastic neurons.",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 15,
      "context" : "3 Preliminary: Variational Auto-encoder The variational auto-encoder (VAE) [16, 24] is a directed graphical model with certain types of latent variables, such as Gaussian latent variables.",
      "startOffset" : 75,
      "endOffset" : 83
    }, {
      "referenceID" : 23,
      "context" : "3 Preliminary: Variational Auto-encoder The variational auto-encoder (VAE) [16, 24] is a directed graphical model with certain types of latent variables, such as Gaussian latent variables.",
      "startOffset" : 75,
      "endOffset" : 83
    }, {
      "referenceID" : 15,
      "context" : "However, the parameters of the VAE can be estimated efficiently in the stochastic gradient variational Bayes (SGVB) [16] framework, where the variational lower bound of the log-likelihood is used as a surrogate objective function.",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 22,
      "context" : "Such a recurrent connection has been applied for structured output prediction problems [23, 13, 28] to sequentially update the prediction by revising the previous guess while effectively deepening the convolutional network.",
      "startOffset" : 87,
      "endOffset" : 99
    }, {
      "referenceID" : 12,
      "context" : "Such a recurrent connection has been applied for structured output prediction problems [23, 13, 28] to sequentially update the prediction by revising the previous guess while effectively deepening the convolutional network.",
      "startOffset" : 87,
      "endOffset" : 99
    }, {
      "referenceID" : 27,
      "context" : "Such a recurrent connection has been applied for structured output prediction problems [23, 13, 28] to sequentially update the prediction by revising the previous guess while effectively deepening the convolutional network.",
      "startOffset" : 87,
      "endOffset" : 99
    }, {
      "referenceID" : 15,
      "context" : "(a) the predictive process of output Y for the baseline CNN; (b) the generative process of CGMs; (c) an approximate inference of Z (also known as recognition process [16]); (d) the generative process with recurrent connection.",
      "startOffset" : 166,
      "endOffset" : 170
    }, {
      "referenceID" : 23,
      "context" : "Alternatively, we use the importance sampling to estimate the conditional likelihoods [24]:",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 15,
      "context" : "2 Learning to predict structured output Although the SGVB learning framework has shown to be effective in training deep generative models [16, 24], the conditional auto-encoding of output variables at training may not be optimal to make a prediction at testing in deep CGMs.",
      "startOffset" : 138,
      "endOffset" : 146
    }, {
      "referenceID" : 23,
      "context" : "2 Learning to predict structured output Although the SGVB learning framework has shown to be effective in training deep generative models [16, 24], the conditional auto-encoding of output variables at training may not be optimal to make a prediction at testing in deep CGMs.",
      "startOffset" : 138,
      "endOffset" : 146
    }, {
      "referenceID" : 4,
      "context" : "3 CVAE for image segmentation and labeling Semantic segmentation [5, 23, 6] is an important structured output prediction task.",
      "startOffset" : 65,
      "endOffset" : 75
    }, {
      "referenceID" : 22,
      "context" : "3 CVAE for image segmentation and labeling Semantic segmentation [5, 23, 6] is an important structured output prediction task.",
      "startOffset" : 65,
      "endOffset" : 75
    }, {
      "referenceID" : 5,
      "context" : "3 CVAE for image segmentation and labeling Semantic segmentation [5, 23, 6] is an important structured output prediction task.",
      "startOffset" : 65,
      "endOffset" : 75
    }, {
      "referenceID" : 4,
      "context" : "The multi-scale approaches have been used in the sense of forming a multi-scale image pyramid for an input [5], but not much for multi-scale output prediction.",
      "startOffset" : 107,
      "endOffset" : 110
    }, {
      "referenceID" : 16,
      "context" : "2 Training with input omission noise Adding noise to neurons is a widely used technique to regularize deep neural networks during the training [17, 29].",
      "startOffset" : 143,
      "endOffset" : 151
    }, {
      "referenceID" : 28,
      "context" : "2 Training with input omission noise Adding noise to neurons is a widely used technique to regularize deep neural networks during the training [17, 29].",
      "startOffset" : 143,
      "endOffset" : 151
    }, {
      "referenceID" : 33,
      "context" : "The proposed training strategy also is related to the denoising training methods [34], but in our case, we inject noise to the input data only and do not reconstruct the missing input.",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 18,
      "context" : "For the proof of concept, we create an artificial experimental setting for structured output prediction using MNIST database [19].",
      "startOffset" : 125,
      "endOffset" : 129
    }, {
      "referenceID" : 35,
      "context" : "Then, we evaluate the proposed CVAE models on several benchmark datasets for visual object segmentation and labeling, such as Caltech-UCSD Birds (CUB) [36] and Labeled Faces in the Wild (LFW) [12].",
      "startOffset" : 151,
      "endOffset" : 155
    }, {
      "referenceID" : 11,
      "context" : "Then, we evaluate the proposed CVAE models on several benchmark datasets for visual object segmentation and labeling, such as Caltech-UCSD Birds (CUB) [36] and Labeled Faces in the Wild (LFW) [12].",
      "startOffset" : 192,
      "endOffset" : 196
    }, {
      "referenceID" : 32,
      "context" : "Our implementation is based on MatConvNet [33], a MATLAB toolbox for convolutional neural networks, and Adam [14] for adaptive learning rate scheduling algorithm of SGD optimization.",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 13,
      "context" : "Our implementation is based on MatConvNet [33], a MATLAB toolbox for convolutional neural networks, and Adam [14] for adaptive learning rate scheduling algorithm of SGD optimization.",
      "startOffset" : 109,
      "endOffset" : 113
    }, {
      "referenceID" : 0,
      "context" : "Similar experimental setting has been used in the multimodal learning framework, where the left- and right halves of the digit images are used as two data modalities [1, 28].",
      "startOffset" : 166,
      "endOffset" : 173
    }, {
      "referenceID" : 27,
      "context" : "Similar experimental setting has been used in the multimodal learning framework, where the left- and right halves of the digit images are used as two data modalities [1, 28].",
      "startOffset" : 166,
      "endOffset" : 173
    }, {
      "referenceID" : 35,
      "context" : "2 Visual Object Segmentation and Labeling Caltech-UCSD Birds (CUB) database [36] includes 6, 033 images of birds from 200 species with annotations such as a bounding box of birds and a segmentation mask.",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 36,
      "context" : "[37] annotated these images with more fine-grained segmentation masks by cropping the bird patches using the bounding boxes and resized them into 128 × 128 pixels.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 35,
      "context" : "The training/test split proposed in [36] was used in our experiment, and for validation purpose, we partition the training set into 10 folds and cross-validated with the mean intersection over union (IoU) score over the folds.",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 36,
      "context" : "92 with GraphCut for post-processing) [37] even without post-processing.",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 36,
      "context" : "Model (training) CUB (val) CUB (test) LFW pixel IoU pixel IoU pixel (val) pixel (test) MMBM [37] – – 90.",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 11,
      "context" : "Labeled Faces in the Wild (LFW) database [12] has been widely used for face recognition and verification benchmark.",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 10,
      "context" : "As mentioned in [11], the face images that are segmented and labeled into semantically meaningful region labels (e.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 34,
      "context" : "Following region labeling protocols [35, 13], we evaluate the performance of face parts labeling on the subset of LFW database [35], which contains 1, 046 images that are labeled into 4 semantic categories, such as hair, skin, clothes, and background.",
      "startOffset" : 36,
      "endOffset" : 44
    }, {
      "referenceID" : 12,
      "context" : "Following region labeling protocols [35, 13], we evaluate the performance of face parts labeling on the subset of LFW database [35], which contains 1, 046 images that are labeled into 4 semantic categories, such as hair, skin, clothes, and background.",
      "startOffset" : 36,
      "endOffset" : 44
    }, {
      "referenceID" : 34,
      "context" : "Following region labeling protocols [35, 13], we evaluate the performance of face parts labeling on the subset of LFW database [35], which contains 1, 046 images that are labeled into 4 semantic categories, such as hair, skin, clothes, and background.",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 12,
      "context" : "7% in [13], setting the state-of-the-art performance on the LFW segmentation benchmark.",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 23,
      "context" : "To make a prediction for CVAE with partial output observation (yo), we perform iterative inference of unobserved output (yu) and the latent variables (z) (in a similar fashion to [24]), i.",
      "startOffset" : 179,
      "endOffset" : 183
    } ],
    "year" : 2015,
    "abstractText" : "Supervised deep learning has been successfully applied to many recognition problems. Although it can approximate a complex many-to-one function well when a large amount of training data is provided, it is still challenging to model complex structured output representations that effectively perform probabilistic inference and make diverse predictions. In this work, we develop a deep conditional generative model for structured output prediction using Gaussian latent variables. The model is trained efficiently in the framework of stochastic gradient variational Bayes, and allows for fast prediction using stochastic feed-forward inference. In addition, we provide novel strategies to build robust structured prediction algorithms, such as input noise-injection and multi-scale prediction objective at training. In experiments, we demonstrate the effectiveness of our proposed algorithm in comparison to the deterministic deep neural network counterparts in generating diverse but realistic structured output predictions using stochastic inference. Furthermore, the proposed training methods are complimentary, which leads to strong pixel-level object segmentation and semantic labeling performance on Caltech-UCSD Birds 200 and the subset of Labeled Faces in the Wild dataset.",
    "creator" : null
  }
}