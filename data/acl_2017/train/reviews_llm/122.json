{
    "reviews": [
        {
            "comments": "\n\nStrengths:\nThe paper presents an innovative approach to dialogue state tracking (DST) by introducing the Neural Belief Tracker (NBT) models, which integrate Spoken Language Understanding (SLU) and DST. A key strength is the use of pre-trained word vectors to handle lexical and morphological variations, thereby eliminating the need for hand-crafted semantic lexicons. The proposed models operate directly on word vector spaces, demonstrating a significant advancement in dealing with the ambiguity inherent in natural language processing. The paper provides a thorough evaluation of the models on two datasets and shows improved performance over baseline models, particularly in scenarios with richer vocabulary and longer sentences. The approach is also beneficial in noisy environments, as indicated by the performance increase when using the DSTC2 transcriptions.\n\nWeaknesses:\nWhile the NBT models perform well compared to baseline systems, the paper does not discuss the models' performance relative to human-level understanding or other state-of-the-art approaches that might not use delexicalisation. The paper focuses on English language dialogue systems, and it is unclear how the models would perform in other languages or multi-domain scenarios. Additionally, the paper does not address computational complexity or the models' scalability to larger datasets and real-world applications. It would also be beneficial to include a more detailed discussion of the limitations and potential failure cases of the proposed models.\n\nGeneral Discussion:\nThe paper makes a significant contribution to the field of task-oriented dialogue systems by proposing a novel belief tracking framework that leverages semantic information from pre-trained word vectors. The results are promising, suggesting that the NBT models can efficiently learn linguistic variations without the need for manual semantic dictionaries. The authors should consider expanding their research to include multi-domain dialogue systems and other languages to demonstrate the models' versatility and robustness. Future work could also explore the integration of the NBT models with end-to-end trainable dialogue systems and investigate the computational requirements for deploying these models in real-world applications.\n\n"
        }
    ]
}