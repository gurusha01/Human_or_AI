{
    "reviews": [
        {
            "level": 1,
            "comments": "The paper presents a thorough investigation into event factuality identification using a two-step supervised framework that leverages neural networks, specifically an attention-based CNN combined with BiLSTM. The contributions are significant, as they introduce a novel approach to identifying event factuality in raw texts, a challenging problem in natural language processing (NLP).\n\nIn terms of clarity, the paper is generally well-structured, with a logical flow from the introduction to the methodology and results. The introduction effectively sets up the importance of event factuality and highlights the need for improved identification methods. However, some sections, particularly those detailing the methodology, could benefit from clearer explanations or visual aids to enhance understanding, especially for readers less familiar with the specific neural network architectures employed.\n\nThe relevance of the research is high, as it addresses a critical area in NLP with potential applications in opinion detection, question answering, and rumor identification. This aligns well with current trends in AI and language processing, making the paper timely and valuable for both researchers and practitioners in the field.\n\nThe methodology is robust, employing deep learning techniques to extract and identify features related to event factuality. The proposed model's combination of BiLSTM and CNN is a commendable innovation, allowing it to learn effective representations from both syntactic paths and words. The experimental setup is sound, using FactBank as a dataset, and the evaluation metrics (Precision, Recall, F1-measure) are appropriate for the tasks. The paper presents results that demonstrate the superiority of the proposed model over several baselines, which adds to the credibility of the findings.\n\nOverall, the quality of the paper is high, with a solid foundation in both theory and practice. The results suggest that the proposed approach can effectively identify event factuality, particularly in distinguishing between negative and speculative values. Future work could explore additional features and further optimize the model, which the authors have already indicated as a direction for continued research. The paper makes a valuable contribution to the field and sets a precedent for future studies on event factuality identification. Thus, it is recommended for acceptance with minor revisions for clarity and presentation.",
            "GPTZero": "97;3;0"
        },
        {
            "level": 3,
            "comments": "The paper presents a novel approach to event factuality identification using a complex neural model that combines various techniques, including an attention-based bidirectional LSTM and CNN. While the contributions and methodology are ambitious, there are significant concerns regarding clarity, relevance, and overall quality.\n\n**Contributions:** The authors propose a two-step supervised framework to identify event factuality from raw texts. They introduce an attention-based CNN for detecting source introducing predicates (SIPs) and combine it with a deep neural network model that utilizes BiLSTM and CNN for factuality classification. However, the contributions are somewhat diminished by the reliance on hand-crafted features, which seems contradictory to the purported advantages of deep learning. The reported improvements over baseline methods lack convincing significance, particularly given the complexity of the model.\n\n**Clarity:** The paper is generally well-written and structured, making it relatively easy to follow. However, some terminologies and claims could benefit from clearer definitions and justifications. For example, the term \"proper combination\" of models is vague, and the rationale behind the two-output design lacks compelling evidence. Additionally, the redundancy in describing well-established techniques like LSTMs and attention mechanisms detracts from the overall clarity.\n\n**Relevance:** The topic of event factuality is relevant in the context of NLP applications, and the authors successfully contextualize their work within existing literature. However, the use of traditional classifiers alongside deep learning techniques raises questions about the novelty of the approach. The balance between traditional and modern methods could be better articulated to strengthen the relevance of the proposed framework.\n\n**Methodology:** The methodology is comprehensive, but the reliance on hand-crafted features alongside deep learning techniques is a point of contention. The lack of clarity regarding hyperparameter optimization during cross-validation raises concerns about the validity of the results. Furthermore, the modest performance improvement (2% over baselines) does not convincingly justify the complexity of the model.\n\n**Overall Quality:** While the paper presents a potentially valuable contribution to event factuality identification, it falls short in several areas, particularly in experimental validation and justifying the chosen methodologies. The combination of traditional and modern techniques, while innovative, requires clearer exposition and stronger empirical backing to elevate its standing in a top-tier conference.\n\nIn summary, while the paper has informative elements and presents a structured approach, it needs significant revisions to address methodological concerns, improve clarity, and strengthen the relevance of its contributions. As it stands, I recommend against acceptance for this conference, but with substantial revisions, it could be a worthy submission in the future.",
            "GPTZero": "88;12;0"
        },
        {
            "level": 4,
            "comments": "The paper presents a comprehensive approach to identifying event factuality using a two-step supervised framework that employs neural networks. The authors effectively combine traditional classifiers with a bidirectional attention-based LSTM and a CNN to enhance the identification of factuality in raw texts. However, there are several concerns regarding the methodology, clarity, and overall contributions that need to be addressed.\n\n**Contributions**: The proposed framework introduces a novel method for event factuality identification, emphasizing the role of source introducing predicates (SIPs) and cues. The integration of attention mechanisms with BiLSTM and CNN is a notable aspect, as it aims to enhance the extraction of meaningful features from syntactic paths and words. Despite these contributions, the overall improvement in performance (approximately 2% over existing baselines) raises questions about the effectiveness of such a complex model given the amount of preprocessing involved.\n\n**Clarity**: The paper is generally well-written and structured, making it accessible to readers. However, certain terminologies and concepts could benefit from clearer explanations. For instance, the term \"properly\" in the context of model combination lacks sufficient definition. Additionally, the justification for the two-output design is weak and requires more robust experimental support.\n\n**Relevance**: The topic of event factuality is relevant to current NLP research, particularly in applications such as opinion detection and rumor identification. However, the paper does not sufficiently demonstrate the practical implications or advantages of the proposed model in comparison to simpler models.\n\n**Methodology**: The methodology appears sound but is marred by a lack of clarity regarding hyperparameter optimization. Given the numerous hyperparameters involved, the absence of a detailed optimization strategy raises concerns about the validity of the reported results. Furthermore, the reliance on hand-crafted features contrasts with the authors' motivation for using deep learning to learn representations, creating a discrepancy in the paper's narrative.\n\n**Overall Quality**: While the paper presents a comprehensive analysis and incorporates advanced techniques, the modest performance improvements, coupled with the concerns raised, suggest that the paper may not meet the high standards expected for a top-tier conference. It is informative, but the contributions could be significantly strengthened through clearer justification of choices, better optimization strategies, and more impactful results.\n\nIn summary, the paper offers a valuable exploration of event factuality identification but requires further refinement in methodology and justification to enhance its impact and relevance in the field. It is suggested to address the feedback provided, particularly concerning model optimization and the justification of design choices, to improve the overall quality of the submission.",
            "GPTZero": "75;25;0"
        },
        {
            "level": 5,
            "comments": "The paper presents a complex neural model for detecting the factuality of event mentions in text. The authors combine several components in their model: (1) traditional classifiers for detecting event mentions, factuality sources, and source introducing predicates (SIPs); (2) a bidirectional attention-based LSTM model that learns latent representations from various dependency paths; and (3) a CNN that utilizes these representations to perform two output predictionsâ€”one to differentiate specific from underspecified cases and another to predict the actual factuality class.\n\nFrom a methodological perspective, while the combination of familiar methods (attention-based BiLSTM and CNN) is reasonable, the reliance on hand-crafted features (such as different dependency paths encompassing factuality concepts) is somewhat surprising given the complexity of the deep learning model. The evaluation of the model raises concerns, as the authors report results from a 5-fold cross-validation without detailing how they optimized the model's numerous hyperparameters. Moreover, the reported 2% macro-average gain over the rule-based baseline, along with an overall performance of 44%, seems modest, especially when considering that the micro-average performance does not surpass that of a simple MaxEnt classifier.\n\nOverall, the paper is well-written and relatively easy to understand. However, in its current form, it may not meet the standards expected for a top-tier conference. \n\n**Remarks:**\n\n1. The authors frequently refer to the \"proper\" combination of LSTM and CNN in their model. It would be beneficial to clarify what this \"properness\" entails and how it manifests in the architecture. What constitutes an improper combination in this context?\n\n2. The justification for the two-output design appears weak. The first argument, which suggests that it allows for the later addition of cues (i.e., manually-designed features), seems to contradict the advantage of learning representations inherent to deep models. The second argument regarding this design addressing imbalance in the training set lacks experimental support.\n\n3. There is a discrepancy between the motivation for using a complex deep learning architecture to learn latent representations and the subsequent definition of manually designed features (i.e., various dependency paths and lexical features) as inputs for the model.\n\n4. Given that bidirectional LSTMs with attention have become standard in various NLP tasks, the detailed description of the attention-based bidirectional LSTM may be unnecessary.\n\n5. The \"baseline\" presented in Section 3 is integral to the model, as it generates inputs for it. Referring to it as a baseline could undermine the paper's clarity.\n\n6. The reported results stem from a 5-fold cross-validation. However, numerous hyperparameters necessitate optimization (e.g., number of filters and filter sizes for CNNs). The authors should clarify their optimization process for these values. Reporting results from cross-validation does not facilitate fair hyperparameter optimization, raising concerns about either not optimizing at all or potentially optimizing on the test set.\n\n7. The statement regarding non-applicable values (e.g., PRu, PSu, U+/-) suggests that underspecification in only one dimension (polarity or certainty) is not an option. An example could easily illustrate a situation where the event is negative, but the certainty about its absence remains unspecified across different modalities.\n\n**Language & Style Improvements:**\n\n1. \"to a great degree\" should be revised to \"to a great extent\" or \"to a large degree.\"\n2. \"events that can not\" should be corrected to \"events that cannot\" or \"events that do not.\"\n3. The phrase \"describes our networks...in details shown in Figure 3\" should be improved to \"describes our networks as shown in Figure 3 in detail.\" ",
            "GPTZero": "100;0;0"
        }
    ]
}